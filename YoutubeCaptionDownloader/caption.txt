With the all the information that you are
being bombarded with when auditing, testing,
reverse engineer and so forth, it’s important
AND natural to look out for patterns.
For example a lot of web applications encode
data in base64.
Sometimes in cookies, sometimes in APIs.
And one thing I immediately notice in base64
strings is “ey!”
Look at this string.
Does it tell you anything?
Well maybe you already can recognise that
it is base64 without having to attempt to
decode it, but anything besides that?
Anything about the data it encodes?
Without having to do a base64 decoding I KNOW
this is going to be JSON data.
You see, JSON starts with a curly brace and
a quote, and that results in e, y
And being able to see that saves time, and
allows you to quickly find interesting data.
Same with debugging binary exploitation challenges.
When you look at a hex memory dump, it is
very overwhelming when you start out.
So many different values.
But eventually you start to learn to see here
patterns.
That is a stack address, I know that because
it’s very similar to the stack pointer and
something you see a lot when doing this stuff.
But also here this fairly random looking data,
I don’t even have to decode values from
it, to see what it is, it is clearly ASCII.
These bytes are in the ascii range.
You can generally see that based of the first
nibble.
Ascii really only goes from around 2-something
to 7-something.
20 is a space.
You might also see soem null bytes and obviously
A or D also for new lines but most characters
are in this area.
So over time your brain develops this intuition
to quickly judge if most of these values look
like ascii.
And so looking for and learning patterns like
this will help you to be much more efficient
when researching something.
﻿This post caught my attention.
A reddit user posted pictures of a mysterious
raspberry pi zero.
He wrote that his roommate found a bunch of
these hidden behind desks, vending machines
and trashcans in the college library.
Some people were speculating: a wifi dongle
attached and used to intercept internet traffic...
Looks like a pi he was using it as a rogue
access point to do a man-in-the-middle attack.
YEP. definitely
So I reached out to them and offered my help
to figure out what it does.
And to my surprise, they were interested and
we hopped onto a Skype call.
So in this video I want to tell you the process
of us analysing this raspberry pi zero and
how we figured out what it does.
Before I joined this fun, they already took
the SD card out of the raspberry pi and plugged
it into a PC.
This caused an F: drive to show up.
It’s called boot and contains some weird
files that can be really confusing.
they first thought it’s encrypted stuff,
But they quickly realized that maybe windows
is not the best operating system to look at
this.
Actually when you open the Windows Disk management
utility, you can see that the F drive is only
one partition on this whole removable disk.
And there are 3.6GB in another partition.
But Windows didn’t mount this.
Windows only automatically mounted, and made
the filesystem accessible for the first partition
called boot.
That filesystem was FAT32.
The File Allocation Table (FAT) is a computer
file system.
The FAT file system is a [...] , legacy file
system and proves to be simple and robust.
If you're a windows user you definitely have
seen FAT before.
It’s very simple and very old, so a lot
of systems support that.
And so it’s used for the boot partition
of the raspberry pi.
Also google is your best friend, if you are
confused by those files here, you can simply
pick one and google it.
You will immediately find this repository
with that file, and it looks exactly like
that partition.
And as you can see this is part of the official
raspberrypi firmware repository.
This repository contains pre-compiled binaries
of the current Raspberry Pi kernel and modules,
userspace libraries, and bootloader/GPU firmware.
Because we are looking here for whatever this
raspberry pi does, these files are mostly
uninteresting.
They are just part of the raspberry pi system
and we can ignore them.
However when you are very careful you might
notice that there is one weird file.
Waitz.txt.
And it contains the wifi and bluetooth mac
address.
We didn’t know what to make from it, just
keep that name in the back of your mind, it
will come up again.
So our goal was it to look at the second partition.
And the issue why Windows can’t mount it
is, because it’s very likely a typical linux
filesystem like ext4.
The ext4 or fourth extended filesystem is
a journaling file system for Linux, developed
as the successor to ext3.
And Windows just doesn’t have filesystem
drivers to understand that filesystem.
Those bits and bytes on there just don’t
make sense for Windows.
Because I was in a skype call with this guy,
we first tried to make this work on his windows
machine.
And we found and downloaded a program called
ext2fsd, hoping it would allow windows to
mount it, but it later said that it can’t
process ext4.
So that didn’t work.
Of course we were also thinking about different
options.
Either we try to create an image of the sd
card, and upload it so I can have a look at
it on a linux machine, or he could install
a linux virtual machine.
Before we install a full VM, we tried the
windows linux subsystem, where you get kinda
like a ubunut VM inside of windows and I thought
that could then just mount it.
Then we thought about using dd in linux to
create an image.
But nope.
The drives are not exposed and accessible
from in there…
This was all so frustrating… okay… so
I guess we have to download a tool for windows
to create an image of the sd card.
I did a quick google search for windows dd
alternatives and I found this image burner
tool.
Hoping it could just create a damn image from
the card.
And now something very embarrassing happened.
So… when downloading that tool we made sure
to use the site’s own mirror, so we don’t
get malware bundled software from these shady
mirrors, and when he installs it, this happened…
next next next.
Installed.
Then we execute it…
Search Manager added… uhmmmm…… ooooops...
this doesn’t look good….
Virus threat protection.
Doing a quick scan… and…
1 Threats found.
Cleaning that up… hopefully…
We are so dumb…
I’m such an idiot… later during editing
I actually noticed that we just cliked next
next next when the installer asked if we want
to install that crapware.
I feel so embarrassed.
I’m supposed to be a security professional
here, and I just made some computer science
student install some malware…
And even I fall for these shitty tools once
in a while out of frustration…
I’m so sorry that I did that to your laptop…
And it turns out this tool is crap and can’t
create an image from the disk… goddamit…
Then I had some other idea… maybe the git
bash comes with dd???
I remember that git for windows comes with
a nice bash terminal where you get a lot of
linux tools… so I made him install that
and to my surprise, it does list the drives
in /dev as sda, sdb and so forth…
And it also has dd… awesome!!
dd is a command-line utility for Unix and
Unix-like operating systems whose primary
purpose is to convert and copy files.
But here comes the cool things.
On Unix, device drivers for hardware (such
as hard disk drives) [...] appear in the file
system just like normal files; thus dd can
also read and/or write from/to these files.
As a result, dd can be used for tasks such
as backing up the boot sector of a hard drive.
I link an older video from me where I talk
a bit more about linux files as well.
But what this means is we can now use dd,
and then specify the correct device drive,
in our case sdc as in file… so sdc is the
whole drive, and sdc1 and sdc2 are the two
single partitions.
But let’s take an image of the whole card.
the input file, IF, is the sdc drive.
And as out file, OF, we can write a sd.img
file somewhere.
And then he uplaoded it for me and then I
downlaoded it.
All of that took a while because it’s a
full like 7GB image of the whole disk.
Anyway… so here I have it now on my linux.
The first thing I did was using fdisk.
For computer file systems, fdisk is a command-line
utility that provides disk partitioning functions.
As we know the SD card contains two partitions,
so fdisk can help us understand the raw bits
and bytes of that sd.image file to understand
the partitions.
And it finds two.
It also specifies at what exact sectors inside
of the sd.img this particular partition starts
and ends… a sector is simply a unit of 512
bytes. and now you can also understand why
you can’t easily move or insert partitions
in front of another, because they are at fixed
places in there on that disk.
At exactly this offset.
So now we are going to mount that second filesystem.
To do this we have to find the byte offset,
so we can take the sector offset from fdisk
times the sector size in bytes and this is
it.
Then we use the mount command to create a
loop device from this particular sd.image’s
byte offset…
A loop device is like a virtual or pseudo
device that doesn’t physically exist.
We could also write that partition onto a
real disk, like a usb stick and then plug
it in and mount it, or we use that loop feature.
And we tell the mount command to mount it
into the folder partition2.
So now it will take the sd.img file and understands
it as if it was a disk that was just plugged
in.
And ubuntu automatically noticed that a new
file system got mounted and opens the file
explorer of that device… see here, the device
now shows up as rootfs… the name of that
partition was root filesystem.
When we look at these folder, we can already
tell that this is a typical linux filesystem.
Here are well known folders like bin, dev,
etc, home, lib, media, mnt, opt and so forth…
We also can immediately see a tshark.txt file…
TShark is a network protocol analyzer like
wireshark, just as commandline tool… sooo…
were the people right?
Does this try to sniff and man-in-the-middle
WIFI connections?
Is this a malicious device?
So now we need to find out how it works.
This is actually just a bit of boring detective
work.
We have here a linux system and we have to
look for programs that could run here…
But like with the boot partition, here experience
really helps.
If you know how a typical linux filesystem
looks like, you can just ignore that stuff
and directly look for non-typical files.
And looking at locations where a developer
might have placed the programs that are executed
on here.
You could also directly look for scripts and
config files that determine what will be automatically
executed on start.
All this is just experience you acquire over
time if you work on linux.
So I start with the home folder.
When you login as a user, this is your default
folder, so maybe important or interesting
files are located there.
And we can then immediatly find a clean.sh
script.
That is definetly not a standard linux file.
And here we can see a systemctl call to stop
the waitz service.
You remember that name, right?
So there is a systemd service called waitz
running.
There are also other intersting paths here
which are definetly worth investigating too.
But before we moved on, we thought that waitz
is maybe the person’s nickname.
So we did a quick google search for things
like a potential github profile, but no luck.
Now that we know there is a service called
waitz, and waitz appears to be an important
string, we can search for files and folders
with that name…
And this reveals that there is a folder in
home/pi/hubCode/bin/com/waitz… and there
are java classes in here… so com.waitz.hub.scanning
blah are typical java paths.
This is a java program.
And look at those class names…
CommandListener, NetworkThread, Channel Hopper,
WifiData, WifiPacket, BluetoothPacket, BluetoothReader,
SHELL COMMAND THREAD?
Whow… okay…
At this point I was wondering if hubCode is
maybe a known tool that people use.
So we can google for names and snippets like
that, and search on github directly, but nothing
shows up.
So then the detective work continues.
Let’s look at some of these files here…
the state.txt turned out to be itnersting.
There is a wifiCmd specified with a tcpdump,
so a packet reading dump of the wlan1 interface…
there is also a flood 1 config and maybe some
bt, bluetooth settings… mhmhhm… really
suspicious.
here we also found the systemd waitz service
configuration file.
systemd will use this config file to automatically
start the service described in here… the
name is Waitz MQTT Service…
huh??
I know MQTT, it’s a machine-to-machine connectivity
protocol.
It was designed as an extremely lightweight
publish/subscribe messaging transport.
It is useful for connections with remote locations.
For example, it has been used in sensors communicating
[...] and in a range of home automation and
small device scenarios..
It kinda would make sense because the person
said that there were multiple raspberry pies
scattered around the library, hidden in various
places.
And so maybe MQTT is used to create a distributed
network of wifi and bluetooth things… for
whatever purpose?!
Well..
We can also learn from the systemd service
config here, that the following script is
executed on start.
Service.sh…
And in there are a few interesting comments…
get device information, download bundle.
Unzipping bundle… blah… looks like an
update mechanism…
And then when that is done it will call the
hubCode scripts, start.sh.
And look at that one… this prints “starting
waitz service script”.
It will make sure the system has tshark installed.
Then it will call tshark on the wlan1 interface.
And it also seems to get some broker credentials…
broker is a term from MQTT, so this again
reinforces that MQTT is infact used here.
And then later the java application is executed…
the waitz.hub.production program and it even
sets include path for a mqtt library… so
yep okay, there is some mqtt communication
going on.
We can also have a look at the getcreds python
script, because credentials are always cool.
And it will use this amazon API to get them.
But to do so you need to know those parameters
sent along that request.
And in the gen_token module we should be able
to find those parameters.
And that module will actually execute a shell
script called fingerprint.sh and take the
output as a secret, and then calculate like
a secret token… crc32 of the secret + the
current time…
Okay… my code audit inner-self is screaming
loud right now.
Because I see what they try to do here.
But they use crc32 with a secret concatenated
to the time t.
My chest hurts…
They actually want to use HMAC instead…
but in the end it doesn’t matter too much,
because while the fingerprint is like a unique
hardware ID based on the bluetooth mac, the
wifi mac and the pi serial number, this is
not perfect.
Anybody with access to such a raspberry pi
can easily extract or possibly even guess
those values, because none of these are really
random.
So becasue anybody with physical access can
always extract those tokens, I suggest to
just use preshared secret unique to each device,
like an API token.
It can be compromised but you can then also
revoke access for that particular api token.
This little bit of obfuscation here is useless
for anybody who actually wants to do harm
and figure out the secret… it just takes
like 1minute longer to get it, but adds unecessary
development complexity…
You actually can’t do this better with a
raspberry pi.
It’s not a secure hardware device.
Anyway… we were going basically slowly through
all scripts and codes… at some point even
used JD-gui to look at the java classes to
understand what they are doing.
I mean at this point it’s just like reading
code of any programming project.
It’s just like a code audit or getting familiar
with a new project.
You just have to know how to read code and
how software projects might be structured
and deployed.
Our main goal was to determine if this is
a malicious actor who wanted to attack or
sniff wifi of students in the library, or
if this is a harmless school project…
So we spent maybe 1 or 2 hours on looking
around, reading those files and slowly assemble
the mysterious puzzles of “what this is”.
So fast forward a bit.
We slowly realized that it doesn’t do much.
It does not collect any packet data or trying
to sniff passwords or whatever.
Actually it just logs MAC addresses that it
finds from bluetooth and wifi devices in the
area…
This is to 99% just to track people…
This is a very typical application.
Probably every public place you go has stuff
like that.
Probably most shopping malls or airports do
that… it helps to autoamtically record how
busy areas are and how people are moving through
a building.
This is very valuable data for businesses…
they don’t care about the individual person,
it’s just to understand the flow of people.
So this is probably doing a similar thing...
One other thing we did was, We knew the raspberry
pi zero has bluetooth and the wifi dongle
is actually dual band and offers two wifi
interfaces.
So if it is monitoring bluetooth and wifi
in the area, it probably would use the second
wifi to connect to the school’s wifi to
use MQTT and send away the data.
So we thought it would be interesting to find
the username and password they are using to
connect to the wifi.
So I can easily search for that in files on
the raspberry pi. he told me the name of the
school and the name of the school’s wifi.
He is from UCSD… and like I often do, I
google stuff… and for whatever reason I
decided to google “waitz ucsd”,l to see
if there is any connection… and this reddit
thread pops up…
UCSD - the name of the school - Waitz.
Did they stop supporting the app?
Now listen to this beautiful reaction.
Oh wowowowo… what?!
And we find this website…
Is this it?!
What does Waitz do??
Waitz reports the real-time "busyness" for
locations around campus.
How does waitz work?
Waitz gathers our data through small hardware
devices.
These devices pick up smartphone signals in
the area around them.
We then normalize these signals to reach a
"busyness" measurement.
Don't waste time
Know before you go
So this was just part of a network to give
students indication how busy certain areas
at the school are… actually that’s a really
cool and useful project… but Oh man…
Oh my god!
Hahahahah… you found it…
I guess I contact them and and say I found
one of their cthings…
And you know what makes the whole story even
more beautiful?
There was actually a comment 9h before we
figured it out, on the original thread on
reddit.
Please return this to the Library, this is
the property of Waitz, it isn’t nefarious,
it is extremely basic and giving you an idea
of how many people are in the library.
Waitz was started by a recent graduate who
did this as a project while enrolled at the
university.
This was so much fun...
﻿Remember the boss Magmarok in the Fire and
Ice dungeon?
It’s part of another quest, or flag, that
we still need to get.
Magmarok shoots fireballs and and when he
gets below half of his health, he will heal
himself up.
Here is a clip from the let’s play episode:
Ok, let’s try this again.
Yeah, that’s easy!
Eeeezy!
Easy, look at this skills I have.
This movement.
Oh shit what is he doing now?
He healed.
He healed.
So how can we defeat him?
Like I mentioned previously, the motivation
for me to make this series came from Antonin
Beaujeant asking me originally, to make videos
about Pwn Adventure 3 and he shared his workshop
slides covering Pwn Adventure 3 with me.
However this CTF has always been something
I wanted to do myself.
So he was a huge help and was of course the
spark to motivate me to finally do it.
And that means I didn’t want any spoilers,
but he did spoil me a little bit.
In his very first message to me, he suggested
that I could make a video about the “double
integer overflow to kill the boss”.
Dun dun duuun.
So anyway, I knew that we had to kill Magmarok
with one or two Integer Overflows, and I’m
not going to pretend I didn’t know that
and make up a story how I figured it out myself.
Nevertheless I think it’s still interesting
to actually find it.
It happens sometimes that you hear, a software
has a certain bug, but no technical details
are known yet, so you have to find it yourself.
And that’s what I tried to do.
The past few videos were about reverse engineering
the network protocol, developing our proxy
and parsing packets.
And I will be using that heavily here.
I added again a few more packets to the parser
off camera.
one new packet in particular is very important
here, and that is the “update health”
packet.
It’s a simple packet, it is sent from the
server to the client and comes with a health
value and an ID to identify who’s health
it is.
You might discover this packet when you get
damaged and slowly regenerate.
But you also get the health value of the monsters
that you damage.
While implementing this I first defined the
health to be an unsigned integer, indicated
by capital I when unpacking the binary data.
Though when I killed a spider I noticed that
the health suddenly is extremely large, and
that doesn’t make sense.
So this means we interpreted the binary data
wrong.
In fact this tells me this is supposed to
be a signed integer.
Unsigned integers are just positive numbers,
while signed integers means that certain binary
values are interpreted as negative numbers.
And changing the parsing to a lower-case i
shows us now a nice negative value for when
we kill the spider.
So we keep in mind, that the health is a signed
value.
I don’t want to explain here in detail again
how signed and unsigned numbers work, so I
created a short bonus episode for those of
you who need some additional information.
But with this knowledge we can put together
a plan to find this mysterious integer overflow.
We are looking for where unsigned and signed
numbers are somehow carelessly mixed together.
In assembler this means we are looking for
signed and unsigned operations.
In the bonus video I have shown you, that
addition works perfectly fine with signed
and unsigned values.
So that wouldn’t be a difference in assembler.
The difference is in how we interpret this
data.
And one such interpretation happens with comparisons.
Because with signed values a -1 is smaller
than a 1.
But the equivalent unsigned value a 0xFFFFFFFF,
4.2 billions is much larger than a 1.
And in x86 assembly we have different instructions
for that.
For example for a signed comparison we would
do JLE, jump if less or equal, while with
unsigned values we would do JBE, Jump if below
or equal.
So greater and less than, are signed interpretations
of data, while above and below is the unsigned
intepretation.
And that helps us now with our plan.
We essentially look for where a signed value
like the health, is handled with an unsigned
instruction like below or above.
Or the other way around, we take an unsigned
value and compare it with less or greater
instructions.
So a good start to look, is the damage function
for Magmarok.
Because in the end, dealing damage to Magmarok
is the only way how we as a player can interact
with him.
Or in more abstract terms, that is the only
input we can give to the Magmarok “program”.
This function takes an Actor, an Item, the
amount of damage and the damage type as parameter.
We can control the damage and type of damage
based on the weapon or spell we use.
From our time debugging the game with gdb,
or from the enums IDA recognized we know that
there is PhysicalDamage, FireDamage, ColdDamage
and ShockDamage.
If we compare a little bit how IDA and Binary
Ninja disassemble the Damage function, we
can see that IDA displays a bit more information.
In fact it names certain variables it was
able to get from the debug information embedded
in the binary.
But we can do some of this by hand in Binary
Ninja as well.
You see that it shows the types of the parameters
here, but didn’t set the type or name of
the parameters.
So we know arg1 is the this pointer, pointing
to the Magmarok object itself, this is an
actor, probably our player, an item, and damage
and damage type.
And we can also see here based on the calling
convention which parameters corresponds to
which register and thus we know what kind
of local variables are set here from the parameters.
But if we compare that now to IDA, we realize
that something is not right.
IDA said that the type would come from rsi,
while we thought r8 is the source.
So what is true now?
Well if you would blindly rely on IDA now,
you would have a hard time understanding what’s
going on.
But this is only true for the IDA 64 free
version.
I don’t know if it was a bug, or if this
analysis is only a feature from more advanced
plugins in the Pro version, but when I ask
my friend to open it in a recent version,
then IDA Pro does it correct.
So the point of this story is, I rarely rely
on one tool, I don’t understand IDA, or
any other tool, well enough, to be able to
figure out issues like this.
I’m sure a professional reverse engineer
has no issues with that.
But I like to compare the output from Binary
ninja, IDA, Hopper, radare and whatever.
It helps me to understand the stuff better.
Anyway.
Let’s have a closer look.
First we compare the damage type to 1.
If it was not equal to 1, we go over here.
So if it’s not fire damage, because that
is type 1.
Then we check if it’s cold damage, type
2.
If it’s equal, we would go down here, but
if it’s not equal, so any other kind of
damage, we load a 2 into eax, move it into
this address here, load the damage amount
into ecx, load the 2 again down here and then
perform a division.
So we divide the damage by two.
However, if the damage was fire damage.
We go into this crazy block.
And xmm registers usually means there are
some floating point calculations.
And there is a pow float function, so it takes
some value to the power of, something?
Reading this forward is always a bit ugly,
but we can also backtrace.
So after all of this, the damage is set from
eax.
And eax comes from this variable, but is subtracted
from 0.
So this makes it negative.
This means the damage value that was calculated
is actually more like a healing value.
Negative damage is healing.
So let’s rename it to healing.
And healing could be set in this block to
whatever is in this unknown variable.
But healing is only set here, if the condition
before is false.
And it compares here the healing to that unknown
value.
So if this unknown value is smaller than the
healing, then healing is set to that value.
Which means there is a cap on the amount of
healing that is calculated.
So doing healing larger than that value is
not allowed.
And don’t forget, we are hunting for an
integer overflow, so we need to pay attention
to these comparisons and here, we have JBE,
which is an unsigned comparison.
And this unkown value is the result of a subtraction
from a fixed value, 0x2710, which is 10.000
in decimal.
And it’s subtracting a value stored at the
offset 0x38 from rax.
And rax is this.
This is a pointer to the current Magmarok
object, so taking an offset from that address
means we are referring to an attribute of
Magmarok.
Let’s investigate this with gdb.
First we need to set a breakpoint somewhere
in this function.
As this is an external library, we can’t
simply copy the address here, but gdb knows
the symbols and addresses so we can just disassemble
the Magmarok Damage function and also set
a breakpoint there.
Now we just have to walk up to Magmarok and
shoot with something at him, to trigger the
damage function, and we hit the breakpoint.
Let’s walk a few steps forward so the function
prologue is done.
And then print this.
So you can see that this is a pointer to a
Magmarok object.
And by dereferencing the pointer when printing,
we can also print the whole object.
Including the attributes coming from inherited
classes such as actor.
So for example Magmarok has 10.000 health!
Or he has an attribute if healing is active.
And we know he can heal himself.
With gdb we can also now learn more about
the offsets.
For example we can get the address of where
m_health is stored, and calculate the offset
from where Magmarok starts.
Which turns out to be 0x38.
And the healing_active attribute at offset
0x148.
I have chosen those two because they will
be important, but of course you could map
out all of them like that.
And that is super useful for reversing with
a disassembler.
We now head to the structures in Binary Ninja
and create new one, that we call Magmarok.
And let’s give it some size, like 0x150,
so we can fit both attributes we know in there.
Now we don’t know the other fields, but
we know that at offset 0x38 we have an integer
health and at 0x148 we have a bool for healing
active.
Then we can go back to our damage function
and change the type from the default integer
that was set for this to a Magmarok pointer.
And now, look!
The pointer was automatically resolved and
Binary Ninja can tell us now that this is
an offset to the health!
Cool, right?
So defining structures once you learn more
about what stuff means, is part of reversing,
like renaming functions and variables and
so forth.
You slowly build up the whole picture.
Now we know, the current health of Magmarok
is subtracted from 10.000.
So our unknown value could be called, health_difference.
It’s the difference between the full health
and where Magmarok currently is at.
So if the health_difference is smaller than
the healing we wanted to do, then the healing
is capped at the difference.
Let’s do an example, if Magmarok has 9800
health, then the difference is 200.
And when we try to heal for 500 health points,
then that would be larger than 200 and the
healing would be capped, set to that value.
So we can’t heal more than up to 10000.
Now remember, here we have an unsigned comparison
on the result of a hardcoded 10.000 minus
the current health of Magmarok.
And subtraction is always very tricky.
There is no check if the health is larger
than 10.000.
So this unsigned comparison could really screw
up, if the health of Magmarok were larger
than 10000.
For example if the health were 15.000, then
subtracting 15.000 from 10.000 would result
in -5000 if interpreted as a signed value,
but -5000 is a huuuge value if interpreted
as unsigned.
And so this unsigned check, jbe would interpret
the result as 0xFFFFEC78, or 2.5 billion.
So if we now would try to heal for 500 HP,
then the check would say, no 2.5billion is
not smaller than what we try to heal.
So we don’t cap and allow to heal.
If this would have been a signed check, so
JLE, jump if less or equal, then yeah,it would
be interpreted as -5000, which would be smaller
than the 500 we try to heal.
So… this thing here could be unsafe, if
we somehow can get the health of Magmarok
higher than 10.000.
If its not higher than 10.000, then the subtraction
would not overflow the integer and apply a
cap to the healing.
So while we can heal Magmarok with fireballs,
this check will always prevent us to heal
higher than 10.000.
So it’s kind of like a chicken and egg problem,
right?
If the health would be higher than 10k, we
could heal him even higher, but if the health
is below or equal to 10.000, we can only heal
him up to 10k.
But theoretically.
We know that the health is a signed integer.
We know that from killing spiders that had
a negative health.
So if we can keep healing magmarok so high,
that the value doesn’t fit in the 32bit
signed integer anymore, it overflows and wraps
around to a negative value.
Then Magmarok would be instantly dead!
Hmmhmh…
But the problem is, by itself, this function
here is safe.
We can’t heal over 10k.
But we know, that Magmarok can also heal himself.
So there is a second logic somewhere that
manipulates Magamarok’s health.
So if we somehow can abuse that to get over
10.000 health, then we have a clear path laid
out to kill Magmarok.
So now we have to find that.
A good way to start is just by looking at
the other Magmarok functions.
And the tick() is a function that is constantly
called.
It’s a tick, like on a clock.
This function exists for a lot of objects
so they can update their behaviour according
to the game time.
So if Magmarok would do something, it most
likely would originate from in here.
Like with any object function, the first parameter,
is the this pointer.
This parameter points to the current Magmarok
Object and it is passed in via rdi.
And so here we can see that rdi is used a
few times..
So we can change all their types to a Magmarok
pointer.
And we can already see, that here it checks
if the healing is active, and the health is
referenced multiple times as well.
Now if the healing is 1, so true, active,
we check if the health is less or equal to
0.
Basically checking if Magmarok is still alive.
And as you know, this is a signed comparison.
So a negative health would be interpreted
here properly.
Then we check if Magmarok’s health is greater
than or equal to 5000.
Which we know is the trigger for the healing.
When we got him to 50% health he initiating
his healing sequence.
So if healing is not active, he is not dead
and health is under 5000, he will switch into
healing mode.
At least that’s what I guess.
I haven’t really reversed how these states
work in this game, I just see something is
referenced here and it would make sense.
But we are looking for where the health is
modified, so let’s look for something that
sets or modifies the health.
I really wish we could look for cross-references
to the health attribute.
Anyway, here is one example.
The health is moved into ecx, then we add
0x136f to it, that’s 4975 in decimal, and
the result of the addition is moved into the
health.
So…
We know that there is a delay between Magmarok
going into healing, where he does this animation,
and then actually healing up…
Do you see the issue?
There is a race condition here.
A time of check time of use kind of thing.
The decision if Magmarok is going to heal
is decided when he falls under 5.000 HP, but
then the actual healing, happens later.
And the healing is not just setting the health
back to 10k, it’s actually adding 4975 to
the health.
This means, we can push Magmarok over 10.000
health.
We just have to kick him into healing mode
by damaging him.
And as soon as he falls under 5.000, and he
decided he is going to heal, but first has
to cast his spell and the animation starts,
we quickly switch to fireballs to heal him
back up over 5025 health.
Because then a few seconds later his healing
spell succeeds and heals him for 4975 HP,
which then pushes him over 10k.
And by pushing him over 10k, we know we can
bypass this healing cap and keep healing him
with fireballs.
And that could maybe kill him, because healing
too much can cause an integer overflow of
his health, making his health suddenly negative
and thus instantly killing him.
To pull that off I modify the network proxy
a bit.
I shoot TheGreatBallsOfFire and ZeroCool straight
down.
And collect those packets.
Both of these packets cause the magic spell
being shot straight down.
We also know the position of Magmarok from
the actors list.
So what we can do is, we can craft a position
update packet, and tell the server we are
standing above Magmarok, by setting a higher
Z value than him, and then we send the shoot
packet.
And because we never actually moved there,
the client will keep sending the real position
updates.
This means the server thinks we are always
teleporting above Magmarok, shoot a spell,
and teleport back behind the safe chest.
I was thinking about how to trigger this for
the game, and I decided to place the creation
and injection of these packets into the sneaking
parser, so when we press down the sneak button,
this packet is sent to the server, we parse
it here and maybe decide to inject these two
packets into the traffic.
And this makes fire balls or ice balls rain
onto Magmarok.
Cool huh!
We basically invented a new spell.
A meteor shower.
So all we have to do now is carefully damage
him with cold spells or other attacks and
observe his health.
Once we get close to 5000 we have to be careful.
Okay.
Now a bit of damage is missing.
Now I take it slow.
I exchange the Zero Cool spell with the GreatBallsOfFire
spell.
So presing sneak now will cast a fireball
on him that will also heal him.
Then I switch to a pistol with low damage,
shoot him with it, and this pushes him under
5000 HP and initiate his healing sequence.
now we have a couple of seconds time to heal
him above the threshold with some fireballs
by pressing sneak.
Healing is coming!
Okay, we were successful.
His healing spell is over, he healed up and
his health is above 10k.
Now we just have to keep healing him, and
that should eventually kill him.
See how he sometimes shoots up?
That’s because even though we stand here,
we tell the server we are actually above him
to shoot a fireball.
So for a split second Magmarok thinks we are
there.
But when we keep doing this, and you can see
here the signed and unsigned raw byte values
as a comparison, at some point his health
will overflow and kill him!
Quest: Complete, Fire and Ice.
Let’s loot the chest.
Acquired flag of the Lava.
Some bosses just roll over and die.
﻿It is time to get serious.
Reverse Engineering isn’t about toys and
games.
Sometimes it’s about malicious software.
I recommend you run this next challenge in
a VM or someone else’s computer you have
gained access to, especially if they are a
Firefox user.
Okay, this time I needed to get a VM.
And I saw that they also offer this Flare
VM which is like the Kali Linux of Windows
Malware Analysis.
And because I have no clue, I go with that.
For this I used a free Windows Test VM and
then executed the Flare installer to install
all tools.
The challenge description is hinting at malicious
software and itt may target Firefox?
So I also install firefox.
And then we can get started
Before we head into it, I have to say again.
I have very little experience with windows.
I would say about myself, that “I have no
clue what I am doing”.
Of course that is not completly true.
You can’t go a few years in this field without
picking up some knowledge over time.
Actually my very first introduction into reverse
engineering and exploitation WAS with windows,
namely a friend who introduced me to game
cracking with olly debugger and then the corelan
and lena tutorials.
And generally by having a more abstract computer
science knowledge and a basic understanding
of how computers work, I don’t feel completely
lost.
I have a rough idea what I want to do, and
I can somehow figure it out.
I just very much lack detailed technical knowledge
and experience.
for example I have very limited knowledge
about the windows APIs.
And I only know a FEW popular TOOLS.
And so I will be a lot more inefficient and
my approach is a lot less structured than
usual.
But let’s learn together and share your
tips in the comments.
So here we have the binary.
If you forgot to turn off windows defender,
then windows will actually detect it as malware
and then remove it.
So make sure to deal with that.
Because I’m unsure how to approach this
I decided to throw it into virus total.
Of course somebody else did that before.
But I’m not really interested in what tool
flagged this as malware, I was actually interested
in the file details tab.
That one provides a good first quick overview
over the binary, without executing it yourself.
So binstall is a browser assitant installer,
which would match with the firefox hint in
the description.
And it appears to be .net, so maybe another
c# program?
We can also go on the comments tab where other
plattform analysis tools posted their results.
For example we can checkout the joe sandbox
result.
That service appears to run the binary and
record what it does.
It also labeled it malicious.
And here are some great first hints.
It creates an undocumented autostart registry
key.
And it drops a PE file.
PE file is a regular windows binary file.
And you can see it drops a browserassist.dll.
But into the Internet Explorer folder?
Not firefox?
Mhmh..
There is a lot more nice information there,
but let’s move into our own VM.
So Flare installed a lot of tools in various
folders.
Disassemblers, debuggers, decompilers and
other utility tools.
One of the first tools that were ever showed
to me wa PEID, so I use that again.
It’s a tool to detect what kind of binary
it is.
And for binstall it detects that it’s a
C# .net binary.
Extra information will also show some guesses,
that the binary might be packed, so parts
of it might be encrypted.
Because it’s C# we can also trhow it into
IlSpy again, but you can quickly see it got
obfuscated.
So while all the names are gone, you can still
click on them and follow their references,
but also the functions them selve appear to
implement decryption or deobfuscation routines.
So not something we want to really analyse
if we don’t have to.
And we know it drops a .dll anyway, so it’s
probably also not important.
Nontheless I was playing around a bit with
it a bit.
And so I used Process Monitor to monitor all
events on the system as well as checking out
API monitor to monitor all calls.
So when running binstall we can then use the
filters or the search in Process monitor to
hopefully find interesting things it did.
Like accessing the registry or creating a
file.
And so after a bit of digging we can also
discover here the dropped dll location.
I also tried API monitor and selected a few
possibly itnersting APIs such as file system
or networking stuff.
And then I wanted to launch and attach to
the binstall .exe.
But it didn’t really work and crashed.
But trying out different attach methods I
found one that works.
And so API monitor recorded all the Windows
APIs that binstall was using and we selected
to trace.
And also here with a bit of digging we can
find the file it creates.
The browserassist.dll.
With peid we can also investigate the dropped
dll.
And this one looks like a regular binary.
So not C#.
And the extra information checks also think
that it doesn’t look encrypted.
Great.
We can also throw it into the ida free version
here and check a bit the strings.
Here are references to typical HTTP header
values.
Content-type, encoding, POST, GET and so forth.
So again it makes sense that it does something
with the browser.
Now I was confused why the dll was dropped
into the internet explorer folder, so I actually
thought maybe it does infect IE.
And when I opened the internet explorer, I
noticed this weird smiley face.
Send a smile, send a frown?
Did the malware inject that?
That’s funny.
Mhmh.. it appears to fake a Internet Explored
feedback form.
That’s quite interesting.
Let’s have a quick look at the privacy statement.
Mhmh… that looks like the normal microsoft
privacy statement?
Ehhmmm….
Oh… whaaat?
This is not the challenge?
This is actually in the Internet Explorer?
Let’s pretend this didn’t happen.
We move on.
Now in the meantime it was kinda hard to avoid
spoilers on reddit and twitter becasue people
talked about the challenges publicly.
SHAME YOU!
Just kidding, I think it’s great that you
help eachother.
And somewhere I read that you should use an
older firefox version, something like firefox
version 40, so that’s why I also downloaded
that one.
In that moment I was kinda annoyed that it
would only work with older firefox versions
and was wondering how you could even figure
that out.
Anyway… so I opened the old firefox version
and now I was wondering what to do.
There didn’t appear to be anything obviously
different, but it’s a malware right?
So it would do something a bit more sneaky.
Next I thought I could try to trace calls
to the browserassist.dll in case firefox does
anything with it.
You can add external dlls to the API monitor,
but it says that it doesn’t export any functions.
So the .dll appears to not work like a typical
.dll with exported functions… mhmh… next
I decided to attach the x32 debugger to firefox.
And I wasn’t really sure how to approach
it, but I thought a good start would be to
see if the dll is loaded somewhere in memory,
so I checked the Memory Map tab and also found
it in there.
Over her eyou also se a description of the
different segments, but for the debugger the
text segment, the code is obviously the most
interesting.
This lead me to this area here.
So that’s kinda like the entry point of
the dll, I guess.
And because I didn’t know what it does I
simply set a breakpiint at the start and end
of it.
But it didn’t trigger right away when using
the browser, only when I restarted it.
And while pressing the button to continue
execution after that breakpoint, I noticed
that this code was executed quite a lot on
load.
And I happen to notice some ascii strings
being referenced at some point earlier on
the stack.
This is the stack view here.
That’s just memory that’s still around.
For example I saw an injects and content string.
So while I kept doing this continue break
continue break thing, and looking at the stack,
eventually I noticed this json data…
Code, addCmd.
After.
askPassword.
Ont he path js/view.js?
On the host *flare-on.com?
What?
That looks like a filter.
It applies to all flare-on.com domains, includign
subdomains.
And js/views.js is obviously a javascript
file.
So I went into the browser, went to flare-on.com
where we had this simple command line interface,
opened js/views.js and noticed some very suspicious
javascript.
I mean that looks very obfuscated.
So I opened up the same javascript file on
my regular host chrome browser and compared
it.
And holy cat.
Look at the difference.
The malware in firefox appears to have injected
javascript into this script.
In theory this could be now injecting ads
or a script to steal your credit car dinfo
or so.
But this challenge apparently added an askPassword
function.
So clearly this comamndline interface was
extended with some functionality, but what
exactly?
I just randomly tried some stuff but it didn’t
work.
But askPassword is a javascript function,
so we can open the developer tools and just
directly call it.
Now the function itself was defined inside
of com.fireye.flareon.view.
So here is the function.
When we call it, we see that we are now asked
to enter a password.
And when we enter something, we get a su,
authentication failure… ahhh..
So su is the secret command.
Switch user.
So now we need to find the password.
By looking around the other javascript files
I noticed a controller.js which also had additional
code injected.
A cp function which seems to be called when
the password is Entered.
We can also set a breakpoint in cp, then trgger
su and enter a password.
And here we go.
So we see that p in this case is the password
we entered.
The first check is if the length is 10.
So we know the password must be 10 characters
long.
And then we check the first character.
The first character xored with 16 must result
in 123.
Because it’s xor, we can simply xor 123
with 16, and the result will be the first
valid character of our password.
And peaking ahead we can see that there are
similar rules like that for all other characters
of the password.
So I copied the javascript code into a new
html file, to more easily work on it and cleaned
up the if-case a bit.
But then we quickly reach some of these functions.
So the 5th character is equal to an integer
which is returned by this function.
If you carefully check how far this function
spans, you can just copy the whole thing,
let it evaluate, and this is the result.
The whole thing is just obfuscation for the
number 66.
And there are a few more like that, but same
principle.
Here are all the rules cleaned up.
Oh f.
That’s the problem with using this test
vm.
I think it expired and after a little bit
of time it will, you know, shut down.
This is annoying….
Ok… we are back… here are all the rules
cleaned up.
And then I started to write the reverse of
each of these conditions to create the whole
password.
We can simply use the String function fromCharCode,
which takes ascii integer numbers as parameters
and turns them into a regular ascii string.
So the first character is 16 XOR 123.
The second character is shifted to the left
by two and must be equal to 228.
This means if we shift 228 right by 2, we
get the next valid character.
Character three has a little twist, I will
take about it in second.
Next character was this obfuscatied function
and so it’s just 66.
Fifth character subtracted by 109 will result
in -22.
Which means if you subtract 22 from 109 you
will get the correct password character.
And it’s all kinda simple, but then in the
end we reach two more rules that are a bit
more complex.
Feel free to practice your school level math
to rearrange the equation so that our password
character is alone on one side.
But I’m not in school anymore.
And I’m really lazy.
So I just decided to bruteforce those two
values.
I mean each of them only has less than 128
options.
we are talking ascii characters here.
Oh and the 3ird character was a bit special
because the check is doing here a shift right.
Which means the lower bits of that number
will be lost.
So 14 is the result of a shift right, which
means if we shift the 14 back, we don’t
know what the lower bits were.
And up here we do the reverse.
We shift the bits up, but then remove them
with %255, so now only the lower bits remain.
So based on these two values you can easily
assemble all bits of the whole ascii number.
But again, I’m lazy.
I just brute force it too.
I clean up a bit more and here is the final
script.
If we find the correct password I alert it,
and otherwise just return false.
And then I have three nested for loops, each
one is responsible for one of the three unknown
characters.
And then I just open that file in the browser,
and basically instantly it finds the correct
password.
Awesome.
We can copy it now, execute su, enter it and
BOOM!.
We are root.
Awesome……….
Right?...
ehm… how do we get the flag now?
I was hoping this was it?
Goddamit.
After a short moment of rage I tried to approach
it again with logic and saw that when we enter
the password correct, it sets the root variable
to 1.
So I searched the sources for location where
this variable is used.
And I find one location here.
And scrolling up we can see it’s in the
function changeDirectory.
So that’s interesting.
The other aprt in the if case where it checks
for root is again obfuscated.
When we carefully copy that out again and
evaluate it, it evaluates to “key”...
sooooo… let’s try that.
Let’s try to cd to key.
Oh wow that works.
We are now in key.
And as we learned in the first video, we can
enter “ls”.
Urgh… what is that… so first time I saw
that I was a bit shocked, but I think I screwed
up some internal state.
Because I had the clever idea to refresh the
browser and do it again, on a clean session
where I didn’t debug, and now it works.
We get the flag.
Command Injection.
Let’s submit the flag and we are done…
awesome.
Oh and btw.
At the end I checked also the latest version
of firefox, and the malicious javascript was
also injected there.
So the spoiler or tip to use an old firefox
version wasn’t actually necessary.
Eeehhh…
LiveOverflow from the future again.
I was just editing this part, happy that I’m
almost done and then I realized.
Wait a moment.
Could it be that the js file was just locally
cached and the new firefox used the old firefox’s
cache?
So here is the old firefox, showing the injected
js.
Then I open the new firefox, open that js
file and we also see the injected JS.
But now I force a refresh with CTRL+SHIFT
R and boom.
File is actually loaded and the injection
is gone.
I first thought not to include that part in
the video, but I thought it’s quite interesting
that the new browser version 60 was able to
still use the cache written by the older version.
AND this also means another question stands.
How could you have figured out that you needed
an older version.
Were there any references in the dll to that?
Please let me know in the comments.
﻿readme_revenge was a pwnable challenge at
the 34c3ctf and in the end 30 teams solved
it. Difficulty: easy-ish? “You can't own
me if I don't use a libc! Right? Right?”.
We can download the binary here and this was
the IP and port to interact with the challenge.
When I read the title I knew immediately I
had to try it.
You see two years ago at the 32c3ctf there
was a challenge called just “readme”.
Back then I tried to solve it but failed.
After the CTF was over I looked at writeups
from other people and tried to understand
it and even made a video about it. Two years
ago I did not have the skill, knowledge or
experience to solve it. So when I saw that
there is a readme_revenge at the 34c3ctf I
just felt like, I had to solve it. It was
my personal challenge and in some way it was
very close to my heart. It was a challenge
I failed two years ago, and now I can proof
to myself that I improved. So let’s have
a look at it.
Like I said, the challenge reminded me of
this older challenge and I assumed it was
pretty similar. And it was easy to verify.
For that challenge you didn’t have to get
code execution, but the flag was actually
embedded in the file. And if you look at the
strings of the binary you can see a placeholder
flag. So the binary running on the server
contains the real flag instead. And that is
also where the name comes from “readme”.
Your task is to read or leak this flag from
the target binary. The solution of the original
readme challenge was super creative and really
blew my mind at the time. So I encourage you
to watch it because I had that knowledge in
the back of my mind when approaching this
challenge. So while it was obviously not the
same challenge, it was a “revenge” of
the readme challenge, it was similar in many
ways. So i had a pretty good idea already.
But let’s check it out.
When we run it the program waits for input
and then greets us with “Hi, liveoverflow,
bye”. So it just reflects what we write.
I immediately checked for format string vulnerability
and entered a format string modifier like
%x, but it didn’t do anything. I also just
tried a long input and to my surprise I immediately
got a segfault. Well that’s a good start.
Let’s look at it in gdb. So I run the binary
with the long input.
FYI, If you don’t know why my gdb looks
so colorful, it’s because I use the pwndbg
gdb extension.
But here was my second surprise, the binary
had all the symbols still included, so we
get all the function names. That’s neat.
So where did we crash? we got a segfault in
printf? Inside of libc? To be more precise
in __parse_one_secmb. That’s weird. The
instruction that caused the segfault is a
compare where it calculates an address based
on rax and rdx. And rax is clearly overwritten
with As. So it tried to access bad memory.
But in libc? Does this mean printf of libc
has a buffer overflow vulnerability? Well.
we will see. Let’s have a look at main.
Disassemble main. It’s super short. We have
a scanf, to read in a variable called “name”.
And then we call printf with that name. There
is a small but important detail here with
the variable name. Usually local variables
are placed on the stack, so they are referenced
as offsets from the stack pointer. Makes sense,
right? But in this case the variable is stored
at an offset from the instruction pointer
rip. This means it’s not on the stack, if
it’s an offset of the instruction pointer,
so an offset to the binary itself. This means
it’s a global variable stored in a data
segment. You can see here gdb has already
calculated or resolved this address for us.
RIP at this point would be this address +
this offset here. So 6b73e0. And if we look
at the virtual memory map of this process,
we see that this address is in here. It says
it would be “heap”, but I’m not sure
why it says that. Because I’m pretty sure
that’s not a heap. If we look at the sections
defined in the elf binary with objdump, we
can see that the address belongs to .bss . Which
is used for statically allocated variables.
Anyway, let’s go back to the crash. If we
look now at the location where name is stored,
we can print the memory. Here we see that
there was a bit of a size allocated for the
name. However we wrote much more As than that.
Because we have all the symbols, we can also
see which variables we have overwritten. So
we overwrote a huge dl_static_dtv array. No
idea what that is. We overwrote a dl_lazy
variable, a dl_osversion variable. I mean
we have killed a lot of stuff. And apparently
libc printf referenced something from in here.
mhmh... we have a very clear buffer overflow
and we overflow global variables and many
of those variables are libc internal variables.
The binary was statically built with libc,
which means the whole libc functions are part
of this binary. that’s the reason why those
variables are part of our binary data segment.
Usually, when dynamically referencing and
loading libc, these variables would be located
in the dynamically loaded libc memory. Anyway.
Here we have found the vulnerability. So how
can we turn that now into reading the flag
from memory. Clearly just blindly overwriting
data doesn’t work, so let’s do this systematically.
I wanted to carefully control what I overwrite,
so let’s take a snapshot of the memory without
an overflow.
To do this I set a breakpoint at the end of
main, then I rerun it with a small input and
then I print the memory starting at “name”
in 4 byte, or 32bit, chunks. I just keep enter
pressed until I reach the end. So now I can
get a huge list with all the memory and the
symbol names.
Then I copy the whole thing into sublime,
and using some text editor hotkey magic to
quickly reformat this data. Removing all the
pwndg prompts, making it all a python comment,
and then taking the memory value. In the end
I want to rebuild the whole memory with the
correct values. So I will use a buffer variable
where I will append the raw bytes. And in
a second I will define a new function b32
that will convert this memory value to raw
bytes. I can do this with import struct, and
then struct.pack with capital I for 32bit
values. I will also create a function b64,
because we have a 64bit binary, so might come
in handy as well.
So now this python script prints the whole
memory. Cool.
Theoretically if we use this to overflow the
buffer, it will overwrite the memory with
completely safe values. Basically not change
anything. And indeed. It seems to have worked
and we didn’t get a segfault.
But now comes the true challenge. What DO
we overwrite that could help us leak the flag
from the memory? Well, I didn’t know. In
the old readme challenge we smashed the stack
cookie in a buffer overflow on the stack,
which executed the stack smashing detection
function. That function would print the program
name. The program name is referenced from
a pointer on the stack. And so overwriting
that pointer with the same overflow on the
stack, with the address of the flag, caused
the flag to be printed when the stack got
smashed. So I kept that inspiration in mind.
So I was just going through the symbols one
by one and tried to find one that sounds interesting.
dl static dtv, slotinfo list. Dtv gaps. Tls
generation. Domain bindings, cat counter,
exit fn called, prefetch multple threads.
Debug. Gnah.. nothing immediately jumps out
to me. Oh libc argv and libc argc, so there
is a pointer to argc and argv as well? I keep
that in mind! The old readme challenge also
used an overwrite of the program name pointer
to point it to the flag. So might be useful
again.
Gconv lock. This all means nothing to me.
Nothing screams “HEY I PRINT YOUR FLAG IF
YOU CHANGE ME”. But then I reached the printf
function table. And FUNCTION TABLE always
screams: “change me and you can redirect
code execution”. But why is there such a
thing as a printf function table? If we look
up this function in the libc source code,
we can maybe learn more about it. A comment
here says “Array of functions indexed by
format character. ” and in here is also
a function called “__register_printf_specifier”.
So if we google for that function we can quickly
find that there is such a thing as “Customizing
printf”.
“The GNU C Library lets you define your
own custom conversion specifiers for printf
template strings, to teach printf clever ways
to print the important data structures of
your program.
The way you do this is by registering the
conversion with the function register_printf_function”
Let’s read up a bit more about it. This
function takes a spec, a handler function
and an arginfo function.
“if spec is 'Y', it defines the conversion
‘%Y’. You can redefine the built-in conversions
like ‘%s’,”
“The handler-function is the function called
by printf and friends when this conversion
appears in a template string.”
“The arginfo-function is the function called
by parse_printf_format when this conversion
appears in a template string”
That sounds perfect! Our printf template string
contains a %s. If we somehow could redefine
the conversion for %s, we could define our
own handler function. And could execute any
code we want. I mean we can’t call register_printf_function,
but we could maybe overwrite and modify the
underlying table directly.
If we look again into the sourcecode of the
register_printf_function, we can maybe figure
out how it would work if we want to redefine
%s. So we would pass in a small ‘s’ as
spec. And we would give it a function as converter
and arginfo. And down here it simply uses
spec as an offset into the printf_function_table
and printf_arginfo_table. That sounds easy.
We know there is a pointer to the __printf_function_table
in the memory that we can overwrite, so we
could point it to some other memory. And that
memory should then have a function defined
at the array position small s. So that would
be at offset 0x73 or entry number 163 in decimal.
Cool. So let’s try that. First let’s look
for some memory area we could abuse for this.
Let’s try here _dl_static_dtv. Let’s hope
it’s not important. So now we want to overwrite
the printf function table to point there.
Let’s try it out. We write that into a file,
set a breakpoint in gdb. And use the file
as input. Now let’s see the memory, oh it’s
not there… But it should be there? This
is the stuff that could drive you crazy, but
you need to chill and approach it logically.
So the overflow happens because of a scanf.
The scanf used %s to read input. So let’s
checkout the man-page of scanf.
The scanf() family of functions scans input
according to format as described below.
s Matches a sequence of non-white-space characters;
The input string stops at white space. AHA!
So maybe our memory dump contained some white
space.
So what are typical whitespace characters?
Of course 0x20 a regular space is a whitespace
character. But also new line would be a problem.
And basically all of these.. So 0x09, 0x0a,
B C and D. So let’s make sure that these
can’t occur in our buffer. I just ad a few
lines of code to replace these with a regular
capital X. let’s try it out.
Oh segfault. Ok we clearly did something now.
Let’s checkout the memory in gdb. And yup!
There is our value… But wait… that’s
not quite right? Why 58 at the end? OHHHHH…
our address had a space too. Well good we
caught that. So let’s point it at 24 instead.
Cool!
next we want to try to set a function for
%s.
So from our new table address, we have to
get the array entry for ascii value `s`, which
is 0x73. Which means we have to take that
times 8, because we are on 64bit so each array
entry, each function address is 8 bytes wide.
Cool. So let’s go to that address and write
there a test values. Let’s see if we successfully
redirected code execution!
We run it with the input. But hmpf. Segfault.
Let’s look at the code why. It tried to
calculate rcx + rdx*8. HEY! That looks almost
like what we calculated. Rdx is also infact
the 0x73. So the letter ‘s’. But rcx is
zero. So this calculation points to bad code.
But why is that happening, didn’t we overwrite
the function table entry with a value? It
shouldn’t be zero? But if we look at the
disassembly of this function, we see that
it references the arginfo table just before
it. HA!. we didn’t modify that. Sooo…
once we pointed that to the same address,
we can try it again.
both tables should be ok now. Let’s rerun
it with that. And we get a segfault at a call
`rax`, and `rax` is the value we wanted it
to be. Awesome! So what to do next?
I first thought about pointing it to printf,
and maybe we can somehow control the first
parameter too, based on how this printf modifier
function is called, but then decided to use
the technique I have learned from the old
readme challenge. Using stack_chk_fail. Let’s
get the address of that function. That could
work. But to print the flag we also would
have to control the program name pointer and
point it to the flag. But remember, there
was some kind of argv pointer in there too.
Previously it pointed into the environment
variables on the stack, so let’s just point
it somewhere here. And then this is now a
list of argument string pointers. And so the
first pointer has to point to the program
name. so we point it to the flag instead.
This is the address of the flag in the file.
I’m excited. Will it work now?
We pipe the exploit output into readme_revenge
and BOOM! Stack smashing detected. And here
is our flag!
So what we did was, we overflowed the printf
modification table and redefined what to do
when printf encounters a %s. Upon finding
the %s it took the address of our modified
function table which pointed to stack_chk_fail
instead. That function is then executed and
gets the program name to show it in the error
message. But we also modified the pointer
to the program arguments, argv and pointed
the program name, which is the first argument,
to the the flag. So the error printed the
flag.
And here is a screenshot from when I did that
during the CTF, to grab the real flag. Printf
is so fun sometimes!
I’m so proud of myself. Because this really
shows me how much I have learned in the past
two years and how I improved. Back then I
would have not been able to solve this. But
now I did it pretty straight forward. Makes
me feel really good.
﻿Hohoho, was a challenge at the 33c3ctf with
fairly high points.
It’s listed in the misc category, which
means it’s not quite clear what the objective
is.
The text reads “Santa claus had a massice,
multi-day lag and is still stuck at sorting
out christmas trees and presents” - keep
in mind that the 33c3ctf happened during the
33c3 conference between christmas and new-years.
“Help him with the trees at,” and then
we get a server and port to connect to.
“If he doesn’t reward you with the satisfactory
present, you might have to bash him a bit.”
Notice how the bash is written in italic?
That is a hint for what this is all about.
Bash.
The Gnu Bourne-Again Shell.
And there is a rate-limit so you won’t accidentally
DoS the service.
This was an amazing team effort for us.
Like with all challenges during the CTF, we
didn’t do them all alone, but especially
this one spanned across the whole team everybody
making a bit of progress.
So I didn’t do the first two parts of the
challenge.
I joined towards the end.
But let me quickly recap what the solutions
were for the first parts.
So when you connect to the service you are
greeted with a merry christmas and a menu.
You can help santa, continue helping him,
visit the north pole or quit.
And also you get a unique ID that tracks your
progress, and you can use that ID with the
Continue option to continue where you left
off.
That’s a great help.
So when you decide to help santa you get these
two trees which are actually a special version
of the towers of hanoi.
You have to sort these layers to their respective
place and the rules of hanoi applies, that
you can’t place a bigger layer ontop of
a smaller layer.
You specify the moves with pairs of numbers
like 1, 3 which moves the red small palte
from tree 1, to the empty tree 3.
And then you basically just have to solve
this.
You can quickly find code and examples online
about this hanoi version.
And that’s what my friends did.
They basically wrote some code to solve the
towers of hanoi and produce a file with the
moves necessary.
After you solved it, you get another menu
where you can simply answer some questions
but they kinda got stuck there.
You can take notes of the unique ID you used
to solve it (to be more precise only up to
the last move), adn then you can very quickly
get to this menu again to figure out the next
stage.
As far as I know, at this point another person
started working on it as well.
I think by just trial and error, and after
quite some more time spend on this, he noticed
a bash eval error in only one particular branch
of the question/answers tree.
BAM!
There we have it.
There is a bash shell injection.
Our input is passed to an eval in a bash script.
So from here on it should be simple, right?
Well… this is where the real challenge started.
My friend wrote a little script to comfortably
test the bash injection.
So you can simply run that script and quickly
test a payload.
With that he slowly figured out, by more trial
and error and systematic testing, you are
not allowed to use any letters or numbers,
except you MUST use an n, or i, for the option
selection ONCE.
And all other special chars are allowed.
That’s very very restrictive.
How the heck can we get basically now a full
command injection working if we can’t use
letters to launch any program?
I think I joined here my friend at like 11pm
or something.
And we sat down playing around with this bash
injection.
Obviously there are a couple of different
creative ways to solve this, but they are
all kinda based on the same concept.
And so before I show you how we did it, let’s
establish some bash shell basics.
I have prepared here a folder with a couple
of test files.
Now have you ever wondered what happens when
you do something like ls * (star)?
You might have thought that `ls` implements
that, but infact your shell expands this.
When you press TAB it will expand it for you
right there, and not just when you execute
it.
So you can do stuff like match or expand to
all filenames that start with A.
Now think what would happen if you just enter
*?
Unknown command AAAA?
Well that’s logical, * is expaned to all
files in this folder, and the first file was
AAAA, so it thought that this is the program
to execute, like cat or ls, and the other
file names are the parameter.
And this shell expansion is very powerful
and convinient for us.
For example we know that cat is in /bin/cat.
We can try to match this with special characters.
Besides star, which stands for as many chars
as you want, questionmark only represents
one character.
So for example /???/??? 
Will expand to all 3 character files that
are in a folder with 3 characters.
And it just happens so, that the first one
macthed is cat.
That’s very lucky, because this means we
can execute cat.
And all the other files that match this are
passed as arguments to cat, so it will print
all these binaries.
And obviously we can also follow the cat primitive
with more shell expansions like star.
So the stars would expand to our files here,
the beginning would expand to cat and a lot
of crap, but that doesn’t matter, in the
end these files here will be printed.
And you can use that now to slowly explore
the whole system.
By trying to match important files.
This is how we got the sourcecode of this
challenge.
This is also how we found the flag file in
/flag.
The issue is, we cannot read it, otherwise
we were done already.
Apparently our current user doesn’t have
the correct permissions.
But this way we also found a binary that seems
to read the flag for us, we just have to execute
it.
And that’s also easy, we can just use shell
expansion to execute it.
But it also wants a password.
The password is as plaintext in the binary
and we can see it through cat, but we have
no way to enter these characters, right?
How can we supply this password now?
Well, let me just show you the solution, and
walk you through.
I know it looks redicolous, but once you disect
it, it’s simple.
But it took us like 7hours to figure this
out.
This was not an easy process for us.
We went to bed at like 9am in the morning,
after pulling an all nighter.
But we knew we were close, we just needed
more time to figure out the detail.s
First of all there are three sections.
There are two function defnitions, ae and
oe.
Those are special german characters, but they
are not standard ascii, so they are not filtered.
And the third section is actually executing
the get_flag program I mentioned earlier,
and that program gets a parameter, the password.
So all these lines just slowly construct the
password.
How it’s doing this you will understand
in a second.
So let’s have a look at the first function.
The first function ae, is actually just printf.
Printf is a program located in /usr/bin/printf,
and we got lucky that it gets matched by these
?? and the single n for priNtf.
As a paremter to printf we use $@. Variables
in bash start with a $. And $@ is a special
variable in bash, which represents all parameters
passed to a function.
So the function ae will just call printf with
all the parameters give to it.
Nothing special, just a wrapper so we can
reuse printf more often as function ae.
Printf is cool, because we can use escape
sequences to get special characters.
In particular we can use octal escape sequences
like backslash 101, which is 65 in decimal,
or hex 41, so it gets converted into a capital
A.
Maybe you already get what we are working
towards.
Now we have a function ae, that can evaluate
escape seqences, thus print ANY string we
like, it only requires numbers.
So we got around the restrictions of letters.
So if we find a way how we get numbers, we
can construct escape sequences and then print
a string.
So let’s have a look at the second function
oe.
Oe uses now ae, which is printf, to print
another special bash variable.
$#. That is like argc in C programming.
It represents the amount of parameters passed.
So calling oe with 3 parameters will print
a 3.
And calling oe with 1 parameter will print
a 1.
Now we have a primitive to construct any number
we want.
And this is what happens in the last section.
There is one ae at the start, which will print
a string, and evaluating all escape sequences.
And then we have a long list of constructed
escape sequences.
4 backslashes are necessay but whatever, they
result in one single backslash at the end.
Because you like have to escape the escape
for the escape backslash.
Whatever.
So backslash and then we call oe with 1 parameter,
oe with 4 parameters and oe with 7 parameters.
So \147.
Which is 103 in decimal, or hex 67.
And that’s the ascii character small ‘g’.
And then we repeat this for every character
we want to create.
So once you evaluate all the oes, you have
a string left with all the escape sequences,
then you perform do an ae, a printf to evalueate
them all, and all that is left over, is the
password for the get flag binary.
BOOM!
No ascii letter or number needed but we can
construct any character sequence we want.
So when we inject that, we get this ascii
christmas present and at first I panicked
because I couldn’t see the flag.
And I thought WTF?
My heart skipped a beat, feeling devestated
at 8am in the morning, but it was there after
all.
Submitted it, and at that point only 11 teams
had solved it.
We were really proud.
And this was a great example of a challenge
where the whole team worked together and I
would have never got it by myself.
﻿In the last video we learned some basics about
how the heap works and now we want to apply
this to heap level 1 from exploit-exercsies
protostar to solve it.
Actually I want try something.
We do some roleplaying.
Let’s first be the security researcher who
want’s to find a bug to exploit in this
binary.
Afterwards we play developer trying to understand
the exploit to fix the issue.
So we put on our black hoodie and get started…
first we open the binary heap1 in gdb and
execute it.
We get a segfault.
And it also shows us that the segfault was
caused by strcpy, because it tried to copy
a string from the address 0, to this other
address here, and 0 is obviously not valid
memory - so it crashes.
We know how linux binaries work, so we make
an educated guess that this application might
require some input and we try the arguments.
Run with aaaa.
Again another segfault, but the attentive
viewer will notice that the address is now
different, so this is a different strcpy,
which again can’t copy from address 0, so
we guess that it requires another argument.
And this time the program runs through without
errors.
Now we try to find a bug, so the simplest
thing to do is, we just throw some long inputs
at the program and see if something happens.
So for the first argument I choose to do a
pattern with letters and for the second argument
I do numbers, just so I could idnetify them
if something would occur.
We run that, and we got a different segfault.
Again because of strcpy, but this time the
destination address looks invalid.
It tried to copy the string with the numbers,
which we know is the second argument, to the
address 46,46,46,46 which is the hexcode for
FFFF.
So whatever happened, we somehow overwrote
an address, that is used as the destination
of the strcpy.
And this means we can now use the first argument
to fully control where we want to write.
And we can fully choose what to write, with
the second argument.
Now we have a lot of freedom what we want
to overwrite.
For example we can overwrite the return pointer
on the stack to redirect code execution, or
we can overwrite an entry of the global offset
table, which I explained in a previous video,
to achieve the same.
Let’s do the latter one, it’s usually
more reliable than the stack - which likes
to move around.
So let’s check what kind of function is
called after the evil strcpy.
We can peak into the source code and see that
there is a printf, and we could assume that
we want to overwrite printf on the global
offset table, but that is deceiving.
That’s not the case.
So let’s better stick to the assembly.
First of all we have to find the location
from were we were calling the strcpy.
We can use backtrace for that, which will
look at the stack and the stored return pointers
to figure out where we are - as a sidenote,
if you found a bug that smashes the stack,
then backtrace can not make much sense of
it anymore.
So it doesn’t always work.
And here we can see that currently we are
in strcpy, but we were coming from this address.
So let’s set the disassemblu flavor to sane
intel syntax and disasemble the address.
This will now disassemble the whole function
this address belongs to.
Our address ended in 5a, so we are here after
the strcpy.
And as you can see there is a call to puts
next.
Which btw is not printf like in the source
code.
That’s because the compiler replaced the
printf with puts for optimization reasons.
Ok, so let’s overwrite the global offset
table entry for puts.
As shown in the got video we can figure out
the address of puts by first disassembling
the function trapoline in the procedure linkage
table, which would now jump to an address
stored at this address.
So this means this is the address of the puts
global offset table entry.
So this is the target we want to write to,
thus we place it in the first argument.
gdb run, but we use backticks in the first
argument to execute /bin/echo.
As you know echo simply outputs whatever you
pass to it as arguments, and we can use that
to get characters with hexvalues we can’t
type.
For example the hex value 8.
So echo -ne, -n because we don’t want that
echo places a newline at the end of the output.,
and -e because we want echo to convert hex
escaped numbers into the raw characters.
Just to make sure everything works we echo
the whole test string up to the Fs again.
Now echo inside of the backticks will be executed
and the output of that will be placed inside
of the quotes as the first argument.
And when we run this we get the same segfault
as before, so all is fine.
Next step is obviously to replace the Fs with
the address of the puts global offset table
entry.
And when we now run it we get a segfault somehwere
else, this time because of 30303030, which
is ascii for 0000.
And when we look at the registers with info
registers we can see that we sucessfully got
control of EIP, which means we can now redirect
code anywhere we want.
In this case we want to call winner, winner
has this address here.
So we place that into the second argument
instead of argv2 by using echo in backticks.
We execute it and we get winner.
Which also works great outside of gdb.
In summary we can say this:
we identified a bug by guessing and playing
around with it.
Through gdb we learned that somehow we can
control the destination of a strcpy, and we
learned we even control what we want to copy.
And we abused that to overwrite the function
address of puts to redirect code execution
to the winner function.
All without knowing why this even happened
and not even knowing that the heap was involved
at all.
Being a good security researcher we create
a writeup, an advisory for this.
Providing our proof of concept exploit as
well as some additional information that might
help the developer.
Now let’s change sides and become the developer.
We take off our black hoodie, and put on our
grey hoodie.
Because that's what developers wear.
So we just got this email from this dude who
found a bug in our program.
He even provided a Proof of Concept exploit
with it.
Now we want to figure out why and how this
happened, so we can fix it.
In the advisory it says that it has to do
something with strcpy.
So we read the manual about strcpy.
And have this “oh shit” moment when we
realized we didn’t even read the documentation
that would have told us what a bad idea that
was.
So now we could fix that.
For example using strncpy or use strlen to
check the length before we copy it and then
exit.
But because we are a good developer we try
to learn from this advisory and try to understand
how the exploit exactly works.
In the last video, the heap malloc introduction
video, we already thought about how the heap
should look like from this program.
So let’s see how it looks in reality.
To do this let’s set a breakpoint after
each malloc and strcpy.
We dissasemble main and look for all those
calls and set breakpoints afterwards.
Then we run it with the proof of concept exploit
arguments.
And we hit the first breakpoint.
So now the first malloc happened.
So we are currently here in the assembler
code and the result of malloc is in eax.
So eax contains the address on the heap where
we have enough space for the internet struct
i1.
And we can look at this address and we can
see it’s simply 0.
With info proc mappings we can see the memory
segments, and there is also the heap and we
can have a look at that.
Oh, maybe it’s a good idea to add this heap
output as a gdb hook as well.
So we see it automatically at each breakpoint.
define hook-stop
x/64wx 0x
end
So if we now continue we should set the priority
of i1 to 1, and then malloc for the name.
Let’s have a closer look at the heap.
So as we learned the i1 variable points here.
So this is where the struct starts and you
can se that the first attribute, which is
the priority is set to 1.
And before that we have the heap metadata,
the chunk header, which contains the lnegth
of this chunk, including the last bit set
to 1 which means that the previous block is
not free.
It’s in use.
And what we see is what we expected, we see
here two chunks of 8 bytes, including the
headers it’s obviously 16 bytes.
Another cool thing we can do is to define
a variable i1 in gdb and set it to the address
of this object.
Aaand we can even add the type of this variable
which is “struct internet”.
Now we can print this variable i1 and gdb
can display us the attributes priority and
name.
And we can see that priority is 1, and name
is still zero, because we have allocated memory
for the name but not yet assigned it to the
i1 attribute name.
If we continue to the next breakpoint the
address of the name got assigned and the i2
object got allocated.
And the result of malloc is again in eax,
that’s the address of the i2 object.
So we can also define the variable i2 in gdb.
And when we print that we can see that it’s
still empty.
Now if we continue the priority of i2 should
be set to two, which we can verify by looking
at the heap memory as well when we print the
i2 object.
Also all of our 4 mallocs are done now.
And if we compare that to what we expected
in the earlier video, we can see that it fits
perfectly.
There is only one thing that we didn’t talk
about yet, and that’s this big value after
all chunks at the end.
Well this area down here is all free memory
and in exploitation terms this is often referred
to as the wilderness.
This is number is the remaining size of the
heap.
This whole thing is basically a huge heap
chunk, and that number is its length.
I made a three part video about the cookbook
challenge from a ctf, and that exploit abuses
this number to redirect code execution.
It’s super awesome.
You should watch it.
Anyway.
Right now the name of i1 is still an empty
string.
But this is about to change with the next
breakpoint.
Because we are about to execute the first
strcpy, which copies this super long first
argument.
Continue.
Now first thing we notice is here in the heap
memory.
Those ascii characters appear and it looks
like they have overwritten a lot of stuf on
the heap.
What earlier was supposed to be chunk header
metadata, like the size is now 44444444.
Let’s have a look at the objects i1 and
i2.
So i1 looks fine, i1 has still priority 1
and name with the string that we passed to
it.
How about i2?
Uh… that looks fucked.
Priority is now a super huge number.
In fact that’s just 45454545 in decimal,
and that’s the Es.
And the name is 46464646, which we know are
Fs.
And yeah, we seem to have overwritten a lot
of stuff on the heap.
Infact we have overwritten the next chunk
on the heap after the i1 name.
And now the next strcpy will take i2->name,
which is pointing to some bad memory and try
to copy there the 2nd argument.
Really frckn awesome.
So this challenge showed one aspect of heap
exploits.
It doesn’t attack the heap algorithm itself,
it attacks the application, which uses objects
on the heap that we can modify by overwriting
stuff.
And those modified objects then bend the execution
flow.
Cool, huh?
﻿Now that we played the game to learn more
about the game mechanics in the first episode,
and that we have set up our own server in
the second episode, we can finally start gathering
technical information about the game and start
reverse engineering the client.
The very first lead that we get is provided
on the official website “Our hackable components
all live in their own sandbox, (the net code
and game logic are completely custom), so
you won't have to hack the engine (Unreal
4) itself!”.
That is already very good information and
we will keep that in mind.
So my plan right now is, not immediately to
try to hack anything.
That’s stupid.
I have no clue what to do.
So first I want to get a good overview of
the whole thing.
And then that will lead to information I can
probably use to dig even deeper.
I’m essentially doing information gathering
or reconnaissance.
And sure I will poke certain parts that I
find intriguing and have a quick deeper look.
But it makes no sense wanting to jump into
a hole right away, if you don’t even know
where the holes are.
We also have 3 different clients, a windows,
linux and mac client.
And obviously the code had to be compiled
for each one of them differently.
But also probably not every file is different.
So I thought it might be interesting to look
at the differences and similarities.
To do that I wrote a simple python script
that simply walks the directory tree to get
all files, and then creates hashes of all
of them in order to figure out which files
are identical and which files are unique.
So let’s try this out on the clean client
files downloaded from pwnadventure.com.
And we can see quite a lot of files are identical.
Some .dlls, some config files.
Nothing sounds too interesting.
Maybe you wonder why there are .dlls in the
linux and mac clients, because dlls are for
windows, that’s because this game is based
on mono.
And mono is a Cross platform, open source
.NET framework.
So this allows you basically to write windows
.net applications and compile them to run
on mac and linux.
The unique files are also not that interesting,
you can see different binaries for the different
systems.
So dylib is a dynamic library for mac, while
on linux it’s an .so file a shared object.
But the clients we just compared are essentially
just the launcher.
The actual game is downloaded during the update
process.
So here I have gathered all three updated
game directories, and so let’s run the script
on it as well.
Each fully updated client is around 2gb of
files each, so this will take a little bit
to run.
Hashing those big files takes a few seconds.
Ok so now we have a lot more files to compare.
But they are all pretty boring.
A lot of .ini files, so these are mostly config
files and then also a lot of .pak files, these
are, based on the name, I assume, the actual
3D files and stuff like that.
Though it’s a bit weird to me that other
resource files, such as MapTerrain.pak are
different on each system.
I would have assumed all of them are the same.
But whatever.
Nothing really looks that interesting here.
Though this way you might discover a file
that is called “GameLogic”.
A GameLogic.ddl for windows, a GameLogic.dylib
for mac and a shared object libGameLogic for
linux.
Mhmhm…
But let’s have a bit more dynamic approach.
Like I said in the first video, I will mostly
do this on Linux, so let’s start with that
and execute the Launcher.
But the Launcher is not the real game, so
let’s just hit play and wait for the actual
game to have started.
Once it’s on the main menu, we look at the
process tree with pstree and some flags to
get more details.
Here it is.
PwnAdventure3 has this process ID.
The children of this process here are threads,
ondicated by the curly braces.
And each thread was also given a meaningful
name, whichs quite awesome.
So we have an async I/O thread, some message
passing stuff, the main thread I guess, RT,
remote,(?) or real time(?) heart beat, a render
thread, SDL Timer, and SDL is a framework
often used for games, so no suprise here,
a TaskGraph and I don’t know.
Okay.
Let’s take the process ID and look for it
in the regular process list.
So this binary that was executed lies in the
launcher directory, but then PwnAdventure3_Data,
PwnAdventure3, PwnAdventure3, Binaries, Linux,
and then the file is called PwnAdventure3-Linux_shipping.
Let’s exit the game and see what happens
when we call it directly.
We see some kind of debug or log output, and
the game is actually starting!
So we have just bypassed, so to say, the launcher
or updater and figured out how to directly
start the game.
Next let’s look at the /proc file system.
That’s magical linux stuff, it looks like
folders and files, it feels like folders and
files, but is actually a bit more magic than
that.
However we can explore it like files.
So we go to /proc and the process ID of our
currently executed game.
And with ls we can see the available folders
and files.
For example here you can check all the environment
variables, the commandlines on how the program
was executed, but also the memory map of the
virtual memory of this process.
The output is huge for this game, so let’s
pipe it into `less` so we can scroll more
nicely.
So up here we have our game binary mapped
into memory.
Then some memory areas that are used for something
else, probably a lot of different heaps and
mapped memory of the game files and stuff
like that.
Oh damn there are a LOT.
Let’s just skipt o the end with SHIFT+G.
Ok so here are the addresses of our stack,
the linux dynamic loader and linker and if
we scroll up a bit we find some other dynamic
libraries used by the game.
Lib thread, libdl, and the libGameLogic again.
Interesting! lib rt, libm, and libstdc++.
Oh so we might actually have a game written
in C++ here.
Libcrypto, mhmh.
We can also search for “mono” in here
with / mono Enter.
And then with n and SHIFT+n we can search
for it.
Though it doesn’t appear in this process.
So it looks like only the launcher is written
in .net using the mono framework, the game
itself is not.
Let’s have a quick look at the binaries
themselves.
Let’s start with the “file” command.
So the main game binary here is a 64bit executable,
it’s dynamically linked and stripped.
So no debugging information available.
With ldd we can see which dynamic libraries
it requires.
And here we can also find the libGameLogic.so
again.
Most of the other libraries are system libraries,
so these just offer basic functionality like
threading and crypto functions, but the gameLibrary
most certainly is something that has to do
with the game itself.
Obviously.
If we check the file output for that binary,
we see that it’s a shared object, so not
a standalone executable, it’s also dynamically
linked and is NOT STRIPPED.
Damn.
So that means we get a lot of debug information.
Before we leave the proc filesystem, let’s
quickly check the fd folder.
That folder contains a list of all the currently
opened file descriptors and to which file
they point.
Which means this is a list of all the files
currently accessed by the game.
0,1 and 2 are obviously stdin, stdout and
stderr, so pretty standard, but all the other
ones are other files.
As you can see most of them are the .pak resource
files.
Let’s try to head into the game.
Connection Error.
Failed to load master server certificate.
Oh oh.
I guess it wasn’t that easy to bypass the
updater and make it work?
Let’s see if we can fix that.
We execute the launcher again, head into the
game.
And then verify that now we can connect and
find that server certificate.
Yup. ok… so let’s find the process id
of this process now, by listing all processes
and grepping for pwn, and then we go to cd
/proc/ the process id.
Now let’s see if the process was executed
with any special command line arguments.
We can do that by reading the cmdline file.
But nope, it’s just the binary path, which
is always the first command line argument.
No additional ones used.
Then let’s check the environment variables.
You can also cat that file, but the file is
not pretty, the variables are null byte seperated.
But we can pipe the file into sed and use
a simple replace rule to match all null-bytes
and replace them with newlines.
Now we get a nice formatted output.
But I didn’t see any special environment
variables either.
Also the current working directory is the
same as from where we launched it previously.
So I just played around with it a bit and
simply went into the folder of the binary
and executed it from there.
And then it worked.
Oh well.
There is me trying to be smart.
Anyway.
Let’s do one last thing, and that is investigating
the networking side.
To do that I drop into the game and start
by checking netstat.
With netstat and -a for Showing both listening
and non-listening sockets, as well as -c to
continiously print connections, then grepping
the output for pwn, we see that the game periodically
connects to master.pwn3 on port 3333 and 3002.
Port 3333 is the master server, as specified
in the server.ini file, but port 3002 is actually
the game server, but master and game server
are on the same IP, so instead of showing
game.pwn3 it shows master.pwn3.
Cool.
Next let’s exit the game again and open
wireshark.
Then monitor any interface and filter for
all tcp packets to port 3333 and filter for
only packets that contain a payload.
So where the tcp length is larger than 0.
Then launch the game again.
And I also log in with an account.
If we peak into the content of the packets,
it looks like binary and we can’t immediatly
see what it stands for.
It’s certainly not like HTTP human readable
json data or sth like that.
Howeve ther are a few ascii strings in there,
which is an indication that it might not be
encrypted?
“Ghost in the shellcode”.
That was the name of the CTF this was part
of.
However these packets going from the client
to the server, with all the same size, change
a lot.
So that looks more like encrypted content,
or maybe just compressed.
But we did see some libcrypto earlier, so
yeah, we don’t know yet.
Now let’s switch to port 3002, which we
saw in netstat to be assigned as our game
server.
There is a lot more action here.
The game constantly sends updates to the server
and receives updates.
Of course it’s an MMO so we expect a flood
of packets.
Let’s go back to the start.
Wireshark tells us that these are some weird
packets.
However that doesn’t look right to me at
all.
Wireshark tries to guess and decode certain
protocols, but it looks like it might be something
custom.
Of course layers below, the ethernet, TCP
and IP layer are ok, just the payload of TCP
is probably something custom.
So in order to not get wrong decrypted protcols
I go into the settings and disable all enabled
protocols, and just enable ethernet, ipv4,
and TCP.
Ok that looks less awful now.
So these packets are much smaller, which also
makes sense.
With every little change you want to inform
the server and vice-versa.
All these packets with size 70, are actually
just 2 bytes of data of actual TCP payload.
The values changing here belong to the ethernet,
IP and TCP protocol layer.
For example that part here is a timestamp.
So that probably doesn’t interest us.
We probably want to focus on the data.
And the server just sent us a lot of zeroes.
OK here we have the first time I think, the
client sending something to the server.
Actual ascii data, so that doesn’t look
encrypted either.
But I don’t know what it stands for yet.
\After that it sends a huge bunch of packets
with the same data.
Mhmmh..
Maybe we see nothing happen because nothing
happens in the game?
Let’s go down where there is more action.
Let’s try to do some stuff.
Then we observe the traffic while playing
the game.
Walking around doesn’t immediately show
a change, however jumping triggers a slightly
larger packet.
And actually it seems to trigger two.
One for initiating the jump, and one for getting
back onto the ground.
Because of walking and looking around, we
can also see some slight changes in the previous
packets.
So this is an indication that it’s not encrypted
and it might be simply our position in the
game world.
And jumping added something to it, but a lot
of it stays the same, so it might be something
like “I jumped at this position”.
And “I landed on this position”.
I think we already learned a lot about the
game today.
No worries, I won’t show every little detail
I play around with, but it was important to
me to show you that it’s important to investigate,
and that you can slowly and incrementally
learning more about the game, how it works
and that can be fun too.
Also btw.
Make notes of these things.
While doing this I was writing down what i
did and what I found, because this way I don’t
forget a week later what I already discovered.
Next week, we will open the disassembler.
﻿I don’t like pop-under ads and as a Chrome
user I’m happy that Google agrees with me.
They consider them to be bugs in their popup
blocker.
I made a few videos a few months back where
we have reverse engineered one particular
obfuscated JavaScript library, used and sold
to advertisers, in order to figure out the
trick they use.
And then reported it to Google to get the
bugs fixed.
Back then it has also motivated Masato Kinugawa
to research a few more techniques and overall
we killed quite a few bugs that allowed pop-unders.
And I think we were quite successful.
For a long time the popunder library did not
have a working popunder technique for Chrome
and had to resort to a tab-under.
which was awesome, for a while we are the
reason why a lot of advertisers that use this
script couldn’t create terrible pop-under
ads on Chrome.
But now I was made aware by SilentHammer on
the subreddit, that the popunderjs library
has been updated and ships now with a working
pop-under for the current Chrome version 65
up to the current development version 68.
And indeed, the demo works.
There is a pop-under.
So let’s figure out how it is done and then
report it as well.
The first few steps that I’m doing now are
the same I did in the previous videos.
I essentially want a local mirror of the scripts
so I can modify them and play around with
it.
So I use the Chrome developer tools to get
all the script files loaded by this site and
save them.
And because of the licensing, and this being
the demo, and I don’t know how the license
check works (It might check the hostname)
I do not only download all the files, but
I also change the /etc/hosts file so that
the domain points to localhost.
Then I use php to launch a local webserver
and serve the files with the same folder structure
as the server.
Now I have all the files locally and can change
them however I want.
For example I can clean them up and beautify
the scripts.
The files are loaded locally now.
And a quick test, yep the popuner still works.
Ok…
So let’s have a first look.
The javascript code is clearly still super
obfuscated.
So nothing we really want to work through
statically.
And trying to look at the script dynamically,
with the chrome developer tools is also still
super annoying, because the script constantly
traps the debugger with the debugger keyword.
We can disable the debugger and still run
it, but then we can’t set any breakpoints
if we do want to pause.
Goign up in the callstack we can see where
this debugger call is coming from and it’s
coming from this function a().
And here we can see that a() is always repeatedly
called with setTimeout.
So we can try to overwrite setTimeout with
our own function, which also logs some information
about the call.
This hopefully disables the debugger traps.
When we now reload the page it looks really
good, we don’t break, but we also don’t
see anything in the console.
But that’s because the code constnatly clears
the console.
Luckily the developer tools are cool and just
tell us the line where this clear is called.
So we can go there, set a breakpoint by clicking
the line number and BOOM, the debugger breaks
here.
Now we can analyse the code.
Capital I is the window object.
The Kn variable is the string console, and
hn is the string clear.
So this simply calls window.console.clear().
Perfect!
We can also find this line in our script and
can just comment it out.
Now when we reload the page we see exactly
the outputs.
And as you can see, some stuff tried to call
setTimeout, however also the popunder is not
working anymore.
So i guess just overwriting it didn’t help
us.
Let’s revert it back.
Another thing we used was the performance
tab.
This one can be used to record every javascript
function call.
So we can hit record, trigger the popunder,
aaand hit stop again.
Now it takes a moment to gather everything.
And here we have it.
This is the timeline, and all of these colorful
bars are function calls.
So here is clearly our start, this is the
mousedown event.
Later in here we also see a onBeforeOpen,
which is actually a call into the demo.js…
So this is a library sold for advertisers,
and so the library creator offers here functionality
that you can run code just before and after
the popunder was opened.
This means our pop-under createn should happen
after this one here.
Interestingly the whole function graph stops
here now.
Not everything happens down in the hierarchy
from the mousedown event.
There is a weird Function call later, which
at some point results in open.
The orange functions are generally regular
javascript stuff, like events, and all the
javascript functions, and the pink ones are
custom ones.
So these are all the obfuscated functions
as you can see from the name.
And actually there are two of these blocks
starting from a weird arbitrary function call
which result in open.
And open is the function to create a new popup
or tab.
So it does it twice.
I have actually no clue what triggers this
initial function.
If it would have been directly called from
the mousedown event it would be part of that
block.
So that’s weird.
But looking at this I don’t see anything
special.
There are no calls to create new HTML elements,
nothing external is loaded, it’s just these
open calls.
So that’s super wierd.
We can also look at from where open is called,
by looking here at the call stack and following
that link.
So this apparently calls open.
And these should be the parameters of open.
Let’s search for this snipped in the script.js
file we have and then add some console.log
outputs to print the parameters passed to
open.
We save the new script, reload the page, trigger
a popunder and look at the console.
So we see two opens.
Both have the first parameter about:blank
and the second one _blank.
A look into the API reference for open we
can see that that is the URL and this is the
name.
But the first open has additional optional
windowFeatures.
It defines width, height, and stuff like that.
The second open didn’t have that.
Okay, nothing too special here either.
WHile playing around I also noticed that the
anti-debugger trapping is not that aggressive,
so we can actually add our own debugger statement
here at the open call, reload the page, disable
the breakpoints and then prepare to be super
fast.
Because we can very quickly reactivate the
breakpoints, quickly switch to the browser
window, HOPE that the anti-debugging traps
don’t trigger first, click somewhere to
create a popunder and hope that our breakpoint
at the open is hit.
And that worked.
Here we are.
Now we can see the state of the variables
which we already know.
We can also see the callstack and have a look
at where this call is coming from.
Notice how it says here postMessage async,
that will explain a lot later but when I looked
at it the first time, I was just a bit confused.
And looking at this function here, we see
a variable i, which is a MessageEvent object
with a data attribute containing our window.open
parameters… mhmhm...
At this point I got a bit frustrated.
If you have watched the previous videos you
know what kind of crazy techniques were used
to pull off a pop-under.
I didn’t fully trust the developer tools
to be honest, because maybe there are tricks
to hide stuff from it.
I was expecting something really really crazy
and I decided to get out the big guns.
I wanted to directly look at the native functions
being called from javascript, so nobody can
hide anything.
I went to the Chromium sources and followed
the “Checking out and building Chromium
for Mac” instructions.
If you want to follow along and build Chromium
as well, make sure you have enough disk space.
Not only did it take me over night to build
it, in the end I also needed almost 80GB disk
space for it.
So be warned.
But that’s not too bad, because with minimal
changes you don’t have to rebuild the whole
thing again, it only has to rebuild the part
you modified.
So that’s cool.
I also have to give my kudos to the build
team, or whoever is responsible for this,
these instructions just worked.
I had no issues at all, it just worked which
I did not expect.
Anyway… so…
I want to log important javascript function
calls.
For example the open call.
But also things like createElement or any
other API call.
All these calls somehow have to be executed
by the underlying Browser so you can’t fake
or hide anything.
In the end these native functions have to
be called.
It’s the first time for me looking at these
sources, so I have no clue what I am doing.
But let’s maybe think about this for a second.
Maybe you have heard of V8 - Chrome uses the
V8 JavaScript Engine.
And there is a sub directory for the v8 engine
with the sources.
So maybe this is a good point to start?
Well, maybe, but probably not.
V8 is just JavaScript, but we are not really
interested in logging when something creates
an Array or so.
We want the APIs that glue together the Browser
and the JavaScript, and that is mostly the
DOM.
The Document Object Model is what we can use
from JavaScript to interact with the Browser
and the HTML.
However Chrome also has a lot of other APIs,
like the Notification.requestPermissions and
these are probably not included in the DOM,
but we deal with that when we need to.
Let’s start with something easy and look
for the document.createElement function.
In previous popunder videos that was a crucial
part in the trick so it would be awesome to
log that.
And so the DOM is most likely part of the
actual browser engine and in case of Chrome
that would be blink.
I looked around in the huge codebase for a
bit and then I found it in /chromium/src/third_party/blink/renderer/core/dom.
So I open that folder in sublime and then
let’s start searching for createElement.
Oh we find something in a .h header file,
let’s actually restrict it to only c++ source
code files.
So here we go.
We find some functions in document.cc.
Which I think is awesome.
Because the javascript function would be document.createElement.
So here we definitely find a lot of important
APIs.
Soo.. createElement…
There we go “Entry point of "create an element".”
That sounds perfect.
So I guess this is the native C++ function
being called when you call document.createElement
in Javascript.
Let’s test that.
Let’s add a simple recognizable printf()
here, just so we know if this is being executed.
Then we rebuild chrome and as you can see
it goes pretty fast now.
Only had to build the change we made.
And then let’s execute our own Chromium
build.
I also wrote a short test create script, that
will call createElement whenever we click
the link here.
But it doesn’t seem to work.
Damn. no output.
It also links here the specification of the
HTML living standard that defines these kind
of things.
And it says here “concept create element”,
so not really sure what that mens.
But when I searched a bit more in the document.cc
source code, I found the CreateElementForBinding
function which links to the dom-document-createelement
specification.
OK this one actually sounds like the correct
function.
So let’s add a printf, here.
Then we compile Chromium again, open the test
webpage and click the button.
And awesome!
Our printf works.
Now we have all the power to log every function
we want.
It might just be a bit tedious to add these
printfs everywhere.
I played around with it a bit more.
Added printfs to different kind of functions
like getElementsByTagName and stuff like that
but.
It didn’t reveal anything new.
It just didn’t seem to do anything weird...
mhmh...
At this point I decided to sit down and started
to implement what I already know.
I know 100% that there are two open calls
and we know their parameters.
We also know that it somehow is all triggered
from a onmousedown event, so let’s do that
as well.
And then we try that.
It opens a popup, but as expected it only
opens ONE.
The second open call is blocked by the pop-up
blocker.
The browser allows one user interaction, the
click, to open one window, because if the
user clicked, then one window is fine.
But not a second one.
However let’s just for testing disable the
popup-blocker and allow this page to create
any popups it wants.
When we now try it again, the second open
call actually creates a new tab.
And the tab gains focus.
See, the popup at this point is in the backrgound.
Let’s add a setTimeout to our script, to
close the new tab after 1 second again and
try that.
We click the link, it opens the popup and
tab, the main window gains focus and then
the tab is closed when the timeout hits.
BOOM… we have a successful popunder.
Holy crap.
This was damn simple.
As long as we can open two windows, one popup
and one tab, we can get focus back to the
main window.
But with activated pop-up blocker, which is
the default, this doesn’t work.
So the creator of this pop-under script actually
found a technique to bypass the pop-up blocker
and open multiple windows.
And this is where the postMessage comes into
play from earlier.
While looking around a bit more, looking at
call stacks and stuff, at some point I stumbled
over it again and it clicked.
WAIT. postMessage and here is the message
data?
Maybe the reason why the two open calls were
shown in their own function block is because
they were onMessage events, triggered from
an asynchronous postMessage.
That totally makes sense, why didn’t I understand
that earlier?
So I quickly implemented this.
I create an onMessage handler, which looks
at the data and either creates a new popup
for data 1 or a new tab, which is also closed
again with 2.
And then I simply trigger a postMessage with
1 and 2 in the popunder function.
This should create both the popup and the
tab.
Let’s try that in the browser, clicking
the link, it creates both.
Amazing.
We bypassed the pop-up blocker.
This also means we can spam popups now.
If we just keep sending postMessages in a
loop.
Look here.
So, now we are done here.
I have reported this issue to Chromium and
hopefully it gets fixed soon.
﻿Let’s continue with the Blocky puzzle challenge.
We identified a packet sent from the server
to the client that contains the state of the
input buttons, 32bits and the state of all
the output lines.
We then used the proxy to inject random input
states and collect a lot of data.
And so I have been running this brute-forcing
over night.
wc -l counts the lines of a file and with
watch, which is just executing wc over and
over, we can easily observe how the test data
grows.
So shortly after I started around midnight
I had already 4000 samples, and then I went
to bed.
In the next morning after 9:00 am we had 100.000
samples.
But I let it run even longer and in the end
I had about 340.000 samples.
So… how can we do machine learning with
that?
First of all, before we even do any real analysis
of this data, we have to figure out which
output bits are actually important for us.
Not all of the over 170 bits are useful.
Some are just the lines directly connected
to the button, or other lines in the middle.
So we have to figure out which are the important
output bits.
If you look at the data you can immediately
see that every output starts with 6 1s, and
then two 0s.
And that makes sense if you look at the end
of the puzzle.
The final stage of the puzzle just combines
a lot of output lines with OR gates.
So if only one of these lines is HIGH, a 1,
then the OR result will be HIGH, and all these
lines will be high.
You can see for example here the very first
OR gate in this chain, with 3 inputs.
And with the random button inputs it’s very
rare that all 3 of them are 0.
Thus the output is almost always high and
thus the whole chain stays high.
And at the end of the chain the signal is
inverted, and so we then have two low.
Because we probably never guessed the correct
input and one of these lines will always be
high, thus we see this pattern here.
This means that the important output lines
for us are the ones feeding into the final
OR gates.
Those must be 0, and then the whole line becomes
0 and thus the final door opens.
Now we need to find which bits in our output
correspond to these OR inputs.
To do that I simply position myself over the
puzzle and then use the proxy to inject a
random input.
Then I write down the state of one OR input.
Get another random input, and write down the
states.
And I’m continuing this for a bit and we
get this ON/OFF pattern for these two lines
to the OR gate.
Now we can take our over 170 bits output and
try to find this pattern in there.
To help with that I wrote a few simple loops
in python.
Btw I’m using jupyter notebook here, easy
to run with Anaconda, because this kind of
exploratory data analysis is really nice with
it.
The outer loop goes over each bit.
So first we look at the first bit of our output.
Then we go over each test case.
So we basically compare the first bit of the
output with the pattern we have written down.
If they match, cool.
But if they don’t match we break out of
the loop.
And then we check the next bit.
We go over each second bit in the output,
compare it to our pattern and if it finds
a bit that doesn’t match, we break out.
But if all bits would match, we would never
break out of the for loop and then this else
case of the for loop is executed.
YEP, for loops can have an else cases, which
is executed when we didn’t break.
This means we found a output bit that matches
the pattern.
But when we did that we find two matching
bits.
172 and 173.
Let’s see if they indeed are always the
same, or if we just need more data.
So I collect a few more samples so that if
indeed it was just coincidence, then the probability
that they would still match goes very low.
And when we run this now, indeed, we see now
that 173 is the magic bit.
Now we just have to keep doing that for all
OR gate inputs.
Write it down and then we get all the important
output bits.
Infact there are 15.
So we can ignore the rest.
So our goal is it to get all of these bits
to 0.
Because then the whole chain stays off, the
inverter makes it high and the door will open.
Before I mentioned anything about machine
learning, I wanted to say that what I have
is “gefährliches halbwissen”.
That is a cool german expression and it translates
to “dangerous superficial knowledge”,
you use this to describe somebody who knows
a little bit and they think they know enough
to voice an opinion, but their views or opinions
are dangerous because they only have superficial
knowledge and don’t really get it.
And that very much applies to me.
So I will not prefix everything I say with
a “sorry, maybe, I’m not sure”, and
will just tell you what is currently going
on in my head.
I’m just sharing with you the process of
me learning.
And that also means to do dumb stuff.
So I try to use the little bit of knowledge
I have and see how far I can get.
I know very well that a professional would
do it completely differently.
And in some way I’m really scared to share
my thoughts, that’s also the reason for
this disclaimer, because I’m well aware
that they are probably wrong.
So if you are a professional in this field,
I’d love to know what I got right and what
I got wrong.
And if somebody of you can make a proper model,
I would LOVE to see it.
So first of all, what kind of algorithm or
method of machine learning or AI should we
used.
Most of you probably know about neural networks,
deep learning and stuff.
And we have 32 input bits and 15 important
output bits.
That could be something that could be modeled
with a neural network, right?
Each input bit connects to simple binary functions,
ANDs and ORs and those outputs connect again
with other simple functions and eventually
result in the 15 output bits.
And I think a well modelled neural network
could totally solve this.
Basically each neuron, or a combination of
neurons could implement such a simple logical
function, and thus if we have multiple layers
it should theoretically be perfectly able
to learn that.
But if you model it like that, then you are
just predicting the output for a given input.
And that doesn’t really help us because
we don’t want to know what a given input
gives us, we can just test that already ingame,
right.
What we want is, we know the output we want.
We want the output to be all 0.
So actually what we want to know is, what
inputs lead to the outputs being all 0.
Which means we probably want to reverse the
model.
The output bits become the input of the network
and the input bits become the output of the
neural network.
So the neural network would train the theoretical
inverse of the binary function.
Given these output bits, what was the input
for it.
If that works, we could maybe ask the network
to tell us, here we have these 0 output bits,
what would the input be.
But the inverse of an OR and AND function
is not that simple, right?
For example for an OR gate you know that 0
means the inputs were 0, but if it was 1,
then one or both inputs could have been 1.
So that introduces an uncertainty and I would
hope the neural network still could work with
that, but I don’t know.
The whole magic or difficulty for neural networks,
as far as I understand, is mostly deciding
how many layers the network should have, what
kind of activation function to use and a lot
of other stuff.
And that’s exactly why I have no clue what
I am doing.
I think I could look at the activation functions
and know that for our case we probably don’t
want something like sigmoid because that models
more like analog data, and we want something
more digital, ON/OFF, so maybe a Rectified
linear unit or even binary step function,
because here certain connections can be completely
turned off - and that’s what we want because
not every input bit is connected to every
function in the real network.
I even went so far to checkout tensorflow,
I installed it and I googled for “neural
networks boolean tensorflow”, because essentially
we have boolean data.
And there was one blog post in particular,
“Solving XOR with a Neural Network in Tensorflow”,
which caught my attention, because we also
want to learn boolean functions, just something
more complex..
I and I started to adapt that code to my problem,
but then I also kinda gave up…
I think I need to do a bit more learning of
basics and playing with known simpler examples
before I try to apply this to something so
weird.
But there was another thing I wanted to try
out.
You see neural networks are just one topic,
there are a lot of other machine learning
algorithms out there.
And there is a whole subcategory about learning
rules and decision trees.
The goal [of a decision tree] is to create
a model that predicts the value of a target
variable based on several input variables.
That’s exactly what we want.
I thought maybe we can just use such an algorithm
to find exactly the binary AND and OR combinations
of input bits that lead to this particular
output.
And then we can solve that with z3
And I remembered a tool that I have seen once
called weka.
Weka is a collection of machine learning algorithms
for data mining tasks.
It’s a tool from the Machine Learning Group
at the University of Waikato in New Zealand.
To work with this tool I quickly transform
the data into an arff file format, which basically
just describes the attributes we have in our
file and splits it all to comma separated
values.
So here we can open the file and load all
attributes.
Let’s only look at one particular output
bit, so I remove the others from the dataset.
Then in the classify tab we can select an
algorithm from a list of many many different
ones.
Again, I have no clue what I am doing so I
just select one, let it run and see what happens.
As a test the output bit I selected is not
one of our final ones, it’s a simpler one,
an output state much earlier in the whole
puzzle.
There are also a lot of variables you can
control, but I have no clue so I just click
Start.
And very quickly it extracted some rules,
a decision list.
So this particular output bit is influenced
by input bit_31 and bit_12.
Let’s write this down in a table.
It basically says, if input bit_31 was 0,
then the output bit_17 is 0 as well.
Which means it doesn’t matter if bit_12
was 0 or 1 But if the input bit_31 was not
0, so it was 1, then bit_12 is important.
If bit_12 is 1, then our output is also 0,
but if that was not the case, if bit_12 was
0, then the output bit is 1.
If we draw this as gates we have an AND gate
that takes in the bit_31, but only triggers
when bit_12 is 0, so bit_12 goes through an
inverter first.
So now only if bit_31 is high and bit_12 is
low, the AND gate will put out a 1.
Cool!
So we used a machine learning algorithm called
PART to learn a simple gate.
Weka will also run this model on other data
in the dataset and you see in all testcases
this ruleset is perfect.
100% accuracy.
So that is really cool and I tried it with
one of our final output bits, which have much
more complex connections and gates going on.
That runs a bit longer and when finally a
model was found, then it’s just insane long.
It’s huuuuge.
The number in parentheses shows how many of
testcases are covered up to this particular
rule.
For the simple gate before half of all cases
were already covered by the first rule, and
the other half was handled by these two rules.
But here we have rules that sometimes have
only like 6 or 3 cases in our dataset.
So that doesn’t look good.
That looks like overfitting.
And also the test on the whole dataset reveals,
that it’s only 99.8% correct.
Which is not bad, for a lot of real life applications
it’s probably really good, but I was hoping
such an algorithm could really uncover the
logic connections perfectly.
I tried a couple of different algorithms and
weka really makes this explorative process
fun.
But again my lack of experience probably fails
me here.
Maybe one of these algorithms if the variables
are tweaked correctly could be perfect.
But I don’t know.
I gave up on this too.
Now you see I did all this over the course
of many many hours and so I was handling this
training data a lot.
And one time I thought I could checkout how
many inputs actually I resulted in a desired
0 in one of these output bits and I wrote
this simple loop.
Just print the input if the particular output
bit was 0.
I ran this and I couldn’t believe my eyes.
While the 0s and 1s were rushing by, I noticed
one column to just stayed constant.
Look at this!
And that turned out to be true for every output
bit.
Each output bit had at least one bit constant
in the input.
Now the inverse of this was not true, not
every input where this was a 1 resulted in
this output to be 0, but in every case where
it was 0, this input bit was 1.
This means, our final solution MUST have these
bits set to this constant value.
So I wrote a quick script to extract all constant
bits and this is what I got.
This really surprised me.
Every second bit was constant!
Holy shit!
This is awesome.
This also means, only 16bit of 32bit are remaining.
And bruteforcing 16bit, that’s easy.
There are just 65.000 possibilities left.
So I modified the proxy again, to instead
of just using fully 32bit random values, to
keep 16bit fixed and bruteforce the other
16bit.
And in the packet parser we can then check
the important bits to be all 0.
This means we found the valid input.
So I print WINNER WINNER and just kinda stop
everything.
So I go in game, start the bruteforce and
now we just have to wait.
I watched some TV show and came back to it
like 1:30h later and to my surprise it was
done.
It had disconnected but it found a valid input.
So here it is, this is the valid input.
Let me login again, and inject the packet
with this value.
And here we go.
Quest complete..
Blocky’s Revenge.
And the door opened.
Let’s have a look at that from the top perspecitve.
So door is closed.
And injecting the correct input packet and
boom.
Evert output is 0.
Let’s walk to the open chest and get the
“Flag of the Block”.
Oh!
And also the weapon Heap Spray!
Of course Heapspray is a Shotgun.
Haha
And here is the final input.
How beautiful.
While my machine learning idea didn’t work
out how I was hoping, I think the solution
is still cool.
Through data analysis we found that half of
all input buttons have to be fixed, and so
w reduced the brute-force search space dramatically
to only 16bit.
2 bytes.
And that was easy to do.
﻿Let’s move on to exploit-exercises stack
level 5. You should have watched the previous
videos to understand how we got here.
The challenge description says
Stack5 is a standard buffer overflow, this
time introducing shellcode.
And the hints are:
that, it might be easier to use someone elses
shellcode. That is also what we will do.
And
If debugging the shellcode, use the “int3”
instruction with the opcode hex CC, to stop
the program executing and return to the debugger.
And that is very helpful.
Ok, let’s have a look at this code. It is
surprisingly small. There is just one function
call to gets(), which we know allows us to
overwrite data on the stack.
So how do we get from no functionality of
the program, to a root shell? So put on your
wizard's hat, because we will do some magic.
Let’s open this program in gdb, and let’s
just throw a long string against it. To do
that let’s already prepare our exploit script.
So first we want to find the offset that allows
us to control the instruction pointer. I’d
like to use a simple pattern like the alphabet.
So I create this exploit variable and assign
the long string to it, and then print that.
Now redirect the output of this script into
a file, which we then can use as input for
gdb.
Before we execute the program, let’s create
a breakpoint at the return of main. And let’s
define a hook, like we have done in a previous
video. Define hook stop, and we want to display
the current instruction that will be executed
next, so examine one instruction at the location
of eip.
And then examine 8 words as hex from the stack.
And end.
Then execute it, and we hit the breakpoint
at the return. The next line shows us how
the stack looks like right now. And when we
execute the ret, we will jump to the address
that was on the stack before.
So no execute it again with the alphabet.
We are at the return again, and we can see
that we have overwritten stuff on the stack.
So now we try to return to address hex 54545454.
Which is obviously invalid, so we get a Segmentation
Fault.
And with examine as string, we can see that
we have overwritten the return pointer with
T’s.
So let’s update our exploit script.
This will be our padding. And we create the
variable eip, which we can use to control
the instruction pointer and jump anywhere
we want. And I use struct to create a binary
string from the address again. So struct.pack.
But where do we want to jump to? We don’t
have any win() function like in previous levels.
Do you have any idea where we could jump to?
I think I will give you a second to think
about this.
Right, we can just jump to the stack where
we control data. So obviously we could place
some assembler code there.
Now let’s find a good address. We could
just jump right after the instruction pointer
we control. To do that just run again, execute
the ret and have a look at the stack pointer.
So that is the address we want to jump to.
And now we have to append code that we want
to execute after the return pointer, so why
not use the opcode CC, the int3, they were
suggesting in the challenge description.
Let’s also quickly have a look at the intel
instruction reference. Let’s search for
“Int 3”.
Ok mmhh… call itnerrupt procedure. what
else do we find.
In this table about general exceptions it
calls this instruction breakpoint? Huuu, that’s
interesting.
Ok and here is the description of it.
Interrupt number 3, traps to debugger. And
down here it reads:
The INT 3 instruction is a special one byte
opcode (CC) that is intended for calling the
debug exception handler. (This one byte form
is valuable because it can be used to replace
the first byte of any instruction with a breakpoint,
including other one byte instructions, without
over-writing other code).
wooooh. What does that mean?
Well, how do you think gdb works? Or any other
debugger for that matter? How can you just
stop the CPU from executing something. Or
just step one instruction?
Actually a debugger can just use the INT 3
instruction.
Let’s make an example. We just created a
breakpoint at this ret. What we actually did
was, we replaced this return instruction in
memory with int 3. And when the CPU reached
this instruction, an exception was raised.
Or in hardware terms an interrupt got triggered,
which stopped the CPU from continuing excecuting
this and called an interrupt handler (similar
to how a syscall caused an interrupt and execution
continued somewhere else). And we can now
decide how we want to handle this exception.
And if we are a debugger we would now replace
this INT 3 instruction again with the original
value, the return instruction.
That can also be used as an anti reversing
technique. Because a regular application will
not use the CC instruction. So a malware might
constantly scan itself for the CC opcode,
and if it finds it, it knows that somebody
attached a debugger and tried to set a breakpoint.
And now we will use the CC in our payload.
So let’s append a couple of CCs after the
overwritten return pointer.
Don’t forget to write the output of the
script into the exploit file. And then test
this in gdb.
Ok run again. We can see that we stopped at
the ret and we see the address where we would
return to. And when we continue now, we pop
the instruction pointer value from the stack,
thus continue excecuting on the stack, where
we have our INT 3 instrucitons, and as you
can see, gdb stopped because it received a
signal SIGTRAP, a trace/breakpoint trap. Cool.
This way we know that we have code execution,
because we successfully injected an assembler
instruction. Now does that work without gdb
too?
Let’s try it… But we get an illegal instruction?
That is not what we should see. We should
get the breakpoint message.
Let’s open it in gdb here and try it again.
Still illegal instruction. Let’s set the
hooks and the breakpoints like in the other
gdb session.
Ok run. mhmh… The addresses on the stack
are not the same. Why are they different?
Let’s do something crazy. Print the whole
stack. I just print a thousand strings or
something. Let’s se what we get.
Ok first we have some gibebrish. Let’s go
further.
UUUh… see. Now we get some interesting stuff.
Let’s do the same in the other gdb session.
This looks like the environment variables.
For example here us the USER environment variable
that we have used in a previous programming
video. Mh and when you look at the addresses,
they are still diferent.
So let’s look a bit further down.
mh! down here they are the same. So between
here and the environemnt variables above there
mus be something different.
And when you look closely, you can see that
the PWD environment variable, the current
working directory is different. They have
a different length. So obviously the one execution
environment needs more space on the stack
to store this path. And thus pushing the stack
further up.
No wonder that the stack addresses are not
the same anymore.
So how can we cope with that? There are a
couple of techniques that you can use to get
a bit more control over the stack. For example
by removing all environment variables before
executing a binary. But there is another very
easy but effective trick. here is a hint:
nop, nop, nop, nop, nop
Riiiight… a nop slide…
Let’s just add a looooot of NOP instructions.
A Nop instruction performs no operation. And
it has the opcode hex 90.
And instead of picking a very specific stack
address, let’s just pick one that we hope
hits our nops.
So run again. Now we can see we have a lot
of NOPs on the stack. And the address we will
jump to points somewhere else further down.
If we look at more of the stack, we can see
that it points almost right in the middle
of the nops. So let’s just single step forwards.
And now we happily slide down the nop slide
until we reach the bottom with our traps!
Boom. Cool. And that also works now outside
of gdb.
Now instead of CC, we want to execute something
useful. So let’s look for some shellcode.
As the challenge description said, it’s
best to reuse shellcode from other people.
I really like the collection of shellcode
from shellstorm.
Shellstorm has a lot of different kind of
shellcode, for a lot of different system.
So we are looking for a Linux Intel 32bit
shellcode.
FreeBSD, Linux on ARM, 64bit, and here we
have 32bit.
They all have a short description and do different
stuff. But we are looking for a simple execve
that will execute a shell. So, why not take
this one.
If you look at the assembler code, what it
does is basically just pushing some values
on the stack, which are infact just a string
that is the path /bin/sh. And then calls execve.
Copy the bytes into the python exploit script
as payload and we can throw it against the
program.
mhmh… nothing happens. Does it not work?
Let’s add the CC at the start of the payload
if we still hit it.
It should work. Remove the CC againa and try
it in gdb. let’s single step. We are sliding
down the nop slide. All seems fine. And now
comes the shellcode. And it says: “Executing
new program, /bin/dash”. That first sounds
weird, but is correct. /bin/sh just points
to /bin/dash.
So why the hell does it not work?
Also on a side note. This gdb session is no
broken. Because execve, replaces the current
program with another one. So stack5 got replaced
by /bin/dash. And you can see that when you
try to execute it again. So you would have
to load stack5 again with file.
Ok. So what’s the issue then?
This is one of the things I got nuts. When
I first got stuck like this I spend houuurs
trying to figure out what is happening. As
much as I want to see anybody else suffer
like me, I tell you what the problem is.
A shell you execute, wants some input, right?
From standard input. But!. We used a program
and redirected it’s stdoutput into the stdinput
of this program. And when the program was
done it closed that pipe. So now the shell
is executed, but doesn’t have any input.
Because it’s closed. So it will just exit.
And there is a neat trick to get basically
around that. When you use cat without parameters,
it simply redirect it’s stdinput to the
standard output. See like here. You type something
in, and it get’s reflected out.
Now you can chain programs together on one
line, for example with semicolon. So we can
first print the output of the exploit, and
afterwards cat is executed, so we can enter
new input. And if we group that now with some
brackets, and redirect their combined output
into the stack level, the exploit will first
run and execute a shell, and then cat will
take over and we can simply relay input via
cat to the shell.
BAM! it works. We have an ugly shell, and
we can verify our identity with whoami, or
id.
So now we escalated privileges to root. Damn.
feels so good. It’s just beautiful.
﻿In the previous video of this series we soldered
and set up the arduino board for the riscure
embedded hardware CTF.
I couldn’t release this video earlier, because
the competition was still under way.
But now it’s over and I can release all
the solutions and show how I worked on these.
And i’m excited to take you along with me
on this journey of slowly exploring this unknown
land.
As I mentioned in the previous video, the
“secure filesystem” is a good challenge
to start, because you can learn how to interact
with the board.
And this video will be about that.
Ok, so we already learned how to flash the
challenge onto our board.
The challenges come as a .hex file.
That is a special file format which is not
really a raw binary, but has the binary data
as hex encoded strings inside.
Avrdude can read that file format and flash
the raw bytes onto the board.
This binary would usually contain AVR assembler
code, which we could disassemble and reverse
engineer.
But that would make many challenges trivial.
So this is actually encrypted and without
the secret key embedded on the board we cannot
analyse it.
So only way for us to solve this, is to load
it onto the board and figuring it out by interacting
with the board.
So when I loaded the binary onto the board,
the first thing I did was checking the serial
monitor feature of the arduino IDE. usually
you can use that to send and receive data
via the serial connection.
And it actually looks like there is some data,
but it seems corrupted.
It is not readable.
So either it’s binary data, or we have the
wrong settings.
Serial has this baudrate setting, it defines
how much time you get for each symbol, or
packet if you will.
So if you read very slow or too fast, you
will only read garbage.
By simply trying out different default baud
rates offered by the drop down menu, I got
the correct value.
And we see a list of files.
A cat.txt and also a passwd file, which probably
is our goal.
When I hit enter or other keys, it doesn’t
react, we don’t get a response or see our
keys.
I actually tried out different line ending
settings - what should be sent if we hit enter
- and we will soon learn that i just missed
the correct answer.
But at this point I couldn’t figure it out.
I thought maybe something is weird with the
arduino console, so I connect to the board
via screen.
And that also seems to work.
I get the file list.
But I have the same issue there, nothing really
happens when I write anything on the keyboard.
Before we continue, let us quickly establish
what a serial connection really is.
And then check if we actually send data or
if that is broken.
So let’s say you want to transmit the letter
A. We know that the ascii representation as
a numbr of this letter is hex 41 or decimal
65.
In binary that would be 100 0001.
A simple way to transmit this information
between two components, two devices, two circuits,
two chips, two whatever, is to simply use
7 single wires, and simply apply +5v or 0
volt depending on 1 or 0.
That would be a parallel connection.
And that one is very fast, right?
You can transmit 7 bits immediately.
But you waste space.
Another way would be a serial communication.
You could have a clocl that always checks
in an interval the state of one single wire,
and if it was high you read a 1 and if it
was low, you read a zero.
And over a short period of time you can assemble
the whole 7 bits into an ascii A.
So.
And this is basically how the arduino and
many many embedded devices communicate.
There are two LEDs on the board, one says
TX and the other one RX.
TX stands for transmitting and RX stands for
receiving.
So these are basically two wires, one allows
sending data in serial, the other one to receive
data as serial.
If you look closely, you can also see RX and
TX being available as a pin here.
So we can hook up a logic analyzer and capture
what is send over these single wires.
We connect 3 probes, one RX, one TX and one
to ground.
Then we use the Logic software to collect
a trace for like 10 seconds.
And then we very quickly connect to the board
via screen and type something and press enter.
Now let’s look at the trace.
So this one signal here is the receiving side,
and the other one is the sending side, from
the perspective of the arduino.
And you can see that it sends some data and
that it received some data.
You can also enabled the protocol decoding
and then you can actually read what kind of
characters or bytes were send in these serial
packets.
So for example here are our a,s,d that we
pressed.
And here is the start of the file list output
that we received.
And now you understand also the baud rate,
if you have the matching rate it will perfectly
read these highs and lows, if you are too
fast, your read too little, and if you read
too slow, you read too much.
So now in reality, the serial connection doesn’t
actually go from the arduino into your computer.
It’s just goes from the microcontroller,
the atmega to this chip here.
CH340, which is a USB to UART converter.
Uart stands for Universal asynchronous receiver/transmitter.
So the microcontrolelr and this chip already
speak a specific protocol to exchange this
serial data via RX and TX.
And then this gets translated into USB packets,
and the driver on your computer will make
it look like a serial interface.
When you then send serial data, the driver
will do the USB communication with that chip,
and that chip then does the uart or serial
communication with the microcontroller, which
runs code that can read that data.
So its a fairly complex system.
But whenever you see RX or TX on a pcb, it’s
very likely that it’s some kind of serial
connection, maybe for debugging, where you
can hook up a UART to USB chip.
And read it with your computer.
So now we know that sending data actually
works.
But we do something wrong.
Next I try to interact with the board through
a python script, because that allows me to
control each byte I want to send, rather than
hoping the terminal is configured properly.
I use pyserial for that.
After installing the module I can import pyserial
and setup a serial connection.
Then I can start reading bytes from the serial
connection and I also get the file list.
So that works.
And then I noticed something.
Each line doesn’t end with a simple newline,
it ends with a carriage-return and a newline.
AHA!
So I try it again.
This time I use an example line from the challenge
description and send it with python.
That example apparently can read the cat.txt
file.
Argh forgot the newline and carriage-return.
Ok, so now we can read from the serial connection.
And it worked!
We see the content of cat.txt.
That’s awesome.
Ok, so we figured out how to interact with
the board.
Each line has to end with a carriage return
and a newline.
But how we solve that challenge now will be
in another video.
So now that we know that we need a carriage
return for the line ending, we can modify
a couple of terminal settings.
I create a special keyboard shortcut with
SHIFT+Enter, which sends a special text, which
also allows us to specify escape sequences
like newline and carriage return.
So… now when we hit shift+enter we should
send these instead of just a newline.
Let’s try it.
When we now access the screen and hit shift+enter,
the board actually responds and tells us that
it’s an invalid request.
And we can even request the example files
now.
Ok, now we are all set to solve this challenge.
I was actually very confident that I know
the solution for this task already.
Like I said in another video that covered
the idea behind this challenge, it’s either
super simple for you, or super hard and mindblowing.
I wonder if you can figure out which video
i’m referring to.
﻿exploit-exercises/protostar offers a linux
image with several challenges to learn binary
exploitation. But a lot has changed over the
years and if you compile these challenges
yourself on a modern system it’s not as
easy anymore. I already showed you that in
the previous videos about the stack challenge.
I had to make a 3 part video series to explain
how we can still do it. And that also only
on 32bit. So if you are just starting out,
make sure that you use the Linux image that
you can download here and don’t compile
it yourself. Otherwise all the tutorials about
it won’t work. And now for this video, let’s
continue with some other challenge. We compile
them on a current Ubuntu version, without
any compile flags and see what we get.
Obviously the rules of the game, that is hacking,
are, that maybe there are techniques I just
don’t know about. I don’t really know
the edge cases in exploitation, I mostly know
the general techniques and I think I have
some reasonable amount of creativity. But
I don’t know everything. So it’s likely
that there are people out there that could
exploit it. In that case, I’d love to see
a PoC for that. That being said, let’s continue
with format0.
So what is this challenge about? The attacker
can pass in an argument, that argument is
then being passed as the string variable to
the format parameter of sprintf. So we can
inject stuff like %d or %s.
It’s also vulnerable to a buffer overflow,
because sprintf, does not print to the console,
to stdout, like regular printf, but prints,
or stores the formatted string, in buffer.
And the buffer is only 64 bytes long.
Now when you attack this on the VM that you
can download here that has these challenges
precompiled, the target variable would be
placed after the buffer so that you can overflow
the buffer, and write into target. And then
you have target modified and when you make
it so that it’s overflown with 0xdeadbeef
you pass this check.
So enter 64characters, and 0xdeadbeef and
you won.
But the challenge here also said, try it with
less than 10 bytes. And you would do that
by abusing format string modifiers that would
stretch the formatted output to for example
64 characters, and then you can simply enter
0xdeadbeef afterwards. So for example %64d
would output a number with a up to 64 character
padding. And so 64 characters plus 0xdeadbeef
are written into buffer and you win.
Well is that still possible?
First we have to install gcc and gdb on this
fresh maschine and I’m also going ahead
to install peda, a gdb extension that makes
things look nicer.
So let’s start with the simple buffer overflow
example. But first let’s set a breakpoint
in vuln() before we compare deadbeef. Then
let’s start the binary and pass in an input
that is much larger than 64bytes. Okay.
So we hit the breakpoint and it compares eax
with 0xdeadbeef. But eax is 0. How can that
be? Didn’t we overflow the stack?
Well, we certainly did, the issue is that
the target variable doesn’t come after the
buffer. It is before, so we can write as much
data as we want, we won’t overwrite target.
You can also see this here. Eax is loaded
from base pointer - 0x54, while the address
for the string is loaded from basepointer
- 0x50, so it’s located after target.
Well does this mean it’s not exploitable?
mmhh... So if you are familiar with format
string exploits, you also know that you can
write data with it, by abusing the %n modifier
which writes the amount of already printed
characters to an address on the stack. And
we can overflow the stack, so we could place
an address there and then carefully construct
the number of characters printed before, such
that it writes 0xdeadbeef to an address. And
so we could write to target, and win that
way, right?
But ASLR is our problem. Let me add a printf
to the code to print the address of target.
ampercant target returns the reference of
a variable, so that’s the address.
And when we compile it and run it in a nice
while true loop, you see how crazy the address
of target changes. Target is a local variable
so it’s located on the stack. So this is
also a stack address.
But how much does it change? It always starts
with 0x7ff and ends in a C. And this one nibble
here only appears to be C,D,E or F. That’s
a huge number. It’s over 1 billion. but
maybe in this case actually doable. Just takes
some time. Maybe a day or so. I just like
to refer to the previous three part video
where we bruteforced a 3 byte stack cookie,
that was roughly 16 million possible options.
And so here, 260 million, is in reach, I would
say. At least for a very small binary like
this. The execution speed is quite fast.
Let’s see how it looks like on 32bit. We
have to install the gcc multilib to do that.
And then we can compile it with -m32.
When we execute it a few times, you can see
that it obviously has less randomness than
on 64bit. It’s only two full bytes and then
again a nibble. That’s about 1 million attempts
to hit it. So definitely even more in reach.
But of course it’s only feasible if you
can do millions of attempts reasonably fast,
for example locally. If this were an application
that takes longer to start or a remote service,
then that would probably mean you couldn’t
really do it.
How to create a format string exploit and
how that exactly works with %n you can watch
in multiple other videos that I have done.
But there is one additional trick that comes
to mind we could look out for. So to write
with %n we expect the target address to be
on the stack. In a classic format string exploit
you would use your input that is maybe also
placed on the stack and reference itself.
But nobody says it has to be an address you
place there, the stack is full of values,
maybe you get lucky. If we look on the stack
when we are at the 0xdeadbeef compare in the
execution flow, you can see a lot of stack
addresses. And so these would always be valid
stack addresses even with ASLR. Now if one
of those would magically point to target,
then we could just reuse it. We could just
reference that address.
But if we check the address we know of target,
we can see that it doesn’t show up. Oh well.
But you see how creative you can get with
exploitation. We could have been lucky.
But let’s actually continue that train of
thought.
Ok we don’t have the whole target address
on the stack, but we do have a lot of other
stack addresses. And we have an overflow,
so we can overflow into the addresses. And
just overwrite some low bytes and keep the
whole front.
Let’s add another printf to print the target
value. And print the resulting formatted buffer.
And let’s play with that. Here you can see
the sprintf formatted result.
Let try to find AAAABBBB on the stack by consuming
values from the stack with someformat modifiers.
I wanna find the offset where on the stack
this value is placed, and we can explore that
with %lx and the dollar notation.So at stack
offset 1 it’s not, at offset 2 it’s not
at offset 3 it’s not. And so forth. But
here at offset 9 we now printed the hex value
of our input.
Now let’s look at the stack layout for a
nice stack address we could partially overwrite.
Ok so down here is one, let’s see what offset
that has. Let’s keep going.
There it is, at offset 19.
Which also means from the start at offset
9 to offset 19 we have 10 groups of 8 bytes,
so 80 bytes to fill and reach this value.
We can achieve that with a format string that
pads a number to 80 bytes, and then some input
to proof that we overflow.
And when we now execute it, we see that the
end of our address that got printed by our
19 lx, got overwritten with As.
If you paid attention you saw that target
is always at an offset with a c, so we can
choose some input that ends’ with a C as
well to overwrite it. For example L, that
is 0x4c.
Let’s execute that now, and you can compare
what address we got now through the overwrite
with L, and what target really was. You see
that often it’s not the same, but eventually,
it will match.
And so if we replace the %lx to print a 8
byte hex value to %n, then we will WRITE to
that address.
So now we are writing the amount of printed
characters, 81, because 80 + the single L
to this address. And maybe at some point we
hit target. Let’s keep trying.
BOOM! There we hit target, we wrote 0x51 to
it, which is 81 in decimal. And that works
fairly reliably, we can try those few attempts
by hand.
And I think that’s awesome, unfortunately
it’s not quite the solution, because target
has to be 0xdeadbeef. And that’s 3 billion
in decimal. So with this technique we would
have to first print 3 billion characters before
we can do %n, and that’s not possible.
Anyway I think you can see how much exploitation
can become a puzzle that you slowly try to
piece together. In the end I didn’t manage
to solve it but exploring this was really
fun.
I really wonder if somebody is able to make
a semi reliable exploit for this.
﻿We have already had many episodes where we
read assembler code and reverse engineered
how a program works.
And we even have written our first exploit
by using a buffer overflow vulnerability in
a program written in C.
In this episode I want to show you how you
can learn how to read assembler produced by
C code yourself.
The idea is simple.
Just write some C code with different C language
features, and then look at the assembler code
that is produced by compiling it.
This is often part of normal research.
For example listen to what Ian Beer from google
project zero says during a talk about his
research on Inter Process Calls on OSX.
One approach to reversing, or to understanding
how this kind of thing works would be to sit
in IDA and just reverse the serialization
and deserialization code, and slowly build
up a picture of how it works.
But another kind of quite nice way to do it,
is just, write a test program to send little
messages and then find the right place using
lldb to break and just start dumping hex.
So, because he had to understand a fairly
complex data structure, he simply wrote a
test program to analyse it, instead of reversing
a full application.
Or there was was a talk and paper from blackhat
USA in 2007 about how to reverse C++ programs,
by looking at C++ concepts and how they look
like in assembler.
So now I have created three different C code
testcases and you can find them in my github
repository, or just write it yourself.
One is about variables and datatypes.
One is about function calls.
And one is about control flow stuff like loops
and ifs.
So let’s start with the variables.c.
First thing I want to point out are those
triple Xs.
Those triple Xs are defined as an assembler
NOP instruction.
The reason for that is, later when we look
into the disassembly, we can find those NOPs
which are separating our tests, and that is
pretty neat.
So this makes it easier to see which line
of C Code is responsible for which lines in
assembler.
I will not go over every single test, this
is something you could do yourself.
Simply pause the video at certain points or
clone the repository.
Anyway.
Let’s get started.
First of all you can see here a couple of
simple numbers.
First we define a couple of numbers.
Unsigned and signed, integers and floating
numbers.
And different sizes with uint32 or uint64.
The latter is important, because normal Integers
might have a different size depending on 32bit
or 64bit, so it can lead to bugs.
So better use datatypes you are guaranteed
to get a certain size.
If you want to learn more about how to program
C properly, there is a great blog entry called
“How to C in 2015”.
After that we create an array with 32bit unsigned
integers, and we access one element of this
array.
Then we look at a single character.
And then also a string.
And maybe you know that a star * means “pointer”
in C. So we define a variable that is pointing
to a string.
I have added a Makefile, so you can simply
type `make` into the terminal to compile all
files.
Or make clean to remove the binaries.
This will create a 32bit and a 64bit version
of the variables program.
But as you can see, I get an error trying
to compile a 32bit version with -m32 in this
64bit machine.
So I have to install the 32bit libraries first,
to be able to build the code.
After installing those, the build works fine.
A Makefile is just a little script that defines
how a project has to be compiled.
So let’s open the code, 32bit and 64bit
version next to each other in gdb and disassemble
main.
And also open the code.
Ok now let’s look at the first integer examples
with negative values and signed and unsigned
values.
First of all, all those local variables are
stored somewhere on the stack, you can see
that because they are referenced relative
to the base-pointer.
Then you notice that the assembler code doesn’t
know negative numbers.
They are fff something.
If you are interested how negative numbers
are displayed, watch my 10th episode about
numbers.
And also there is no difference between variables
that are signed or unsigned.
But there is one difference between the 32bit
and the 64bit code.
Because we defined one number to be 64bit
long, but on 32bit the registers are only
32bit.
So if you want to write full 64bit, you have
to write two times.
The floating point numbers are also interesting.
Because they got stored somewhere else in
the program.
And that value is then moved into the local
variable.
The array is also interesting.
We created an array with 10 values but only
set the first 5 values to a default value.
As you can see those values are stored on
the stack.
And then it is moved from that location on
the stack to the real array location.
Instead of writing it directly to the array
it does it this way.
No idea why.
And you can see down here when we reference
the 3rd entry.
So you can see that this is the real location
of the array on the stack.
Next come the strings.
You can see that a character is just a byte.
It doesn’t matter if we have an unsigned
int with 8bit or a char.
It’s the same.
And strings are also referenced over an address.
So the local variable is not an array of charactes.
the local variable contains an address pointing
to a string.
Now let’s have a look at the control_flows.
Open it in radare.
Analyse all, seek to main function and enter
Visual mode.
First we set a variable to zero.
And then comes the if.
This is done by loading this local variable
in a register and comparing to hex ff.
And then jump if it was less or equal.
So you can see which branch it may take.
Then comes a while loop.
We load the local variable again in a register,
compare it to a value, and either jump inside
the block or leave.
And inside the block we load this value again,
increment it and write it back.
Now compare it to the foor loop.
It’s basically the same!
We start by setting the variable to 0.
Then we compare if the loop condition is still
true.
And inside the loop block, we can see our
NOP.
And at the end of the block we increment the
variable by 1.
Exactly the same like the while loop.
So you can see that a for and a while loop
in C are basically the same.
Next let’s have a look at how functions
are called.
Again open both the 32bit and 64bit version.
First thing you notice that the 64bit version
moves a 0 in eax.
No idea why.
Otherwise the function call looks the same.
Except look at the addresses.
If you have no ASLR, then 64bit code is generally
at hex 40 something.
While 32bit code is at hex 80 something.
Knowing stuff like that is helpful, because
if you see an address with 40 something, you
know immediately that it’s pointing into
your code.
So the next function returns a value and we
save it in a variable.
And you can see that in both cases, the value
is taken from the eax register.
Ok, so apparently return values are handled
via eax.
Now function 3 is interesting, because we
pass a parameter to it.
In 32bit you can see that the value is loaded
from somewhere and then stored on top of the
stack.
And then the function is called.
But on 64bit we see that the value is loaded
into the edi register.
This is our first big difference.
Functions in 64bit seem to be called with
parameters in registers, while in 32bit the
parameters are stored on the stack.
Next function uses 2 parameters.
And again, you can see how 32bit just places
the value on the stack.
First parameter on top of the stack, the second
a bit further down.
But in 64bit you can see that it uses esi
and edi for that.
Now we get curious.
What does 64bit do when we have so many parameters,
that we cannot keep them all in registers?
First of all 32bit code again.
You can see how the parameters are stored
on the stack.
And the first parameter is on top of the stack,
and the last value moved.
That’s what we would expect.
In 64bit we can see that the first couple
of parameters are stored in registers edi,
esi, edx, and so forth.
But from the 7th parameter on, they get stored
on the stack as well.
Awesome!
Now you can identify all kind of different
assembler patterns.
You don’t need a decompiler all the time.
You can do this all in your head.
And when you reverse more and more programs,
those patterns become more easy to recognize,
and you will not feel overwhelmed again with
the mass of weird instructions.
You will be able to scan over a function and
say: “ah here is a local variable.
Then calls this other function with this variable
as parameter.
And the return value is used in a loop”.
And you can use the same method to understand
how different disassemblers like hopper, radare,
gdb display code.
Or for example how different the at&t assembler
syntax is from the intel syntax.
I hope you have a lot of fun next time reversing
a program.
﻿What does iOS 9.3 and the Nintendo Switch
have in common?
They both use the browser engine WebKit with
a version that is vulnerable to a known memory
corruption vulnerability.
Remember the news of the pegasus malware for
iOS, which was discovered when it was used
in a targeted attack against the human rights
activist Ahmed Mansoor?
That malware used a webkit exploit as the
first stage, to gain arbitrary code execution.
Qwerty and the pangu team then used this bug
in their jailbreakme website.
And it turns out, the browser of the Nintendo
Switch is so old, that is also has this bug.
And this is what a lot of people are using
right now as a first entry point in hacking
the switch.
Obviously the whole jailbreak is extremely
complex, even just getting code execution
is insane.
But I spent now quite some time understanding
the bug itself and the first crucial part
which creates an arbitrary read/write primitive.
So you can overwrite anything in memory, for
example function pointers or jitted code.
But let’s start at the beginning.
<intro>
First we need to figure out how to access
the browser in the switch.
You may have heard that the Nintendo Switch
doesn’t have a browser, so what the heck
am I talking about?
Well there is no good browser implemented,
but it turns out, that when you connect to
a wifi, which requires you to login in a captive
portal, it will use a browser view and load
that page for you.
A captive portal is common in hotels and airports
and stuff.
So we have to figure out how to load our own
website here.
When you look at the network settings, you
can specify a proxy server, which is great
because then I can run a proxy server on my
laptop and intercept all the traffic.
I use Burp Suite as my proxy server and just
have to make sure it listens on all interfaces,
so other devices on the same network can use
it.
So now we just have to enter the IP of this
laptop into the proxy settings of the switch.
When we now connect to the wifi, the switch
will establish connections through this laptop.
And we can see here in the Burp history view,
that the switch tried to contact conntest.nintendowifi.net
That site just responds with a simple string
that the connection works.
It uses this to check if you have internet
connection or not.
So, if this check fails, it will think you
first need to authenticate from a captive
portal.
So next we need to redirect this request to
a different page, basically our “captive
portal”.
We can do that by simply modifying the /etc/hosts
file, to point the conntest domain to another
IP.
For example localhost.
Then we spawn a simple webserver on our machine,
for example with php -S.
We can place a index.html file in here to
verify that this works.
And with a browser we can see that we have
now on localhost a webserver running.
So, when the switch now connects to the wifi,
it will try to contact conntest and it will
go through the proxy on my laptop.
My laptop sees in the /etc/hosts file what
the IP for conntest is.
So the proxy will connect to localhost instead,
which will access our index.html file.
Let’s try it.
We search for the wifi.
We connect to it.
It will check if there is access to the internet.
It didn’t get the expected result for conntest
back and tells you you have to login.
When we now press next, it will load what
it thinks is the captive portal.
Now we have access to a browser that loads
our website.
We can also have a look at the requests in
burp, which shows us the User Agent the switch
uses.
So now that we have that setup, let’s read
up a bit more on the webkit bug.
It was assigned CVE-2016-4657 and has the
description: “WebKit in Apple iOS before
9.3.5 allows remote attackers to execute arbitrary
code or cause a denial of service (memory
corruption) via a crafted web site.”
The description can be a bit misleading.
Makes it sound like it’s only an iOS issue,
but its generally a webkit bug, and would
affect anything that used that particular
webkit version.
In our case the nintendo switch.
Also this is not an exploit where you just
type into metasploit `use exploit/nintendoswitch/webkit`.
This is something where you actually have
to understand it quite in depth to be able
to use it.
Now let’s take qwerty’s jailbreakme code,
which uses the webkit bug, extract the first
relevant part and adapt it to the nintendo
switch.
I won’t go through all this process because
that took me ages to understand, but I want
to show and explain to you what I got now...
So let’s walk through it.
First we create a Typed Array of unisgned
32bit integers.
And in memory this will create a struct with
a couple of different values such as a JSCell
which contains a couple of interesting values
such as a structure ID that determines kind
of the type of this object.
We will look at that later again.
A butterfly pointer, which is used in a bit
more complex objects but not quite relevant
for us right now, a vector which contains
a pointer to a chunk of memory that represents
our array.
And the length of that memory.
So that array gives us basically access to
raw bytes in memory.
Obviously you can’t access beyond it’s
length.
Then we create a more flexible array.
A standard array like you might use it.
That array is a bit different, as it can contain
arbitrary types.
Any kind of objects.
So instead of just pointing to raw memory,
it points to more complex objects called JSValues.
And here is an example of the integer with
the hex value 41414141, it would store 0xffff0000
before it, to indicate the value is an integer.
Look at the amazing phrack paper if you want
to know more details about these JSValues.
In the case of the exploit it will set the
first element of the Array to a big ArrayBuffer
and the second to some number.
An Array Buffer is also access to raw bytes.
Basically different typed arrays can point
to the same buffer in memory.
Whatever, read the javascript reference.
So If I’m not mistaken, the first element
of the array is now a JSValue with a pointer
to an array buffer.
Next we create a simple Javascript Object
and overwrite its toString() function.
That function is called whenever you want
to get a string representation of that object.
So if I return 1337 object as a string, and
I would alert this object, it would call to
string and show me that one.
But in this case the function does a bit more.
It first sets the reference to the array we
just created to null, as well as setting another
property to null.
In a second you will see that this “stale”
property is also a reference to the arr array.
Theoretically now all references to the array
are gone, and the garbage collector can free
that array.
To force the garbage collector to kick in
right now, we can use the function which just
allocates and removes a lot of objects.
And when you do this a couple of times you
can be fairly certain that the garbage collector
did the work.
After the garbage collection the function
will now allocate a lot of new Uint32Arrays.
The reference to those are stored in buf,
so we can access those arrays.
And if everything goes well those arrays might
be allocated where the previous array was.
But how is this object with that toString
function used now.
We define an object that we use as properties.
And I think we allocate more than just two,
so the properties are not stored inline, but
I’m not 100% sure here.
Anyway, one of these properties is called
stale, and it is set to the array reference.
That is the property that the toString function
will set to null.
Another property is `length` which is set
to the not_number object.
Then we create a new empty array target and
apply those properties to it with Object.defineProperties.
This means all those properties we defined
will be set to the target array.
During this assignment, the toString() function
of not_number will be called and causes the
garbage collection of the array.
As well as the allocation of a lot of Uint32Arrays.
And this is where the bug happens.
Theoretically the stale property was set to
null, and should not be accessible.
But somehow the reference is still there.
Some stuff internally did not properly check
everything.
This means that we have a reference into some
memory where previously the arr array was
allocated.
And we also allocated a lot of Uin32Arrays
and we hope that these now overlap.
As I mentioned earlier, the Uint32Arrays allow
direct memory access, they can read and write
raw bytes.
While the arr array was a complex object,
with JSValues.
Now it’s already clear what you can do with
this.
You can use the Uint32Arrays, which are accessible
via buf.
To read and write raw bytes at the location
where the stale property thinks a standard
Javascript object is.
So first it has to find if and how the buf
and the stale array overlap.
To do this, we can simply add a number to
the first element of stale.
But what is the first element of stale now.
Isn’t that garbage memory?
well ideally, if everything works, it points
to where we created the uInt32Arrays, and
we populated that memory region with 0xffff000041414141,
which is a JSValue representing an integer.
In fact the number 0x41414141.
This means that now we add hex 101 to the
first element of the stale array, making it
0x41414242.
We can then simply search through the whole
uInt32Array memory looking for this 0x41414242.
Keep in mind that the buf has access to raw
bytes, so it will infact see the 0xffff0000
and the 0x41414141, while the stale array
things this is a javascript object, and only
uses the 0xffff0000 internally to determine,
that we have an integer and the value of it
is 0x41414141.
So what can we do with this now.
This is where exploitation really become creative.
The phrack article says that once you have
the ability to craft arbitrary javascript
objects, you could craft a Float64Array to
create a read/write primitive, but qwerty
used a Uint32Array.
To quote him, here is his reason:
“Easier than float to do math with.
Lol.”
And I guess he has a point.
Floating point values in raw bytes are really
annoying.
So first of all, why do we want to craft a
Uint32Array.
If you remember the basic structure of a Uint32Array,
it uses a vector to point to some raw memory.
If you control where this pointer points to,
you can control where you can read data from
and write data to it.
Because it thinks it points to the actual
array.
There is a super clever way how to craft this
array now.
Qwerty creates a new object with four properties.
A,b,c,d.
He probably just took that from the phrack
article, because when you look at how a simple
object with only four properties is stored,
it stores the values inline.
This is very helpful in a second.
As you see, the values set, like the hex 1337
are simply placed here in memory after eachother.
So that’s a very neat way to control a couple
of consecutive values in memory.
The two 64bit values are the JSCell and the
butterfly pointer.
The JSCell, or more specifically the structure
ID inside of the JSCell determines, what this
Javscript Object actually is.
In the phrack article it looks like, this
object here has the ID 136.
So in order to craft a Uint32Array, we would
have to know the structure ID of that.
According to the phrack article, this ID can
change sometimes, maybe at restart or between
different webkit builds.
But apparently it’s very common to be 105.
Nontheless, because my exploit was very unstable
I tried to see if the value is maybe different
and the phrack article shows a technique how
to do that.
Back to the new object for a second.
So this will allocate a new object with 4
properties that looks like this in memory.
0x69, or in decimal 105, then zero, the pointer
to the smash array, which we allocated way
at the beginning and 0x100.
The function u2d is a clever little helper.
As every number in javascript is basically
a float, we can create a new dataview of 16bytes,
so 64bit, set the high and the low 32bits
and return the float representation of those
bytes.
This new object creation will also overwrite
stale[0].
Just a few seconds ago I mentioned that stale[0]
points to a JSValue representing a number,
but now it was overwritten with a JSValue
representing a pointer.
A pointer to the JSObject that was just created.
This JSObject it points to is not very interesting
for us.
It’s not an arbitrary object we have crafted.
But remember, that the JSValue with the pointer
to this object is in the memory that is overlapped
by the buf.
This means we can use buf to manipulate the
pointer.
And what we do is, we add 0x10 or decimal
16, which moves the pointer into the properties
of the JSObject.
Now suddenly the 0x69 is the JSCell value.
And the zero here is the butterfly.
And the smsh address becomes the vector, the
pointer where the actual array is in memory.
To be clear this points into the similar struct
of that array, so this doesn’t point into
the memory location of that smash array, but
also into this JSObject struct with its vector
pointer and its length.
And 0x100 is the length of that array, which
is actually just the Object structure of the
smash array.
So now you know how we can misalign the pointer
to this object, which will interpret the properties
here as the actual object.
This means we can now try different structureIDs
in a loop and check with instanceof if we
have crafted a Uint32Array.
We remember the original stale[0] pointer
in stale[1], then missalign stale[0], then
we can check the type of the stale[0] object,
if it’s not correct, we increment our structureID
guess, and assign a new value to the stale[1]
‘a’ property, which will look like the
StructureID from the missaligned pointer in
stale[0].
What we basically created now is, we have
two pointers in stale.
Which slightly overlap in memory.
We also have somwhere an array called smsh.
We have also set the memory location for our
crafted array, the vector pointer, to point
to smsh.
To the smash structure, not the actual memory
location of the smash array.
This means we have another object that we
can fully control.
Stale is an array.
The first element of stale points to a crafted
Uint32Array.
So when we access the elements of that array,
we obviously access the 32bit values of the
smsh JSObject structure.
And as you know, the object contains 64bit
values, and the fourth 64bit value is the
length of the smsh array.
So stale[0] of [0] and [1] would be the first
64bit, 2,3 would be the second 64 bit, 4,5
would be the third 64bit and 6,7 would be
the 4th 64bit.
So with stale[0][6] we can overwrite the length
of the smash array.
And we can now check the length of the smsh
array.
Let’s try this on the switch.
We load the page and it might not immediately
work, but it will refresh and try again.
Ok so we triggered the bug and we found overlapping
memory by looking for the 0x41414242 value.
Now we check the current length of smash,
we craft our object, try to find the structure
id, we actually find it’s 105, so I didn’t
have to go through this trouble of iterating
over them, then we change the length of smsh
and print the smsh length again.
And it changed.
Isn’t this crazy!
So now we can just modify the vector where
the smash array points to in the exact same
way, and then simply read the raw data it
points to from the smsh array.
or write to the smash array.
It gives us super simple access to the whole
memory of the process.
Next steps could be to find the address of
the browser binary in memory to dump it.
Maybe find some function pointers in memory
you can overwrite, create a ROP chain or maybe
even shellcode because we should have jitted
code, I guess?
This video is already crazy long.
So let’s stop here for now.
I really learned a lot working through the
first part of qwerty’s exploit.
I hope this this also gives you a sense for
how frckn complicated these modern memory
corruption exploits are and what kind of work
and knowledge is required to do them.
I only scratched the surface here.
I hope this also increases your respect for
the people who do this kind of research.
At this point I also want to thank Retr0id
and Ando who I just met on IRC and were in
the same boat as me and we and we helped eachother
trying to figure how this works.
And also a huge thank you to qwerty, who answered
a lot of my noob questions and shared his
progress with me.
I really appreciate you supporting somebody
who tries to learn this!
If this sounds like fun to you, make sure
you read the phrack paper by samuel groß,
or saelo about “attacking javascript engines”,
which gives a way more in depth insight into
how this works.
There is also another article more specifically
about firefox, which is different from webkit,
but also gives you a better idea of how browsers
w ork.
Thank you very much, keep on hackin’ in
the free world, and doot doola doot doo.
﻿Welcome to LiveOverflow. Here you can find
videos about computer internals, with a focus
on hacking and security concepts. I also record
myself solving hacking challenges - it might
be a bit boring to watch, but if you always
wondered how other people work and think,
it might be interesting for you.
Now let me tell you a short story about why
I am doing this here.
I was too young in the 90s and didn’t exist
in the 80s to be part of the seemingly golden
age of the hacker culture. When I was a teenager
I loved taking apart electronics and looking
at the green circuit boards wondering with
what kind of magic it is imbued with. Once
my dad brought home our first computers and
we got access to the internet, I found myself
being fascinated with “hacking” and wanted
to learn more about it. But all I found was
crap, people trying to sell old information
or fake products. So I never got into hacking
until much later. I started programming in
Visual Basic and made my first websites with
html. Eventually I moved on to php and other
programming languages. Some years pass and
I moved out to another city to go to university.
One day I was sitting in front of my computer
coming across this hacking game by stripe.
A CTF where one level was to exploit a buffer
overflow. I knew what a stack was. And I was
able to read simple assembler code from university
classes. But not until I saw the shell popping
up, my mind being blown and struck in awe,
I realized I was at a position in life where
I can pursue a dream I had as a kid. And I
still wear the T-Shirt I got from the stripe
CTF with pride. At the same time I had the
opportunity to join a hackerspace where I
met so many intelligent people and I went
down a rabbit hole.
Not many years have passed since then. And
I still feel I have only explored a tiny fraction
of what is out there.
The content I am creating here is an attempt
to give anybody who want’s to understand
the world better, an opportunity to start
somewhere. I want to give to others, what
I wish I found when I was a teenager sitting
in the basement typing into google “how
to hack”.
At the same time I see more and more people
making tutorials on how to use certain hacking
tools, rather than explaining the underlying
concepts. I understand that it looks cool,
and that you can feel very powerful. But there
is more to hacking than that.
Understanding concepts, understanding how
your phone and laptop do stuff, understanding
on a technical level how you are able to watch
this video right now. That is amazing. There
is so much awesome stuff to discover and break.
So I invite you to join me on this adventure
and “Hack the Planet!”.
﻿Now that we solved the photomanager challenge
in the United Exploitation area, I thought
about checking out casino.
Should also not be too hard with 150 points.
Welcome to our casino, Riscure Roiyale!
Please enjoy your stay by playing a game,
or drink something at our bar.
Reach 1000 credits and you will be rewarded
with a special prize.
We have seen loads of cheaters lately, so
we have extra guards walking around.
Do not feel threatened by them, they will
only kick out the people that cheat.
Of course, once you earn a lot of money, they
will start investigating the matter.
Better spend some money at our bar if this
happens.
PS. we all know casinos are scams.
As you know I’m hanging out on the rhme2
IRC channel and I wittnessed a conversation
some time ago by somebody who worked on the
challenge and asked if it’s possible to
just reach the 1000 credits through playing
and just getting lucky.
But this person also said they tried running
it for days(?), I think.
And didn’t work.
So while it’s not a real spoiler, it does
safe us some time to not explore that path.
You could have also come to that conlcusion
reading the PS, but it’s not that clear.
Anyway, lets flash the challenge on to the
board with avrdude and connect to it over
serial with screen.
Welcome to the caison!
Get a currecny of 1000 and we give you the
secret key.
That’s what we want.
Occasionally we give away coupons for free
drinks.
We have guards walking around, looking for
cheaters.
Don’t get caught cheating.
Or we will take our curreny back.
Currently we got 50 credits.
And no coupons.
And the menu offers to play, to cheat, go
for a drink at the bar, request some free
money or restart.
When we pick Play, we can choose between roulette
or spin the wheel.
If we pick roulette we can enter a number
and in this case I entered the wrong one,
the ball landed on 28, and we lost.
And we are down one credit.
If we spin the wheel, it seems like we have
a chance to win the secret key, and I guess
that’s what the person on IRC just tried
to do over and over again for hours.
But, casions are a scam, right?.
But we did win a coupon.
Awesome.
Let’s try roulette again.
Nothing.
And obviously if we pick cheat, we get kicked
out.
So let’s start over.
Spin the wheel.
And oops, we lost all credit.
But when we ask for free money, we get another
50.
Maybe we can just get up to 1000 this way
;)
Let’s request more money.
Ah. only lets us go up to 550.
But that’ already pretty awesome.
So let’s go playiiin… spin the wheel.
Won 10.
If we keep goign like this we get to 1000
for sure!
Another coupon.
Maybe lets go for a drink at the bar.
We can type in our drink now.
Club Mate of course!.
We hand in the coupon and get that drink.
So here we have some string input, that’s
definetly something to consider exploring
further.
Without a coupon it seems to only offer us
milk or beer.
So let’s pick the only viable option.
Beer. didn’t do much.
So mhmh… if we cant get 1000 by just playing
and getting lucky, the only interesting input
so far seems to be going to the bar if we
have a coupon.
So let’s write a script to explore that
input further.
So this is the menu structure.
To choose a drink we need to get a coupon.
So upon starting it up, we read the menu until
its done with printing it, then we select
play, and we read until the menu is finished
with printing.
Then we spin the wheel, and with a bit of
luck we get a coupon.
when we try that now it seems to work fairly
well, but we can have bad luck and loose all
credit.
We could also see what happens if we succeed
with the roulette.
So let’s change the menu selection to roulette
and pick a number and try that over and over
again until we hit it.
Maybe that can give us a coupon, by only consuming
1 credit for each spin and we don’t loose
everything like with the wheel.
So we make a loop to try it over and over
again, until we read that we have now one
coupon.
Let’s let it run, aaand yes!
That works.
So we can now add user input, so we can then
play with the drinks at the bar.
Ohh that works.
Cool. so let’s see what happens if we enter
a lot of AAAAs.
It looks like there is limited space, as you
can see the echoed back As are way less than
what we entered, also we don’t get an error.
So let’s do that again, but this time enter
a different payload.
Always when a program prints out user input,
you should try out format strings.
So let’s enter some percantage x.
And what a surprise!
We print some numbers.
This worked!
And if you decodde those hex values you will
see, that it’s the input string we entered.
The %x itself.
To leak data with format strings it would
be cool to place an address into our input,
and then use %s to use that address as a string
location.
This way we could dump the whole memory.
So let’s enter some recognisable characters
and see where they are.
And it’s easy, the start of our string is
already where the format parameters will be.
So the first x printed AB, and the second
x printed CD.
If we now use %s instead, it will use hex
4142 as an address and print the string at
that location.
AHAH!
AB and CD are already valid string locations.
And by sheer luck we already hit a string
in memory.
The guards are keeping an eye on you.
That’s awesome, so this definetly works,
now all we gotta do is create a loop that
simply tries to print as many strings as possible,
but tryiong different addresses.
So let’s create a loop, that simply counts
up all the addresses.
And just leak strings from everything.
I guess it’s best if we do it this way.
We open a new connection, than we first try
to get a coupon.
So we spin the roulett multiple times.
If we succeed we continue to try out an address,
and then repeat.
Also I add some code to really extract the
leaked string, and then we can move the address
forward based on the length we leaked, so
we don’t like read the same string at different
offsets all the time.
It’s faster this way.
Oh and we also know that AB and CD were valid
addresses that leaked strings, so let’s
use that as a start address.
And in case we run out of credits and didnt
get a coupon, we just reset the game again.
So let’s run it.
This looks really good.
We leak all those strings awesome.
But In let it run for a bit and never saw
a flag.
And decided to maybe it’s betetr to start
from the beginning.
So I et the start address to 0101, because
I didn’t want to have nullbytes in the string,
so that’s the first valid address, and suprisingly
there it is.
We found it almost immedaitly!
Awesome.
So let’s hand in the flag!
Casino solved!
﻿Let’s continue with our project reverse
engineering the protocol of my air conditioner
remote.
Last time we implemented our own poor man’s
logic analyzer, this time we will use something
more advanced.
last time we tried to log the digital output
with an arduino and serial communication to
the laptop.
Though that was a little bit too slow.
We could try to speed up the implementation,
by for example not sending text via serial
in every iteration, because that is slow.
We could do this by implementing a buffer,
an array, that always saves 100 samples and
then pushes them out.
But I want to show you a real logic analyzer
this time.
This is the Saleae Logic Pro 8.
This is a professional analog and digital
logic analyzer.
let’s hook this one up to the circuit and
collect samples.
So this one can collect a lot of signals in
parallel, but we only need one.
in this case we connect the black ground wire
to the ground pin.
It uses these precise hooks which can be easily
attached to a pin.
And the orange wire goes to the data-out of
the ir receiver.
The arduino is only still connected because
because we use it for the 5volt power supply.
Then we connect it to the laptop and launch
the Saleae Logic application.
With the big green button we can configure
the device.
We can select the sample rate, the speed it
collects data points with.
So for exampel currently it would collect
500 million samples per second of digital
data, and 50 million samples per second analog
data.
In this case our orange cable was channel
number 3.
And we can also specify to only log for a
tenth of a second.
That should be enough.
But, we really don’t need to collect such
a crazy detailled trace.
We can select a way slower sampling rate.
Like with our arduino we can now define a
trigger.
We want to trigger the recording only when
the input drops to LOW.
Because then the IR receiver saw infrared
light.
Let’s try it.
Start.
Waiting for trigger.
Pressing a button on the remote.
And boom.
There is our collected trace.
So first of all you can see two traces of
channel 3.
The top one is the digital trace, the bottom
one the analog trace.
So what does this mean?
Let’s zoom into one of the edges.
Ok, you can see that the top channel always
has a sharp vertical edge down.
Because in digital logic there is only 1 or
0.
But in the analog world we meassure voltage
and we can see that we meassured almost 5V
at the start and then over roughly, maybe
5 microseconds the voltage slowly dropped
down to basically 0 Volt.
In the real analog world obviously voltage
doesn’t drop immediatly, it takes a short
amount of time to drop down.
And when it dropped under roughly 2.5V, the
logical interpretation is then a 0.
And you can see how many sample points this
device can collect.
We have here, I don;t know, hundreds of collected
points per peak, while with the arduino we
only had 1 to maximum 3 samples per peak.
And this trace is also now much more beautiful,
there are no wide peaks.
They all have the same width, just sometimes
a bigger gap between each other.
Now last time I already hinted at the bit
interpretation of this trace.
This is a very typical pattern for an IR consumer
remote.
As far as I know it’s based on the protocol
created by a company called NEC.
But it can vary in bandwith and frequency
and so forth used.
But the general idea is the same, you always
have a pulse and then either a short or a
long pause until the next pulse.
And a long pulse refers to a 1 and a short
pulse refers to a 0.
This means we can now extract the bits of
a transmission and try to reverse engineer
which bits are used to do what.
So let’s start.
So that’s definetly a one.
That’s a one.
And that’s a one.
This is a zero.
And this is a zero.
Urgh.
I already have enough.
This is annoying.
So this application also has a cool feature
called Analyzers.
Protocol Analyzers.
So we can select from a big list of low level
protocols how we want to interpret our data.
The issue is only, that it doesn’t have
the NEC or IR consumer protocol by default.
The one you see here in the list, is the one
I have written myself.
So that’s what you have to do if you face
a protocol that is either unknown, custom
or just not supported.
But Saleae offers a Analyzer SDK which you
can use to implement your own Protocol Analyzers.
And that’s what I did.
The documentation of the SDK was a bit rough.
And it was C++.
And it took me several hours, so I will not
do this here again.
But I will put my code on github so it hopefully
helps other people.
Infact you can even install the Logic Application,
you don’t need the device for that, and
compile my code to check out the traces yourself.
I will also make them available.
No let’s add my analyzer.
First of all we have to tell the Analyzer
some information.
In this case it wants a pulse width, you will
see in a second what I mean by that.
Then we can also define if we want to interpret
+5V as 1 or 0.
Usually it’s seen as 1, but in this case
we might want to invert this, just because
the outout is LOW, when the LED of the remote
is ON.
But in the end it doesn’t matter.
We can also select what we want to display,
so in this case let’s go with single bits.
SAVE.
Let’s also set the text output to hex only,
and then let’s have a look at the data.
That looks pretty cool.
You can see those blue bubbles over the digital
data telling us if it was a 0 or 1.
Long pauses are a 1, short pauses are a 0.
You can also see those white dots, which I
have added to show you what is interpreted
as pulse width.
And you can see in a long 1, there are basically
4 pulses.
In a short 0, there are basically 2.
So if we had the pulse width a bit longer
or shorter, then we wouldn’t be able to
read the data properly.
For example if we would use 530, then you
see the pulse width slowly drift away and
kind of corrupt the data we read.
Another available setting is interpreting
the data as whole words, so now the whole
packet becomes one frame and the bits are
shifted into a 64bit variable.
And you can specify if you either want to
have the first bit to be the first or last
bit in the 64bit variable.
Now let’s document our test properly, that
when we collect a longer sample with a lot
of different commands, we are still able to
identify which one is which.
So let’s start.
I suggest we start with turning it on and
while it’s set to the lowest temperature
which is 18.
Then we increase the temperature up to the
maximum of 32.
After that we turn it off and on again.
Then we cycle through the 3 modes.
Afterwards we cycle through the 4 fan modes,
while we are on a/c, then we switch the mode
to the fan, and we cycle through the 3 fan
modes.
Back to the a/c mode.
Then we switch from celsius to farenheit and
back.
I honestly don’t know how the timer works
so I ignore that one.
Last two modes are their weird feel good home
thing and the silent mode.
And we finish by turning it off again.
Cool.
We stop the collection and now we can inspect
them.
On the right you can see the decoded protocol
view, which is super cool because it displays
us the each individual captured packet.
And when we click on one, we automatically
jump there.
We can now also export this data as a simple
CSV file for further analysis in python.
Now let’s explore this data in python.
We open the file and read it.
Split it by newlines.
To have a list of each line.
But we don’t want the csv header and the
last empty line, so let’s slice that.
And we can use python list comprehention to
already split each line at the comma.
And we loop over each command.
By the way, you can execute python scripts
directly in sublime with ctrl+B. Next let’s
convert the hex value to an integer, and then
a binary string.
Because we did like a sequence of commands,
it would make sense to compare each line and
visualize which characters change.
So let’s always safe the last printed value
and diff it with the current one.
We can simply define a function diff which
iterates over both strings and adds a character
if the characters differ.
And now we can take this output and analyze
further.
So the first packet was 18 degrees celsius.
And then we incremented it up to 32.
And we notice that this one bit here changes
with every increment.
And the 2nd bit here changes with every 2nd
increment.
Si that looks like a counter jsut reversed.
So it looks like we do want to change the
endianess of those words, and we can do that
by changing the settings in the analyzer and
export it again.
So it looks like up to 5 bits are involved
in the temperature selection.
It’s not quite regular binary to decimal,
but it’s definitely incrementing.
After that we turned it off and on again,
and it looks like this bit is responsible
for that.
Next we cycle through the 4 different modes.
First one is dehumidifier.
Simple increment.
But the one after is fan, which has a different
fan intensity than the other modes.
So those two might be the fan intensity.
And if we look closely at the commands after
those, where we tested changing the 4 fan
settings, we can see that those one are now
incrementing.
After that we switched to fan mode, which
again changes also the fan intensity, but
then we tested the different fan levels here
too and we see those change as well.
I guess you get the idea now how it works.
this is how we can slowly reverse engineer
which bit is responsible for what.
So now it’s your turn, can you figure out
which bits are responsible to change the screen
from farenheit to celsius or activate the
silent mode?
The saleae logic trace, as well as my analyzer
code and exported hex values are available
on github for you to play around with.
﻿Welcome to this video walkthrough of a real
life exploit.
We will have a look at a Javascript Framework
called AngularJS.
You can use that to create fancy modern web
apps.
While the concept is pretty cool, the framework
suffers from a design issue.
Any exploit I will show in this video was
not found by me.
References and credits are in the description
and displayed here.
Big thanks to mario from cure53 and gareth
heyes from PortSwigger web security blog - most
of what I show is based on their research
and work.
In the first part I will give a very quick
introduction to how to write apps with AngularJS.
If you haven’t used it before, take some
time and follow a simple tutorial to understand
it better.
For example the official AngularJS getting
started tutorial.
And after we had a look at a simple angularjs
example, I will explain my setup here how
we can debug angularjs.
So that in part two we can focus on stepping
through the code of an old version of AngularJS,
where we try to bypass the sandbox an learn
about the Angular internals.
In another video I will then show off some
more advanced sandbox escapes for more recent
versions.
But let’s start.
I have written a very simple AngularJS Testbed.
Meaning a place where you can easily play
around with Angular.
Let’s start by looking at an angularjs example
app.
Look at this table.
On the left you can see angular JS expressions
in double curly braces, basically how you
would write them into your html.
And on the right you can see the result after
AngularJS evaluated those expressions.
And I have made here several examples with
a variable username, and some functions…
Also note that the alert function did not
trigger a popup!
The result is empty.
But where do those values, variables and functions
come from?
Let’s have a look at the HTML sourcecode.
Just to make it clear again, AngularjS is
a pure Javascript framework.
So here is no server part.
All those expressions are evaluated on the
client side in the browser after the html
page got downloaded.
Here you can see now that we use angularJS
version 1.5.7.
And then we create a new angular application
with the name “scopeExample”.
And then attach a controller to it with the
name “MyController”.
We can pass different variables to the controller,
but most important to us is the scope.
The scope is just an Object from AngularJS
which is available inside the app.
And you can see in the code we write, that
all variables and functions we define are
attached to that scope.
They are a property of that scope object.
And when we look again at our table where
we used the double curly braces to get the
username, angularjs will basically evaluate
the expression, and check if the identifier
username exists in the current scope...
And in this case there is a username in the
scope and it contains the string “World”.
Thus the result is “World”.
Similar with the function sayHello.
The scope has this function attached and thus
we can call that function within the expression.
But alert, is not in the scope.
We didn’t define that.
So this function doesn’t exist and thus
has an empty result.
Two more things I want to point out.
The first coloumn has also curley braces but
they are not evaluated, because they have
the ng-non-bindable attribute set.
That deactivates angularjs for that element.
The other thing is the $eval.
This is not the normal javascript eval function
it’s dollar eval.
Again, this is evaluated against the scope.
We didn’t define the function $eval ourselves,
but angularjs has that already attached to
the scope object.
And that dollar eval is similar to regular
javascript eval.
But it doesn’t evaluate arbitrary javascript,
it evaluates angularjs expression.
Thus $eval sayHello is equivalent to double
braces sayHello.
Double braces also evaluate angularjs expressions.
Ok no let’s dive in.
Let’s open the testbed for angularjs version
1.0.8.
Which is very old.
But we need that to understand later exploits.
So this is a very simple .php app.
If you look at the sourcecode you see a form
where you can enter a text.
And then whatever is in the GET variable q
will be html escaped and safely echoed into
the page.
You can see that when you try to inject a
script tag to pop alert.
It doesn’t work.
It’s properly escaped.
So are we safe from XSS?
NO!
We are not.
AngularJS destroys everything that we have
tought web-developers.
Escaping your string is not enough in this
case.
The crucial detail here is that our input
is reflected into an html element that has
angularJS enabled.
Two things to mention here, first of all,
this is not how angularjs apps are supposed
to be written.
AngularJS apps should not be mixed with server
side templating.
Meaning that the intended way for angularjs
apps to get data is via API calls after the
site is loaded.
So mixing here php with angularjs is bad practice.
Does that mean that this example is irrelevant?
No!
In reallife this happens all the time.
Some older php app gets extended with some
fancy angularJS and boom.
You have a just genetically engineered a monster.
You can test for angularjs expression injection
by using something simple like 1+1.
If the result shows 2, instead of the curly
braces, then you likely have a angular js
(or a similar frmework) injection.
Ok so let’s start.
Let’s first explore why alert doesn’t
work, by looking at angularjs internals.
Open the developer console and then go to
the sources tab.
On the left you can see available javascript
source files.
In the center you see the javascript code.To
the right you can find stuff like the call
stack, the variable scope, breakpoints etc.
Which is important when you debug javascript
code and step through it.
We will make use of that shortly.
And at the bottom (maybe you have to hit escape
first to open it) you have a console where
you can type in javascript code.
If you pause at a breakpoint, you have access
in that console to all the variables at this
point in execution.
Before we execute it, let’s quickly take
a look at the angularjs code.
This is a not minified version, meaning everything
is nicely commented and indented.
I have also modified the code by adding the
keyword “debugger;” in different places.
Those are like breakpoints.
When javascript executes that statement, it
will stop execution right there and we can
look at the state of the variables etc.
Ok now let’s execute the expression by submitting
this form.
The site loads, executes angularjs, the expression
gets evaluated and we hit our first breakpoint.
In the next video we will step through the
evaluation of this expression and try to understand
how angularjs evaluates them.
﻿Let’s have a look at the third flare-on
challenge.
FLEGGO.
When you are finished with your media interviews
and talk show appearances after that crushing
victory at the Minesweeper Championship, I
have another task for you.
Nothing too serious, as you'll see, this one
is child's play.
Let’s download the FLEGGO 7zip, unpack it
and inside we find a FLEGGO zip, which contains
dozens of binaries… urgh… this looks time
intensive.
There are so many binaries but we have to
start somewhere.
So let’s load one into IDA.
Unlike previous challenge, this is clearly
a regular compiled PE binary.
Typically, especially when you don’t have
a lot of experience yet, you have no clue
where start.
There are quite a few functions and you have
to start somehow.
So one idea you can try is to look for functions
that were recognized here, or in case of windows
especially look for imports.
So this binary imports these function.
And quite a few here could provide an interesting
starting point.
Immediately the is debugger present function
pops out to me, so maybe that’s something
we have to circumvent.
But also opening, reading and writing files
could be super helpful.
It’s likely that xrefs, cross references
where these functions are being used, are
implementing something meaningful.
Another strategy is to look for strings referenced
in the assembly.
But looking here into the strings doesn’t
look promising.
Nothing really special.
Though the problem here is that the freeware
of IDA is a bit crappy with analysis, the
proper Pro version would have totally done
that for you, but in this case we have to
specify the string type by hand.
You see in linux binaries a string is typically
just bytes and then null-terminated.
On windows on the other hand it’s often
16bits and so a string is always based on
a character, null-byte, character, null-byte,character,
null-byte and so forth.
So you see if you would look for linux c strings,
you would not find them.
But in the IDA preferences we can select how
we want to look for strings.
And in this case C 16bits will work for us.
Now we find meaningful strings.
As you know IDA is not the only tool and I
often use Binary Ninja.
But also there the regular version as of making
this video wouldn’t recognise it outright,
though I was told that the current development
build, which you can switch to in the preferences,
handles it.
So downloading that and then checking the
strings we also find them here.
So this is also a great way to find meaningful
starting locations when reversing.
Now if we look closer at what we found here,
we can see that we are asked for a password.
And in the function where that string is used,
you can see here the address of it loaded
and then calling this sub, which is probably
printf.
And then it’s followed by this format string
%s.
And if we peek into this sub, follow it a
bit we reach some scanf.
So this is just some weird windows wrappings
around a scanaf implementation.
So here we read a string.
Then down here we see that a decision is made
if you pass or not, and so the function right
before must check the password input.
And right at the start inside that function
we load the string “IronManSucks”.
And you can also see that there is a loop
and something is compared, so it’s VERY
likely this is the password.
We can also execute this binary and we get
the expected password prompt, where we can
enter IronManSucks.
And we see “Hello Batman”, which looks
good but it’s followed by “Step on a brick!”
and otherwise nothing happens.
Mhmhm..
There is a second thing we need to explore.
Why are there so many binaries.
How do they belong together and are they the
same or what is different with them?
I actually sneaked that into the video.
The file we opened in IDA, was different from
the one opened in Binary Ninja, but both had
the same strings and password.
And the binary we executed was also a different
one and apparently worked.
So they are definitely very similar.
So I switched over to my macbook because I
prefer to code there to explore this further.
I first did a quick hexdump comparison.
I cat the binary, pipe it into hexdump and
write the result into a a.hex and a b.hex
and then use vimdiff to compare them.
And they appear very different.
One possibility could have been that they
are all straight copies of the same binary
and then just patched after the fact.
Just a few bytes changed.
But with this test we get evidence that this
doesn’t seem to be the case as too much
changes.
So it’s likely fully compiled with changes.
Interesting though.
Because I didn’t really have a good plan
what to look for I also opened up a binary
in Hopper disassembler.
And there the strings were found right away,
with proper cross references AND the decompilation
of that function that asks for the password
looks really good as well.
Good job hopper!
But then something clicked.
Remember the error, go step on a brick?
It’s right here.
At the password check.
This should printf, this is the scanf and
then this checks the password, right?
I thought we figured out that the password
is IronManSucks.
No?
So let’s look at it again.
On this function hopper really fails.
Oh man.
Decompilation is so hard.
It can work so perfect on one function and
then another is pretty terrible.
But then I realized, this function is a lot
larger for being just a simple string compare.
And when looking at the call graph we see
that after the comparison it seems to successfully
print Oh hello batman.
But after it is more code.
And if compare the start where IronManSucks
is compared with this part below, put it right
next to each other you see that they are basically
identical.
There is a second string compare function.
And that value for the string compare is coming
from an address that is currently not mapped.
So this means this is coming from dynamic
memory when the program is executed.
So there is a secret password.
When we look at the cross reference where
else this address is used we find this location
here and that is a memcpy.
So some string is copied from somewhere to
this address.
And the string address that is copied is in
eax and I guess eax is the return of this
function here.
And this function, let’s decompile it executes
FindResource and then LoadResource.
So this function looks up a resource in the
executable and loads it.
So it loads that data.
And then it’s mem copied to that area.
So let’s give that address a proper name.
The resource loaded was called BRICK so let’s
call it BRICK.
At this point I went into my Windows VM and
used x64dbg to look into this dynamically.
I loaded the binary, let it run until we see
the password prompt, then I look at the stack
around that string and find this return address.
This way we find the important part in the
disassembly.
It’s so weird because this is a debugger.
It’s not a disassembler with fancy crazy
features like IDA, Binary Ninja or Hopper.
So there are no such things as cross references
and so forth.
So it’s a bit more tricky but that’s why
you use a disassembler first and then based
on that find the stuff in the debugger.
Anyway.
Here we have the password comparison function
and the disassembler already shows us that,
down here, this password is references.
So this looks like the secret password.
We can set a breakpoint here, then continue
the program, enter our password, we hit the
breakpoint and can slowly step forward.
And now we can observe the string comparison
here slowly.
Each loop compares more.
And then?
We can step a bit further, look at the program
output and there we have it.
Eveyrthing is awesome along a .png file reference
as well as a dash…
So we have seen the writeFile imports earlier
and so looking into the FLEGGO folder we find
now a 72562746.png.
Which is a lego page with number 42.
But to be completly honest with you, when
I actually did that the first time I didn’t
step far enough in the debuger to get this
output.
I got the image but didn’t see this.
You will facepalm in a moment.
So please imagine this wasn’t there and
I only got the image.
This meant I was actually reverse engineering
more of the program and saw that the BRICK
resource loaded is pretty large, and the password
we use of it is just at the beginning super
short.
And I saw that there are other parts referencing
data from inside that region.
And looking around there I found this XOR
function.
You see here a loop and xoring with a constant
value.
Going out you see the constant xor key pushed
onto the stack and the address of what is
xored.
And there are actually two different things
xored.
And so they both point inside of what is loaded
from BRICK.
And based on their address and the start address
of BRICK we can calculate their offset inside
of the BRICK data.
This gets important in a moment.
So right now I knew that there is a hidden
password loadded from an embedded resource
called BRICK.
This password can be used when executing the
binary to get an image.
And we have two more hidden XOR encrypted
strings.
So I went ahead and wrote some python code.
I knew I wanted to read the BRICK resource
from the file, so I looked for a module that
can work with PE files.
And I found one, pefile.
And here in the project description there
are also some examples and working here with
resources sounds about right.
So basically you have these dictionaries with
entries and you can traverse this tree.
It’s a bit weird, but I was actually just
doing this by hand and coincidentally the
first resource I found through that, from
all directories using the first entry, I finally
found some data.
And we get the offset from inside the binary
+ the size.
And the size matched what we saw in the disassembler
when loading it.
So that’s BRICK.
This means the first part must be the password
and remember the other two things referenced
inside BRICK.
Here I calculate their offset based on what
I got from the disassembler and also extract
that.
And for those I also have to do the XOR decryption.
And then I simply print the result.
The password and the decrypted A and B data.
LOOK AT THIS!
This looks like passwords and here we also
get the .png and the single character.
So at this point I knew I could extract images,
each image has a number, each filename of
the image appears to be connected to a single
character, so it was clear to me what to do.
Just put the single characters in the correct
order, based on the image numbering, and you
get the flag.
Because I don’t want to enter all passwords
by hand, I just installed wine on mac and
used wine to execute the windows binary.
Pass the password and I get the image.
Put that into a loop in python with subprocess
to pass in the password, and we got them all.
Then it was just a matter of a bit of puzzling.
I wrote down all the image filenames with
their number and then wrote a few lines of
python to assemble the flag from the single
characters based on that.
And here is the flag.
Let’s submit it and unlock the next challenge.
COOL!
Now I told you before that I missed this output
from the real binary if I had realize that
the whole resource parsing and xor decryption
wouldn’t have been necessary.
AND on top of that, I realized now that the
password is also in clear text in the resources..
So using strings wouldn’t find it because
it would also look for null-terminated c strings,
the radare2 utility rabin2 can find also 16bit
strings.
And it turns out that the cleartext password
is ALWAYS found after the BRICK string.
Goddamit.
All I had to do was using strings on the binary,
find the password, execute it to get the image
to char match as well as the png itself and
assemble the flag.
I went way too far with reversing this.
But again, I learned stuff.
I never really worked with windows resources
and it was good practice.
﻿In this video we will revisit the license
check program from last time. You can get
the same compiled 64bit binary from github
and you can also watch the last video where
I went into more detail how to crack this
simple program.
I will show now different simple tools and
techniques that exist to analyse a program
like that to circumvent the license check.
This should show you that there are a variety
of different ways how to solve this challenge.
The file command is very useful to check what
kind of files you have. So ‘file’ on our
binary says it’s a ELF 64-bit executable
for Linux. You can also do ‘file *’ to
get the information on all files in the directory.
And it then also finds the C source code here.
So that’s very useful.
Let’s open the program in a text editor
like vim. As you can see it looks very weird.
I have introduced ASCII before, so you know
that every character has assigned a number.
But there are numbers that don’t have a
printable character assigned. If you look
at the man page of ascii, you see that for
example value 0 to hex 1f are not a normal
characters. And ascii is also only defined
up to hex 7F or 127. But because our computer
works with bytes, so 8 bit, this number can
range from 0 to 255, And ascii only uses half
of them. So all those weird blue values in
vim are such numbers that don’t have a printable
character assigned. You can also do a hexdump
of the file, to get the actual values. ‘hexdump
-C license_1’ and you can see that there
are many many 0s in the file. hexdump displays
them as dots, but in vim they are the blue
stuff. But when you look closely there are
quite a few meaningful strings in there. For
example right at the beginning “ELF”,
which is a magic value, hinting that this
file is an executables.
You also can find some strings to libraries
such as libc, which defines functions such
as printf and strcmp.
And here we also see strings we know, the
“Checking License”, “Access Granted”,
“WRONG!” and “Usage” message. And
also this weird looking “AAAA-ZION-42-OK”
string. hmmhmh…
Remember from last video that there was a
string compare in it? Might get the license
key we enter compared to this string?
Let’s try it! Access Granted. Indeed! The
license key of this program was in there all
along.
There is a great tool called ‘strings’
that is doing what we just did, just nicer.
It will scan a file and prints out all printable
character sequences with at least a certain
length. So let’s try it with ‘strings
license_1’. And there are our strings.
Last time we used gdb to read the disassembly
and also debug the program. This time let’s
just use objdump for the disassembly. ‘objdump
-d license_1’. You notice that this file
has a lot of more code than just the ‘main’
function. That is because the compiler puts
a bit more stuff into the actual binary. You
know, computers are a little bit more complex
than they seem at first. But all of this is
just standard stuff you basically find in
any gcc compiled binary. And usually only
the user created functions like main are interesting
to us.
Objdump can be used to get a looot of more
information about this program. Let’s print
everything with ‘objdump -c license_1’
and pipe it into less for easier navigation.
So first it says the file is a elf binary
for the x86-64 architecture. The stack is
not executable, indicated by the missing ‘x’,
which is interesting once we will look at
classic buffer overflows.
And maybe the last interesting info are the
sections. We can see here where certain data
will later end up in memory. Interesting for
us are the .text section. This section holds
our code and it starts at address 4004d0 and
is hex 1e2 big. And if you check the address
where the main function was, you will notice
that it’s in there.
The other interesting section is .rodata,
which is the read only data section. So our
strings can be found in there. If you open
up gdb and break at the strcmp, you can check
the registers. And one of the registers will
have an address in from this .rodata section.
You can print this address with x/s, and voila,
there is our key again.
Let’s have a look at another active tool.
It’s called strace and it can trace system
calls and signals. When I introduced programming
in C, we used printf to print text. That was
a nice function that we added to our program
from the libc library. But printf is just
a wrapper around a function that the linux
system itself provides us. Linux itself offers
many different kind of functions called syscalls.
You can read more about them in the man page
to syscalls. One of those functions is ‘write’.
And write can be used to write text to the
standard output, which we can read on the
console. So let’s execute the license program
with strace. The first line is execve, which
is the function that tells the linux kernel
to now execute this program license_1. And
then a lot of magic happens that we ignore
from now. And somewhere all the way at the
bottom here, the code that I have written
starts. And you can here see the write syscalls
that were executed with the text that we know.
Interesting, huh?
There is another cool tool called ltrace.
Similar to strace it traces certain functions.
But this time it traces library functions.
Functions like printf or strcmp come from
the libc library. So ltrace can show us their
occurrence. So first you can see the printf.
And then comes the strcmp. And it shows us
the actual strings it compares. So that also
tells us how the license check works in a
cool way.
Let’s thow this file into a graphical user
interface. I will use hopper on mac. As you
may know IDAPro is very expensive. But hopper
is a great alternative which is actually affordable.
Hopper sees that it is a ELF executable and
it can automatically analyse it for us.
It places our curser at a function called
start. And not main. Like we have seen with
objdump before, there are a few more functions
created by the compiler and this here is the
real entry point of the program. But what
those functions are doing is not important
right now. We are only interested in the main
functionality. So we can look for the main
function in the list of labels.
So here is our main function, like in gdb.
Just a bit more colorful and hopper can also
show us with those arrows where branches are
going to. At the end of the last video I have
already showed the control flow graph which
you can access at the top right. And a very
cool feauter from hopper is the decompiler.
Decompiling sounds like it would reverse assembler
code back to C code. But that is not easy.
The compiler changes and optimises stuff and
you just cannot simply reverse it. But hopper
can guess how it might have looked like. Sometimes
it makes mistakes, but often it looks pretty
good.
So it shows us here how it checks if we have
supplied a license key, and then it does the
strcmp and prints either ‘Access Granted’
or ‘WRONG!’. So that’s pretty cool.
To the left you can also find a button to
display all strings. And as you can see it
also found the key. When you click on it it
will jump to the address where the key is
located. And XREF stands for cross reference,
that means this address is referenced somewhere.
We can follow that xref, and we can see that
this is the assembler code where the address
of the key is moved into the esi register.
This prepares the function parameters for
the strcmp.
Some kids may have the opinion that mac users
suck. To please them we will install now radare2
by cloning the radare2 repository with git.
You might have to install git with sudo apt-get
install git.
To install radare run sys/install.sh and wait.
Once it’s installed you can go to the license_1
program and open it in radare with ‘r2 license_1’.
You may remember this address from objdump
earlier, this is the start of the text segment
that contains our code. first run ‘aaa’,
to automatically analyse an autoname functions.
Then use ‘afl’ to print all functions
that radare found.
Each character in radare means something.
And with ? you always get information about
what characters you can use. So ‘a’ performs
analysis of code. ‘a?’ shows us that we
can append ‘f’ to analyse functions. And
‘afl’ lists those functions. Makes sense,
right?
ok so afl shows us that it found a main function.
Let’s change our current location with ‘s’
to seek to the location of the function main.
You can also use tab-completion here. Now
the location in those brackets changed. With
‘pdf’ we can print the disassembly of
the current function.
Like hopper it shows us the disassembly with
nice arrows where branches go to. And it created
comments for us with strings that are referenced
in there.
You can also type capital VV to enter visual
mode. This shows you a control-graph view
of this function. You can move it around with
arrow keys. The blue border indicates that
we currently select this box. With Tab and
Shift Tab you can select other blocks. When
you have a block selected you can move the
block with Shift + hjkl.
With ‘p’ you can cycle through different
representations. For example with our without
the address in the beginning. Or this minimalistic
view, which is useful if you have a damn huge
function. And with ? you can display a help.
This help tells you that capital R is the
most important shortcut you will ever learn
for radare… So press Shift+R and be happy.
You can also use radare2 like gdb to debug
this program. To do that start radare with
-d flag.
Seek to the main function, analyse all with
‘aaa’ and display the disassembly with
pdf. Now place a breakpoint at the start with
‘db’. Now go into Visual View with “VV”
again. Like with vim you can enter command
mode with ‘:’, where you type ‘:dc’
to run the program. Now we hit breakpoint
1. And if you look closely you notice rip
in the first box. This shows us where the
instruction pointer currently points to.
With s you can step instructions. But we should
use capital S, otherwise we follow functions
which we don’t want to. So Shift+S to step
further.
Ah damn. We didn’t supply a license key.
But you get the idea.
I hope this helps you to explore more tools
and techniques. And remember that no tool
is better than the other. They all have different
features and representations of information.
It makes sense to master them all.
Except radare. Some say radare is the best.
But nobody ever masters radare.
﻿Last video was pretty boring reversing. And
I also told you that I gave up and looked
at a write-up, which told us the the main
component in the key verification check is
RSA encryption or decryption. I was really
surprised because I was not able to find out
that it’s RSA. But now that I know it’s
RSA I don’t just wanna write the keygen,
I want to understand how RSA is implemented
in assembler here, so that I learn and in
the future I will then be able to recognize
RSA again. So let’s head right in.
We have encountered RSA on this channel before,
and I recommend to watch that one as well
to learn a bit more about it. But let’s
have a quick look on wikipedia page again.
RSA has a public and private key. And at the
heart of the RSA encryption or decryption
is a modulo exponentiation. To encryp you
take the message, which you converted to a
number and raise it to the power of the public
key modulo the public exponent n, and to decrypto
you raise the encrypted message to the power
of the private key d modulo n. So what we
are basically looking for in assembly is simply
an algorithm that implements exponentiation
with modulo. Modular exponentiation is a type
of exponentiation performed over a modulus.
The big problem with this simple math is,
that our CPU only has 64bit registers and
not really instructions for exponentiation
or modulo. So these have to be implemented
by an algorithm. Not only exponentiation has
to be implemented by an algorithm, but we
are dealing with large numbers that don’t
fit into 64bit, so you can’t simply add
two numbers that are much larger with a simple
instruction.
And apparently all of that is what is implemented
here.
So the approach that I took to understand
the assembler code was to meet in the middle.
This image shows a function call tree from
here. Here is our function we enter. And these
leaves were the super simple functions without
any outgoing ones. So they can be understood
in isolation. During my own failed analysis
I actually reversed these very simple functions
but I couldn’t see the wider context of
it. What they are used for. So I will show
you what the simple components do, and then
we research basic modular exponentiation algorithms
and see if we somehow get the wider picture.
So here is the function that is supposedly
implementing RSA. Let’s follow the references
of unknown functions until we reach one of
the simple ones.
Okay, this is a simple loop and has no other
outgoing functions.
So here we have a clear for-loop again. Initilise
i with 0, increment down here and the cindition
is comparing i to the value coming from a
parameter. So that parameter is clearly length.
And inside the loop we then see that i is
used as an offset into some buffer, in fact
it’s used to load a byte from two different
buffers, so we can take that as buffer1 and
buffer2. And these were also our parameters.
So we take that byte and then we add it. Together.
Then we load some other byte which was initially
set to 0, but down here we can also see it
set again, so let’s call it a temporary
value for now. That value is moved around
a bit but then in the end added onto the previous
add result. Then we find another temporary
value. It’s always written here and used
here. So we write that add result of those
bytes and that one temporary value into it,
but load it again, shift it right by 8, and
move that result into the first temp value.
So if our add result was larger than 1 byte,
so if there is something left after the shift
right, that is what is stored in that first
temp value. Then we load the add result again,
only take one byte from it, so these are the
lower 8 bits then and move that into the offset
of the first buffer.
That is a very clear add implementation for
large integers. Integers that span as many
bytes as you want. Was this to fast, do you
not understand how this is implementing an
addition over large integers? Let’s do it
again while at the same time we do some elementary
school math.
Let’s say you want to calculate 151 + 272.
How do you do that in elementary school? You
write it like this and then you go digit by
digit.
So 2 + 1 is 3. Boom. 7 + 5 is 12, so that
is more than a digit, so you know what you
have to do? You have to cut it off there,
take the one as a carry, remember it for the
next round and just keep the 2. Then comes
the last digit, 1+2 is 3, but we also have
a carry of 1, so we add 1 and the result is
4. 423.
Now quick recap of the assembler code, we
load one byte from each number, it’s like
digit, we add it together, we check if we
have a carry that we have to add as well!!!
Right? So that’s the carry. Then we do the
shift right of 8 bits, which would now get
anything that doesn’t fit into the byte,
into the digit. We cut off this byte, and
remember this cut off part in the carry for
next round.
And we only write down the byte that we just
cut off in the first buffer as a result. Makes
sense right? Super simple.
So we can change the type and name of this
function. The first two parameters are the
two numbers A and B, the last parameter is
the length of the buffers that holds A and
B and the function is simply called add.
Now when we back out we find another unknown
function, but that one does a bit more, though
it has also a reference to another simple
function.
This one looks super similar. And we can very
quickly assign the same variable names as
before. This is i, the length, the carry and
so forth.
And instead of a simple add, we see an add
and a subtract here. Could this be simply
a subtract function? But why then the add?
So let’s see. The subtract is done on r10
- edi.
R10 is loaded from rcx + an offset. The offset
is i and rcx is the first buffer. Ok.
So a byte from the first buffer is taken and
subtracted by edi. Edi is coming from this
add.
Edi here is the byte from the second buffer.
And r11 is from r8, r8 is from di, di is from
sil and sil is the carry.
So we do byte1 - (byte2 + carry). That’s
exactly like elementary school math again.
If we have a carry we add the carry basically
to the second value we subtract and subtract
it from the first.
So yeah, this is simply sub. We can also change
the type here, A - B, and the length of the
buffers. Cool.
So we understood these functions. Like I mentioned
at the beginning, I figured that out on my
own before I knew it was RSA, and so now you
are on the same level. Next I want to research
how RSA or better to say modular exponentiation
could be implemented.
Actually from a hardware security lecture
at university, which I also mentioned in a
video where I introduce hardware side-channel
attacks, I already introduced such an algorithm.
Exponentiation by squaring. Let’s checkout
wikipedia.
exponentiating by squaring is a general method
for fast computation of large positive integer
powers of a number.
And here it shows how it’s done. If you
have x to the powe of n, you perform this
recursive algortihm here.
If the exponent n is even you just square
your base x, ad if your exponent n is odd
you also square the base but also multiply
the base to it as well. And then that result
is the new base, the new x and you update
the power. This is defining a recursive algorithm
but it can also be written as a easier iterative
loop. Especially when you work with bits.
Because in binary the number is even when
it ends with a 0 and odd when it ends with
a 1. And division by two in binary is basically
just removing the last digit.
Right? So in binary you just go through each
bit, on a 0 you simply square and on a 1 you
perform a square and multiply.
This means the pseudocode of it looks like
this.
For each bit of the exponent we perform the
suaring, but if the bit was 1 we do an additional
multiply.
So if we look again at our function, we should
maybe find that. Let’s first define the
parameters of this function. If we assume
this is RSA then the first parameter here,
which we called radom_buf at first is in fact
the RSA modulus n.
And is the public exponent e. So we can also
name the parameters of this function now.
Modulo n, the length of n, e, the length of
e, the empty buffer which will probably be
our result and the user input data, that is
our cipher message we will decrypt.
Let’s go into the function and also name
the local variable based on the parameter
names.
Xor esi, esi will zero out esi, so this memset
will zero out the result buffer. Then we have
a memcpy and it copies the data, our user
input, into a new buffer that was allocated
on the stack here. You see how it subtracts
from the current rsp value, so it makes space
on the stack.
Then we have a for loop. Init i = 0, and the
loop condition depends on the length of the
exponent buffer. So the length is loaded,
shift left by 3, that is equivalent to a *8
and then we compare it to i. Because e is
1 0 1, thus the e length 3, this loop go from
0 to 3*8 - 24.
Then inside the loop we have seen this kind
of pattern before in the base32 encode algorithm.
Here we load i, and divide it by 8. So that
will be 0, 1 and 2, which will be used to
load a byte from the e buffer. So for example
this will be 0 for the first 8 iterations
of the loop. And then here i is masked with
0x7, so that is the modulo 8. And then a bit
is shifted by this value.
So this produces the same pattern like in
that other video. So here we go over each
bit of the public exponent. And if the bit
is set we execute this part, if it’s not
set we skip it.
Does this remind you of something? Look at
the pseudo code again. Here it says we go
over each bit of the exponent and then we
execute the multiply if the bit is set and
square everytime.
That is the same loop pattern here, or is
it? It’s the same function. It’s not different.
Like one is square and one multiply. And don’t
call me stupid now. It took me a bit to remember
but eventually I figured it out. when you
square x, you can also write x * x. So there
you have a multiplication.
So this function should be multiplication
including modulus. It does take the modulo
n as a parameter, and the outer function here
doesn’t appear to do the modulo.
Let’s look into that function and start
again by naming the local variables based
on the parameters we passed to it.
We know that these two buffers hold the data
that is being multiplied, so that’s A and
B and this unkown buffer will probably hold
the result.
Then we have another for loop. And the same
pattern of multiplying the condition length
by 8, and here the divide by 8 and shift by
up to 8. So this is again checking single
bit,s and the buffer it is checking is, B.
So this loops over the bits of B.
If the bit is set it will call this add, and
otherwise always this add here.
Mmhmh… that is kind of similar to the modular
exponentiation. There we looped over bits
and multiplied to achieve the exponentiation.
And here we loop over bits and add numbers
to achieve, hopefully multiplication.
So how can you multiply by adding?
Well let’s see what is being added?
Ok we know the result, but what is var_38.
It was used up here in the memcpy so it holds
a copy of the number A.
So in every loop we do A + A, so we double
it. And if a bit in B is set, we add this
A to the result.
If you don’t see why this also implements
multiplicatio, we have to go back to elementary
math. Let’s multiply two numbers. 123 * 102.
So we first do 1 * 3, 2, 1
Then 0, then two times 3, is 6, eh 4, and
2.
Then we have to add these up. 12546. Ok so
here is an adding step involved. ANd that
is actually the same that is happening here.
Let’s do an example with binary numbers
then it becomes clear. Let me also kinda do
it in reverse order, so we start with the
first bit, not the front.
We find the first bit which is set, so we
note down, 0 1 0 1, then we have a 0 we note
down, and then another 0101.
Now if we compare this to our loop, we would
have in the first step added the current A
to the result. So that’s this line. Then
we would double it, and in binary, doubling
the number is just shifting it by 1 to the
left. So we add a 0 at the end. See where
this is going?
Then in the next loop we look at the third
bit, where we now add the doubled value. And
the doubled a value in this case is now 10100.
I hope I made it clear. So this clearly implements
multiplication. However what is the other
function? It takes the intermediate result
and the modulus. So I guess that one implements
the modulus.
Let’s name again the local variables and
have a look at the obvious for loop. Though
this time the for loop is initialised with
the length and counting down to 0.
And in the loop we see that a byte from A
and the modulus is loaded and compared. Quick
reminder, the modulus was the buffer with
the random looking data.
So it goes over each byte from the front comparing
the current value to the modulo. If the value
byte is smaller than modulo byte then that
means the whole value number is smaller and
then we just leave the function.
If the byte was larger, then our value is
larger which means the modulo has to be applied
and it does that here with a subtraction.
It’s subtracting the modulus from the current
value. But if the bytes were the same we keep
looping until we find a larger or smaller
byte. So essentially this is just a check
if the value is larger or equal than the modulus,
and if that is the case we subtract it. That
means if our value was more than twice the
modulus, then this wouldn’t quite work,
but that will never be the case. Because this
is done in a loop constantly with only additions
before, so immediately when the add makes
the value larger, it will cut it back down.
Amazing. Now we covered all functions and
we finally were able to see that yeah, this
implements RSA.
I have never looked so closely at algorithms
that implement exponentiation, modulo or multiplication
with larger integers in assembler, so maybe
I would have solved it if I had known that
before. But as you know, it’s all about
learning and studying new things and so even
the fact that I surrendered and looked up
a write up doesn’t matter. I’m suuuper
happy that I was able to fully understand
it now. And I’m sure I will recognize RSA
in assembler next time. This is what CTFs
are for.
So indeed, we have RSA decryption here. Our
DLC unlock code, at least the first 12 bytes,
is encrypted text, and then we compare the
decrypted data to the buffer that was created
before. The buffer that was combining the
xored last 4 bytes of the unlock code with
the PWNADV3 string.
Now all that is missing is to use everything
we learned about the key verification and
create a keygen.
But this video is getting pretty long so I
will create a short additional video just
implementing the keygen, and I will release
that in a few days. So you have the chance
to implement your own keygen now.
﻿Have you ever looked at the chip of a credit
card and a mobile phone sim card and thought,
wait... they look quite similar?
And would you like to know what makes these
two old phones, a nokia and motorola, so special,
even in 2018?
In this series I want to talk about mobile
networks and mobile network security.
And by that I don’t mean android or iOS
apps.
I mean the networks.
SIM Cards, Baseband and Basestations.
Most of us know how the internet works.
It’s so easy to setup a lab and use wireshark
to look at the traffic.
But we basically don’t really learn about
how mobile networks work.
You can’t just wireshark the radio network.
I only learned about this a few years ago
in university, where I took a course on telecommunication
security.
And that was a great foundation that I will
obviously use for these video, but it’s
really hard to do anything practical with
mobile networks for reasons you will see soon.
But then Vadim Yanitskiy, @axilirator on twitter,
contacted me, if I would want to see some
GSM osmocom demos and I could record it for
some videos.
And of course I took this opportunity and
met up with him, and that was so awesome.
So thanks to him I finally got some real hands-on
practical experience with this topic and I’m
so excited to try to pass this on to you.
I hope over the course of several videos you
will have a great basic understanding of how
the mobile network works and you know where
to go to, in case you want to learn more.
So I started this video showing you a credit
card and a sim card.
And the reason why they look so similar, is
because both are so called smart cards.
A smart card, or chip card, is any pocket-sized
card that has embedded integrated circuits.
Many smart cards include a pattern of metal
contacts to electrically connect to the internal
chip.
Here on wikipedia you can see some great images.
The actual chip is smaller than the gold connectors,
and they just connect with tiny bond wires
to there.
And all the outer stuff is just plastic.
Here you see how they are connected, crazy
right?
So when you look at your phone, and I would
ask you, how many computers are in there?
What would you answer.
That was actually an opening question in the
university class I had, and I think it’s
a great question.
Maybe some people would respond with one,
it’s a single small smartphone computer.
But maybe you knew, that the sim card is actually
a tiny computer itself.
Your phone computer communicates with the
tiny embedded sim card computer.
And that computer can’t do much, but it
can do a lot more than some of you might think.
In a very simple way you can imagine this
small computer just contains a private key.
And with public-private key cryptography you
can use it to authenticate to something.
And the idea is that it’s super hard to
extract that private key from the smart card.
Not comparable to the simple magnetic strip
on a credit card.
The private key never leaves the chip.
If you want to do some crypto, your phone
will communicate with the sim card and ask
it to do it.
In the same way a credit card reader, using
the chip, will do so.
Nobody can clone a sim card or credit card
that way.
There are attacks on smart cards which I have
touched on before with power analysis and
other crazy hardware hacks.
But generally the cost is pretty high to do
that.
But in theory if you could extract the private
key from it, you could clone a sim card or
clone a credit card chip.
So you can’t clone a sim card that easily,
but what if you just steal a sim card?
Can you just use it?
And that is why you need a pin for your credit
card when you use the chip or sim card.
The small computer inside the sim card refuses
to do the crypto stuff you want, if you wont
tell it the secret pin.
That’s another protection.
So how does this look like in practice?
Vadim showed me SIMtrace.
So Osmocom SIMtrace or SIMtrace 2 is a software
and hardware system for passively tracing
the SIM mobile equipment communication.
As you can see here, you have this basically
fake sim card that is connected with a flat
flexi-pcb cable and connects to this board.
And this is where you put the real SIM card.
So basically the phone is still using the
real sim card, it’s just forwarded through
that.
But because the sim card is not inside the
phone anymore, you can now intercept and record
that communication and forward that via USB
to your PC.
And then you can observe all the messages
and commands the phone sends to the SIM card
and see how the sim card responds.
So when you turn on the phone, the phone asks
you to enter the PIN.
Let’s enter the pin and then look what happened.
Here is wireshark… wireshark you ask?
How what?
Okay… so wireshark is a convenient tool
to analyze packet based communication.
And in this case you can see here the protocol
is GSM SIM.
And wireshark is listening on localhost.
So the simtrace software actually records
the SIM communication and then puts them into
a UDP packet and send them onto localhost.
That’s why you can use wireshark to then
collect all these packets.
And it looks like they have an ethernet layer,
and an IP layer and the UDP layer.
But that’s just to transport the data.
The actual interesting payload is the GSM
SIM protocol.
Somebody wrote a payload decoder for wireshark
to analyse that data.
So ignore all the references to IPs and MAC
addresses, that’s not what is sent between
the SIM card and the phone.
You only focus on the GSM SIM layer.
Anyway.
When we look at the packets that were collected
after the pin was entered, we can see what
the sim and phone did.
The first important packet here is the VERIFY
CHV.
The info also says something about ISO/IEC
7816-4.
And when you look that up, you will learn
that this is a prtocol stadard.
ISO 7816 is an international standard related
to electronic identification cards with contacts,
especially smart cards.
And sspecifically section 4 is about Organization,
security and commands for interchange.
It was created in 1995 and According to its
abstract, it specifies things such as “contents
of command-response pairs”, “access methods
to files and data in the card” (remember
the sim card is a small computer, so the sim
card also has files).
And also defines “access methods to the
algorithms processed by the card.”.
So what does VERIFY CHV mean.
Let’s peek into the GSM standard.
Here CHV is described as “Card Holder Verification
information”; access condition used by the
SIM for the
verification of the identity of the user.
Can you guess what that is?
That’s a fancy description for your pin.
The user who knows the pin can verify that
they are the user, by presenting the pin to
the simcard.
And we can also check what VERIFY does.
This function verifies the CHV (so the pin)
presented by the ME (the mobile equipment,
the phone) by comparing it with the relevant
one stored in the SIM.
The verification process is subject to the
following conditions being fulfilled:
- CHV is not disabled;
- CHV is not blocked
So either your pin is blocked because you
entered it too much.
Or you had disabled the pin.
And further we can read.
If the CHV presented is false, the number
of remaining CHV attempts for that CHV shall
be decremented.
After 3 consecutive false CHV presentations,
not necessarily in the same card session,
the respective CHV shall be blocked and the
access condition can never be fulfilled until
the UNBLOCK CHV function has been
successfully performed on the respective CHV.
So this is all fancy documentation language.
But here is basically defined that you have
three attempts for your pin.
And if you fail, the sim is locked, until
you use that other special longer code to
unblock it again.
Interesting, right?
Anyway… after that we can see some SELECT
FILE commands.
So the phone requested the content of files
stored on the SIM card.
One file contains the IMSI. the international
mobile subscriber identity, which uniquely
identifies this sim card.
Also remember that you can store some contacts
on your sim card?
W ell here you can see how the phone requested
the phonebook on the SIM card.
There is one other cool thing.
Vadim looked at the wireshark trace and saw
this.
“Oh also very interesting thing, I will
show you.
It is related to the sim card menu.”
And I was like, sim card menu?
I have never seen a sim card menu.
“you will, for example menu Vodafone services.”...
ohhh that’s what this menu always was.
It’s like a thing I never used.
So this is a menu running on the simcard?
“Exactly.
it’s Probably java application.”.
You heard right.
Usually there is JAVA running on SIM cards.
Java Card refers to a software technology
that allows Java-based applications to be
run securely on smart cards.
It is widely used in SIM cards (used in GSM
mobile phones) and ATM cards.
Crazy right.
And when we click around on that menu, the
phone obviously has to forward whatever we
did in the menu to the sim card, and the sim
card has to respond what kind of text to show
on the screen.
“We can choose one.
It’s in german I think.
“
For example here.
TERMINAL RESPONSE SELECT ITEM. we select an
item in the menu.
And then the sim card responds with a new
text for the menu.
FETCH.
DISPLAY TEXT.
“Simcard said, please display text.
I’m not sure if wireshark is powerful..
OH OK. it is here.”.
So Vadim wasn’t sure if that weird part
of the SIM protocol was actually implemented
in wireshark, but it was.
Here it shows the text “MMS-InfoServices
koennen nur mit MMS faehigen Handys empfangen
werden”.
So that’s german, its a german sim card,
so the menu was german and it translates to:
“MMS infoServices can only be received with
phones that support MMS.”
And I had pressed the back button on the phone.
So the terminal response.
So the response WE gave and the phone forwarded
to the SIM card was hex 11.
Which stands for “backward move requested
by user”.
Isn’t that awesome.
We use these mobile phones every day, but
we have almost no understanding and insight
into how they work.
I hope you found this interesting, thanks
so much to Vadim and all the others in the
OSMOCOM project for creating all those tools.
stay tuned for the next videos.
We will soon learn what makes these phones
so special.
﻿Wow… we have almost solved all challenges
of Pwn Adventure 3.
Only one challenge, “Pirate’s Treasure”,
with 500 points is left.
From our let’s play a long time ago we also
know that there is this pirate ship with a
chest.
Let’s check the boat.
Is that a chest as well?
I don’t trust it!
Oh.
heh.
DLC.
Oh I guess I was wrong with the free-to-play,
I guess you have to pay.
Unlock code entered is not valid.
Try again.
Okay.
I guess we know what we have to do here.
And when you try to open it, it asks for a
“Pirate’s Treasure DLC” unlock code.
So clearly we have to find a valid code, or
key.
So this is probably a keygen challenge.
A quick look into the functions of the libGameLogic
library shows that there are functions called
SubmitDLCKey.
The interesting one is from the Player class
because it will call the VerifyKey function
of the KeyVerifier class.
The return value of this function will be
in the al register.
And through a few indirections eventually
checked here.
This is where it decideds if we print the
failure message or are succesful.
Now you can simply modify the client here
or set a breakpoint and make sure that we
pass this check, but this would be way to
easy.
The client might think it was correct, but
the server, which has the same verification
code, wont give us access to the chest and
thus wont give us the item that is the flag.
So we have to look deeper into the VerifyKey
function.
And that function is not looking super crazy
but it definitely requires some work to go
through.
So how do we tackle this now.
As always with reversing, this already feels
overwhelming.
There is so much assembler code and we have
no clue what’s going on.
So let’s try to be systematic about it and
start with a highlevel view and then work
ourselves down the layers.
Let’s start with a look at the flow graph
and see if we can identify some sections that
we can kind of isolate from eachother.
And right at the start it looks like all this
part over here is part of a big loop.
Then we have a short contained loop afterwards.
After that a simple check.
Then another loop, followed by a longer sequence
of operations which ends in another loop.
And if we pass all of this, we set the return
value to 1, which means the key was correct.
So let’s look at the first loop.
The loop condition here is a comparison and
shortly before that is a call to get the size
or the length of a C++ string.
And of course our VerifyKey function will
get the unlock code we entered as a string
parameter, so this will probably get the size
of the key we entered.
And the return of the call to size, so the
length of the string will be in rax and compared
to rdi.
And rdi is coming from this local variable,
which is actually this local variable and
this one was also set to 0 initially.
If you look at the block right before it loops
back up you see the same variable being loaded,
incremented by 1 and then moved back.
So this is clearly a for loop.
We have the init - i set to 0.
We have the condition, if i is above or equal
the size of the string, we exit the loop,
so the for loop condition is i < size of the
string.
And we have the increment here, which simply
increments i.
So this loops over our input string.
We also know that the string address is passed
to the function via rdi, so this local variable
here is our input key.
And when we look what this loop does we see
that it uses the key and the current i value
with the brackets operator []. So it accesses
the ith element of the string.
And this ith character is then compared to
0x20, which is of course ascii character space.
And the same check is happening for dash.
So if it finds a space or dash in the input
key it will skip this whole part and move
directly to the i increment.
So it ignores those characters.
If it was any other character we have another
check here for 0x19.
And we see that based on some condition this
value is incremented.
So if this check fails we immediately return
from the VerifyKey which means the key had
the wrong format.
But if it’s correct it increments another
value or counter.
So that mens this is the number of correct
characters.
If you look closely at this check, then you
see it depends on a function call to this
obscured function cfZTUjEJ.
So we have to look into that one.
Remember that this is orange here because
it is dynamically loaded, so we have to find
the actual function implementation via the
function search.
Here we got it.
In here we have a check if the character is
a lowercase letter, by checking if the current
character to check is larger or equal to lowercase
‘a’ and smaller or equal than lowercase
‘z’.
If that is the case we subtract 0x20 or space.
This is a super cool property of ascii.
If you check the ascii table you will notice
that the distance of the lowercase to uppercase
letters is exactly 0x20.
This means if you want to convert from lower
to uppercase or upper to lowercase you just
have to subtract or add 0x20.
So here it makes sure that the input is uppercase
by converting lowercase letters.
After that is another loop.
This local variable is incremented here, so
that’s probably another i. we then take
a character from an offset here from i and
compare it to our character we are checking.
If we follow this, interpret this as an address
we land here.
A string 0123456789ABCD and so forth.
BUT be careful, it’s not the full alphabet.
ABCDEF G is missing, I is missing and more.
So this for-loop loops over these valid characters
and checks our input character and it has
to match.
One small but very important detail here is,
that the function takes not only the character
to check, but also a char pointer.
And at the location of this char pointer it
will also increment a value along the for-loop
increment value i.
So it will keep incrementing that value until
the valid current character is found.
This might all look pretty complicated but
long story short, if we go back to the key
verifier, the first loop here is an input
check or validator.
It ignores spaces and dashes but counts and
enforces valid characters.
And our valid input characters are the numbers
and letters in the alphabet we found.
And this one function also helps creating
a new array that maps our input to indices
of the alphabet.
So for example the input letter 0 would be
found immediately and stays 0, but A would
be found after 10 iterations of the loop,
so it would store a 10, Makes sense right,
it just maps out the input key to indices
of the alphabet.
After that we only work with this new array.
Besides that it also counts the amount of
valid characters and compares it to 0x19 which
is 25 in decimal.
So our input has to be 25 characters long.
This means we have understood this part, and
can move on.
On to the next smaller loop.
So this is also clearly a for-loop.
We initialize a value to 0, compare it to
the constant 0x18, which is decimal 24, so
one less than what we thought was our input
length.And then this value is incremented
here.
So that is i of this for-loop.
And inside that loop we take again a value
from the offset of i, I assume we get the
i-th valid input value, then we also load
this other variable, add our character to
it and move the resulting byte back into that
other variable.
That’s all it’s doing.
And after that loop we load that other variable,
apply a binary AND with 0x1f
Load another byte into eax and compare those
two.
Ehh..
So maybe it’s time to set a breakpoint in
the code and see what is happening.
Our assumption is that if we enter 25 valid
characters, we should get to here.
And we also just assumed that this loop simply
sums up the first 24 character indices we
have, and stores the sum result in this variable.
So let’s break here.
To find this we can disassemble they VerifyKey
function by giving it the full name surrounded
by SINGLE quotes.
Gdb should also know tab completion so that
shouldn’t be an issue.
As you can see our addresses in gdb are very
different from the ones in the disassembler.
that’s because our library is loaded somewhere
into memory.
But it’s always loaded memory aligned wich
means the lower bytes should be constant.
So we can look for b98 at the end and we find
this line.
We also see it matches the code, “cmp eax,
edx”.
Perfect.
So let’s set a breakpoint there.
Then let’s enter a string, how about we
just enter the first 25 characters of the
alphabet and see what happens.
We hit the breakpoint and see that 0x14 is
compared to 0x18.
We know that our loop loops over an array
at rbp-0x30, so we can look at it.
Maybe shown as single bytes instead.
Yeah that looks good.
It’s the indices of the alphabet form our
input.
The ascci character 0 matched to byte 0, and
the ascii character ‘A’ matched to 0xa,
so that’s 10.
It’s the 10th character in the alphabet.
So now it’s also clear what the code does.
If we now print the memory locations from
our two values that are compared, so rbp-0x41
and rbp-0x18, we see that the sum is compared
to the last character value.
And that’s a mismatch.
We can also verify that in python.
First we define the alphabet with our characters.
Then we loop over the first 24 characters
of our test, and our test input was just using
the alphabet.
And for each character we can then find the
offset, the indice in this string and add
it to the sum.
The result is 276, or in hex 0x114.
The sum is also anded with 0x1f, so the result
is 0x14, exactly what gdb uses to compare
the last character, the 25th character.
So this is a CHECKSUM.
This is a simple verification that you didn’t
mistype the unlock code.
The last character of your input is derived
from the sum over the first 24 characters.
This is our first important milestone.
If we try to reverse the keygen, we know now,
if we find 24 valid characters, then the last
character, the 25th one, is simply the sum
of those.
It must be so hard to follow this boring reversing
in assembler.
But we slowly make progress.
So I let’s do a cut here because we finished
the first part.
﻿Last video we figured out how to overwrite
certain functions with LD_PRELOAD and how
to access the internal objects from libGameLogic.
With that we were able to increase our walking
speed a lot.
So let’s see what else we can do.
One really cool thing would be flying, right?
Flying… so how could we get flying.
There is obviously not an attribute in the
Player class to simply enable flying, but
we can maybe be creative with what we have.
And jumping is definitely close to flying,
we just can't fly very high.
And we will fall back down.
So Maybe we can make something out of that.
I have noticed there is a jumpHoldTime and
jumpSpeed.
So let’s set jumpSpeed to a higher values
and check what it does.
Let’s compile our evil library, then we
LD_PRELOAD it into the game and then let’s
see what changed.
When we now jump, whooooosh… ok I think
the speed was a bit too crazy.
But we get a nice view of the map.
Including an island?
We haven’t found that island during our
let’s play in episode 1.
I wonder what we can find there.
So let’s tone down the speed a bit.
And now also add the jumpHoldTime with a higher
value.
Then we can try it again.
Ok…
So jumping seems fairly normal.
Except that I can keep space pressed, or you
know hold space for a longer time.
And then I keep rising up.
That’s pretty cool flying already, but the
issue is, that once I release space again
we start falling down and we can’t jump
anymore until we touch the ground again….
Mhmh
This is kind of the challenge with game hacking.
We have essentially all power of the world,
we can modify any memory, call any function
we want, we just need to be creative with
what and how we do it, so we can make it usable
and fun.
So when I was looking around a bit more I
found that the Player class has a function
called CanJump(), which returns a boolean,
true or false.
So let’s try to overwrite that function
and always return 1.
When we now try this ingame, we can fly up
when we press space, decline when we release
it, but then we can also press it again to
jump again and thus, fly up!
While the flying is not perfect, because the
player has an awful velocity while in the
air, it’s still pretty neat.
If anybody finds a way to be able to move
horizontally as if you are walking on the
ground, let me know!
Let’s fly a bit higher to see again which
direction the island was.
Hehe so cool.
The island looks awesome from above.
Oh… there is a dark spot over there.
Is that an island?
ENHANCE!
It could be the island!
Let’s fall back to the ground, which takes
a little bit, but then thanks to our super
speed we just quickly run there!
We are approaching it.
ISLAN HERE WE COME!
Entering Cowabungalow!
Oh look there is a chest!
And the Cow King!
Remember the Gold Farm from the Let’s Play
in episode 1?
Welcome to the gold farm.
I farm all day to provide for this island.
But it has all gone wrong.
What’s wrong?
My Cows are missing!
One night I heard a massive amount of thunder
, then my cows had disappeared.
I have no idea where they went.
I will let you know if I see them.
So sounds like we found the Cows!
Ouch!
The Cow King just killed us!
Damn…
With the attack Static Link.
It’s a 1337 Magic Spell.
And dealing a lot of shock damage.
Let’s respawn. and checkout that house here.
Welcome to my humble bungalow.
I was enjoying my private island until those
mad cows showed up.
Where did the cows come from?
One night I heard a thunderous boom, and when
I looked outside there were mad cows everywhere.
There is one in particular that worries me.
That sounds familiar.
I think I know who owned these cows.
Which one worries you?
The one with the crown!
Anything that gets close gets struck by a
bolt of lightning out of the blue.
Do you know any magic?
I do.
Why do you ask?
I have a legendary magical cube here.
I read that it posseses.
TYPO!
THERE IS A TYPO.
LITERALLY UNPLAYABLE!
I read that it posseses the power of the fable
Rubick, and might be able to steal the thunder
of the Cow King, leaving it defenseless.
Have you tried to use it on the cow?
I would, but I’m terrible with magic.
My last attempt got me stranded on this island.
That fast travel spot right there is such
a tease, as whatever magic got me here is
preventing me from using it.
Would you please take the cube and try it?
I will take it and try to use it.
Here it is, I won’t need it back.
No more magic for me.
Good luck, now go steal the Cow King’s thunder.
Thank you.
I will see what I can do.
Acquired Rubick’s Cube.
I am Legend.
AND WHAT THE HECK.
Killed by a Mad Cow.
Thank you.
Ok.
Now let’s go to the Cow King again.
It’s attacking me, let’s spam using the
Rubicks Cube, and I steal the Static Link
skill!
Now I can use Static Link.
There we go.
Quest complete.
Until the Cows Come home.
And a New Achievement.
Monster Kill.
We also get a weapon, the Cowboy Coder.
But let’s check out the chest.
Acquired Flag of the Cow!
1337 Flag.
The key is: I should’ve used dynamic link.
Wuhooo…
Our first flag.
And if we would have found this during the
CTF, we could now submit this flag to the
scoreboard to get points for our team.
Awesome!
We are slowly making progress.
Before we end this, maybe we could also take
a quick look at the original list of challenges
to get an overview what our goals are.
This was the CTF page for the Ghost in the
shellcode CTF 2015.
And here is the challenge we just solved,
“Until the Cows Come Home”.
We would have gotten 100 points for that,
and it was the easiest one.
I think next time I try to go for Unbearable
Revenge.
Btw.
If you wanna follow along and try this out
yourself, you can find all the files in the
description of the videos.
﻿Let’s have a look at format level 4 from
exploit-exercises protostar on a current ubuntu
machine.
And this time I thought instead of building
the complete exploit from the ground up, we
take the old exploit that we developed for
the 32bit linux image, and see if it still
works.
Probably it won’t but then we debug it and
slowly make it work on this 64bit ubuntu.
Okay so here is the source code again.
We have a 512 byte large buffer on the stack,
which is used to read data from standard input.
But it only reads up to 512 bytes, so there
is no buffer overflow.
But then this buffer is passed directly to
printf, so we have a format string exploit.
Our goal is it to redirect code execution
to the hello() function.
Notice how here after the printf() we find
an exit?
Well that was intentionally placed here because
exit is part of libc, so there will be a global
offset table entry for it which we can overwrite.
Then when we call exit here, our overwritten
function would be executed instead.
So it’s actually a pretty straight forward
format string exploit.
Just write to the exit GOT entry the address
of hello and you are done.
Hello() and the GOT table have fixed addresses
and are not affected by ASLR.
At least on this ubuntu version because of
the default compiler options.
I received several comments that wrote that
on their system they default to PIE.
So there the GOT address and the functions
will be affected by ASLR and then I don’t
think these simple cases are exploitable anymore.
We would require a little bit more complex
examples, with more interactions, where we
first can leak values to defeat aslr.
But we will slowly get there, over time.
Let’s not rush too quickly into those topics.
So we compile this now on our ubuntu machine
and we get the old exploit code.
Man this was episode 0x13…
August 2016… holy shit that is a long time
ago.
When I started I thought I would have very
quickly a complete series on all the basics...
and we still haven’t reached ROP and ASLR.
mhmhm…
Goddamit.
Anyway.
Let’s copy that python code.
Looks good.
Now I write it into a file - `exp` and then
we can start gdb with format4 and execute
it.
Run and then we pipe in the exp file as input
to the program.
Uh we print a lot of character, that looks
good but we get a segfault.
We are attempting to write the value in r15,
0x84b4 to the address in rax.
And rax is obviously wrong.
0x58 is X.
So this is the %n part of the exploit.
0x84b4 is the amount of characters already
printed, that’s all this empty space here,
and it tried to write to the 4th value, and
that turned out to be not the address anymore.
So two things.
First of all obviously the amount of characters
that we are writing with %n are wrong, we
don’t even know yet what we want to write.
And most importantly, we are not writing to
the address we have specified in the exploit.
Now with the format string offset we hit our
padding.
Okay so let’s use this opportunity and get
the correct addresses first.
We need the address of the exit GOT entry,
we do this by looking where it is called.
Then we simply disassemble the few instructions
that jump to the GOT entry, that’s the PLT
the procedure linkage table.
And here it references the exit GOT entry.
You can see it will jump to whatever address
is written there, so we have to overwrite
this with the address of hello.
And here is the address of hello.
You can see again that only the last 2 bytes
of the current exit GOT entry and our desired
hello address are different.
Which means we only have to overwrite those
last two bytes.
So let’s place these two new addresses in
our exploit code and we can also throw away
the old format modifiers.
The amount of characters we print is wrong
and the offset doesn’t match anymore either.
And instead we just add a bunch of %p, to
find our new stack offset.
So we write it again to a file, start gdb
and pipe the file in as input.
Ehm… no real output?
Just like an @ and backtick?
Where are the addresses we leak with %p?
These are the small things that can be really
frustrating and this actually happened to
me when I was preparing this episode.
I was going crazy trying to understand what
the heck is happening.
I’m just executing it over and over again,
hoping the computer would do something else.
I’m debugging it to break before the printf
and see that my input is passed to printf.
But no output.
GHNANAN goddamiit work!
But it will not.
If it’s not doing what i want it to do,
I made a mistake.
I am the problem.
I need to calm down, take a step back and
try to figure out a way to figure out my stupid
mistake.
So what exactly is the output we get.
I pipe the exploit output into hexdump and
see that it stops after three characters.
And that is our address but cut off.
The other address and the format string is
missing.
But when I then also did the hexdump of the
exploit I noticed the obvious mistake.
The address has a null byte.
And printf stops at a null-byte.
Strings are null-terminated.
Godam I’m so dumb.
This was not an issue for the 32bit exploit,
because there our address had also 4 bytes
and thus no null-byte.
Now on 64bit the default address is only 3
bytes.
So our next step is - we move the address
at the end of our exploit.
They still get placed on the stack with the
nullbytes.
fgets will read nullbytes.
Just the printf format vulnerability part
must not have a null-byte.
When we move it to the end we want it to be
in a fixed location, so we add padding to
our format string and then make sure we leave
enough space for the two addresses at the
end.
We are on 64bit, so we have 2 times 8 bytes,
so we need 16 characters.
Looks good.
So we try that intput into format4.
Looks good, we print values now.
But I can’t find our address.
Let’s actually have a lot more %p.
How about 100, that fits easily in the 512
bytes.
Ok so where are they.
Here they are are?
But that doesn’t look good.
They should be two individual values.
But it’s pretty clear what happened.
We forgot to also encode the addresses for
64bit.
Struct pack I packs the integer in 4 bytes,
but we want it packed in 8 bytes.
So let’s try it again.
Here they are.
This looks good.
Now let’s find their offset.
We can just count how much to the end.
And then subtract from 100.
So at offset 68 we should find the address.
And yes indeed.
There it is.
So now, we just have to print the correct
amount of characters to write the two bytes.
Actually, we don’t need two writes, we should
be able to do that in one.
So we add another format string with a padding
of the amount of characters we want to write.
That would be 0x676, minus the characters
we already printed before that.
So basically minus 8.
And then we should also remove the spaces
before the %n that would be another character
printed.
So it should work now, right?
Let’s change the %p to %n and try it!
Segmentation fault.
Damn…
So when I was recording all of this I really
thought it should work right away.
But then I got the segmentation fault.
Really confused me.
And that would be again something I could
obsess about.
Why did that happen?
But after I stopped recording and literally
started to write down what I just did, in
the script.
I realized my mistake.
When I wrote down %n
I realized I wrote a whole integer.
But I meant to write only two bytes, so I
would have required %hn.
We should be able to verify this with gdb.
Let’s check it out.
Yes there it is.
Segfault at address 0x676.
We wrote a whole integer, so we overwrote
the higher bytes that were already stored
in the GOT.
So let’s change it to %hn.
To write half a word or whatever that means.
It writes two bytes.
And that worked!
code execution redirected! you win
You see the exploit is different from the
original 32bit version.
It required quite some changes but it also
kinda is still the same thing.
Definitely not a hard challenge on a modern
system.
As long as you don’t compile it with PIE.
﻿In the last video we used the very simple
sandbox bypass from version 1.0.8 and checked
why it doesn’t work anymore for 1.4.7.
After that we started to look at the sandbox
bypass from gareth heyes for this new version.
In this video we will continue where we left
off last time and debug the AngularJS code,
evaluating the evil expression that will lead
to an alert.
So as a quick reminder, the sandboy bypass
looks like this.
It has two parts.
The first part attempts to overwrite the charAt
function with another function.
Which hopefully screws up angular internally.
And the second part is dollar eval, which
is the angular eval to evaluate an expression.
So this is basically a new expression inside
of the other expression.
Also remember that a lot of stuff has changed
internally from the old version.
The concept is the same - angularjs parses
an expression, evaluates it and somehow executes
it.
Just how it’s done has changed.
We will see what it does by stepping through
the code.
Ok.
Let’s start for real.
Here we are at the first breakpoint that we
hit after we load the page.
I placed this breakpoint into a function called
lex.
This is the Lexer.
Wikipedia tells us that lexical analysis is
the process of converting a sequence of characters
into a sequence of tokens.
The lexical analysis is basically the first
step in a compiler.
So if you are a computer science student and
always wondered why the heck you ever need
to know compiler construction, here is a real
life example.
Also if you look at the call stack you can
see that the lexer is called from somewhere
with the name AST compiler, which stands for
“Abstract Syntax Tree” compiler.
It sounds weird but that is literally what
this is.
AngularJS implements a compiler that takes
an agnularjs expression, which looks like
javascript and compiles it to real javascript.
There is a damn compiler inside of angularjs.
A compiler that compiles something like javascript
to javascript.
Anyhow… still freaks me out.
Back to the lexer….
So.
This function has one parameter called text.
And text contains the current angularjs expression.
According to wikipedia this lex function should
parse a string and extract tokens from it.
And after our breakpoint we can see a while
loop that does exactly that.
This while loop iterates over the full length
of text.
And in each iteration it will use text.charAt
to get the next character of the string.
So the first character would be the single
quote from the string a.
When we step one step further we get to an
if that checks if the character is a single
or double quote.
Which is obviously the case.
So we will follow this and call the helper
function - readString.
Because this single quote is an indication
that a string starts.
And this whole while loop is full of ifs and
helper functions like that.
But in the end we will get an array of tokens.
So lets continue until this next breakpoint.
Now we should have all tokens extracted from
the expression.
This.tokens is now an array of Objects.
The first object, or token, is the string
“a”.
Because it’s a fixed string this is also
considered a “constant”.
The next token is the dot between the string
and the constructor.
And the third token is the constructor.
Which is considered an identifier.
All variable names and function names etc.
are identifiers.
Also for example the 8th token is the equal.
Which is an operator.
And before that we have the charAt function
name, which is also an identifier.
Now when I press continue until we hit the
next breakpoint a loooot of stuff will happen.
And we all skip that.
Basically this lexical analysis to extract
the tokens was the start of compilation and
now we will have a look at the result of the
compilation.
So we skip the whole complicated compiling
part.
So continue.
And now we are here.
At the end of AST Compile.
Just before our breakpoint we have here this
variable called fnString.
Stands for function string.
And I printed that string to the console log
down here.
And this. is . the compiled javascript code.
That is the result of compiling our angular
expression to javascript.
This looks a bit awful to read, so let’s
copy it over into javascript beautifier to
indent it properly and have a look at it.
Sweet.
That looks more readable.
It might look crazy and complicated at first,
but it’s actually pretty simple.
So first of all, this code starts like our
expression with the string a.
And stores it in the variable 4.
Then it attempts to get the constructor from
variable 4.
So the constructor of the string.
After that angularjs added a function ensureSafeObject
to check if the constructor of variable 4
is safe.
And because that is just the String constructor,
it’s considered safe.
Remember that this function was responsible
for the exception when we tried to access
the function constructor with the old bypass.
After that the constructor is moved into variable
3 and checked if it has the property prototype.
If that’s the case, the reference to prototype
is saved in variable 1.
And as a last step we check if the string
prototype stored in variable 1 has a charAt
property.
Now we are done with the left side of the
assignment
Up next is the right side.
Here we start also with a string.
String b is moved into variable 5 and follows
it up with referencing concat of it and moving
it into variable 0.
Then angularjs checks if charAt of variable
1 is a safe object.
But that is obviously just the normal charAt
function and that’s considered safe.
Afterwards variable 1 itself is checked, because
we are about to assign something to the string
prototype in variable1 and angularjs want’s
to be sure it’s safe to assign something
to that object.
Man.
If angularjs would just know what is about
to happen.
Now the crucial part.
We assign the concat function in variabvle
0, to the charAt function of the String prototype
in variable 1.
Now the first part of the exploit is done.
At this point charAt should have laid an alien
egg inside of angular’s body, which is about
to hatch and break out of angular’s chest.
The following few lines are then the second
part of the exploit, which is fairly short.
It basically gets dolalr eval now from the
scope object, does some checks on those variables,
including the string parameter we pass to
dollar eval, but it’s just a string.
So all is safe.
And eval is called, which initiates another
parsing, compilation and execution of this
string.
Now that we understand the compiled code.
So let’s see what happens with that.
After our old breakpoint fnString is used
in a call to the good old Function constructor,
which will create an actual function that
can then later be called.
At the end it will return this function fn.
I’m about to hit continue again so we will
jump to our next breakpoint.
The next breakpoint is inside if ensureSafeObject.
That is one of the function called from the
compiled code.
So that means we are actually inside of our
executing expression.
Go!
Boom. ok.
Ensure SafeObject.
In the call stack we can see that we are coming
from fn.
And fn is this compiled function.
You can pretty print this code by clicking
on the curley braces in the bottom left of
the source window.
Yep, this looks familiar.
Just what we looked at before.
Here is our string a.
And getting the constructor of it.
Etc.
When I now continue we are again in ensureSafeObject.
This time further down in the code.
Actually right before we assign and overwrite
charAt.
Just one more check before, the ensureSafeAssignContext.
Ok let’s continue a bit more, until we are
back inside of the lexer.
Why are we here again?
Well as you can see in the call stack we are
coming from fn.
And fn called dollar eval.
And dollar eval is just now triggering evaluation
and execution of this new expression string.
As expected, text is simply what we passed
to dollar eval.
But let’s step further.
We are again heading into the while loop that
is supposed to extract single tokens from
this character sequence.
The index starts again at 0.
So now angularjs tries to get the first character
from the string with charAt.
But charAt is not charAt anymore.
The alien hatches and feeds on angular’s
intestines.
Charat zero appends now zero to the string,
instead of returning a single character.
So ch is super long and thus not the start
of a string.
It’s also obviously not a number.
BUT!
The validation function isIdent thinks that
this is now an identifier.
Remember that usually variables and function
names etc. are identifier.
That means that usually identifiers do not
contain special characters, such as the equal
or curly braces we have in this string.
And if we continue now to the end of the loop,
and look at the tokens, we can see that there
is only one token.
And It’s an identifier with our whole string.
That is just wrong.
An identifier should not have those weird
characters inside.
If we continue now, we hit the next breakpoint
at the end of compilation.
And we can have a look at the resulting javascript
code.
Let’s again copy it over to js beautifier
to see what happenned.
Ah.
You can already see here the part2 of our
exploit embedded in the javascript code.
You can also see that it’s S. Dot. exploit
blah blah.
Remember that all expressions are evaluated
against the scope object?
Well because angularjs thought we had an identifier
in our expression, it placed that identifier
in the compiled code by checking if the scope
object has such a proeprty.
In this case this totally blows up because
the identifier had non valid identifier characters.
When you ident it properly it becomes more
clear.
You can see now the start of our expression
with exploit equals 1 and the three closing
curley braces.
Then the breakpoint and then the alert one.
So when we continue now, we should hit that
breakpoint.
Boom.
Indeed.
We are inside of the compiled code at the
breakpoint.
Pretty print it again.
And let’s enjoy this beauty for a second.
Then hit continue, which will execute alert.
Awesomeee!
And this is how the angularjs sandbox bypass
for version 1.4.7 works.
We overwrite the charAt function that is shared
for all strings.
Which breaks how angularjs parses expressions
allowing us to inject bad characters as an
identifier in the compiled code which we can
abuse to break out and write arbitrary javascript
code.
﻿This is the 10th episode. And as you can see
in the title, I am counting the episodes in
hexadecimal. I am wondering if the google
algorithm will screw this up with the suggested
next video is wrong. Anyway, I want to explain
in this video why hexadecimal is cool and
why you should use it, when it comes to computers.
I will also show you how I convert values
back and forth and how I often work with them.
Ok. So. our computers work in binary, 0s and
1s. Because it is a representation of the
physical behaviour of our circuits that we
have transistors, that are like switches and
they are either turned on or off. A single
value that is either 0 or 1 is called a bit.
You may know that a byte is 8 bits. But maybe
you wonder why that is. Well, this was not
always the case. Early computers might have
had 6 bits per byte. That we use 8 bits for
a byte nowadays is just how history turned
out. It was IBMs fault with the System 360
that heavily pushed for an 8-bit byte. Also
some people say octad instead of byte to make
clear that they mean 8 bit.
An interesting example is ascii, because you
will notice that it actually only uses 7bit.
But because we now generally use 8bit bytes,
we kind of waste the first bit.
We humans grew up with the decimal system.
We are used to counting with symbols from
0 to 9. But that is rather arbitrary. Sure,
we have 10 fingers. But we could also count
in 12ths, because we have 12 finger bones
and we can use the thumb to point to which
number we are at. This is the Duodecimal system
and we actually use it on our clock.
So If you would have grown up with counting
in hex or binary, it would feel as natural
to you.
Instead of thinking of numbers as something
fixed, think of it as a tool. And you can
use whichever number system makes sense for
a particular problem.
So our computers work with bits. And for our
modern computers we have defined that we generally
work with bytes of 8 bits. And 16bit, 32bit
or 64bit architectures just play with this
value to keep it nicely divisible by 8.
When we look at data as raw bits: 0000 0000,
we quickly see that a byte takes a lot of
space if we display it in that way. Maybe
decimal would be a cool representation. It
certainly would take less space to display
them. I will use python now to show you how
we can convert binary to decimal numbers.
We simply say that this string represents
a number in base 2. Let’s do it for a couple
of examples with a simple for loop.
Ok. Well. Takes less space. Though, it kinda
bothers me that the biggest value with 8 bits,
is a weird number in decimal. A number without
any interesting properties or meanings. Let’s
have a look at those numbers in hex. Hex numbers
use symbols from 0-9 and A-F to describe a
number.
We can extend our loop in python.
And now you can see how pretty hexadecimal
numbers are to represent 8 bits. The biggest
8 bit value is also the biggest value in hex
that can be represented by two digits. If
we would add 1 more bit, so that we have 9
bits, we would also have to add another character.
And not only that, if you look closely, it
also nicely represents the two individual
nibbles, that means 4 bits.
So a 8 bit number in hex can be represented
by 2 symbols. And each symbol refers to one
nibble. So this makes it very very clear and
easy to read.
And now you can understand why the decimal
representation is not very fitting for this
kind of stuff.
Can you tell me what is the maximum number
that an unsigned 32bit integer can represent?
Well I don’t know in decimal. I just know
that 32bit is 4 times 8 bit and thus max int
is 0xFFFFFFFF.
Now let me quickly show you some cool tricks
with python to convert stuff back and forth.
Python has some builtin functions to convert
numbers. For example hex() and bin(). And
also to parse a binary or hex number with
the int() function and specifying which base
it is.
If you have a binary string, this means that
maybe not every value in this string is a
nice ascii printable character, you can use
encode and decode on the string to get the
hex representation of the characters. So hex
41 is a capital ‘A’ in ascii.
A much more powerful and important functionality
is offered by python structs. Which I use
all the time when I deal with binary data.
First import struct. And then we can use struct.unpack
on our data. In this case I define that this
data is an unsigned Integer. And you can see
I can convert this binary data now to an integer
number. If you look closely you may wonder
why the capital A seems to be at the end of
the number.
The reason for that is that we have a little-endian
system. bit’s can be interpreted in two
ways. Either the first or the last bit can
refer to the least-significant bit. I think
the picture on wikipedia makes this very clear.
This can be very important when you receive
data from a big-endian system, because then
you have to be careful how you interpret this
data. But with python struct it’s easy and
we can define as which endian system we want
to interpret this data.
If you watch some of my CTF exploitation challenge
videos, you will see me using python structs
a lot. Because it’s great to convert addresses
and other data back and forth.
For example if we want to overwrite an address,
we have to supply the data as a string. So
we can use struct.pack and pack a number as
a binary string.
So the hexadecimal system makes working with
computers much more simple and you should
get used to it.
But we just talked about positive numbers.
From 0 to 0xFF. But how can we represent negative
numbers. Maybe you have heard of the signed
bit, that the first bit tells you if it is
a negative number or not. Though, it’s not
as simple as simply reading the remaining
7 bit and decide if it’s positive or negative
based on the first one. -1 is actually 0xFF.
Well it does have the first bit set, but it’s
not -127. This wheel maybe makes it a bit
more clear how negative numbers are actually
interpreted.
The operation to convert their absolute value
into the negative value, so for example 255
(0xFF) to -1 is called Two’s complement,
you can read that on wikipedia.
And you can also very easily negate a given
number by negating all bits and adding 1.
Many functions return -1 on error. At first
it sounds weird, but now you know that this
is just all Fs. So when you read data and
you only get 1s (or Fs in hex) you might read
an errror.
What about numbers with a fraction. Well.
Don’t get me started on that. It get’s
really ugly. But you can guess that representing
a value with many digits behind the comma
can get very creative if you have only 0s
and 1s.
Now before we end let’s get a summary of
the terminology:
we start with a bit. 0 or 1.
4 bits are a nibble. 8 bits are a byte. And
in hexadecimal we can represent a byte with
two digits.
on 32bit architecture a word refers to 32bit
or 4 bytes. But on 64bit architecture a word
is 64bit, or 8 bytes. And a double word is
obviously the double amount of that.
As you can see, a computer only has bits.
And how we deal with those bits is up to our
interpretation.
I know this was a bit shorter and less technical
video, but I thought it fits and next time
we will dive deep and exploit our first buffer
overflow.
﻿I don’t like pop-under ads and as a Chrome
user I’m happy that Google agrees with me.
They consider them to be bugs in their popup
blocker.
I made a few videos a few months back where
we have reverse engineered one particular
obfuscated JavaScript library, used and sold
to advertisers, in order to figure out the
trick they use.
And then reported it to Google to get the
bugs fixed.
Back then it has also motivated Masato Kinugawa
to research a few more techniques and overall
we killed quite a few bugs that allowed pop-unders.
And I think we were quite successful.
For a long time the popunder library did not
have a working popunder technique for Chrome
and had to resort to a tab-under.
which was awesome, for a while we are the
reason why a lot of advertisers that use this
script couldn’t create terrible pop-under
ads on Chrome.
But now I was made aware by SilentHammer on
the subreddit, that the popunderjs library
has been updated and ships now with a working
pop-under for the current Chrome version 65
up to the current development version 68.
And indeed, the demo works.
There is a pop-under.
So let’s figure out how it is done and then
report it as well.
The first few steps that I’m doing now are
the same I did in the previous videos.
I essentially want a local mirror of the scripts
so I can modify them and play around with
it.
So I use the Chrome developer tools to get
all the script files loaded by this site and
save them.
And because of the licensing, and this being
the demo, and I don’t know how the license
check works (It might check the hostname)
I do not only download all the files, but
I also change the /etc/hosts file so that
the domain points to localhost.
Then I use php to launch a local webserver
and serve the files with the same folder structure
as the server.
Now I have all the files locally and can change
them however I want.
For example I can clean them up and beautify
the scripts.
The files are loaded locally now.
And a quick test, yep the popuner still works.
Ok…
So let’s have a first look.
The javascript code is clearly still super
obfuscated.
So nothing we really want to work through
statically.
And trying to look at the script dynamically,
with the chrome developer tools is also still
super annoying, because the script constantly
traps the debugger with the debugger keyword.
We can disable the debugger and still run
it, but then we can’t set any breakpoints
if we do want to pause.
Goign up in the callstack we can see where
this debugger call is coming from and it’s
coming from this function a().
And here we can see that a() is always repeatedly
called with setTimeout.
So we can try to overwrite setTimeout with
our own function, which also logs some information
about the call.
This hopefully disables the debugger traps.
When we now reload the page it looks really
good, we don’t break, but we also don’t
see anything in the console.
But that’s because the code constnatly clears
the console.
Luckily the developer tools are cool and just
tell us the line where this clear is called.
So we can go there, set a breakpoint by clicking
the line number and BOOM, the debugger breaks
here.
Now we can analyse the code.
Capital I is the window object.
The Kn variable is the string console, and
hn is the string clear.
So this simply calls window.console.clear().
Perfect!
We can also find this line in our script and
can just comment it out.
Now when we reload the page we see exactly
the outputs.
And as you can see, some stuff tried to call
setTimeout, however also the popunder is not
working anymore.
So i guess just overwriting it didn’t help
us.
Let’s revert it back.
Another thing we used was the performance
tab.
This one can be used to record every javascript
function call.
So we can hit record, trigger the popunder,
aaand hit stop again.
Now it takes a moment to gather everything.
And here we have it.
This is the timeline, and all of these colorful
bars are function calls.
So here is clearly our start, this is the
mousedown event.
Later in here we also see a onBeforeOpen,
which is actually a call into the demo.js…
So this is a library sold for advertisers,
and so the library creator offers here functionality
that you can run code just before and after
the popunder was opened.
This means our pop-under createn should happen
after this one here.
Interestingly the whole function graph stops
here now.
Not everything happens down in the hierarchy
from the mousedown event.
There is a weird Function call later, which
at some point results in open.
The orange functions are generally regular
javascript stuff, like events, and all the
javascript functions, and the pink ones are
custom ones.
So these are all the obfuscated functions
as you can see from the name.
And actually there are two of these blocks
starting from a weird arbitrary function call
which result in open.
And open is the function to create a new popup
or tab.
So it does it twice.
I have actually no clue what triggers this
initial function.
If it would have been directly called from
the mousedown event it would be part of that
block.
So that’s weird.
But looking at this I don’t see anything
special.
There are no calls to create new HTML elements,
nothing external is loaded, it’s just these
open calls.
So that’s super wierd.
We can also look at from where open is called,
by looking here at the call stack and following
that link.
So this apparently calls open.
And these should be the parameters of open.
Let’s search for this snipped in the script.js
file we have and then add some console.log
outputs to print the parameters passed to
open.
We save the new script, reload the page, trigger
a popunder and look at the console.
So we see two opens.
Both have the first parameter about:blank
and the second one _blank.
A look into the API reference for open we
can see that that is the URL and this is the
name.
But the first open has additional optional
windowFeatures.
It defines width, height, and stuff like that.
The second open didn’t have that.
Okay, nothing too special here either.
WHile playing around I also noticed that the
anti-debugger trapping is not that aggressive,
so we can actually add our own debugger statement
here at the open call, reload the page, disable
the breakpoints and then prepare to be super
fast.
Because we can very quickly reactivate the
breakpoints, quickly switch to the browser
window, HOPE that the anti-debugging traps
don’t trigger first, click somewhere to
create a popunder and hope that our breakpoint
at the open is hit.
And that worked.
Here we are.
Now we can see the state of the variables
which we already know.
We can also see the callstack and have a look
at where this call is coming from.
Notice how it says here postMessage async,
that will explain a lot later but when I looked
at it the first time, I was just a bit confused.
And looking at this function here, we see
a variable i, which is a MessageEvent object
with a data attribute containing our window.open
parameters… mhmhm...
At this point I got a bit frustrated.
If you have watched the previous videos you
know what kind of crazy techniques were used
to pull off a pop-under.
I didn’t fully trust the developer tools
to be honest, because maybe there are tricks
to hide stuff from it.
I was expecting something really really crazy
and I decided to get out the big guns.
I wanted to directly look at the native functions
being called from javascript, so nobody can
hide anything.
I went to the Chromium sources and followed
the “Checking out and building Chromium
for Mac” instructions.
If you want to follow along and build Chromium
as well, make sure you have enough disk space.
Not only did it take me over night to build
it, in the end I also needed almost 80GB disk
space for it.
So be warned.
But that’s not too bad, because with minimal
changes you don’t have to rebuild the whole
thing again, it only has to rebuild the part
you modified.
So that’s cool.
I also have to give my kudos to the build
team, or whoever is responsible for this,
these instructions just worked.
I had no issues at all, it just worked which
I did not expect.
Anyway… so…
I want to log important javascript function
calls.
For example the open call.
But also things like createElement or any
other API call.
All these calls somehow have to be executed
by the underlying Browser so you can’t fake
or hide anything.
In the end these native functions have to
be called.
It’s the first time for me looking at these
sources, so I have no clue what I am doing.
But let’s maybe think about this for a second.
Maybe you have heard of V8 - Chrome uses the
V8 JavaScript Engine.
And there is a sub directory for the v8 engine
with the sources.
So maybe this is a good point to start?
Well, maybe, but probably not.
V8 is just JavaScript, but we are not really
interested in logging when something creates
an Array or so.
We want the APIs that glue together the Browser
and the JavaScript, and that is mostly the
DOM.
The Document Object Model is what we can use
from JavaScript to interact with the Browser
and the HTML.
However Chrome also has a lot of other APIs,
like the Notification.requestPermissions and
these are probably not included in the DOM,
but we deal with that when we need to.
Let’s start with something easy and look
for the document.createElement function.
In previous popunder videos that was a crucial
part in the trick so it would be awesome to
log that.
And so the DOM is most likely part of the
actual browser engine and in case of Chrome
that would be blink.
I looked around in the huge codebase for a
bit and then I found it in /chromium/src/third_party/blink/renderer/core/dom.
So I open that folder in sublime and then
let’s start searching for createElement.
Oh we find something in a .h header file,
let’s actually restrict it to only c++ source
code files.
So here we go.
We find some functions in document.cc.
Which I think is awesome.
Because the javascript function would be document.createElement.
So here we definitely find a lot of important
APIs.
Soo.. createElement…
There we go “Entry point of "create an element".”
That sounds perfect.
So I guess this is the native C++ function
being called when you call document.createElement
in Javascript.
Let’s test that.
Let’s add a simple recognizable printf()
here, just so we know if this is being executed.
Then we rebuild chrome and as you can see
it goes pretty fast now.
Only had to build the change we made.
And then let’s execute our own Chromium
build.
I also wrote a short test create script, that
will call createElement whenever we click
the link here.
But it doesn’t seem to work.
Damn. no output.
It also links here the specification of the
HTML living standard that defines these kind
of things.
And it says here “concept create element”,
so not really sure what that mens.
But when I searched a bit more in the document.cc
source code, I found the CreateElementForBinding
function which links to the dom-document-createelement
specification.
OK this one actually sounds like the correct
function.
So let’s add a printf, here.
Then we compile Chromium again, open the test
webpage and click the button.
And awesome!
Our printf works.
Now we have all the power to log every function
we want.
It might just be a bit tedious to add these
printfs everywhere.
I played around with it a bit more.
Added printfs to different kind of functions
like getElementsByTagName and stuff like that
but.
It didn’t reveal anything new.
It just didn’t seem to do anything weird...
mhmh...
At this point I decided to sit down and started
to implement what I already know.
I know 100% that there are two open calls
and we know their parameters.
We also know that it somehow is all triggered
from a onmousedown event, so let’s do that
as well.
And then we try that.
It opens a popup, but as expected it only
opens ONE.
The second open call is blocked by the pop-up
blocker.
The browser allows one user interaction, the
click, to open one window, because if the
user clicked, then one window is fine.
But not a second one.
However let’s just for testing disable the
popup-blocker and allow this page to create
any popups it wants.
When we now try it again, the second open
call actually creates a new tab.
And the tab gains focus.
See, the popup at this point is in the backrgound.
Let’s add a setTimeout to our script, to
close the new tab after 1 second again and
try that.
We click the link, it opens the popup and
tab, the main window gains focus and then
the tab is closed when the timeout hits.
BOOM… we have a successful popunder.
Holy crap.
This was damn simple.
As long as we can open two windows, one popup
and one tab, we can get focus back to the
main window.
But with activated pop-up blocker, which is
the default, this doesn’t work.
So the creator of this pop-under script actually
found a technique to bypass the pop-up blocker
and open multiple windows.
And this is where the postMessage comes into
play from earlier.
While looking around a bit more, looking at
call stacks and stuff, at some point I stumbled
over it again and it clicked.
WAIT. postMessage and here is the message
data?
Maybe the reason why the two open calls were
shown in their own function block is because
they were onMessage events, triggered from
an asynchronous postMessage.
That totally makes sense, why didn’t I understand
that earlier?
So I quickly implemented this.
I create an onMessage handler, which looks
at the data and either creates a new popup
for data 1 or a new tab, which is also closed
again with 2.
And then I simply trigger a postMessage with
1 and 2 in the popunder function.
This should create both the popup and the
tab.
Let’s try that in the browser, clicking
the link, it creates both.
Amazing.
We bypassed the pop-up blocker.
This also means we can spam popups now.
If we just keep sending postMessages in a
loop.
Look here.
So, now we are done here.
I have reported this issue to Chromium and
hopefully it gets fixed soon.
﻿I don’t like pop-under ads and as a Chrome
user I’m happy that Google agrees with me.
They consider them to be bugs in their popup
blocker.
I made a few videos a few months back where
we have reverse engineered one particular
obfuscated JavaScript library, used and sold
to advertisers, in order to figure out the
trick they use.
And then reported it to Google to get the
bugs fixed.
Back then it has also motivated Masato Kinugawa
to research a few more techniques and overall
we killed quite a few bugs that allowed pop-unders.
And I think we were quite successful.
For a long time the popunder library did not
have a working popunder technique for Chrome
and had to resort to a tab-under.
which was awesome, for a while we are the
reason why a lot of advertisers that use this
script couldn’t create terrible pop-under
ads on Chrome.
But now I was made aware by SilentHammer on
the subreddit, that the popunderjs library
has been updated and ships now with a working
pop-under for the current Chrome version 65
up to the current development version 68.
And indeed, the demo works.
There is a pop-under.
So let’s figure out how it is done and then
report it as well.
The first few steps that I’m doing now are
the same I did in the previous videos.
I essentially want a local mirror of the scripts
so I can modify them and play around with
it.
So I use the Chrome developer tools to get
all the script files loaded by this site and
save them.
And because of the licensing, and this being
the demo, and I don’t know how the license
check works (It might check the hostname)
I do not only download all the files, but
I also change the /etc/hosts file so that
the domain points to localhost.
Then I use php to launch a local webserver
and serve the files with the same folder structure
as the server.
Now I have all the files locally and can change
them however I want.
For example I can clean them up and beautify
the scripts.
The files are loaded locally now.
And a quick test, yep the popuner still works.
Ok…
So let’s have a first look.
The javascript code is clearly still super
obfuscated.
So nothing we really want to work through
statically.
And trying to look at the script dynamically,
with the chrome developer tools is also still
super annoying, because the script constantly
traps the debugger with the debugger keyword.
We can disable the debugger and still run
it, but then we can’t set any breakpoints
if we do want to pause.
Goign up in the callstack we can see where
this debugger call is coming from and it’s
coming from this function a().
And here we can see that a() is always repeatedly
called with setTimeout.
So we can try to overwrite setTimeout with
our own function, which also logs some information
about the call.
This hopefully disables the debugger traps.
When we now reload the page it looks really
good, we don’t break, but we also don’t
see anything in the console.
But that’s because the code constnatly clears
the console.
Luckily the developer tools are cool and just
tell us the line where this clear is called.
So we can go there, set a breakpoint by clicking
the line number and BOOM, the debugger breaks
here.
Now we can analyse the code.
Capital I is the window object.
The Kn variable is the string console, and
hn is the string clear.
So this simply calls window.console.clear().
Perfect!
We can also find this line in our script and
can just comment it out.
Now when we reload the page we see exactly
the outputs.
And as you can see, some stuff tried to call
setTimeout, however also the popunder is not
working anymore.
So i guess just overwriting it didn’t help
us.
Let’s revert it back.
Another thing we used was the performance
tab.
This one can be used to record every javascript
function call.
So we can hit record, trigger the popunder,
aaand hit stop again.
Now it takes a moment to gather everything.
And here we have it.
This is the timeline, and all of these colorful
bars are function calls.
So here is clearly our start, this is the
mousedown event.
Later in here we also see a onBeforeOpen,
which is actually a call into the demo.js…
So this is a library sold for advertisers,
and so the library creator offers here functionality
that you can run code just before and after
the popunder was opened.
This means our pop-under createn should happen
after this one here.
Interestingly the whole function graph stops
here now.
Not everything happens down in the hierarchy
from the mousedown event.
There is a weird Function call later, which
at some point results in open.
The orange functions are generally regular
javascript stuff, like events, and all the
javascript functions, and the pink ones are
custom ones.
So these are all the obfuscated functions
as you can see from the name.
And actually there are two of these blocks
starting from a weird arbitrary function call
which result in open.
And open is the function to create a new popup
or tab.
So it does it twice.
I have actually no clue what triggers this
initial function.
If it would have been directly called from
the mousedown event it would be part of that
block.
So that’s weird.
But looking at this I don’t see anything
special.
There are no calls to create new HTML elements,
nothing external is loaded, it’s just these
open calls.
So that’s super wierd.
We can also look at from where open is called,
by looking here at the call stack and following
that link.
So this apparently calls open.
And these should be the parameters of open.
Let’s search for this snipped in the script.js
file we have and then add some console.log
outputs to print the parameters passed to
open.
We save the new script, reload the page, trigger
a popunder and look at the console.
So we see two opens.
Both have the first parameter about:blank
and the second one _blank.
A look into the API reference for open we
can see that that is the URL and this is the
name.
But the first open has additional optional
windowFeatures.
It defines width, height, and stuff like that.
The second open didn’t have that.
Okay, nothing too special here either.
WHile playing around I also noticed that the
anti-debugger trapping is not that aggressive,
so we can actually add our own debugger statement
here at the open call, reload the page, disable
the breakpoints and then prepare to be super
fast.
Because we can very quickly reactivate the
breakpoints, quickly switch to the browser
window, HOPE that the anti-debugging traps
don’t trigger first, click somewhere to
create a popunder and hope that our breakpoint
at the open is hit.
And that worked.
Here we are.
Now we can see the state of the variables
which we already know.
We can also see the callstack and have a look
at where this call is coming from.
Notice how it says here postMessage async,
that will explain a lot later but when I looked
at it the first time, I was just a bit confused.
And looking at this function here, we see
a variable i, which is a MessageEvent object
with a data attribute containing our window.open
parameters… mhmhm...
At this point I got a bit frustrated.
If you have watched the previous videos you
know what kind of crazy techniques were used
to pull off a pop-under.
I didn’t fully trust the developer tools
to be honest, because maybe there are tricks
to hide stuff from it.
I was expecting something really really crazy
and I decided to get out the big guns.
I wanted to directly look at the native functions
being called from javascript, so nobody can
hide anything.
I went to the Chromium sources and followed
the “Checking out and building Chromium
for Mac” instructions.
If you want to follow along and build Chromium
as well, make sure you have enough disk space.
Not only did it take me over night to build
it, in the end I also needed almost 80GB disk
space for it.
So be warned.
But that’s not too bad, because with minimal
changes you don’t have to rebuild the whole
thing again, it only has to rebuild the part
you modified.
So that’s cool.
I also have to give my kudos to the build
team, or whoever is responsible for this,
these instructions just worked.
I had no issues at all, it just worked which
I did not expect.
Anyway… so…
I want to log important javascript function
calls.
For example the open call.
But also things like createElement or any
other API call.
All these calls somehow have to be executed
by the underlying Browser so you can’t fake
or hide anything.
In the end these native functions have to
be called.
It’s the first time for me looking at these
sources, so I have no clue what I am doing.
But let’s maybe think about this for a second.
Maybe you have heard of V8 - Chrome uses the
V8 JavaScript Engine.
And there is a sub directory for the v8 engine
with the sources.
So maybe this is a good point to start?
Well, maybe, but probably not.
V8 is just JavaScript, but we are not really
interested in logging when something creates
an Array or so.
We want the APIs that glue together the Browser
and the JavaScript, and that is mostly the
DOM.
The Document Object Model is what we can use
from JavaScript to interact with the Browser
and the HTML.
However Chrome also has a lot of other APIs,
like the Notification.requestPermissions and
these are probably not included in the DOM,
but we deal with that when we need to.
Let’s start with something easy and look
for the document.createElement function.
In previous popunder videos that was a crucial
part in the trick so it would be awesome to
log that.
And so the DOM is most likely part of the
actual browser engine and in case of Chrome
that would be blink.
I looked around in the huge codebase for a
bit and then I found it in /chromium/src/third_party/blink/renderer/core/dom.
So I open that folder in sublime and then
let’s start searching for createElement.
Oh we find something in a .h header file,
let’s actually restrict it to only c++ source
code files.
So here we go.
We find some functions in document.cc.
Which I think is awesome.
Because the javascript function would be document.createElement.
So here we definitely find a lot of important
APIs.
Soo.. createElement…
There we go “Entry point of "create an element".”
That sounds perfect.
So I guess this is the native C++ function
being called when you call document.createElement
in Javascript.
Let’s test that.
Let’s add a simple recognizable printf()
here, just so we know if this is being executed.
Then we rebuild chrome and as you can see
it goes pretty fast now.
Only had to build the change we made.
And then let’s execute our own Chromium
build.
I also wrote a short test create script, that
will call createElement whenever we click
the link here.
But it doesn’t seem to work.
Damn. no output.
It also links here the specification of the
HTML living standard that defines these kind
of things.
And it says here “concept create element”,
so not really sure what that mens.
But when I searched a bit more in the document.cc
source code, I found the CreateElementForBinding
function which links to the dom-document-createelement
specification.
OK this one actually sounds like the correct
function.
So let’s add a printf, here.
Then we compile Chromium again, open the test
webpage and click the button.
And awesome!
Our printf works.
Now we have all the power to log every function
we want.
It might just be a bit tedious to add these
printfs everywhere.
I played around with it a bit more.
Added printfs to different kind of functions
like getElementsByTagName and stuff like that
but.
It didn’t reveal anything new.
It just didn’t seem to do anything weird...
mhmh...
At this point I decided to sit down and started
to implement what I already know.
I know 100% that there are two open calls
and we know their parameters.
We also know that it somehow is all triggered
from a onmousedown event, so let’s do that
as well.
And then we try that.
It opens a popup, but as expected it only
opens ONE.
The second open call is blocked by the pop-up
blocker.
The browser allows one user interaction, the
click, to open one window, because if the
user clicked, then one window is fine.
But not a second one.
However let’s just for testing disable the
popup-blocker and allow this page to create
any popups it wants.
When we now try it again, the second open
call actually creates a new tab.
And the tab gains focus.
See, the popup at this point is in the backrgound.
Let’s add a setTimeout to our script, to
close the new tab after 1 second again and
try that.
We click the link, it opens the popup and
tab, the main window gains focus and then
the tab is closed when the timeout hits.
BOOM… we have a successful popunder.
Holy crap.
This was damn simple.
As long as we can open two windows, one popup
and one tab, we can get focus back to the
main window.
But with activated pop-up blocker, which is
the default, this doesn’t work.
So the creator of this pop-under script actually
found a technique to bypass the pop-up blocker
and open multiple windows.
And this is where the postMessage comes into
play from earlier.
While looking around a bit more, looking at
call stacks and stuff, at some point I stumbled
over it again and it clicked.
WAIT. postMessage and here is the message
data?
Maybe the reason why the two open calls were
shown in their own function block is because
they were onMessage events, triggered from
an asynchronous postMessage.
That totally makes sense, why didn’t I understand
that earlier?
So I quickly implemented this.
I create an onMessage handler, which looks
at the data and either creates a new popup
for data 1 or a new tab, which is also closed
again with 2.
And then I simply trigger a postMessage with
1 and 2 in the popunder function.
This should create both the popup and the
tab.
Let’s try that in the browser, clicking
the link, it creates both.
Amazing.
We bypassed the pop-up blocker.
This also means we can spam popups now.
If we just keep sending postMessages in a
loop.
Look here.
So, now we are done here.
I have reported this issue to Chromium and
hopefully it gets fixed soon.
﻿I don’t like pop-under ads and as a Chrome
user I’m happy that Google agrees with me.
They consider them to be bugs in their popup
blocker.
I made a few videos a few months back where
we have reverse engineered one particular
obfuscated JavaScript library, used and sold
to advertisers, in order to figure out the
trick they use.
And then reported it to Google to get the
bugs fixed.
Back then it has also motivated Masato Kinugawa
to research a few more techniques and overall
we killed quite a few bugs that allowed pop-unders.
And I think we were quite successful.
For a long time the popunder library did not
have a working popunder technique for Chrome
and had to resort to a tab-under.
which was awesome, for a while we are the
reason why a lot of advertisers that use this
script couldn’t create terrible pop-under
ads on Chrome.
But now I was made aware by SilentHammer on
the subreddit, that the popunderjs library
has been updated and ships now with a working
pop-under for the current Chrome version 65
up to the current development version 68.
And indeed, the demo works.
There is a pop-under.
So let’s figure out how it is done and then
report it as well.
The first few steps that I’m doing now are
the same I did in the previous videos.
I essentially want a local mirror of the scripts
so I can modify them and play around with
it.
So I use the Chrome developer tools to get
all the script files loaded by this site and
save them.
And because of the licensing, and this being
the demo, and I don’t know how the license
check works (It might check the hostname)
I do not only download all the files, but
I also change the /etc/hosts file so that
the domain points to localhost.
Then I use php to launch a local webserver
and serve the files with the same folder structure
as the server.
Now I have all the files locally and can change
them however I want.
For example I can clean them up and beautify
the scripts.
The files are loaded locally now.
And a quick test, yep the popuner still works.
Ok…
So let’s have a first look.
The javascript code is clearly still super
obfuscated.
So nothing we really want to work through
statically.
And trying to look at the script dynamically,
with the chrome developer tools is also still
super annoying, because the script constantly
traps the debugger with the debugger keyword.
We can disable the debugger and still run
it, but then we can’t set any breakpoints
if we do want to pause.
Goign up in the callstack we can see where
this debugger call is coming from and it’s
coming from this function a().
And here we can see that a() is always repeatedly
called with setTimeout.
So we can try to overwrite setTimeout with
our own function, which also logs some information
about the call.
This hopefully disables the debugger traps.
When we now reload the page it looks really
good, we don’t break, but we also don’t
see anything in the console.
But that’s because the code constnatly clears
the console.
Luckily the developer tools are cool and just
tell us the line where this clear is called.
So we can go there, set a breakpoint by clicking
the line number and BOOM, the debugger breaks
here.
Now we can analyse the code.
Capital I is the window object.
The Kn variable is the string console, and
hn is the string clear.
So this simply calls window.console.clear().
Perfect!
We can also find this line in our script and
can just comment it out.
Now when we reload the page we see exactly
the outputs.
And as you can see, some stuff tried to call
setTimeout, however also the popunder is not
working anymore.
So i guess just overwriting it didn’t help
us.
Let’s revert it back.
Another thing we used was the performance
tab.
This one can be used to record every javascript
function call.
So we can hit record, trigger the popunder,
aaand hit stop again.
Now it takes a moment to gather everything.
And here we have it.
This is the timeline, and all of these colorful
bars are function calls.
So here is clearly our start, this is the
mousedown event.
Later in here we also see a onBeforeOpen,
which is actually a call into the demo.js…
So this is a library sold for advertisers,
and so the library creator offers here functionality
that you can run code just before and after
the popunder was opened.
This means our pop-under createn should happen
after this one here.
Interestingly the whole function graph stops
here now.
Not everything happens down in the hierarchy
from the mousedown event.
There is a weird Function call later, which
at some point results in open.
The orange functions are generally regular
javascript stuff, like events, and all the
javascript functions, and the pink ones are
custom ones.
So these are all the obfuscated functions
as you can see from the name.
And actually there are two of these blocks
starting from a weird arbitrary function call
which result in open.
And open is the function to create a new popup
or tab.
So it does it twice.
I have actually no clue what triggers this
initial function.
If it would have been directly called from
the mousedown event it would be part of that
block.
So that’s weird.
But looking at this I don’t see anything
special.
There are no calls to create new HTML elements,
nothing external is loaded, it’s just these
open calls.
So that’s super wierd.
We can also look at from where open is called,
by looking here at the call stack and following
that link.
So this apparently calls open.
And these should be the parameters of open.
Let’s search for this snipped in the script.js
file we have and then add some console.log
outputs to print the parameters passed to
open.
We save the new script, reload the page, trigger
a popunder and look at the console.
So we see two opens.
Both have the first parameter about:blank
and the second one _blank.
A look into the API reference for open we
can see that that is the URL and this is the
name.
But the first open has additional optional
windowFeatures.
It defines width, height, and stuff like that.
The second open didn’t have that.
Okay, nothing too special here either.
WHile playing around I also noticed that the
anti-debugger trapping is not that aggressive,
so we can actually add our own debugger statement
here at the open call, reload the page, disable
the breakpoints and then prepare to be super
fast.
Because we can very quickly reactivate the
breakpoints, quickly switch to the browser
window, HOPE that the anti-debugging traps
don’t trigger first, click somewhere to
create a popunder and hope that our breakpoint
at the open is hit.
And that worked.
Here we are.
Now we can see the state of the variables
which we already know.
We can also see the callstack and have a look
at where this call is coming from.
Notice how it says here postMessage async,
that will explain a lot later but when I looked
at it the first time, I was just a bit confused.
And looking at this function here, we see
a variable i, which is a MessageEvent object
with a data attribute containing our window.open
parameters… mhmhm...
At this point I got a bit frustrated.
If you have watched the previous videos you
know what kind of crazy techniques were used
to pull off a pop-under.
I didn’t fully trust the developer tools
to be honest, because maybe there are tricks
to hide stuff from it.
I was expecting something really really crazy
and I decided to get out the big guns.
I wanted to directly look at the native functions
being called from javascript, so nobody can
hide anything.
I went to the Chromium sources and followed
the “Checking out and building Chromium
for Mac” instructions.
If you want to follow along and build Chromium
as well, make sure you have enough disk space.
Not only did it take me over night to build
it, in the end I also needed almost 80GB disk
space for it.
So be warned.
But that’s not too bad, because with minimal
changes you don’t have to rebuild the whole
thing again, it only has to rebuild the part
you modified.
So that’s cool.
I also have to give my kudos to the build
team, or whoever is responsible for this,
these instructions just worked.
I had no issues at all, it just worked which
I did not expect.
Anyway… so…
I want to log important javascript function
calls.
For example the open call.
But also things like createElement or any
other API call.
All these calls somehow have to be executed
by the underlying Browser so you can’t fake
or hide anything.
In the end these native functions have to
be called.
It’s the first time for me looking at these
sources, so I have no clue what I am doing.
But let’s maybe think about this for a second.
Maybe you have heard of V8 - Chrome uses the
V8 JavaScript Engine.
And there is a sub directory for the v8 engine
with the sources.
So maybe this is a good point to start?
Well, maybe, but probably not.
V8 is just JavaScript, but we are not really
interested in logging when something creates
an Array or so.
We want the APIs that glue together the Browser
and the JavaScript, and that is mostly the
DOM.
The Document Object Model is what we can use
from JavaScript to interact with the Browser
and the HTML.
However Chrome also has a lot of other APIs,
like the Notification.requestPermissions and
these are probably not included in the DOM,
but we deal with that when we need to.
Let’s start with something easy and look
for the document.createElement function.
In previous popunder videos that was a crucial
part in the trick so it would be awesome to
log that.
And so the DOM is most likely part of the
actual browser engine and in case of Chrome
that would be blink.
I looked around in the huge codebase for a
bit and then I found it in /chromium/src/third_party/blink/renderer/core/dom.
So I open that folder in sublime and then
let’s start searching for createElement.
Oh we find something in a .h header file,
let’s actually restrict it to only c++ source
code files.
So here we go.
We find some functions in document.cc.
Which I think is awesome.
Because the javascript function would be document.createElement.
So here we definitely find a lot of important
APIs.
Soo.. createElement…
There we go “Entry point of "create an element".”
That sounds perfect.
So I guess this is the native C++ function
being called when you call document.createElement
in Javascript.
Let’s test that.
Let’s add a simple recognizable printf()
here, just so we know if this is being executed.
Then we rebuild chrome and as you can see
it goes pretty fast now.
Only had to build the change we made.
And then let’s execute our own Chromium
build.
I also wrote a short test create script, that
will call createElement whenever we click
the link here.
But it doesn’t seem to work.
Damn. no output.
It also links here the specification of the
HTML living standard that defines these kind
of things.
And it says here “concept create element”,
so not really sure what that mens.
But when I searched a bit more in the document.cc
source code, I found the CreateElementForBinding
function which links to the dom-document-createelement
specification.
OK this one actually sounds like the correct
function.
So let’s add a printf, here.
Then we compile Chromium again, open the test
webpage and click the button.
And awesome!
Our printf works.
Now we have all the power to log every function
we want.
It might just be a bit tedious to add these
printfs everywhere.
I played around with it a bit more.
Added printfs to different kind of functions
like getElementsByTagName and stuff like that
but.
It didn’t reveal anything new.
It just didn’t seem to do anything weird...
mhmh...
At this point I decided to sit down and started
to implement what I already know.
I know 100% that there are two open calls
and we know their parameters.
We also know that it somehow is all triggered
from a onmousedown event, so let’s do that
as well.
And then we try that.
It opens a popup, but as expected it only
opens ONE.
The second open call is blocked by the pop-up
blocker.
The browser allows one user interaction, the
click, to open one window, because if the
user clicked, then one window is fine.
But not a second one.
However let’s just for testing disable the
popup-blocker and allow this page to create
any popups it wants.
When we now try it again, the second open
call actually creates a new tab.
And the tab gains focus.
See, the popup at this point is in the backrgound.
Let’s add a setTimeout to our script, to
close the new tab after 1 second again and
try that.
We click the link, it opens the popup and
tab, the main window gains focus and then
the tab is closed when the timeout hits.
BOOM… we have a successful popunder.
Holy crap.
This was damn simple.
As long as we can open two windows, one popup
and one tab, we can get focus back to the
main window.
But with activated pop-up blocker, which is
the default, this doesn’t work.
So the creator of this pop-under script actually
found a technique to bypass the pop-up blocker
and open multiple windows.
And this is where the postMessage comes into
play from earlier.
While looking around a bit more, looking at
call stacks and stuff, at some point I stumbled
over it again and it clicked.
WAIT. postMessage and here is the message
data?
Maybe the reason why the two open calls were
shown in their own function block is because
they were onMessage events, triggered from
an asynchronous postMessage.
That totally makes sense, why didn’t I understand
that earlier?
So I quickly implemented this.
I create an onMessage handler, which looks
at the data and either creates a new popup
for data 1 or a new tab, which is also closed
again with 2.
And then I simply trigger a postMessage with
1 and 2 in the popunder function.
This should create both the popup and the
tab.
Let’s try that in the browser, clicking
the link, it creates both.
Amazing.
We bypassed the pop-up blocker.
This also means we can spam popups now.
If we just keep sending postMessages in a
loop.
Look here.
So, now we are done here.
I have reported this issue to Chromium and
hopefully it gets fixed soon.
﻿I don’t like pop-under ads and as a Chrome
user I’m happy that Google agrees with me.
They consider them to be bugs in their popup
blocker.
I made a few videos a few months back where
we have reverse engineered one particular
obfuscated JavaScript library, used and sold
to advertisers, in order to figure out the
trick they use.
And then reported it to Google to get the
bugs fixed.
Back then it has also motivated Masato Kinugawa
to research a few more techniques and overall
we killed quite a few bugs that allowed pop-unders.
And I think we were quite successful.
For a long time the popunder library did not
have a working popunder technique for Chrome
and had to resort to a tab-under.
which was awesome, for a while we are the
reason why a lot of advertisers that use this
script couldn’t create terrible pop-under
ads on Chrome.
But now I was made aware by SilentHammer on
the subreddit, that the popunderjs library
has been updated and ships now with a working
pop-under for the current Chrome version 65
up to the current development version 68.
And indeed, the demo works.
There is a pop-under.
So let’s figure out how it is done and then
report it as well.
The first few steps that I’m doing now are
the same I did in the previous videos.
I essentially want a local mirror of the scripts
so I can modify them and play around with
it.
So I use the Chrome developer tools to get
all the script files loaded by this site and
save them.
And because of the licensing, and this being
the demo, and I don’t know how the license
check works (It might check the hostname)
I do not only download all the files, but
I also change the /etc/hosts file so that
the domain points to localhost.
Then I use php to launch a local webserver
and serve the files with the same folder structure
as the server.
Now I have all the files locally and can change
them however I want.
For example I can clean them up and beautify
the scripts.
The files are loaded locally now.
And a quick test, yep the popuner still works.
Ok…
So let’s have a first look.
The javascript code is clearly still super
obfuscated.
So nothing we really want to work through
statically.
And trying to look at the script dynamically,
with the chrome developer tools is also still
super annoying, because the script constantly
traps the debugger with the debugger keyword.
We can disable the debugger and still run
it, but then we can’t set any breakpoints
if we do want to pause.
Goign up in the callstack we can see where
this debugger call is coming from and it’s
coming from this function a().
And here we can see that a() is always repeatedly
called with setTimeout.
So we can try to overwrite setTimeout with
our own function, which also logs some information
about the call.
This hopefully disables the debugger traps.
When we now reload the page it looks really
good, we don’t break, but we also don’t
see anything in the console.
But that’s because the code constnatly clears
the console.
Luckily the developer tools are cool and just
tell us the line where this clear is called.
So we can go there, set a breakpoint by clicking
the line number and BOOM, the debugger breaks
here.
Now we can analyse the code.
Capital I is the window object.
The Kn variable is the string console, and
hn is the string clear.
So this simply calls window.console.clear().
Perfect!
We can also find this line in our script and
can just comment it out.
Now when we reload the page we see exactly
the outputs.
And as you can see, some stuff tried to call
setTimeout, however also the popunder is not
working anymore.
So i guess just overwriting it didn’t help
us.
Let’s revert it back.
Another thing we used was the performance
tab.
This one can be used to record every javascript
function call.
So we can hit record, trigger the popunder,
aaand hit stop again.
Now it takes a moment to gather everything.
And here we have it.
This is the timeline, and all of these colorful
bars are function calls.
So here is clearly our start, this is the
mousedown event.
Later in here we also see a onBeforeOpen,
which is actually a call into the demo.js…
So this is a library sold for advertisers,
and so the library creator offers here functionality
that you can run code just before and after
the popunder was opened.
This means our pop-under createn should happen
after this one here.
Interestingly the whole function graph stops
here now.
Not everything happens down in the hierarchy
from the mousedown event.
There is a weird Function call later, which
at some point results in open.
The orange functions are generally regular
javascript stuff, like events, and all the
javascript functions, and the pink ones are
custom ones.
So these are all the obfuscated functions
as you can see from the name.
And actually there are two of these blocks
starting from a weird arbitrary function call
which result in open.
And open is the function to create a new popup
or tab.
So it does it twice.
I have actually no clue what triggers this
initial function.
If it would have been directly called from
the mousedown event it would be part of that
block.
So that’s weird.
But looking at this I don’t see anything
special.
There are no calls to create new HTML elements,
nothing external is loaded, it’s just these
open calls.
So that’s super wierd.
We can also look at from where open is called,
by looking here at the call stack and following
that link.
So this apparently calls open.
And these should be the parameters of open.
Let’s search for this snipped in the script.js
file we have and then add some console.log
outputs to print the parameters passed to
open.
We save the new script, reload the page, trigger
a popunder and look at the console.
So we see two opens.
Both have the first parameter about:blank
and the second one _blank.
A look into the API reference for open we
can see that that is the URL and this is the
name.
But the first open has additional optional
windowFeatures.
It defines width, height, and stuff like that.
The second open didn’t have that.
Okay, nothing too special here either.
WHile playing around I also noticed that the
anti-debugger trapping is not that aggressive,
so we can actually add our own debugger statement
here at the open call, reload the page, disable
the breakpoints and then prepare to be super
fast.
Because we can very quickly reactivate the
breakpoints, quickly switch to the browser
window, HOPE that the anti-debugging traps
don’t trigger first, click somewhere to
create a popunder and hope that our breakpoint
at the open is hit.
And that worked.
Here we are.
Now we can see the state of the variables
which we already know.
We can also see the callstack and have a look
at where this call is coming from.
Notice how it says here postMessage async,
that will explain a lot later but when I looked
at it the first time, I was just a bit confused.
And looking at this function here, we see
a variable i, which is a MessageEvent object
with a data attribute containing our window.open
parameters… mhmhm...
At this point I got a bit frustrated.
If you have watched the previous videos you
know what kind of crazy techniques were used
to pull off a pop-under.
I didn’t fully trust the developer tools
to be honest, because maybe there are tricks
to hide stuff from it.
I was expecting something really really crazy
and I decided to get out the big guns.
I wanted to directly look at the native functions
being called from javascript, so nobody can
hide anything.
I went to the Chromium sources and followed
the “Checking out and building Chromium
for Mac” instructions.
If you want to follow along and build Chromium
as well, make sure you have enough disk space.
Not only did it take me over night to build
it, in the end I also needed almost 80GB disk
space for it.
So be warned.
But that’s not too bad, because with minimal
changes you don’t have to rebuild the whole
thing again, it only has to rebuild the part
you modified.
So that’s cool.
I also have to give my kudos to the build
team, or whoever is responsible for this,
these instructions just worked.
I had no issues at all, it just worked which
I did not expect.
Anyway… so…
I want to log important javascript function
calls.
For example the open call.
But also things like createElement or any
other API call.
All these calls somehow have to be executed
by the underlying Browser so you can’t fake
or hide anything.
In the end these native functions have to
be called.
It’s the first time for me looking at these
sources, so I have no clue what I am doing.
But let’s maybe think about this for a second.
Maybe you have heard of V8 - Chrome uses the
V8 JavaScript Engine.
And there is a sub directory for the v8 engine
with the sources.
So maybe this is a good point to start?
Well, maybe, but probably not.
V8 is just JavaScript, but we are not really
interested in logging when something creates
an Array or so.
We want the APIs that glue together the Browser
and the JavaScript, and that is mostly the
DOM.
The Document Object Model is what we can use
from JavaScript to interact with the Browser
and the HTML.
However Chrome also has a lot of other APIs,
like the Notification.requestPermissions and
these are probably not included in the DOM,
but we deal with that when we need to.
Let’s start with something easy and look
for the document.createElement function.
In previous popunder videos that was a crucial
part in the trick so it would be awesome to
log that.
And so the DOM is most likely part of the
actual browser engine and in case of Chrome
that would be blink.
I looked around in the huge codebase for a
bit and then I found it in /chromium/src/third_party/blink/renderer/core/dom.
So I open that folder in sublime and then
let’s start searching for createElement.
Oh we find something in a .h header file,
let’s actually restrict it to only c++ source
code files.
So here we go.
We find some functions in document.cc.
Which I think is awesome.
Because the javascript function would be document.createElement.
So here we definitely find a lot of important
APIs.
Soo.. createElement…
There we go “Entry point of "create an element".”
That sounds perfect.
So I guess this is the native C++ function
being called when you call document.createElement
in Javascript.
Let’s test that.
Let’s add a simple recognizable printf()
here, just so we know if this is being executed.
Then we rebuild chrome and as you can see
it goes pretty fast now.
Only had to build the change we made.
And then let’s execute our own Chromium
build.
I also wrote a short test create script, that
will call createElement whenever we click
the link here.
But it doesn’t seem to work.
Damn. no output.
It also links here the specification of the
HTML living standard that defines these kind
of things.
And it says here “concept create element”,
so not really sure what that mens.
But when I searched a bit more in the document.cc
source code, I found the CreateElementForBinding
function which links to the dom-document-createelement
specification.
OK this one actually sounds like the correct
function.
So let’s add a printf, here.
Then we compile Chromium again, open the test
webpage and click the button.
And awesome!
Our printf works.
Now we have all the power to log every function
we want.
It might just be a bit tedious to add these
printfs everywhere.
I played around with it a bit more.
Added printfs to different kind of functions
like getElementsByTagName and stuff like that
but.
It didn’t reveal anything new.
It just didn’t seem to do anything weird...
mhmh...
At this point I decided to sit down and started
to implement what I already know.
I know 100% that there are two open calls
and we know their parameters.
We also know that it somehow is all triggered
from a onmousedown event, so let’s do that
as well.
And then we try that.
It opens a popup, but as expected it only
opens ONE.
The second open call is blocked by the pop-up
blocker.
The browser allows one user interaction, the
click, to open one window, because if the
user clicked, then one window is fine.
But not a second one.
However let’s just for testing disable the
popup-blocker and allow this page to create
any popups it wants.
When we now try it again, the second open
call actually creates a new tab.
And the tab gains focus.
See, the popup at this point is in the backrgound.
Let’s add a setTimeout to our script, to
close the new tab after 1 second again and
try that.
We click the link, it opens the popup and
tab, the main window gains focus and then
the tab is closed when the timeout hits.
BOOM… we have a successful popunder.
Holy crap.
This was damn simple.
As long as we can open two windows, one popup
and one tab, we can get focus back to the
main window.
But with activated pop-up blocker, which is
the default, this doesn’t work.
So the creator of this pop-under script actually
found a technique to bypass the pop-up blocker
and open multiple windows.
And this is where the postMessage comes into
play from earlier.
While looking around a bit more, looking at
call stacks and stuff, at some point I stumbled
over it again and it clicked.
WAIT. postMessage and here is the message
data?
Maybe the reason why the two open calls were
shown in their own function block is because
they were onMessage events, triggered from
an asynchronous postMessage.
That totally makes sense, why didn’t I understand
that earlier?
So I quickly implemented this.
I create an onMessage handler, which looks
at the data and either creates a new popup
for data 1 or a new tab, which is also closed
again with 2.
And then I simply trigger a postMessage with
1 and 2 in the popunder function.
This should create both the popup and the
tab.
Let’s try that in the browser, clicking
the link, it creates both.
Amazing.
We bypassed the pop-up blocker.
This also means we can spam popups now.
If we just keep sending postMessages in a
loop.
Look here.
So, now we are done here.
I have reported this issue to Chromium and
hopefully it gets fixed soon.
﻿I don’t like pop-under ads and as a Chrome
user I’m happy that Google agrees with me.
They consider them to be bugs in their popup
blocker.
I made a few videos a few months back where
we have reverse engineered one particular
obfuscated JavaScript library, used and sold
to advertisers, in order to figure out the
trick they use.
And then reported it to Google to get the
bugs fixed.
Back then it has also motivated Masato Kinugawa
to research a few more techniques and overall
we killed quite a few bugs that allowed pop-unders.
And I think we were quite successful.
For a long time the popunder library did not
have a working popunder technique for Chrome
and had to resort to a tab-under.
which was awesome, for a while we are the
reason why a lot of advertisers that use this
script couldn’t create terrible pop-under
ads on Chrome.
But now I was made aware by SilentHammer on
the subreddit, that the popunderjs library
has been updated and ships now with a working
pop-under for the current Chrome version 65
up to the current development version 68.
And indeed, the demo works.
There is a pop-under.
So let’s figure out how it is done and then
report it as well.
The first few steps that I’m doing now are
the same I did in the previous videos.
I essentially want a local mirror of the scripts
so I can modify them and play around with
it.
So I use the Chrome developer tools to get
all the script files loaded by this site and
save them.
And because of the licensing, and this being
the demo, and I don’t know how the license
check works (It might check the hostname)
I do not only download all the files, but
I also change the /etc/hosts file so that
the domain points to localhost.
Then I use php to launch a local webserver
and serve the files with the same folder structure
as the server.
Now I have all the files locally and can change
them however I want.
For example I can clean them up and beautify
the scripts.
The files are loaded locally now.
And a quick test, yep the popuner still works.
Ok…
So let’s have a first look.
The javascript code is clearly still super
obfuscated.
So nothing we really want to work through
statically.
And trying to look at the script dynamically,
with the chrome developer tools is also still
super annoying, because the script constantly
traps the debugger with the debugger keyword.
We can disable the debugger and still run
it, but then we can’t set any breakpoints
if we do want to pause.
Goign up in the callstack we can see where
this debugger call is coming from and it’s
coming from this function a().
And here we can see that a() is always repeatedly
called with setTimeout.
So we can try to overwrite setTimeout with
our own function, which also logs some information
about the call.
This hopefully disables the debugger traps.
When we now reload the page it looks really
good, we don’t break, but we also don’t
see anything in the console.
But that’s because the code constnatly clears
the console.
Luckily the developer tools are cool and just
tell us the line where this clear is called.
So we can go there, set a breakpoint by clicking
the line number and BOOM, the debugger breaks
here.
Now we can analyse the code.
Capital I is the window object.
The Kn variable is the string console, and
hn is the string clear.
So this simply calls window.console.clear().
Perfect!
We can also find this line in our script and
can just comment it out.
Now when we reload the page we see exactly
the outputs.
And as you can see, some stuff tried to call
setTimeout, however also the popunder is not
working anymore.
So i guess just overwriting it didn’t help
us.
Let’s revert it back.
Another thing we used was the performance
tab.
This one can be used to record every javascript
function call.
So we can hit record, trigger the popunder,
aaand hit stop again.
Now it takes a moment to gather everything.
And here we have it.
This is the timeline, and all of these colorful
bars are function calls.
So here is clearly our start, this is the
mousedown event.
Later in here we also see a onBeforeOpen,
which is actually a call into the demo.js…
So this is a library sold for advertisers,
and so the library creator offers here functionality
that you can run code just before and after
the popunder was opened.
This means our pop-under createn should happen
after this one here.
Interestingly the whole function graph stops
here now.
Not everything happens down in the hierarchy
from the mousedown event.
There is a weird Function call later, which
at some point results in open.
The orange functions are generally regular
javascript stuff, like events, and all the
javascript functions, and the pink ones are
custom ones.
So these are all the obfuscated functions
as you can see from the name.
And actually there are two of these blocks
starting from a weird arbitrary function call
which result in open.
And open is the function to create a new popup
or tab.
So it does it twice.
I have actually no clue what triggers this
initial function.
If it would have been directly called from
the mousedown event it would be part of that
block.
So that’s weird.
But looking at this I don’t see anything
special.
There are no calls to create new HTML elements,
nothing external is loaded, it’s just these
open calls.
So that’s super wierd.
We can also look at from where open is called,
by looking here at the call stack and following
that link.
So this apparently calls open.
And these should be the parameters of open.
Let’s search for this snipped in the script.js
file we have and then add some console.log
outputs to print the parameters passed to
open.
We save the new script, reload the page, trigger
a popunder and look at the console.
So we see two opens.
Both have the first parameter about:blank
and the second one _blank.
A look into the API reference for open we
can see that that is the URL and this is the
name.
But the first open has additional optional
windowFeatures.
It defines width, height, and stuff like that.
The second open didn’t have that.
Okay, nothing too special here either.
WHile playing around I also noticed that the
anti-debugger trapping is not that aggressive,
so we can actually add our own debugger statement
here at the open call, reload the page, disable
the breakpoints and then prepare to be super
fast.
Because we can very quickly reactivate the
breakpoints, quickly switch to the browser
window, HOPE that the anti-debugging traps
don’t trigger first, click somewhere to
create a popunder and hope that our breakpoint
at the open is hit.
And that worked.
Here we are.
Now we can see the state of the variables
which we already know.
We can also see the callstack and have a look
at where this call is coming from.
Notice how it says here postMessage async,
that will explain a lot later but when I looked
at it the first time, I was just a bit confused.
And looking at this function here, we see
a variable i, which is a MessageEvent object
with a data attribute containing our window.open
parameters… mhmhm...
At this point I got a bit frustrated.
If you have watched the previous videos you
know what kind of crazy techniques were used
to pull off a pop-under.
I didn’t fully trust the developer tools
to be honest, because maybe there are tricks
to hide stuff from it.
I was expecting something really really crazy
and I decided to get out the big guns.
I wanted to directly look at the native functions
being called from javascript, so nobody can
hide anything.
I went to the Chromium sources and followed
the “Checking out and building Chromium
for Mac” instructions.
If you want to follow along and build Chromium
as well, make sure you have enough disk space.
Not only did it take me over night to build
it, in the end I also needed almost 80GB disk
space for it.
So be warned.
But that’s not too bad, because with minimal
changes you don’t have to rebuild the whole
thing again, it only has to rebuild the part
you modified.
So that’s cool.
I also have to give my kudos to the build
team, or whoever is responsible for this,
these instructions just worked.
I had no issues at all, it just worked which
I did not expect.
Anyway… so…
I want to log important javascript function
calls.
For example the open call.
But also things like createElement or any
other API call.
All these calls somehow have to be executed
by the underlying Browser so you can’t fake
or hide anything.
In the end these native functions have to
be called.
It’s the first time for me looking at these
sources, so I have no clue what I am doing.
But let’s maybe think about this for a second.
Maybe you have heard of V8 - Chrome uses the
V8 JavaScript Engine.
And there is a sub directory for the v8 engine
with the sources.
So maybe this is a good point to start?
Well, maybe, but probably not.
V8 is just JavaScript, but we are not really
interested in logging when something creates
an Array or so.
We want the APIs that glue together the Browser
and the JavaScript, and that is mostly the
DOM.
The Document Object Model is what we can use
from JavaScript to interact with the Browser
and the HTML.
However Chrome also has a lot of other APIs,
like the Notification.requestPermissions and
these are probably not included in the DOM,
but we deal with that when we need to.
Let’s start with something easy and look
for the document.createElement function.
In previous popunder videos that was a crucial
part in the trick so it would be awesome to
log that.
And so the DOM is most likely part of the
actual browser engine and in case of Chrome
that would be blink.
I looked around in the huge codebase for a
bit and then I found it in /chromium/src/third_party/blink/renderer/core/dom.
So I open that folder in sublime and then
let’s start searching for createElement.
Oh we find something in a .h header file,
let’s actually restrict it to only c++ source
code files.
So here we go.
We find some functions in document.cc.
Which I think is awesome.
Because the javascript function would be document.createElement.
So here we definitely find a lot of important
APIs.
Soo.. createElement…
There we go “Entry point of "create an element".”
That sounds perfect.
So I guess this is the native C++ function
being called when you call document.createElement
in Javascript.
Let’s test that.
Let’s add a simple recognizable printf()
here, just so we know if this is being executed.
Then we rebuild chrome and as you can see
it goes pretty fast now.
Only had to build the change we made.
And then let’s execute our own Chromium
build.
I also wrote a short test create script, that
will call createElement whenever we click
the link here.
But it doesn’t seem to work.
Damn. no output.
It also links here the specification of the
HTML living standard that defines these kind
of things.
And it says here “concept create element”,
so not really sure what that mens.
But when I searched a bit more in the document.cc
source code, I found the CreateElementForBinding
function which links to the dom-document-createelement
specification.
OK this one actually sounds like the correct
function.
So let’s add a printf, here.
Then we compile Chromium again, open the test
webpage and click the button.
And awesome!
Our printf works.
Now we have all the power to log every function
we want.
It might just be a bit tedious to add these
printfs everywhere.
I played around with it a bit more.
Added printfs to different kind of functions
like getElementsByTagName and stuff like that
but.
It didn’t reveal anything new.
It just didn’t seem to do anything weird...
mhmh...
At this point I decided to sit down and started
to implement what I already know.
I know 100% that there are two open calls
and we know their parameters.
We also know that it somehow is all triggered
from a onmousedown event, so let’s do that
as well.
And then we try that.
It opens a popup, but as expected it only
opens ONE.
The second open call is blocked by the pop-up
blocker.
The browser allows one user interaction, the
click, to open one window, because if the
user clicked, then one window is fine.
But not a second one.
However let’s just for testing disable the
popup-blocker and allow this page to create
any popups it wants.
When we now try it again, the second open
call actually creates a new tab.
And the tab gains focus.
See, the popup at this point is in the backrgound.
Let’s add a setTimeout to our script, to
close the new tab after 1 second again and
try that.
We click the link, it opens the popup and
tab, the main window gains focus and then
the tab is closed when the timeout hits.
BOOM… we have a successful popunder.
Holy crap.
This was damn simple.
As long as we can open two windows, one popup
and one tab, we can get focus back to the
main window.
But with activated pop-up blocker, which is
the default, this doesn’t work.
So the creator of this pop-under script actually
found a technique to bypass the pop-up blocker
and open multiple windows.
And this is where the postMessage comes into
play from earlier.
While looking around a bit more, looking at
call stacks and stuff, at some point I stumbled
over it again and it clicked.
WAIT. postMessage and here is the message
data?
Maybe the reason why the two open calls were
shown in their own function block is because
they were onMessage events, triggered from
an asynchronous postMessage.
That totally makes sense, why didn’t I understand
that earlier?
So I quickly implemented this.
I create an onMessage handler, which looks
at the data and either creates a new popup
for data 1 or a new tab, which is also closed
again with 2.
And then I simply trigger a postMessage with
1 and 2 in the popunder function.
This should create both the popup and the
tab.
Let’s try that in the browser, clicking
the link, it creates both.
Amazing.
We bypassed the pop-up blocker.
This also means we can spam popups now.
If we just keep sending postMessages in a
loop.
Look here.
So, now we are done here.
I have reported this issue to Chromium and
hopefully it gets fixed soon.
﻿I don’t like pop-under ads and as a Chrome
user I’m happy that Google agrees with me.
They consider them to be bugs in their popup
blocker.
I made a few videos a few months back where
we have reverse engineered one particular
obfuscated JavaScript library, used and sold
to advertisers, in order to figure out the
trick they use.
And then reported it to Google to get the
bugs fixed.
Back then it has also motivated Masato Kinugawa
to research a few more techniques and overall
we killed quite a few bugs that allowed pop-unders.
And I think we were quite successful.
For a long time the popunder library did not
have a working popunder technique for Chrome
and had to resort to a tab-under.
which was awesome, for a while we are the
reason why a lot of advertisers that use this
script couldn’t create terrible pop-under
ads on Chrome.
But now I was made aware by SilentHammer on
the subreddit, that the popunderjs library
has been updated and ships now with a working
pop-under for the current Chrome version 65
up to the current development version 68.
And indeed, the demo works.
There is a pop-under.
So let’s figure out how it is done and then
report it as well.
The first few steps that I’m doing now are
the same I did in the previous videos.
I essentially want a local mirror of the scripts
so I can modify them and play around with
it.
So I use the Chrome developer tools to get
all the script files loaded by this site and
save them.
And because of the licensing, and this being
the demo, and I don’t know how the license
check works (It might check the hostname)
I do not only download all the files, but
I also change the /etc/hosts file so that
the domain points to localhost.
Then I use php to launch a local webserver
and serve the files with the same folder structure
as the server.
Now I have all the files locally and can change
them however I want.
For example I can clean them up and beautify
the scripts.
The files are loaded locally now.
And a quick test, yep the popuner still works.
Ok…
So let’s have a first look.
The javascript code is clearly still super
obfuscated.
So nothing we really want to work through
statically.
And trying to look at the script dynamically,
with the chrome developer tools is also still
super annoying, because the script constantly
traps the debugger with the debugger keyword.
We can disable the debugger and still run
it, but then we can’t set any breakpoints
if we do want to pause.
Goign up in the callstack we can see where
this debugger call is coming from and it’s
coming from this function a().
And here we can see that a() is always repeatedly
called with setTimeout.
So we can try to overwrite setTimeout with
our own function, which also logs some information
about the call.
This hopefully disables the debugger traps.
When we now reload the page it looks really
good, we don’t break, but we also don’t
see anything in the console.
But that’s because the code constnatly clears
the console.
Luckily the developer tools are cool and just
tell us the line where this clear is called.
So we can go there, set a breakpoint by clicking
the line number and BOOM, the debugger breaks
here.
Now we can analyse the code.
Capital I is the window object.
The Kn variable is the string console, and
hn is the string clear.
So this simply calls window.console.clear().
Perfect!
We can also find this line in our script and
can just comment it out.
Now when we reload the page we see exactly
the outputs.
And as you can see, some stuff tried to call
setTimeout, however also the popunder is not
working anymore.
So i guess just overwriting it didn’t help
us.
Let’s revert it back.
Another thing we used was the performance
tab.
This one can be used to record every javascript
function call.
So we can hit record, trigger the popunder,
aaand hit stop again.
Now it takes a moment to gather everything.
And here we have it.
This is the timeline, and all of these colorful
bars are function calls.
So here is clearly our start, this is the
mousedown event.
Later in here we also see a onBeforeOpen,
which is actually a call into the demo.js…
So this is a library sold for advertisers,
and so the library creator offers here functionality
that you can run code just before and after
the popunder was opened.
This means our pop-under createn should happen
after this one here.
Interestingly the whole function graph stops
here now.
Not everything happens down in the hierarchy
from the mousedown event.
There is a weird Function call later, which
at some point results in open.
The orange functions are generally regular
javascript stuff, like events, and all the
javascript functions, and the pink ones are
custom ones.
So these are all the obfuscated functions
as you can see from the name.
And actually there are two of these blocks
starting from a weird arbitrary function call
which result in open.
And open is the function to create a new popup
or tab.
So it does it twice.
I have actually no clue what triggers this
initial function.
If it would have been directly called from
the mousedown event it would be part of that
block.
So that’s weird.
But looking at this I don’t see anything
special.
There are no calls to create new HTML elements,
nothing external is loaded, it’s just these
open calls.
So that’s super wierd.
We can also look at from where open is called,
by looking here at the call stack and following
that link.
So this apparently calls open.
And these should be the parameters of open.
Let’s search for this snipped in the script.js
file we have and then add some console.log
outputs to print the parameters passed to
open.
We save the new script, reload the page, trigger
a popunder and look at the console.
So we see two opens.
Both have the first parameter about:blank
and the second one _blank.
A look into the API reference for open we
can see that that is the URL and this is the
name.
But the first open has additional optional
windowFeatures.
It defines width, height, and stuff like that.
The second open didn’t have that.
Okay, nothing too special here either.
WHile playing around I also noticed that the
anti-debugger trapping is not that aggressive,
so we can actually add our own debugger statement
here at the open call, reload the page, disable
the breakpoints and then prepare to be super
fast.
Because we can very quickly reactivate the
breakpoints, quickly switch to the browser
window, HOPE that the anti-debugging traps
don’t trigger first, click somewhere to
create a popunder and hope that our breakpoint
at the open is hit.
And that worked.
Here we are.
Now we can see the state of the variables
which we already know.
We can also see the callstack and have a look
at where this call is coming from.
Notice how it says here postMessage async,
that will explain a lot later but when I looked
at it the first time, I was just a bit confused.
And looking at this function here, we see
a variable i, which is a MessageEvent object
with a data attribute containing our window.open
parameters… mhmhm...
At this point I got a bit frustrated.
If you have watched the previous videos you
know what kind of crazy techniques were used
to pull off a pop-under.
I didn’t fully trust the developer tools
to be honest, because maybe there are tricks
to hide stuff from it.
I was expecting something really really crazy
and I decided to get out the big guns.
I wanted to directly look at the native functions
being called from javascript, so nobody can
hide anything.
I went to the Chromium sources and followed
the “Checking out and building Chromium
for Mac” instructions.
If you want to follow along and build Chromium
as well, make sure you have enough disk space.
Not only did it take me over night to build
it, in the end I also needed almost 80GB disk
space for it.
So be warned.
But that’s not too bad, because with minimal
changes you don’t have to rebuild the whole
thing again, it only has to rebuild the part
you modified.
So that’s cool.
I also have to give my kudos to the build
team, or whoever is responsible for this,
these instructions just worked.
I had no issues at all, it just worked which
I did not expect.
Anyway… so…
I want to log important javascript function
calls.
For example the open call.
But also things like createElement or any
other API call.
All these calls somehow have to be executed
by the underlying Browser so you can’t fake
or hide anything.
In the end these native functions have to
be called.
It’s the first time for me looking at these
sources, so I have no clue what I am doing.
But let’s maybe think about this for a second.
Maybe you have heard of V8 - Chrome uses the
V8 JavaScript Engine.
And there is a sub directory for the v8 engine
with the sources.
So maybe this is a good point to start?
Well, maybe, but probably not.
V8 is just JavaScript, but we are not really
interested in logging when something creates
an Array or so.
We want the APIs that glue together the Browser
and the JavaScript, and that is mostly the
DOM.
The Document Object Model is what we can use
from JavaScript to interact with the Browser
and the HTML.
However Chrome also has a lot of other APIs,
like the Notification.requestPermissions and
these are probably not included in the DOM,
but we deal with that when we need to.
Let’s start with something easy and look
for the document.createElement function.
In previous popunder videos that was a crucial
part in the trick so it would be awesome to
log that.
And so the DOM is most likely part of the
actual browser engine and in case of Chrome
that would be blink.
I looked around in the huge codebase for a
bit and then I found it in /chromium/src/third_party/blink/renderer/core/dom.
So I open that folder in sublime and then
let’s start searching for createElement.
Oh we find something in a .h header file,
let’s actually restrict it to only c++ source
code files.
So here we go.
We find some functions in document.cc.
Which I think is awesome.
Because the javascript function would be document.createElement.
So here we definitely find a lot of important
APIs.
Soo.. createElement…
There we go “Entry point of "create an element".”
That sounds perfect.
So I guess this is the native C++ function
being called when you call document.createElement
in Javascript.
Let’s test that.
Let’s add a simple recognizable printf()
here, just so we know if this is being executed.
Then we rebuild chrome and as you can see
it goes pretty fast now.
Only had to build the change we made.
And then let’s execute our own Chromium
build.
I also wrote a short test create script, that
will call createElement whenever we click
the link here.
But it doesn’t seem to work.
Damn. no output.
It also links here the specification of the
HTML living standard that defines these kind
of things.
And it says here “concept create element”,
so not really sure what that mens.
But when I searched a bit more in the document.cc
source code, I found the CreateElementForBinding
function which links to the dom-document-createelement
specification.
OK this one actually sounds like the correct
function.
So let’s add a printf, here.
Then we compile Chromium again, open the test
webpage and click the button.
And awesome!
Our printf works.
Now we have all the power to log every function
we want.
It might just be a bit tedious to add these
printfs everywhere.
I played around with it a bit more.
Added printfs to different kind of functions
like getElementsByTagName and stuff like that
but.
It didn’t reveal anything new.
It just didn’t seem to do anything weird...
mhmh...
At this point I decided to sit down and started
to implement what I already know.
I know 100% that there are two open calls
and we know their parameters.
We also know that it somehow is all triggered
from a onmousedown event, so let’s do that
as well.
And then we try that.
It opens a popup, but as expected it only
opens ONE.
The second open call is blocked by the pop-up
blocker.
The browser allows one user interaction, the
click, to open one window, because if the
user clicked, then one window is fine.
But not a second one.
However let’s just for testing disable the
popup-blocker and allow this page to create
any popups it wants.
When we now try it again, the second open
call actually creates a new tab.
And the tab gains focus.
See, the popup at this point is in the backrgound.
Let’s add a setTimeout to our script, to
close the new tab after 1 second again and
try that.
We click the link, it opens the popup and
tab, the main window gains focus and then
the tab is closed when the timeout hits.
BOOM… we have a successful popunder.
Holy crap.
This was damn simple.
As long as we can open two windows, one popup
and one tab, we can get focus back to the
main window.
But with activated pop-up blocker, which is
the default, this doesn’t work.
So the creator of this pop-under script actually
found a technique to bypass the pop-up blocker
and open multiple windows.
And this is where the postMessage comes into
play from earlier.
While looking around a bit more, looking at
call stacks and stuff, at some point I stumbled
over it again and it clicked.
WAIT. postMessage and here is the message
data?
Maybe the reason why the two open calls were
shown in their own function block is because
they were onMessage events, triggered from
an asynchronous postMessage.
That totally makes sense, why didn’t I understand
that earlier?
So I quickly implemented this.
I create an onMessage handler, which looks
at the data and either creates a new popup
for data 1 or a new tab, which is also closed
again with 2.
And then I simply trigger a postMessage with
1 and 2 in the popunder function.
This should create both the popup and the
tab.
Let’s try that in the browser, clicking
the link, it creates both.
Amazing.
We bypassed the pop-up blocker.
This also means we can spam popups now.
If we just keep sending postMessages in a
loop.
Look here.
So, now we are done here.
I have reported this issue to Chromium and
hopefully it gets fixed soon.
﻿In past videos we have learned how the CPU
works, how to read assembler and how to reverse
engineer the functionality of a simple program.
In the upcoming videos I want to go a little
bit deeper and explore how we can exploit
a program when we have the ability to corrupt
memory.
This first video will be more about how to
setup and get everything running. So we can
focus on the technical part in the next videos.
The title of this video is inspired by the
famous phrack article “Smashing The Stack
For Fun And Profit” from 1996. You can imagine
that a lot of stuff has changed since then.
Though, we first have to learn about the basics,
before we can have a look at modern techniques.
We will kind of follow the timeline of exploitation
technique discovery and attempted mitigations.
Like DEP or ASLR, just to name two.
As basis for the next couple of videos, I
will use challenges included in the Linux
images provided by exploit-exercises.com.
This allows you to set up this system as well,
which I highly recommend.
With protostar you will start with simple
memory corruption and modification, function
redirection, and finally executing custom
shellcode.
In order to make this as easy as possible
to introduce, ASLR and Non-Executable memory
has been disabled.
So first download the protostar .iso and boot
from it in the VMWare Player. As you can see
it doesn’t start with a nice graphical user-interface
like our Ubuntu system does. But don’t panic,
you learned how to use the command-line from
the very first episode.
Now, I will use this moment to introduce you
to `ssh`, which stands for secure shell and
is a program that allows us to connect to
a system over a network, that has an ssh server
running. This would be the kind of access
you get when you have to administrate servers
that run for example a website. That’s the
reason why I introduced you to the command
line in the very first episode, because you
really really have to know how to use it.
You can also tell that I run windows as a
host OS. I think I haven’t mentioned it
before, but the main reason here is, that
I imagine the majority of people start out
on Windows, which means it’s the best way
to reach more people. We don’t want to be
excluding like so many other parts of our
societies. At least for me, hacking conveys
a spirit to be open and share knowledge.
So that’s why I have to download PuTTY for
Windows now, which is a windows client for
ssh.
To use it to connect to this machine we have
to find the IP address of it.
The username and password for the protostar
image is just “user”. So use that to login.
And then execute the command `ip addr`, to
find the assigned IP and then copy it into
putty, save this session and press Open. You
have to login again, but this is much better
now. We can copy data back and forth and we
can have multiple connections.
The equivalent for Mac and Linux is just simply
`ssh`, the username “user” at the ip address.
Ok. At the moment our shell is /bin/sh. And
as you can see, tab-completion doesn’t work.
But we can execute `/bin/bash` instead, which
makes the command-line a bit nicer.
So what do we have here. With uname -a we
can get some system information and we can
see that we have a 32bit linux with a 2.6.32
kernel.
So how does this work now. On the website
it says: The levels to be exploited can be
found in the /opt/protostar/bin directory.
Let’s have a look. `Ls` to list all files
in this directory. Immediately you will notice
this weird red background color for the filenames.
Let’s have a closer look.
With `files` we can check the filetype and
it tells us that it is a setuid ELF 32bit
executable. From earlier videos you may remember
that we have never encountered `setuid` before.
As always, if we want to know something in
linux, we can look in the linux manual. Though,
the man page for setuid is actually about
the setuid function provided by libc. But
that doesn’t bother us, because it might
be related. So let’s see what it says here
about this function.
setuid stands for set user identity.
And… setuid sets the effective user ID of
the calling process.
mhh… with cat /etc/passwd we can see all
users on this system. Remember our user is
called user so we have the id 1001. And the
root user has id 0.
So does that mean, that we can simply write
a C program as our unprivileged user and execute
setuid with id 0, to become root?
Obviously not. That would be horrible. Further
down it tells us about possible errors like
EPERM which says that the user is not privileged
and the uid does not match the real uid of
the calling process. Ok… then… what can
it be used for?
An example usage is, that a root process might
want to drop privileges to an unprivileged
user, that in case the process gets exploited,
the attacker does not gain root privileges.
So if you have a process that has to start
as root but then doesn’t need it anymore,
it’s good to drop them.
Anyway. What does this have to do with our
setuid binary?
Let’s open a second ssh session to look
at all running processes.
Now open a process that keeps running. Something
simple like a vim editor. And then we can
use the other shell to execute `ps aux` to
list all running processes. Now we have to
search a bit, but here it is. The first column
tells us the user of the running process.
And because we as “user” have executed
vim, it will run with our privileges. So no
let’s execute one of those setuid binaries
and do the same.
Let’s search the program name. Here it is.
BUT do you see the first line? It says it’s
running as root. What the fuck? How is that
possible?
Let’s have a look again at the file permissions.
Ok first of all `r` `dash` `x` means that
anybody on the system can read this file and
execute it.
The next 3 permissions are the same and refer
to the permissions for the group. A group
is just an id, that multiple users could share.
So we are in the group that is also called
user. But theoretically you could group multiple
users together.
Ok. Now it get’s interesting. The first
character indicates if a file is a directory.
Well it’s not. So the remaining 3 permissions
are for the owner of the file. The owner of
the file is root. And the owner has the permissions
to read, write and … S? So the s replaced
what should be x for executable. This is called
the setuid bit.
We have already looked at the running process,
so you can guess what this does. When this
bit is set, and I as a regular user execute
it, Linux will actually execute it with the
privileges of the owner. So in this case it
will run as root. Why the hell would somebody
do this?
There are two good examples. First, you may
know sudo. Which is a program that allows
you to run something as root if you are a
normal user. So how can sudo execute a program
as root, even though you typed in the command?
Well it also has the setuid bit.
Another great example is the ping program.
Ping will also run as root, because it has
the setuid bit set. Why you ask? Because ping
wants to send an ICMP packet which is a fairly
low layer. And linux generally doesn’t allow
normal users to create such raw packets. But
because ping is not evil, somebody created
a setuid binary, to allow normal users to
send ICMP packets.
What if there is an exploit for a program
like ping, that would allow you to execute
arbitrary code as root, right? So it’s clear,
that setuid can be really dangerous.
Well. And that’s the whole point of the
challenges from protostar. If we can exploit
one of these programs here, we can escalate
privileges and gain root. This is basically
like jailbreaking on iPhones or rooting on
android devices. You try to find a vulnerability
that allows you to execute arbitrary code
in a privileged mode. Well, on those real
devices, especially iOS this is extremely
fucking complicated, and a lot more layers
are involved, but now you get a better imagination
of the whole thing.
One last thing before we start with the challenges.
You know that you can debug programs, right?
For example you can use strace to spy on the
system calls. Or simply use gdb. And gdb allows
you to modify memory. So you could just open
this setuid binary in gdb, modify the code
and execute whatever you want as root? let’s
try it. Ok it seems to run. So let’s rerun
it and look at the process list. As you can
see it doesn’t run as root anymore. The
reason is, that gdb could not debug a process
that runs as another user. So gdb actually
forces the binary to NOT run as root so it
can actually debug it. So good idea, but unfortunately…
or maybe fortunately it’s not that simple.
I guess we have to rely on good old exploiting
techniques.
See you in the next video when we start with
the first challenge.
﻿In this episode we want to setup a private
Pwn Adventure 3 server so we don’t have
to use the public server that can only handle
a couple concurrent users.
The game itself also has an offline mode,
so you can check out the game a little bit
without any server, but to really experience
the MMO game hacking part, you really want
it to talking to a server.
In the description of the video you will find
a couple of links.
One of them is a github repository that I
have created listing a few options how to
run it yourself.
But let’s talk first about the system requirements.
From the official README it is recommended
to at least have 2 GB of RAM and spawn only
about 2-3 instances per CPU core.
What that means we will see later.
And you will also need a couple of GB free
disk space for the large client files.
So… if you are interested in more details
about the server architecture, it’s probably
most fun and interesting to follow the official
README or follow the guide by Antonin Beaujeant.
He has an easy to follow step-by step guide
on how to install and configure the server
on Ubuntu 14.04 or Ubuntu 16.04.
You will do each step by hand and you have
various options to customize things.
Or maybe just learn more about linux and setting
up a server in general.
It’s a very detailed guide so if you install
a fresh Ubuntu in a VM, you should have no
problems!
The other option is to use the docker files
from my repository.
I wanted to learn more about docker, so I
used this as an opportunity to learn more
about it and created this Dockerfile and the
docker-compose file together with a friend.
I’m not saying it’s a better option.
But for some it might be a more easy option.
If you already have a server with docker and
docker-compose, you would only have to type
`docker-compose build` and `docker-compose
up` to get it running.
But also the steps to install those are just
simple copy and paste.
I have tested this on a Ubuntu 14 and Ubuntu
16 that I installed in a VM, running on VM
Ware on my Windows host.
But my actual personal server that I’m now
playing with is running on this little Intel
NUC that another friend helped me to setup
with CentOS and KVM, so I have a docker VM
with Fedora running on there where I have
deployed my dockerfiles.
And that’s running smoot.
And I also tried it on Digital Ocean.
And essentially all these options are the
same.
You just somehow need a shell, have to get
docker properly installed, check the versions
in case your docker throws errors, you need
enough resources and make sure the machine
is reachable from your game machine.
So for example in your VM network settings
you might want to set it to bridged or whatever
you need.
But then you are good to go.
And then you can simply follow the guide.
In this example I’m using Digital Ocean,
where I select one of the cheaper plans.
In case you don’t know, Digital Ocean is
like Google or Amazon Cloud, you can just
click yourself a server for however long you
want, and only pay the time you used it.
The reason why i’m a Digital Ocean customer
is because Amazon requires a Credit Card,
which I didn’t have for a long time, and
Digital Ocean works with paypal - that’s
the only reason.
Anyway.
After selecting a server, enabling monitoring
and giving it a name, I have to wait a few
seconds until it’s set up and then I get
an IP that I can connect to with ssh.
And then I clone the github repository, and
start the download of the client and server
files contained in the pwn3.tar.gz archive.
It’s around 1.8GB.
While this is running you can open a second
shell and make sure docker and docker-compose
is properly setup.
Which is just essentially following the docker
community edition installation guide and copy
and paste commands.
For future reference, here are the versions
that were working for me.
Once the download is done you can quickly
verify the hashes of the file, to make sure
it’s complete.
Then unpack it with tar xvf and after that
you are ready to build the docker images with
docker-compose build.
This will definitely take a little bit and
then run it with docker-compose up.
then the server should be running.
Keep in mind, that when you now CTRL+C here,
you tear down the docker container again and
everything is lost.
It’s great for testing everything, but when
you want it longer running, use the -d flag
to run it in detached mode.
You can then verify with docker ps and netstat
if everything looks good.
This means, there are two docker container,
the master and game container.
And that you have docker proxy processes listening
on port 3333, 3000 and maybe more.
Next you can try to connect with your client
to it.
For that you have to do two things.
First is to edit your /etc/hosts file.
That file exists on Windows, Mac and Linux.
For Mac and Linux it’s simply in /etc/hosts,
for Windows it’s in this path shown here.
Make sure to edit the file with root or administrator
privileges.
Here we enter the IP of our server and assign
it the name master.pwn3 and game.pwn3.
Those are the two hostnames of my default
server configuration.
The second thing you need to do is to modify
the server.ini config file located somewhere
in the client folder.
You have to replace the official host with
master.pwn3.
WARNING, don’t use an IP here, it took me
half a day to debug why my client wouldn’t
properly connect and once I used a hostname
it worked.
That’s why we have to set the /etc/hosts
file.
After that we can launch our client and wait
for all of the files to be downloaded.
This takes quite a while.
But after that we can press Play.
This will close the Launcher and start the
actual game.
Here we can select “Play Game” and if
it displays the LiveOverflow message, it worked!
You are connected to the master server now.
You can then register an account and after
that create a character.
When you press join the master server will
assign you a game server and drop you into
the game.
Just so you have a better understanding of
how the server and client works.
When you start the Pwn Adventure 3 Launcher,
then the launcher connects to the official
server to check for updates to the client
and download the files.
After that it kills itself and starts the
actual game.
That’s very typical for games.
Then the actual game will read the server.ini
config file, tht we modified earlier.
When you now want to play, the client will
connect to the master server specified in
the server.ini file, so master.pwn3 and you
can register an account, login and create
a character.
This all still happens while connected to
the master.
Then when you press “join”, the master
server selects a game server and port for
you.
The game server runs several instances on
different ports.
In this case the game server is located on
game.pwn3, so the master server will tell
the client, “hey, I found a free server
for you, checkout game.pwn3 on port 3000”.
If there is no game server or just it’s
very busy, you will see a message “waiting
in queue”, or something like that.
And now that you have the game server you
connect to it and get dropped into the actual
game.
Anyway, the setup is essentially the same
on any of the hosts hosts.
So here is my MacBook, my Linux Laptop and
my PC connected to the same server.
Say hello!
Of course the technical details on how you
hack them is different on each operating system.
In case you want to customize the server settings
a bit, checkout the setup scripts in the git
repository.
There you can change the welcome message,
and also the hostname the server will use.
As well as the amount of instances.
This is what I briefly mentioned in the beginning.
This spawns 5 game server instances.
And it worked ok on the Digital Ocean server.
However when you look at the monitoring stats,
it’s really at the limit.
Anyway… now that we finally have everything
setup, we will dive into the hacking parts
next video.
If you watched a little bit of the let’s
play in the last video, or played the beginning
yourself, you know we need a fireball to get
out of this cave.
But soon we will be able to do what this guy
does.
Just flying out of the hole in the cave.
It looks a bit laggy from this perspective,
but whatever.
Flying is flying.
﻿Last video we have explored a format string
vulnerability from the protostar examples,
but had it compiled on a modern system with
ASLR and 64bit.
At first I thought we couldn’t solve it
but explored some tricks and played around
with it, but then actually figured out a reliable
technique.
So let’s explore some more of the format
levels.
Format1, at first, looks very simple.
Remember last time we just failed because
it required that we write to target the exact
value 0xdeadbeef, and here we just have to
write..
Something?
Let’s have quick look if our trick still
works.
So this level also takes an argument, but
passes it directly to printf.
No sprintf and buffer involved.
Anyway.
we compile it again on our 64bit ubuntu version
and open it in gdb.
Then we set a breakpoint at the if compare
of target, run it and as arguments we use
AAAAAAAAAA.
Then we have a look at the stack.
See how our As don’t show up?
Where are they?
Let’s keep looking further down.
Oh wow.
They are all the way down there.
And what’s all this stuff again?
Well so.
See, we didn’t copy our string input to
a local variable like buffer did in the last
challenge.
We directly print the arguments.
And the arguments are placed, along with the
environment variables all the way at the start
of the stack.
So these are the environment variables.
And you see, there is no stack address we
could overwrite and abuse like we did last
level.
That sucks.
But actually it’s still solveable, we don’t
need the trick from last video at all.
It’s simpler than you might think.
But let’s explore that with the next challenge,
format2, that one we haven’t looked at yet
and boils down to the same thing.
Looks a bit more promising, right?
It does read data into a local variable on
the stack.
But it doesn’t look like we can overflow
the buffer.
This program gets the input from standard
input instead of an argument.
And then later target is checked if it’s
64.
Ok.
So let’s compile it and open it in gdb.
Again we look for the if-compare, seems to
be here, 0x40 is 64.
And set a breakpoint then run it.
This time it’s waiting for input, so enter
some As and Bs.
Now we hit the breakpoint and let’s have
a look at the stack.
Mh, we know that our buffer has 512 bytes,
and looks like there are a loot of stack addresses
in range.
But why is that, isn’t the 512 bytes buffer
unallocated or empty?
Well no not really.
You see it’s a local variable on the stack,
which means it simply moved the stack pointer
further up to make space for it, but doesn’t
clear it.
So these are leftover values from other functions
that ran before and had a stack there, which
then got destroyed again when they returned,
but their values always remain there.
For regular program execution that doesn’t
really matter, except that you must not expect
a variable to be initialised with zeros, because
you can have bad luck and something was in
it’s place before.
Anyway.
Let’s see where our target variable is.
We can use print and then ampercant target
to get a pointer, so basically the address
of target.
But what is that?
That doesn’t look like a stack address?
Somebody who has some experience with exploitation
on 64bit knows already what that is.
It’s a very recognisable address.
With vmmap you can check the virtual memory
and see that it’s part of our binary?
Look at the permissions for this memory region.
It is read and writeable, not executable.
So it’s not where code is.
It’s in a data segment.
And when we look at the code we see that target
isn’t defined in a function as local variable.
It’s a global variable, so it’s placed
in a data segment.
Now if you have some experience with exploitation
64bit targets, you also know that that means,
this address is not affected by ASLR by default.
Lets add another printf here, like we did
last video to print the address of target.
And when we run it a few times, you see target
doesn’t change.
Awesome!
So it should be fairly straight forward.
Step 1: let’s find our input on the stack.
We enter some As followed by %x to print stack
values.
And here we are.
1, 2, 3, 4, 5, 6.
At offset 6 we have our input.
So we could place our address there instead
of the As, and then replace the 6th %x with
the %n to write to it.
Let’s try it.
So we should now enter our input via echo,
so we can encode raw characters in hex.
Then pipe the input into format2.
So let’s enter the address of target.
Ah see, there it is, but it’s 4 bytes, so
there is also a space still included.
This has to be a zero, because the address
is only 3 bytes.
So we add that, but now we don’t see any
output anymore.
What happened?
Well, printf prints strings.
And strings are null-terminated in C. So printf
stops when it reahed the 0.
So we never reach our %x format modifiers.
This means, we should move our address to
the end, so we can have format stuff before.
Now let’s try to find again our address.
This time I’m using the dollar syntax to
enter an offset directly.
So we know our start was at offset 6, so the
address has to be further down.
Also don’t forget to escape the dollar here
on the commandline, because dollar is a special
charachter for the shell.
If we keep going with the offsets, we can
find the As.
Now sometimes the offset might not be right,
so maybe you have to add or remove a few characters
as padding to align it perfectly.
Ok now looks good.
Let’s change it to a %n.
Segmentation fault.
Well that didn’t work.
Weird.
Let’s write our input to a file, open gdb,
and use that file as input to investigate
the crash.
So here we are at a move.
It tries to move whatever is in r15d into
the address in rax.
And so rax appears to be an invalid address.
It’s not our target.
There is a 0xa.
And that is obviously a newline.
So that’s the issue.
We are on 64bit, so we have 64bit addresses.
But we only entered 4 bytes, and after the
echo is a newline.
So we just have to add 4 more nullbytes.
Ok we don’t get a crash now.
But target is still 0.
How is that?
Let’s make it crash again by making the
address invalid again.
This way we should be able to investigate
if our address would be correct and what is
written to it.
So we see, rax looks good.
It only is invalid because of what we changed.
Otherwise it would be great.
And so it tries to write r15d to it, and that
is, 0?
What?
Shouldn’t %n write the amount of characters
already printed?
Let’s think for a second.
Ohhhhhh.
Of course it’s 0.
Because we didn’t pint anything yet.
Before we do the %n we obviously have to print
something first.
So let’s add %64d, to print 64 characters.
Now that’s 4 characters long, this means
we shifted everything by 4, and in order to
lign up everything again, that the address
is at the correct offset, we have to subtract
4 characters somewhere.
But luckily we made the padding earlier large
enough and so that’s simple.
And here we go, it’s “you modified the
target”.
FINALLYYY finally we managed to exploit a
simple example on a modern system without
much hassle.
Goddamit.
So maybe now you wonder, but the system has
ASLR, why is this address fixed.
Well, the system has aslr, and the system
libraries like libc are affected by aslr,
you can see that when you use ldd to print
the library dependencies of the binary, it
keeps changing.
But the binary itself is not affected by ASLR.
Unless we specifically compile it to be position
independent code.
And wie can do that with the -pie flag for
position independent executable and -fPIC
for position independent code.
If we now execute format2 and check the address
of target, then we see it keeps changing a
lot.
Now it’s going to be much harder.
Maybe with some strategies from the last video
it’s doable.
I leave that as an exercise to you watching.
﻿Last video we learned from the official documentation
of ledger about JTAG. that sounds really cool
so let’s investigate that more.
On the STM32 description page, you can scroll
down and find resources about Development
Tools, specifically to an ST-Link In-circuit
debugger and programmer for STM8 and STM32
MCUs.
This device can do JTAG/SWD stuff.
SWD stands for Serial Wire Debug.
So very similar to JTAG but something ARM
specific.
It basically has only two wires for data.
we also don’t really need to buy that device.
Because I got a cool tip from Thomas.
He told me I should just get a development
board for the STM32.
A development board is like an arduino, it’s
a board with the chip you want to build something
with, and all the pins are exposed and you
can build a proof of concept, before actually
designing your product with a PCB.
And this STM32 has to be programmed and possibly
debugged as well, so these boards might come
with a built in ST-Link.
So here I have an official Nucleo board from
STMicroelectronics with an STM32.
Now I have a different STM32 on here, the
F446RE, but that doesn’t matter because
we are interested in this part of the PCB.
See this gap here, they are here because you
could even just break it off.
That part basically is the ST-Link component.
And you see here that the ST-Link is connected
to the Nucleo with some jumpers.
A jumper just connects two pins together.
So if you take out those jumpers, then you
just have a bare ST-LINK here and the Serial
Wire Debug pin headers are exposed here.
And on there it also says SWD.
In the general user manual documentation for
the nucleo board you can also find some details
about this SWD debug connector.
So that CN4 connector has 6 pins, but the
sixth one is reserved and not used right now.
Usually the first pin is also marked by something
like a dot.
Next we have to somehow connect this to the
ledger.
First is VDD, that’s the +5V of the target,
the second one is the SWD clock signal, the
third just connects to ground, then we have
the SWD IO pin, that one is the actual data
carrying pin, and we have an exposed reset
line that can be used by the st-link to reset
the target chip.
So how do we connect this to the ledger?
Let’s assume we haven’t seen this convenient
line of pins on the bottom side of the ledger
pcb and let’s look at the STM32F042 datasheet.
So we are looking for Power, Ground, SWD IO,
SWD Clock and reset.
In the pinout table we can find them.
SWDIO is Pin PA13, and SWD Clock is Pin PA14.
And every chip also has a reset pin.
In this case it appears to be called NRST.
Here is the package pinout how the chip looks
from the top.
And PA13 and PA14 are over here and reset
is here.
Now how do you know which way you have to
look at the chip.
The text is a bit misleading because what
you need to look for is a symbol like this
dot.
This indicates the top left corner.
So these two pins that disappear into the
PCB should be SWD IO and SWD CLK.
And to verify that we have the correct orientation
we can also check these two pins.
These go directly to the USB and in the pin
definitions table we see that PA12 and PA11,
so the two pins right below PA13 and PA14
are in fact for USB.
So theoretically we could just hook up the
ST-Link board to those pins, but luckily,
when we follow those two pins on the backside
of the PCB, we see that they connect to these
two pads.
The center is connected to the ground plane,
so that is GND and this one seems to connect
to the other side of the chip, where reset
is located, so that should be RESET and then
this must be VDD, the +5V power supply.
So this matches exactly our SWD connector
pinout.
So let me solder some cables to it so we can
easily connect it to the board.
Here is how I did it.
I have some small generic holed perfboards
that can be used for prototyping pcbs.
I got them in different formats and there
is this long one that could fit nicely.
I noticed that the pad spacing matches exactly
the 2.54mm or 0.1inch hole grid.
So my plan, not sure if that works is just
to lay the ledger pcb on it like this, put
a lot of solder on this side and hope it flows
down onto the pcb and connects the whole thing.
Not sure if that’s a good idea, but it seemed
reasonable to me at the moment.
So I get my soldering iron and all the equipment
I might need ready.
Probably should use a different solder tip
and then let’s make a plan.
To keep it in place I thought maybe using
some electrical tape, but that kinda failed…
my second idea was to apply a bit of solder
and make the solder spiking up a bit, so I
can just stick those into the holes.
You can see here barely the pointy end.
And then I tried electrical tape again, but
fail… just always slips off a bit… then
I thought I could use a piece of wire to make
kind of like a pin sticking up and then putting
it on the pcb, but unfortunately the only
wire I had was way too thick.
So in the end, I just carefully laid it on
top and applied solder and crossed my fingers…
and to my surprise, that worked!
It seems to hold and has flow down onto the
pad… so I do it on all five holes and here
is the result.
You can clearly see the solder being on the
pcb.
Next I would like to add some nice pins to
the PCB so I can connect some wires to the
ST-Link. let’s quickly check my electronics
supply.
There are some pins.
I think I will take some 90 degree ones so
they stick out to the side.
And the whole thing stays flat.
Something like this would be cool.
So now I just have to connect these solder
spots with these pins.
And that sounds easier than it is because
solder is really like sticking to pads and
make them cross over the solder protection
layer, the green stuff is tricky.
As you can see I just splash a bunch of sodler
on those three pins and I just can’t get
them connected, and thanks to gravity it just
accumulates on the other side.
So I gotta remove some of the solder with
this copper mesh.
That acts like a sponch and just sucks up
liquid solder.
Then I decided to use some short snippets
of the wire from earlier and use that as a
simple bridge connection.
And that works really well.
Cool.
Before I connect it I wanna do a small sanity
check and make sure that I didn’t accidentally
cause a short.
So I use a continuity tester to check if two
points are electrically connected.
And it looks all pretty good, none of them
are shorted… but… then… this is the
moment I realized something else… do you
see it?
I give you a second to notice it while I’m
just looking at it and trying to process how
that happened.
You see, I scrwed up and soldered the connecter
one pin off…
see that dot there, that is the spike of the
solder pin we did earlier.
That is supposed to be the first pin.
And this back there, there is no pin below
at all.
Godammit!...
I’m an idiot… so that was annoying but
I fixed it… so here we go… this looks
good now.
Next let’s get the Nucleo board and hook
up the cables.
I’m checking again that I got the order
of the cables right but looks all good.
Moment of truth, plugging in the USB cable,
will it still turn on or did I screw up soldering?
Ehm… well…
I didn’t expect that…
So I disconnected the board from the nucleo
again and tried it… and then the screen
turned on… puh..
Ok so it just didn’t work because of the
debug connection, but then I reconnected the
nucleo again to just to reproduce that and
suddenly the screen turned on as well.
What is going on?
Well… in any way we can now connect the
nucleo via USB and then we can try out the
debugging interface.
But immediately when the USB plug touched
the usb connector the ledger reset.
I’m sure that’s not any reason to be concerned,
it’s probably what is supposed to happen?
Also let’s take some electrical tape and
secure the ledger and the screen on the PCB.
Looks pretty neat.
I have to say I like how that worked out.
So let’s connect everything to the laptop
and try the tools.
I will show those tools in a second but it
didn’t work…
I was staring at the setup and realized…
ooooops…
I had those wires connected wrong… goosh…
I’m so happy I haven’t destroyed the ledger
yet, but if we keep going like that it won’t
work for much longer.
Awesome…
Now let’s try this.
I have stlink installed on my mac and then
we can for example run st-info to get some
chip description.
AND IT ANSWERS.
IT’S a F04 device.
STMf04…
Let’s try the real thing.
St-util.
It finds a device, also prints the sram and
flash size and now the gdb-server is listening
on port 4242.
WOHOOO...
Ok… now we need a special gdb to debug this
arm code.
This is pretty simple.
just search for arm-none-eabi download, and
you will find the official arm embedded toolchain
and you can grab the tools for your system.
In my case Mac OS X.
Once you got that you just start the arm-non-eabi-gdb
and connect to a remote target.
Localhost port 4242.
BOOM!
It worked.
We can no continue and with CTRL+C just break
at any point, inspect the registers and even
disassemble some instructions.
But this disassembly looks wrong.
Unlike intel assembler, where instructions
can have different byte lengths, arm instructions
are always 32bit long.
But there are also THUMB instructions and
they are 16bit long.
And this case this runs Thumb code.
And to tell gdb to disassemble this as Thumb
instead, we ask it to disassemble at address
+1.
So an odd address.
Because of this instruction alignment you
always have instructions at even numbers,
right?
Instructions are either 2 or 4 bytes long.
So you shouldn’t think of this +1 as an
odd address, but rather an address that has
the last bit set.
And this is convention to tell you this is
now Thumb code.
You might also see this when disassembling
arm and there is a jump or branch instruction
to an odd address, it’s not an odd address,
it’s an address that has the last bit set
and that means its switching to thumb instructions
from here on out.
Anyway, this way gdb will also interpret this
as thumb and show us now the real instructions.
Now we can use gdb to debug the device, cool,
huh?
One last thing, we can use st-flash to read
the whole flash and create a backup dump of
the whole flash.
We start to dump the memory from 0x80000000
that’s the start of the flash and then we
read 32768 bytes, which is 0x8000, the size
of the flash.
And this memory dump contains the whole firmware.
﻿We have already had many episodes where we
read assembler code and reverse engineered
how a program works.
And we even have written our first exploit
by using a buffer overflow vulnerability in
a program written in C.
In this episode I want to show you how you
can learn how to read assembler produced by
C code yourself.
The idea is simple.
Just write some C code with different C language
features, and then look at the assembler code
that is produced by compiling it.
This is often part of normal research.
For example listen to what Ian Beer from google
project zero says during a talk about his
research on Inter Process Calls on OSX.
One approach to reversing, or to understanding
how this kind of thing works would be to sit
in IDA and just reverse the serialization
and deserialization code, and slowly build
up a picture of how it works.
But another kind of quite nice way to do it,
is just, write a test program to send little
messages and then find the right place using
lldb to break and just start dumping hex.
So, because he had to understand a fairly
complex data structure, he simply wrote a
test program to analyse it, instead of reversing
a full application.
Or there was was a talk and paper from blackhat
USA in 2007 about how to reverse C++ programs,
by looking at C++ concepts and how they look
like in assembler.
So now I have created three different C code
testcases and you can find them in my github
repository, or just write it yourself.
One is about variables and datatypes.
One is about function calls.
And one is about control flow stuff like loops
and ifs.
So let’s start with the variables.c.
First thing I want to point out are those
triple Xs.
Those triple Xs are defined as an assembler
NOP instruction.
The reason for that is, later when we look
into the disassembly, we can find those NOPs
which are separating our tests, and that is
pretty neat.
So this makes it easier to see which line
of C Code is responsible for which lines in
assembler.
I will not go over every single test, this
is something you could do yourself.
Simply pause the video at certain points or
clone the repository.
Anyway.
Let’s get started.
First of all you can see here a couple of
simple numbers.
First we define a couple of numbers.
Unsigned and signed, integers and floating
numbers.
And different sizes with uint32 or uint64.
The latter is important, because normal Integers
might have a different size depending on 32bit
or 64bit, so it can lead to bugs.
So better use datatypes you are guaranteed
to get a certain size.
If you want to learn more about how to program
C properly, there is a great blog entry called
“How to C in 2015”.
After that we create an array with 32bit unsigned
integers, and we access one element of this
array.
Then we look at a single character.
And then also a string.
And maybe you know that a star * means “pointer”
in C. So we define a variable that is pointing
to a string.
I have added a Makefile, so you can simply
type `make` into the terminal to compile all
files.
Or make clean to remove the binaries.
This will create a 32bit and a 64bit version
of the variables program.
But as you can see, I get an error trying
to compile a 32bit version with -m32 in this
64bit machine.
So I have to install the 32bit libraries first,
to be able to build the code.
After installing those, the build works fine.
A Makefile is just a little script that defines
how a project has to be compiled.
So let’s open the code, 32bit and 64bit
version next to each other in gdb and disassemble
main.
And also open the code.
Ok now let’s look at the first integer examples
with negative values and signed and unsigned
values.
First of all, all those local variables are
stored somewhere on the stack, you can see
that because they are referenced relative
to the base-pointer.
Then you notice that the assembler code doesn’t
know negative numbers.
They are fff something.
If you are interested how negative numbers
are displayed, watch my 10th episode about
numbers.
And also there is no difference between variables
that are signed or unsigned.
But there is one difference between the 32bit
and the 64bit code.
Because we defined one number to be 64bit
long, but on 32bit the registers are only
32bit.
So if you want to write full 64bit, you have
to write two times.
The floating point numbers are also interesting.
Because they got stored somewhere else in
the program.
And that value is then moved into the local
variable.
The array is also interesting.
We created an array with 10 values but only
set the first 5 values to a default value.
As you can see those values are stored on
the stack.
And then it is moved from that location on
the stack to the real array location.
Instead of writing it directly to the array
it does it this way.
No idea why.
And you can see down here when we reference
the 3rd entry.
So you can see that this is the real location
of the array on the stack.
Next come the strings.
You can see that a character is just a byte.
It doesn’t matter if we have an unsigned
int with 8bit or a char.
It’s the same.
And strings are also referenced over an address.
So the local variable is not an array of charactes.
the local variable contains an address pointing
to a string.
Now let’s have a look at the control_flows.
Open it in radare.
Analyse all, seek to main function and enter
Visual mode.
First we set a variable to zero.
And then comes the if.
This is done by loading this local variable
in a register and comparing to hex ff.
And then jump if it was less or equal.
So you can see which branch it may take.
Then comes a while loop.
We load the local variable again in a register,
compare it to a value, and either jump inside
the block or leave.
And inside the block we load this value again,
increment it and write it back.
Now compare it to the foor loop.
It’s basically the same!
We start by setting the variable to 0.
Then we compare if the loop condition is still
true.
And inside the loop block, we can see our
NOP.
And at the end of the block we increment the
variable by 1.
Exactly the same like the while loop.
So you can see that a for and a while loop
in C are basically the same.
Next let’s have a look at how functions
are called.
Again open both the 32bit and 64bit version.
First thing you notice that the 64bit version
moves a 0 in eax.
No idea why.
Otherwise the function call looks the same.
Except look at the addresses.
If you have no ASLR, then 64bit code is generally
at hex 40 something.
While 32bit code is at hex 80 something.
Knowing stuff like that is helpful, because
if you see an address with 40 something, you
know immediately that it’s pointing into
your code.
So the next function returns a value and we
save it in a variable.
And you can see that in both cases, the value
is taken from the eax register.
Ok, so apparently return values are handled
via eax.
Now function 3 is interesting, because we
pass a parameter to it.
In 32bit you can see that the value is loaded
from somewhere and then stored on top of the
stack.
And then the function is called.
But on 64bit we see that the value is loaded
into the edi register.
This is our first big difference.
Functions in 64bit seem to be called with
parameters in registers, while in 32bit the
parameters are stored on the stack.
Next function uses 2 parameters.
And again, you can see how 32bit just places
the value on the stack.
First parameter on top of the stack, the second
a bit further down.
But in 64bit you can see that it uses esi
and edi for that.
Now we get curious.
What does 64bit do when we have so many parameters,
that we cannot keep them all in registers?
First of all 32bit code again.
You can see how the parameters are stored
on the stack.
And the first parameter is on top of the stack,
and the last value moved.
That’s what we would expect.
In 64bit we can see that the first couple
of parameters are stored in registers edi,
esi, edx, and so forth.
But from the 7th parameter on, they get stored
on the stack as well.
Awesome!
Now you can identify all kind of different
assembler patterns.
You don’t need a decompiler all the time.
You can do this all in your head.
And when you reverse more and more programs,
those patterns become more easy to recognize,
and you will not feel overwhelmed again with
the mass of weird instructions.
You will be able to scan over a function and
say: “ah here is a local variable.
Then calls this other function with this variable
as parameter.
And the return value is used in a loop”.
And you can use the same method to understand
how different disassemblers like hopper, radare,
gdb display code.
Or for example how different the at&t assembler
syntax is from the intel syntax.
I hope you have a lot of fun next time reversing
a program.
﻿We have already had many episodes where we
read assembler code and reverse engineered
how a program works.
And we even have written our first exploit
by using a buffer overflow vulnerability in
a program written in C.
In this episode I want to show you how you
can learn how to read assembler produced by
C code yourself.
The idea is simple.
Just write some C code with different C language
features, and then look at the assembler code
that is produced by compiling it.
This is often part of normal research.
For example listen to what Ian Beer from google
project zero says during a talk about his
research on Inter Process Calls on OSX.
One approach to reversing, or to understanding
how this kind of thing works would be to sit
in IDA and just reverse the serialization
and deserialization code, and slowly build
up a picture of how it works.
But another kind of quite nice way to do it,
is just, write a test program to send little
messages and then find the right place using
lldb to break and just start dumping hex.
So, because he had to understand a fairly
complex data structure, he simply wrote a
test program to analyse it, instead of reversing
a full application.
Or there was was a talk and paper from blackhat
USA in 2007 about how to reverse C++ programs,
by looking at C++ concepts and how they look
like in assembler.
So now I have created three different C code
testcases and you can find them in my github
repository, or just write it yourself.
One is about variables and datatypes.
One is about function calls.
And one is about control flow stuff like loops
and ifs.
So let’s start with the variables.c.
First thing I want to point out are those
triple Xs.
Those triple Xs are defined as an assembler
NOP instruction.
The reason for that is, later when we look
into the disassembly, we can find those NOPs
which are separating our tests, and that is
pretty neat.
So this makes it easier to see which line
of C Code is responsible for which lines in
assembler.
I will not go over every single test, this
is something you could do yourself.
Simply pause the video at certain points or
clone the repository.
Anyway.
Let’s get started.
First of all you can see here a couple of
simple numbers.
First we define a couple of numbers.
Unsigned and signed, integers and floating
numbers.
And different sizes with uint32 or uint64.
The latter is important, because normal Integers
might have a different size depending on 32bit
or 64bit, so it can lead to bugs.
So better use datatypes you are guaranteed
to get a certain size.
If you want to learn more about how to program
C properly, there is a great blog entry called
“How to C in 2015”.
After that we create an array with 32bit unsigned
integers, and we access one element of this
array.
Then we look at a single character.
And then also a string.
And maybe you know that a star * means “pointer”
in C. So we define a variable that is pointing
to a string.
I have added a Makefile, so you can simply
type `make` into the terminal to compile all
files.
Or make clean to remove the binaries.
This will create a 32bit and a 64bit version
of the variables program.
But as you can see, I get an error trying
to compile a 32bit version with -m32 in this
64bit machine.
So I have to install the 32bit libraries first,
to be able to build the code.
After installing those, the build works fine.
A Makefile is just a little script that defines
how a project has to be compiled.
So let’s open the code, 32bit and 64bit
version next to each other in gdb and disassemble
main.
And also open the code.
Ok now let’s look at the first integer examples
with negative values and signed and unsigned
values.
First of all, all those local variables are
stored somewhere on the stack, you can see
that because they are referenced relative
to the base-pointer.
Then you notice that the assembler code doesn’t
know negative numbers.
They are fff something.
If you are interested how negative numbers
are displayed, watch my 10th episode about
numbers.
And also there is no difference between variables
that are signed or unsigned.
But there is one difference between the 32bit
and the 64bit code.
Because we defined one number to be 64bit
long, but on 32bit the registers are only
32bit.
So if you want to write full 64bit, you have
to write two times.
The floating point numbers are also interesting.
Because they got stored somewhere else in
the program.
And that value is then moved into the local
variable.
The array is also interesting.
We created an array with 10 values but only
set the first 5 values to a default value.
As you can see those values are stored on
the stack.
And then it is moved from that location on
the stack to the real array location.
Instead of writing it directly to the array
it does it this way.
No idea why.
And you can see down here when we reference
the 3rd entry.
So you can see that this is the real location
of the array on the stack.
Next come the strings.
You can see that a character is just a byte.
It doesn’t matter if we have an unsigned
int with 8bit or a char.
It’s the same.
And strings are also referenced over an address.
So the local variable is not an array of charactes.
the local variable contains an address pointing
to a string.
Now let’s have a look at the control_flows.
Open it in radare.
Analyse all, seek to main function and enter
Visual mode.
First we set a variable to zero.
And then comes the if.
This is done by loading this local variable
in a register and comparing to hex ff.
And then jump if it was less or equal.
So you can see which branch it may take.
Then comes a while loop.
We load the local variable again in a register,
compare it to a value, and either jump inside
the block or leave.
And inside the block we load this value again,
increment it and write it back.
Now compare it to the foor loop.
It’s basically the same!
We start by setting the variable to 0.
Then we compare if the loop condition is still
true.
And inside the loop block, we can see our
NOP.
And at the end of the block we increment the
variable by 1.
Exactly the same like the while loop.
So you can see that a for and a while loop
in C are basically the same.
Next let’s have a look at how functions
are called.
Again open both the 32bit and 64bit version.
First thing you notice that the 64bit version
moves a 0 in eax.
No idea why.
Otherwise the function call looks the same.
Except look at the addresses.
If you have no ASLR, then 64bit code is generally
at hex 40 something.
While 32bit code is at hex 80 something.
Knowing stuff like that is helpful, because
if you see an address with 40 something, you
know immediately that it’s pointing into
your code.
So the next function returns a value and we
save it in a variable.
And you can see that in both cases, the value
is taken from the eax register.
Ok, so apparently return values are handled
via eax.
Now function 3 is interesting, because we
pass a parameter to it.
In 32bit you can see that the value is loaded
from somewhere and then stored on top of the
stack.
And then the function is called.
But on 64bit we see that the value is loaded
into the edi register.
This is our first big difference.
Functions in 64bit seem to be called with
parameters in registers, while in 32bit the
parameters are stored on the stack.
Next function uses 2 parameters.
And again, you can see how 32bit just places
the value on the stack.
First parameter on top of the stack, the second
a bit further down.
But in 64bit you can see that it uses esi
and edi for that.
Now we get curious.
What does 64bit do when we have so many parameters,
that we cannot keep them all in registers?
First of all 32bit code again.
You can see how the parameters are stored
on the stack.
And the first parameter is on top of the stack,
and the last value moved.
That’s what we would expect.
In 64bit we can see that the first couple
of parameters are stored in registers edi,
esi, edx, and so forth.
But from the 7th parameter on, they get stored
on the stack as well.
Awesome!
Now you can identify all kind of different
assembler patterns.
You don’t need a decompiler all the time.
You can do this all in your head.
And when you reverse more and more programs,
those patterns become more easy to recognize,
and you will not feel overwhelmed again with
the mass of weird instructions.
You will be able to scan over a function and
say: “ah here is a local variable.
Then calls this other function with this variable
as parameter.
And the return value is used in a loop”.
And you can use the same method to understand
how different disassemblers like hopper, radare,
gdb display code.
Or for example how different the at&t assembler
syntax is from the intel syntax.
I hope you have a lot of fun next time reversing
a program.
﻿We have already had many episodes where we
read assembler code and reverse engineered
how a program works.
And we even have written our first exploit
by using a buffer overflow vulnerability in
a program written in C.
In this episode I want to show you how you
can learn how to read assembler produced by
C code yourself.
The idea is simple.
Just write some C code with different C language
features, and then look at the assembler code
that is produced by compiling it.
This is often part of normal research.
For example listen to what Ian Beer from google
project zero says during a talk about his
research on Inter Process Calls on OSX.
One approach to reversing, or to understanding
how this kind of thing works would be to sit
in IDA and just reverse the serialization
and deserialization code, and slowly build
up a picture of how it works.
But another kind of quite nice way to do it,
is just, write a test program to send little
messages and then find the right place using
lldb to break and just start dumping hex.
So, because he had to understand a fairly
complex data structure, he simply wrote a
test program to analyse it, instead of reversing
a full application.
Or there was was a talk and paper from blackhat
USA in 2007 about how to reverse C++ programs,
by looking at C++ concepts and how they look
like in assembler.
So now I have created three different C code
testcases and you can find them in my github
repository, or just write it yourself.
One is about variables and datatypes.
One is about function calls.
And one is about control flow stuff like loops
and ifs.
So let’s start with the variables.c.
First thing I want to point out are those
triple Xs.
Those triple Xs are defined as an assembler
NOP instruction.
The reason for that is, later when we look
into the disassembly, we can find those NOPs
which are separating our tests, and that is
pretty neat.
So this makes it easier to see which line
of C Code is responsible for which lines in
assembler.
I will not go over every single test, this
is something you could do yourself.
Simply pause the video at certain points or
clone the repository.
Anyway.
Let’s get started.
First of all you can see here a couple of
simple numbers.
First we define a couple of numbers.
Unsigned and signed, integers and floating
numbers.
And different sizes with uint32 or uint64.
The latter is important, because normal Integers
might have a different size depending on 32bit
or 64bit, so it can lead to bugs.
So better use datatypes you are guaranteed
to get a certain size.
If you want to learn more about how to program
C properly, there is a great blog entry called
“How to C in 2015”.
After that we create an array with 32bit unsigned
integers, and we access one element of this
array.
Then we look at a single character.
And then also a string.
And maybe you know that a star * means “pointer”
in C. So we define a variable that is pointing
to a string.
I have added a Makefile, so you can simply
type `make` into the terminal to compile all
files.
Or make clean to remove the binaries.
This will create a 32bit and a 64bit version
of the variables program.
But as you can see, I get an error trying
to compile a 32bit version with -m32 in this
64bit machine.
So I have to install the 32bit libraries first,
to be able to build the code.
After installing those, the build works fine.
A Makefile is just a little script that defines
how a project has to be compiled.
So let’s open the code, 32bit and 64bit
version next to each other in gdb and disassemble
main.
And also open the code.
Ok now let’s look at the first integer examples
with negative values and signed and unsigned
values.
First of all, all those local variables are
stored somewhere on the stack, you can see
that because they are referenced relative
to the base-pointer.
Then you notice that the assembler code doesn’t
know negative numbers.
They are fff something.
If you are interested how negative numbers
are displayed, watch my 10th episode about
numbers.
And also there is no difference between variables
that are signed or unsigned.
But there is one difference between the 32bit
and the 64bit code.
Because we defined one number to be 64bit
long, but on 32bit the registers are only
32bit.
So if you want to write full 64bit, you have
to write two times.
The floating point numbers are also interesting.
Because they got stored somewhere else in
the program.
And that value is then moved into the local
variable.
The array is also interesting.
We created an array with 10 values but only
set the first 5 values to a default value.
As you can see those values are stored on
the stack.
And then it is moved from that location on
the stack to the real array location.
Instead of writing it directly to the array
it does it this way.
No idea why.
And you can see down here when we reference
the 3rd entry.
So you can see that this is the real location
of the array on the stack.
Next come the strings.
You can see that a character is just a byte.
It doesn’t matter if we have an unsigned
int with 8bit or a char.
It’s the same.
And strings are also referenced over an address.
So the local variable is not an array of charactes.
the local variable contains an address pointing
to a string.
Now let’s have a look at the control_flows.
Open it in radare.
Analyse all, seek to main function and enter
Visual mode.
First we set a variable to zero.
And then comes the if.
This is done by loading this local variable
in a register and comparing to hex ff.
And then jump if it was less or equal.
So you can see which branch it may take.
Then comes a while loop.
We load the local variable again in a register,
compare it to a value, and either jump inside
the block or leave.
And inside the block we load this value again,
increment it and write it back.
Now compare it to the foor loop.
It’s basically the same!
We start by setting the variable to 0.
Then we compare if the loop condition is still
true.
And inside the loop block, we can see our
NOP.
And at the end of the block we increment the
variable by 1.
Exactly the same like the while loop.
So you can see that a for and a while loop
in C are basically the same.
Next let’s have a look at how functions
are called.
Again open both the 32bit and 64bit version.
First thing you notice that the 64bit version
moves a 0 in eax.
No idea why.
Otherwise the function call looks the same.
Except look at the addresses.
If you have no ASLR, then 64bit code is generally
at hex 40 something.
While 32bit code is at hex 80 something.
Knowing stuff like that is helpful, because
if you see an address with 40 something, you
know immediately that it’s pointing into
your code.
So the next function returns a value and we
save it in a variable.
And you can see that in both cases, the value
is taken from the eax register.
Ok, so apparently return values are handled
via eax.
Now function 3 is interesting, because we
pass a parameter to it.
In 32bit you can see that the value is loaded
from somewhere and then stored on top of the
stack.
And then the function is called.
But on 64bit we see that the value is loaded
into the edi register.
This is our first big difference.
Functions in 64bit seem to be called with
parameters in registers, while in 32bit the
parameters are stored on the stack.
Next function uses 2 parameters.
And again, you can see how 32bit just places
the value on the stack.
First parameter on top of the stack, the second
a bit further down.
But in 64bit you can see that it uses esi
and edi for that.
Now we get curious.
What does 64bit do when we have so many parameters,
that we cannot keep them all in registers?
First of all 32bit code again.
You can see how the parameters are stored
on the stack.
And the first parameter is on top of the stack,
and the last value moved.
That’s what we would expect.
In 64bit we can see that the first couple
of parameters are stored in registers edi,
esi, edx, and so forth.
But from the 7th parameter on, they get stored
on the stack as well.
Awesome!
Now you can identify all kind of different
assembler patterns.
You don’t need a decompiler all the time.
You can do this all in your head.
And when you reverse more and more programs,
those patterns become more easy to recognize,
and you will not feel overwhelmed again with
the mass of weird instructions.
You will be able to scan over a function and
say: “ah here is a local variable.
Then calls this other function with this variable
as parameter.
And the return value is used in a loop”.
And you can use the same method to understand
how different disassemblers like hopper, radare,
gdb display code.
Or for example how different the at&t assembler
syntax is from the intel syntax.
I hope you have a lot of fun next time reversing
a program.
﻿We have already had many episodes where we
read assembler code and reverse engineered
how a program works.
And we even have written our first exploit
by using a buffer overflow vulnerability in
a program written in C.
In this episode I want to show you how you
can learn how to read assembler produced by
C code yourself.
The idea is simple.
Just write some C code with different C language
features, and then look at the assembler code
that is produced by compiling it.
This is often part of normal research.
For example listen to what Ian Beer from google
project zero says during a talk about his
research on Inter Process Calls on OSX.
One approach to reversing, or to understanding
how this kind of thing works would be to sit
in IDA and just reverse the serialization
and deserialization code, and slowly build
up a picture of how it works.
But another kind of quite nice way to do it,
is just, write a test program to send little
messages and then find the right place using
lldb to break and just start dumping hex.
So, because he had to understand a fairly
complex data structure, he simply wrote a
test program to analyse it, instead of reversing
a full application.
Or there was was a talk and paper from blackhat
USA in 2007 about how to reverse C++ programs,
by looking at C++ concepts and how they look
like in assembler.
So now I have created three different C code
testcases and you can find them in my github
repository, or just write it yourself.
One is about variables and datatypes.
One is about function calls.
And one is about control flow stuff like loops
and ifs.
So let’s start with the variables.c.
First thing I want to point out are those
triple Xs.
Those triple Xs are defined as an assembler
NOP instruction.
The reason for that is, later when we look
into the disassembly, we can find those NOPs
which are separating our tests, and that is
pretty neat.
So this makes it easier to see which line
of C Code is responsible for which lines in
assembler.
I will not go over every single test, this
is something you could do yourself.
Simply pause the video at certain points or
clone the repository.
Anyway.
Let’s get started.
First of all you can see here a couple of
simple numbers.
First we define a couple of numbers.
Unsigned and signed, integers and floating
numbers.
And different sizes with uint32 or uint64.
The latter is important, because normal Integers
might have a different size depending on 32bit
or 64bit, so it can lead to bugs.
So better use datatypes you are guaranteed
to get a certain size.
If you want to learn more about how to program
C properly, there is a great blog entry called
“How to C in 2015”.
After that we create an array with 32bit unsigned
integers, and we access one element of this
array.
Then we look at a single character.
And then also a string.
And maybe you know that a star * means “pointer”
in C. So we define a variable that is pointing
to a string.
I have added a Makefile, so you can simply
type `make` into the terminal to compile all
files.
Or make clean to remove the binaries.
This will create a 32bit and a 64bit version
of the variables program.
But as you can see, I get an error trying
to compile a 32bit version with -m32 in this
64bit machine.
So I have to install the 32bit libraries first,
to be able to build the code.
After installing those, the build works fine.
A Makefile is just a little script that defines
how a project has to be compiled.
So let’s open the code, 32bit and 64bit
version next to each other in gdb and disassemble
main.
And also open the code.
Ok now let’s look at the first integer examples
with negative values and signed and unsigned
values.
First of all, all those local variables are
stored somewhere on the stack, you can see
that because they are referenced relative
to the base-pointer.
Then you notice that the assembler code doesn’t
know negative numbers.
They are fff something.
If you are interested how negative numbers
are displayed, watch my 10th episode about
numbers.
And also there is no difference between variables
that are signed or unsigned.
But there is one difference between the 32bit
and the 64bit code.
Because we defined one number to be 64bit
long, but on 32bit the registers are only
32bit.
So if you want to write full 64bit, you have
to write two times.
The floating point numbers are also interesting.
Because they got stored somewhere else in
the program.
And that value is then moved into the local
variable.
The array is also interesting.
We created an array with 10 values but only
set the first 5 values to a default value.
As you can see those values are stored on
the stack.
And then it is moved from that location on
the stack to the real array location.
Instead of writing it directly to the array
it does it this way.
No idea why.
And you can see down here when we reference
the 3rd entry.
So you can see that this is the real location
of the array on the stack.
Next come the strings.
You can see that a character is just a byte.
It doesn’t matter if we have an unsigned
int with 8bit or a char.
It’s the same.
And strings are also referenced over an address.
So the local variable is not an array of charactes.
the local variable contains an address pointing
to a string.
Now let’s have a look at the control_flows.
Open it in radare.
Analyse all, seek to main function and enter
Visual mode.
First we set a variable to zero.
And then comes the if.
This is done by loading this local variable
in a register and comparing to hex ff.
And then jump if it was less or equal.
So you can see which branch it may take.
Then comes a while loop.
We load the local variable again in a register,
compare it to a value, and either jump inside
the block or leave.
And inside the block we load this value again,
increment it and write it back.
Now compare it to the foor loop.
It’s basically the same!
We start by setting the variable to 0.
Then we compare if the loop condition is still
true.
And inside the loop block, we can see our
NOP.
And at the end of the block we increment the
variable by 1.
Exactly the same like the while loop.
So you can see that a for and a while loop
in C are basically the same.
Next let’s have a look at how functions
are called.
Again open both the 32bit and 64bit version.
First thing you notice that the 64bit version
moves a 0 in eax.
No idea why.
Otherwise the function call looks the same.
Except look at the addresses.
If you have no ASLR, then 64bit code is generally
at hex 40 something.
While 32bit code is at hex 80 something.
Knowing stuff like that is helpful, because
if you see an address with 40 something, you
know immediately that it’s pointing into
your code.
So the next function returns a value and we
save it in a variable.
And you can see that in both cases, the value
is taken from the eax register.
Ok, so apparently return values are handled
via eax.
Now function 3 is interesting, because we
pass a parameter to it.
In 32bit you can see that the value is loaded
from somewhere and then stored on top of the
stack.
And then the function is called.
But on 64bit we see that the value is loaded
into the edi register.
This is our first big difference.
Functions in 64bit seem to be called with
parameters in registers, while in 32bit the
parameters are stored on the stack.
Next function uses 2 parameters.
And again, you can see how 32bit just places
the value on the stack.
First parameter on top of the stack, the second
a bit further down.
But in 64bit you can see that it uses esi
and edi for that.
Now we get curious.
What does 64bit do when we have so many parameters,
that we cannot keep them all in registers?
First of all 32bit code again.
You can see how the parameters are stored
on the stack.
And the first parameter is on top of the stack,
and the last value moved.
That’s what we would expect.
In 64bit we can see that the first couple
of parameters are stored in registers edi,
esi, edx, and so forth.
But from the 7th parameter on, they get stored
on the stack as well.
Awesome!
Now you can identify all kind of different
assembler patterns.
You don’t need a decompiler all the time.
You can do this all in your head.
And when you reverse more and more programs,
those patterns become more easy to recognize,
and you will not feel overwhelmed again with
the mass of weird instructions.
You will be able to scan over a function and
say: “ah here is a local variable.
Then calls this other function with this variable
as parameter.
And the return value is used in a loop”.
And you can use the same method to understand
how different disassemblers like hopper, radare,
gdb display code.
Or for example how different the at&t assembler
syntax is from the intel syntax.
I hope you have a lot of fun next time reversing
a program.
﻿We have already had many episodes where we
read assembler code and reverse engineered
how a program works.
And we even have written our first exploit
by using a buffer overflow vulnerability in
a program written in C.
In this episode I want to show you how you
can learn how to read assembler produced by
C code yourself.
The idea is simple.
Just write some C code with different C language
features, and then look at the assembler code
that is produced by compiling it.
This is often part of normal research.
For example listen to what Ian Beer from google
project zero says during a talk about his
research on Inter Process Calls on OSX.
One approach to reversing, or to understanding
how this kind of thing works would be to sit
in IDA and just reverse the serialization
and deserialization code, and slowly build
up a picture of how it works.
But another kind of quite nice way to do it,
is just, write a test program to send little
messages and then find the right place using
lldb to break and just start dumping hex.
So, because he had to understand a fairly
complex data structure, he simply wrote a
test program to analyse it, instead of reversing
a full application.
Or there was was a talk and paper from blackhat
USA in 2007 about how to reverse C++ programs,
by looking at C++ concepts and how they look
like in assembler.
So now I have created three different C code
testcases and you can find them in my github
repository, or just write it yourself.
One is about variables and datatypes.
One is about function calls.
And one is about control flow stuff like loops
and ifs.
So let’s start with the variables.c.
First thing I want to point out are those
triple Xs.
Those triple Xs are defined as an assembler
NOP instruction.
The reason for that is, later when we look
into the disassembly, we can find those NOPs
which are separating our tests, and that is
pretty neat.
So this makes it easier to see which line
of C Code is responsible for which lines in
assembler.
I will not go over every single test, this
is something you could do yourself.
Simply pause the video at certain points or
clone the repository.
Anyway.
Let’s get started.
First of all you can see here a couple of
simple numbers.
First we define a couple of numbers.
Unsigned and signed, integers and floating
numbers.
And different sizes with uint32 or uint64.
The latter is important, because normal Integers
might have a different size depending on 32bit
or 64bit, so it can lead to bugs.
So better use datatypes you are guaranteed
to get a certain size.
If you want to learn more about how to program
C properly, there is a great blog entry called
“How to C in 2015”.
After that we create an array with 32bit unsigned
integers, and we access one element of this
array.
Then we look at a single character.
And then also a string.
And maybe you know that a star * means “pointer”
in C. So we define a variable that is pointing
to a string.
I have added a Makefile, so you can simply
type `make` into the terminal to compile all
files.
Or make clean to remove the binaries.
This will create a 32bit and a 64bit version
of the variables program.
But as you can see, I get an error trying
to compile a 32bit version with -m32 in this
64bit machine.
So I have to install the 32bit libraries first,
to be able to build the code.
After installing those, the build works fine.
A Makefile is just a little script that defines
how a project has to be compiled.
So let’s open the code, 32bit and 64bit
version next to each other in gdb and disassemble
main.
And also open the code.
Ok now let’s look at the first integer examples
with negative values and signed and unsigned
values.
First of all, all those local variables are
stored somewhere on the stack, you can see
that because they are referenced relative
to the base-pointer.
Then you notice that the assembler code doesn’t
know negative numbers.
They are fff something.
If you are interested how negative numbers
are displayed, watch my 10th episode about
numbers.
And also there is no difference between variables
that are signed or unsigned.
But there is one difference between the 32bit
and the 64bit code.
Because we defined one number to be 64bit
long, but on 32bit the registers are only
32bit.
So if you want to write full 64bit, you have
to write two times.
The floating point numbers are also interesting.
Because they got stored somewhere else in
the program.
And that value is then moved into the local
variable.
The array is also interesting.
We created an array with 10 values but only
set the first 5 values to a default value.
As you can see those values are stored on
the stack.
And then it is moved from that location on
the stack to the real array location.
Instead of writing it directly to the array
it does it this way.
No idea why.
And you can see down here when we reference
the 3rd entry.
So you can see that this is the real location
of the array on the stack.
Next come the strings.
You can see that a character is just a byte.
It doesn’t matter if we have an unsigned
int with 8bit or a char.
It’s the same.
And strings are also referenced over an address.
So the local variable is not an array of charactes.
the local variable contains an address pointing
to a string.
Now let’s have a look at the control_flows.
Open it in radare.
Analyse all, seek to main function and enter
Visual mode.
First we set a variable to zero.
And then comes the if.
This is done by loading this local variable
in a register and comparing to hex ff.
And then jump if it was less or equal.
So you can see which branch it may take.
Then comes a while loop.
We load the local variable again in a register,
compare it to a value, and either jump inside
the block or leave.
And inside the block we load this value again,
increment it and write it back.
Now compare it to the foor loop.
It’s basically the same!
We start by setting the variable to 0.
Then we compare if the loop condition is still
true.
And inside the loop block, we can see our
NOP.
And at the end of the block we increment the
variable by 1.
Exactly the same like the while loop.
So you can see that a for and a while loop
in C are basically the same.
Next let’s have a look at how functions
are called.
Again open both the 32bit and 64bit version.
First thing you notice that the 64bit version
moves a 0 in eax.
No idea why.
Otherwise the function call looks the same.
Except look at the addresses.
If you have no ASLR, then 64bit code is generally
at hex 40 something.
While 32bit code is at hex 80 something.
Knowing stuff like that is helpful, because
if you see an address with 40 something, you
know immediately that it’s pointing into
your code.
So the next function returns a value and we
save it in a variable.
And you can see that in both cases, the value
is taken from the eax register.
Ok, so apparently return values are handled
via eax.
Now function 3 is interesting, because we
pass a parameter to it.
In 32bit you can see that the value is loaded
from somewhere and then stored on top of the
stack.
And then the function is called.
But on 64bit we see that the value is loaded
into the edi register.
This is our first big difference.
Functions in 64bit seem to be called with
parameters in registers, while in 32bit the
parameters are stored on the stack.
Next function uses 2 parameters.
And again, you can see how 32bit just places
the value on the stack.
First parameter on top of the stack, the second
a bit further down.
But in 64bit you can see that it uses esi
and edi for that.
Now we get curious.
What does 64bit do when we have so many parameters,
that we cannot keep them all in registers?
First of all 32bit code again.
You can see how the parameters are stored
on the stack.
And the first parameter is on top of the stack,
and the last value moved.
That’s what we would expect.
In 64bit we can see that the first couple
of parameters are stored in registers edi,
esi, edx, and so forth.
But from the 7th parameter on, they get stored
on the stack as well.
Awesome!
Now you can identify all kind of different
assembler patterns.
You don’t need a decompiler all the time.
You can do this all in your head.
And when you reverse more and more programs,
those patterns become more easy to recognize,
and you will not feel overwhelmed again with
the mass of weird instructions.
You will be able to scan over a function and
say: “ah here is a local variable.
Then calls this other function with this variable
as parameter.
And the return value is used in a loop”.
And you can use the same method to understand
how different disassemblers like hopper, radare,
gdb display code.
Or for example how different the at&t assembler
syntax is from the intel syntax.
I hope you have a lot of fun next time reversing
a program.
﻿We have already had many episodes where we
read assembler code and reverse engineered
how a program works.
And we even have written our first exploit
by using a buffer overflow vulnerability in
a program written in C.
In this episode I want to show you how you
can learn how to read assembler produced by
C code yourself.
The idea is simple.
Just write some C code with different C language
features, and then look at the assembler code
that is produced by compiling it.
This is often part of normal research.
For example listen to what Ian Beer from google
project zero says during a talk about his
research on Inter Process Calls on OSX.
One approach to reversing, or to understanding
how this kind of thing works would be to sit
in IDA and just reverse the serialization
and deserialization code, and slowly build
up a picture of how it works.
But another kind of quite nice way to do it,
is just, write a test program to send little
messages and then find the right place using
lldb to break and just start dumping hex.
So, because he had to understand a fairly
complex data structure, he simply wrote a
test program to analyse it, instead of reversing
a full application.
Or there was was a talk and paper from blackhat
USA in 2007 about how to reverse C++ programs,
by looking at C++ concepts and how they look
like in assembler.
So now I have created three different C code
testcases and you can find them in my github
repository, or just write it yourself.
One is about variables and datatypes.
One is about function calls.
And one is about control flow stuff like loops
and ifs.
So let’s start with the variables.c.
First thing I want to point out are those
triple Xs.
Those triple Xs are defined as an assembler
NOP instruction.
The reason for that is, later when we look
into the disassembly, we can find those NOPs
which are separating our tests, and that is
pretty neat.
So this makes it easier to see which line
of C Code is responsible for which lines in
assembler.
I will not go over every single test, this
is something you could do yourself.
Simply pause the video at certain points or
clone the repository.
Anyway.
Let’s get started.
First of all you can see here a couple of
simple numbers.
First we define a couple of numbers.
Unsigned and signed, integers and floating
numbers.
And different sizes with uint32 or uint64.
The latter is important, because normal Integers
might have a different size depending on 32bit
or 64bit, so it can lead to bugs.
So better use datatypes you are guaranteed
to get a certain size.
If you want to learn more about how to program
C properly, there is a great blog entry called
“How to C in 2015”.
After that we create an array with 32bit unsigned
integers, and we access one element of this
array.
Then we look at a single character.
And then also a string.
And maybe you know that a star * means “pointer”
in C. So we define a variable that is pointing
to a string.
I have added a Makefile, so you can simply
type `make` into the terminal to compile all
files.
Or make clean to remove the binaries.
This will create a 32bit and a 64bit version
of the variables program.
But as you can see, I get an error trying
to compile a 32bit version with -m32 in this
64bit machine.
So I have to install the 32bit libraries first,
to be able to build the code.
After installing those, the build works fine.
A Makefile is just a little script that defines
how a project has to be compiled.
So let’s open the code, 32bit and 64bit
version next to each other in gdb and disassemble
main.
And also open the code.
Ok now let’s look at the first integer examples
with negative values and signed and unsigned
values.
First of all, all those local variables are
stored somewhere on the stack, you can see
that because they are referenced relative
to the base-pointer.
Then you notice that the assembler code doesn’t
know negative numbers.
They are fff something.
If you are interested how negative numbers
are displayed, watch my 10th episode about
numbers.
And also there is no difference between variables
that are signed or unsigned.
But there is one difference between the 32bit
and the 64bit code.
Because we defined one number to be 64bit
long, but on 32bit the registers are only
32bit.
So if you want to write full 64bit, you have
to write two times.
The floating point numbers are also interesting.
Because they got stored somewhere else in
the program.
And that value is then moved into the local
variable.
The array is also interesting.
We created an array with 10 values but only
set the first 5 values to a default value.
As you can see those values are stored on
the stack.
And then it is moved from that location on
the stack to the real array location.
Instead of writing it directly to the array
it does it this way.
No idea why.
And you can see down here when we reference
the 3rd entry.
So you can see that this is the real location
of the array on the stack.
Next come the strings.
You can see that a character is just a byte.
It doesn’t matter if we have an unsigned
int with 8bit or a char.
It’s the same.
And strings are also referenced over an address.
So the local variable is not an array of charactes.
the local variable contains an address pointing
to a string.
Now let’s have a look at the control_flows.
Open it in radare.
Analyse all, seek to main function and enter
Visual mode.
First we set a variable to zero.
And then comes the if.
This is done by loading this local variable
in a register and comparing to hex ff.
And then jump if it was less or equal.
So you can see which branch it may take.
Then comes a while loop.
We load the local variable again in a register,
compare it to a value, and either jump inside
the block or leave.
And inside the block we load this value again,
increment it and write it back.
Now compare it to the foor loop.
It’s basically the same!
We start by setting the variable to 0.
Then we compare if the loop condition is still
true.
And inside the loop block, we can see our
NOP.
And at the end of the block we increment the
variable by 1.
Exactly the same like the while loop.
So you can see that a for and a while loop
in C are basically the same.
Next let’s have a look at how functions
are called.
Again open both the 32bit and 64bit version.
First thing you notice that the 64bit version
moves a 0 in eax.
No idea why.
Otherwise the function call looks the same.
Except look at the addresses.
If you have no ASLR, then 64bit code is generally
at hex 40 something.
While 32bit code is at hex 80 something.
Knowing stuff like that is helpful, because
if you see an address with 40 something, you
know immediately that it’s pointing into
your code.
So the next function returns a value and we
save it in a variable.
And you can see that in both cases, the value
is taken from the eax register.
Ok, so apparently return values are handled
via eax.
Now function 3 is interesting, because we
pass a parameter to it.
In 32bit you can see that the value is loaded
from somewhere and then stored on top of the
stack.
And then the function is called.
But on 64bit we see that the value is loaded
into the edi register.
This is our first big difference.
Functions in 64bit seem to be called with
parameters in registers, while in 32bit the
parameters are stored on the stack.
Next function uses 2 parameters.
And again, you can see how 32bit just places
the value on the stack.
First parameter on top of the stack, the second
a bit further down.
But in 64bit you can see that it uses esi
and edi for that.
Now we get curious.
What does 64bit do when we have so many parameters,
that we cannot keep them all in registers?
First of all 32bit code again.
You can see how the parameters are stored
on the stack.
And the first parameter is on top of the stack,
and the last value moved.
That’s what we would expect.
In 64bit we can see that the first couple
of parameters are stored in registers edi,
esi, edx, and so forth.
But from the 7th parameter on, they get stored
on the stack as well.
Awesome!
Now you can identify all kind of different
assembler patterns.
You don’t need a decompiler all the time.
You can do this all in your head.
And when you reverse more and more programs,
those patterns become more easy to recognize,
and you will not feel overwhelmed again with
the mass of weird instructions.
You will be able to scan over a function and
say: “ah here is a local variable.
Then calls this other function with this variable
as parameter.
And the return value is used in a loop”.
And you can use the same method to understand
how different disassemblers like hopper, radare,
gdb display code.
Or for example how different the at&t assembler
syntax is from the intel syntax.
I hope you have a lot of fun next time reversing
a program.
﻿We have already had many episodes where we
read assembler code and reverse engineered
how a program works.
And we even have written our first exploit
by using a buffer overflow vulnerability in
a program written in C.
In this episode I want to show you how you
can learn how to read assembler produced by
C code yourself.
The idea is simple.
Just write some C code with different C language
features, and then look at the assembler code
that is produced by compiling it.
This is often part of normal research.
For example listen to what Ian Beer from google
project zero says during a talk about his
research on Inter Process Calls on OSX.
One approach to reversing, or to understanding
how this kind of thing works would be to sit
in IDA and just reverse the serialization
and deserialization code, and slowly build
up a picture of how it works.
But another kind of quite nice way to do it,
is just, write a test program to send little
messages and then find the right place using
lldb to break and just start dumping hex.
So, because he had to understand a fairly
complex data structure, he simply wrote a
test program to analyse it, instead of reversing
a full application.
Or there was was a talk and paper from blackhat
USA in 2007 about how to reverse C++ programs,
by looking at C++ concepts and how they look
like in assembler.
So now I have created three different C code
testcases and you can find them in my github
repository, or just write it yourself.
One is about variables and datatypes.
One is about function calls.
And one is about control flow stuff like loops
and ifs.
So let’s start with the variables.c.
First thing I want to point out are those
triple Xs.
Those triple Xs are defined as an assembler
NOP instruction.
The reason for that is, later when we look
into the disassembly, we can find those NOPs
which are separating our tests, and that is
pretty neat.
So this makes it easier to see which line
of C Code is responsible for which lines in
assembler.
I will not go over every single test, this
is something you could do yourself.
Simply pause the video at certain points or
clone the repository.
Anyway.
Let’s get started.
First of all you can see here a couple of
simple numbers.
First we define a couple of numbers.
Unsigned and signed, integers and floating
numbers.
And different sizes with uint32 or uint64.
The latter is important, because normal Integers
might have a different size depending on 32bit
or 64bit, so it can lead to bugs.
So better use datatypes you are guaranteed
to get a certain size.
If you want to learn more about how to program
C properly, there is a great blog entry called
“How to C in 2015”.
After that we create an array with 32bit unsigned
integers, and we access one element of this
array.
Then we look at a single character.
And then also a string.
And maybe you know that a star * means “pointer”
in C. So we define a variable that is pointing
to a string.
I have added a Makefile, so you can simply
type `make` into the terminal to compile all
files.
Or make clean to remove the binaries.
This will create a 32bit and a 64bit version
of the variables program.
But as you can see, I get an error trying
to compile a 32bit version with -m32 in this
64bit machine.
So I have to install the 32bit libraries first,
to be able to build the code.
After installing those, the build works fine.
A Makefile is just a little script that defines
how a project has to be compiled.
So let’s open the code, 32bit and 64bit
version next to each other in gdb and disassemble
main.
And also open the code.
Ok now let’s look at the first integer examples
with negative values and signed and unsigned
values.
First of all, all those local variables are
stored somewhere on the stack, you can see
that because they are referenced relative
to the base-pointer.
Then you notice that the assembler code doesn’t
know negative numbers.
They are fff something.
If you are interested how negative numbers
are displayed, watch my 10th episode about
numbers.
And also there is no difference between variables
that are signed or unsigned.
But there is one difference between the 32bit
and the 64bit code.
Because we defined one number to be 64bit
long, but on 32bit the registers are only
32bit.
So if you want to write full 64bit, you have
to write two times.
The floating point numbers are also interesting.
Because they got stored somewhere else in
the program.
And that value is then moved into the local
variable.
The array is also interesting.
We created an array with 10 values but only
set the first 5 values to a default value.
As you can see those values are stored on
the stack.
And then it is moved from that location on
the stack to the real array location.
Instead of writing it directly to the array
it does it this way.
No idea why.
And you can see down here when we reference
the 3rd entry.
So you can see that this is the real location
of the array on the stack.
Next come the strings.
You can see that a character is just a byte.
It doesn’t matter if we have an unsigned
int with 8bit or a char.
It’s the same.
And strings are also referenced over an address.
So the local variable is not an array of charactes.
the local variable contains an address pointing
to a string.
Now let’s have a look at the control_flows.
Open it in radare.
Analyse all, seek to main function and enter
Visual mode.
First we set a variable to zero.
And then comes the if.
This is done by loading this local variable
in a register and comparing to hex ff.
And then jump if it was less or equal.
So you can see which branch it may take.
Then comes a while loop.
We load the local variable again in a register,
compare it to a value, and either jump inside
the block or leave.
And inside the block we load this value again,
increment it and write it back.
Now compare it to the foor loop.
It’s basically the same!
We start by setting the variable to 0.
Then we compare if the loop condition is still
true.
And inside the loop block, we can see our
NOP.
And at the end of the block we increment the
variable by 1.
Exactly the same like the while loop.
So you can see that a for and a while loop
in C are basically the same.
Next let’s have a look at how functions
are called.
Again open both the 32bit and 64bit version.
First thing you notice that the 64bit version
moves a 0 in eax.
No idea why.
Otherwise the function call looks the same.
Except look at the addresses.
If you have no ASLR, then 64bit code is generally
at hex 40 something.
While 32bit code is at hex 80 something.
Knowing stuff like that is helpful, because
if you see an address with 40 something, you
know immediately that it’s pointing into
your code.
So the next function returns a value and we
save it in a variable.
And you can see that in both cases, the value
is taken from the eax register.
Ok, so apparently return values are handled
via eax.
Now function 3 is interesting, because we
pass a parameter to it.
In 32bit you can see that the value is loaded
from somewhere and then stored on top of the
stack.
And then the function is called.
But on 64bit we see that the value is loaded
into the edi register.
This is our first big difference.
Functions in 64bit seem to be called with
parameters in registers, while in 32bit the
parameters are stored on the stack.
Next function uses 2 parameters.
And again, you can see how 32bit just places
the value on the stack.
First parameter on top of the stack, the second
a bit further down.
But in 64bit you can see that it uses esi
and edi for that.
Now we get curious.
What does 64bit do when we have so many parameters,
that we cannot keep them all in registers?
First of all 32bit code again.
You can see how the parameters are stored
on the stack.
And the first parameter is on top of the stack,
and the last value moved.
That’s what we would expect.
In 64bit we can see that the first couple
of parameters are stored in registers edi,
esi, edx, and so forth.
But from the 7th parameter on, they get stored
on the stack as well.
Awesome!
Now you can identify all kind of different
assembler patterns.
You don’t need a decompiler all the time.
You can do this all in your head.
And when you reverse more and more programs,
those patterns become more easy to recognize,
and you will not feel overwhelmed again with
the mass of weird instructions.
You will be able to scan over a function and
say: “ah here is a local variable.
Then calls this other function with this variable
as parameter.
And the return value is used in a loop”.
And you can use the same method to understand
how different disassemblers like hopper, radare,
gdb display code.
Or for example how different the at&t assembler
syntax is from the intel syntax.
I hope you have a lot of fun next time reversing
a program.
﻿We have already had many episodes where we
read assembler code and reverse engineered
how a program works.
And we even have written our first exploit
by using a buffer overflow vulnerability in
a program written in C.
In this episode I want to show you how you
can learn how to read assembler produced by
C code yourself.
The idea is simple.
Just write some C code with different C language
features, and then look at the assembler code
that is produced by compiling it.
This is often part of normal research.
For example listen to what Ian Beer from google
project zero says during a talk about his
research on Inter Process Calls on OSX.
One approach to reversing, or to understanding
how this kind of thing works would be to sit
in IDA and just reverse the serialization
and deserialization code, and slowly build
up a picture of how it works.
But another kind of quite nice way to do it,
is just, write a test program to send little
messages and then find the right place using
lldb to break and just start dumping hex.
So, because he had to understand a fairly
complex data structure, he simply wrote a
test program to analyse it, instead of reversing
a full application.
Or there was was a talk and paper from blackhat
USA in 2007 about how to reverse C++ programs,
by looking at C++ concepts and how they look
like in assembler.
So now I have created three different C code
testcases and you can find them in my github
repository, or just write it yourself.
One is about variables and datatypes.
One is about function calls.
And one is about control flow stuff like loops
and ifs.
So let’s start with the variables.c.
First thing I want to point out are those
triple Xs.
Those triple Xs are defined as an assembler
NOP instruction.
The reason for that is, later when we look
into the disassembly, we can find those NOPs
which are separating our tests, and that is
pretty neat.
So this makes it easier to see which line
of C Code is responsible for which lines in
assembler.
I will not go over every single test, this
is something you could do yourself.
Simply pause the video at certain points or
clone the repository.
Anyway.
Let’s get started.
First of all you can see here a couple of
simple numbers.
First we define a couple of numbers.
Unsigned and signed, integers and floating
numbers.
And different sizes with uint32 or uint64.
The latter is important, because normal Integers
might have a different size depending on 32bit
or 64bit, so it can lead to bugs.
So better use datatypes you are guaranteed
to get a certain size.
If you want to learn more about how to program
C properly, there is a great blog entry called
“How to C in 2015”.
After that we create an array with 32bit unsigned
integers, and we access one element of this
array.
Then we look at a single character.
And then also a string.
And maybe you know that a star * means “pointer”
in C. So we define a variable that is pointing
to a string.
I have added a Makefile, so you can simply
type `make` into the terminal to compile all
files.
Or make clean to remove the binaries.
This will create a 32bit and a 64bit version
of the variables program.
But as you can see, I get an error trying
to compile a 32bit version with -m32 in this
64bit machine.
So I have to install the 32bit libraries first,
to be able to build the code.
After installing those, the build works fine.
A Makefile is just a little script that defines
how a project has to be compiled.
So let’s open the code, 32bit and 64bit
version next to each other in gdb and disassemble
main.
And also open the code.
Ok now let’s look at the first integer examples
with negative values and signed and unsigned
values.
First of all, all those local variables are
stored somewhere on the stack, you can see
that because they are referenced relative
to the base-pointer.
Then you notice that the assembler code doesn’t
know negative numbers.
They are fff something.
If you are interested how negative numbers
are displayed, watch my 10th episode about
numbers.
And also there is no difference between variables
that are signed or unsigned.
But there is one difference between the 32bit
and the 64bit code.
Because we defined one number to be 64bit
long, but on 32bit the registers are only
32bit.
So if you want to write full 64bit, you have
to write two times.
The floating point numbers are also interesting.
Because they got stored somewhere else in
the program.
And that value is then moved into the local
variable.
The array is also interesting.
We created an array with 10 values but only
set the first 5 values to a default value.
As you can see those values are stored on
the stack.
And then it is moved from that location on
the stack to the real array location.
Instead of writing it directly to the array
it does it this way.
No idea why.
And you can see down here when we reference
the 3rd entry.
So you can see that this is the real location
of the array on the stack.
Next come the strings.
You can see that a character is just a byte.
It doesn’t matter if we have an unsigned
int with 8bit or a char.
It’s the same.
And strings are also referenced over an address.
So the local variable is not an array of charactes.
the local variable contains an address pointing
to a string.
Now let’s have a look at the control_flows.
Open it in radare.
Analyse all, seek to main function and enter
Visual mode.
First we set a variable to zero.
And then comes the if.
This is done by loading this local variable
in a register and comparing to hex ff.
And then jump if it was less or equal.
So you can see which branch it may take.
Then comes a while loop.
We load the local variable again in a register,
compare it to a value, and either jump inside
the block or leave.
And inside the block we load this value again,
increment it and write it back.
Now compare it to the foor loop.
It’s basically the same!
We start by setting the variable to 0.
Then we compare if the loop condition is still
true.
And inside the loop block, we can see our
NOP.
And at the end of the block we increment the
variable by 1.
Exactly the same like the while loop.
So you can see that a for and a while loop
in C are basically the same.
Next let’s have a look at how functions
are called.
Again open both the 32bit and 64bit version.
First thing you notice that the 64bit version
moves a 0 in eax.
No idea why.
Otherwise the function call looks the same.
Except look at the addresses.
If you have no ASLR, then 64bit code is generally
at hex 40 something.
While 32bit code is at hex 80 something.
Knowing stuff like that is helpful, because
if you see an address with 40 something, you
know immediately that it’s pointing into
your code.
So the next function returns a value and we
save it in a variable.
And you can see that in both cases, the value
is taken from the eax register.
Ok, so apparently return values are handled
via eax.
Now function 3 is interesting, because we
pass a parameter to it.
In 32bit you can see that the value is loaded
from somewhere and then stored on top of the
stack.
And then the function is called.
But on 64bit we see that the value is loaded
into the edi register.
This is our first big difference.
Functions in 64bit seem to be called with
parameters in registers, while in 32bit the
parameters are stored on the stack.
Next function uses 2 parameters.
And again, you can see how 32bit just places
the value on the stack.
First parameter on top of the stack, the second
a bit further down.
But in 64bit you can see that it uses esi
and edi for that.
Now we get curious.
What does 64bit do when we have so many parameters,
that we cannot keep them all in registers?
First of all 32bit code again.
You can see how the parameters are stored
on the stack.
And the first parameter is on top of the stack,
and the last value moved.
That’s what we would expect.
In 64bit we can see that the first couple
of parameters are stored in registers edi,
esi, edx, and so forth.
But from the 7th parameter on, they get stored
on the stack as well.
Awesome!
Now you can identify all kind of different
assembler patterns.
You don’t need a decompiler all the time.
You can do this all in your head.
And when you reverse more and more programs,
those patterns become more easy to recognize,
and you will not feel overwhelmed again with
the mass of weird instructions.
You will be able to scan over a function and
say: “ah here is a local variable.
Then calls this other function with this variable
as parameter.
And the return value is used in a loop”.
And you can use the same method to understand
how different disassemblers like hopper, radare,
gdb display code.
Or for example how different the at&t assembler
syntax is from the intel syntax.
I hope you have a lot of fun next time reversing
a program.
﻿We have already had many episodes where we
read assembler code and reverse engineered
how a program works.
And we even have written our first exploit
by using a buffer overflow vulnerability in
a program written in C.
In this episode I want to show you how you
can learn how to read assembler produced by
C code yourself.
The idea is simple.
Just write some C code with different C language
features, and then look at the assembler code
that is produced by compiling it.
This is often part of normal research.
For example listen to what Ian Beer from google
project zero says during a talk about his
research on Inter Process Calls on OSX.
One approach to reversing, or to understanding
how this kind of thing works would be to sit
in IDA and just reverse the serialization
and deserialization code, and slowly build
up a picture of how it works.
But another kind of quite nice way to do it,
is just, write a test program to send little
messages and then find the right place using
lldb to break and just start dumping hex.
So, because he had to understand a fairly
complex data structure, he simply wrote a
test program to analyse it, instead of reversing
a full application.
Or there was was a talk and paper from blackhat
USA in 2007 about how to reverse C++ programs,
by looking at C++ concepts and how they look
like in assembler.
So now I have created three different C code
testcases and you can find them in my github
repository, or just write it yourself.
One is about variables and datatypes.
One is about function calls.
And one is about control flow stuff like loops
and ifs.
So let’s start with the variables.c.
First thing I want to point out are those
triple Xs.
Those triple Xs are defined as an assembler
NOP instruction.
The reason for that is, later when we look
into the disassembly, we can find those NOPs
which are separating our tests, and that is
pretty neat.
So this makes it easier to see which line
of C Code is responsible for which lines in
assembler.
I will not go over every single test, this
is something you could do yourself.
Simply pause the video at certain points or
clone the repository.
Anyway.
Let’s get started.
First of all you can see here a couple of
simple numbers.
First we define a couple of numbers.
Unsigned and signed, integers and floating
numbers.
And different sizes with uint32 or uint64.
The latter is important, because normal Integers
might have a different size depending on 32bit
or 64bit, so it can lead to bugs.
So better use datatypes you are guaranteed
to get a certain size.
If you want to learn more about how to program
C properly, there is a great blog entry called
“How to C in 2015”.
After that we create an array with 32bit unsigned
integers, and we access one element of this
array.
Then we look at a single character.
And then also a string.
And maybe you know that a star * means “pointer”
in C. So we define a variable that is pointing
to a string.
I have added a Makefile, so you can simply
type `make` into the terminal to compile all
files.
Or make clean to remove the binaries.
This will create a 32bit and a 64bit version
of the variables program.
But as you can see, I get an error trying
to compile a 32bit version with -m32 in this
64bit machine.
So I have to install the 32bit libraries first,
to be able to build the code.
After installing those, the build works fine.
A Makefile is just a little script that defines
how a project has to be compiled.
So let’s open the code, 32bit and 64bit
version next to each other in gdb and disassemble
main.
And also open the code.
Ok now let’s look at the first integer examples
with negative values and signed and unsigned
values.
First of all, all those local variables are
stored somewhere on the stack, you can see
that because they are referenced relative
to the base-pointer.
Then you notice that the assembler code doesn’t
know negative numbers.
They are fff something.
If you are interested how negative numbers
are displayed, watch my 10th episode about
numbers.
And also there is no difference between variables
that are signed or unsigned.
But there is one difference between the 32bit
and the 64bit code.
Because we defined one number to be 64bit
long, but on 32bit the registers are only
32bit.
So if you want to write full 64bit, you have
to write two times.
The floating point numbers are also interesting.
Because they got stored somewhere else in
the program.
And that value is then moved into the local
variable.
The array is also interesting.
We created an array with 10 values but only
set the first 5 values to a default value.
As you can see those values are stored on
the stack.
And then it is moved from that location on
the stack to the real array location.
Instead of writing it directly to the array
it does it this way.
No idea why.
And you can see down here when we reference
the 3rd entry.
So you can see that this is the real location
of the array on the stack.
Next come the strings.
You can see that a character is just a byte.
It doesn’t matter if we have an unsigned
int with 8bit or a char.
It’s the same.
And strings are also referenced over an address.
So the local variable is not an array of charactes.
the local variable contains an address pointing
to a string.
Now let’s have a look at the control_flows.
Open it in radare.
Analyse all, seek to main function and enter
Visual mode.
First we set a variable to zero.
And then comes the if.
This is done by loading this local variable
in a register and comparing to hex ff.
And then jump if it was less or equal.
So you can see which branch it may take.
Then comes a while loop.
We load the local variable again in a register,
compare it to a value, and either jump inside
the block or leave.
And inside the block we load this value again,
increment it and write it back.
Now compare it to the foor loop.
It’s basically the same!
We start by setting the variable to 0.
Then we compare if the loop condition is still
true.
And inside the loop block, we can see our
NOP.
And at the end of the block we increment the
variable by 1.
Exactly the same like the while loop.
So you can see that a for and a while loop
in C are basically the same.
Next let’s have a look at how functions
are called.
Again open both the 32bit and 64bit version.
First thing you notice that the 64bit version
moves a 0 in eax.
No idea why.
Otherwise the function call looks the same.
Except look at the addresses.
If you have no ASLR, then 64bit code is generally
at hex 40 something.
While 32bit code is at hex 80 something.
Knowing stuff like that is helpful, because
if you see an address with 40 something, you
know immediately that it’s pointing into
your code.
So the next function returns a value and we
save it in a variable.
And you can see that in both cases, the value
is taken from the eax register.
Ok, so apparently return values are handled
via eax.
Now function 3 is interesting, because we
pass a parameter to it.
In 32bit you can see that the value is loaded
from somewhere and then stored on top of the
stack.
And then the function is called.
But on 64bit we see that the value is loaded
into the edi register.
This is our first big difference.
Functions in 64bit seem to be called with
parameters in registers, while in 32bit the
parameters are stored on the stack.
Next function uses 2 parameters.
And again, you can see how 32bit just places
the value on the stack.
First parameter on top of the stack, the second
a bit further down.
But in 64bit you can see that it uses esi
and edi for that.
Now we get curious.
What does 64bit do when we have so many parameters,
that we cannot keep them all in registers?
First of all 32bit code again.
You can see how the parameters are stored
on the stack.
And the first parameter is on top of the stack,
and the last value moved.
That’s what we would expect.
In 64bit we can see that the first couple
of parameters are stored in registers edi,
esi, edx, and so forth.
But from the 7th parameter on, they get stored
on the stack as well.
Awesome!
Now you can identify all kind of different
assembler patterns.
You don’t need a decompiler all the time.
You can do this all in your head.
And when you reverse more and more programs,
those patterns become more easy to recognize,
and you will not feel overwhelmed again with
the mass of weird instructions.
You will be able to scan over a function and
say: “ah here is a local variable.
Then calls this other function with this variable
as parameter.
And the return value is used in a loop”.
And you can use the same method to understand
how different disassemblers like hopper, radare,
gdb display code.
Or for example how different the at&t assembler
syntax is from the intel syntax.
I hope you have a lot of fun next time reversing
a program.
﻿We have already had many episodes where we
read assembler code and reverse engineered
how a program works.
And we even have written our first exploit
by using a buffer overflow vulnerability in
a program written in C.
In this episode I want to show you how you
can learn how to read assembler produced by
C code yourself.
The idea is simple.
Just write some C code with different C language
features, and then look at the assembler code
that is produced by compiling it.
This is often part of normal research.
For example listen to what Ian Beer from google
project zero says during a talk about his
research on Inter Process Calls on OSX.
One approach to reversing, or to understanding
how this kind of thing works would be to sit
in IDA and just reverse the serialization
and deserialization code, and slowly build
up a picture of how it works.
But another kind of quite nice way to do it,
is just, write a test program to send little
messages and then find the right place using
lldb to break and just start dumping hex.
So, because he had to understand a fairly
complex data structure, he simply wrote a
test program to analyse it, instead of reversing
a full application.
Or there was was a talk and paper from blackhat
USA in 2007 about how to reverse C++ programs,
by looking at C++ concepts and how they look
like in assembler.
So now I have created three different C code
testcases and you can find them in my github
repository, or just write it yourself.
One is about variables and datatypes.
One is about function calls.
And one is about control flow stuff like loops
and ifs.
So let’s start with the variables.c.
First thing I want to point out are those
triple Xs.
Those triple Xs are defined as an assembler
NOP instruction.
The reason for that is, later when we look
into the disassembly, we can find those NOPs
which are separating our tests, and that is
pretty neat.
So this makes it easier to see which line
of C Code is responsible for which lines in
assembler.
I will not go over every single test, this
is something you could do yourself.
Simply pause the video at certain points or
clone the repository.
Anyway.
Let’s get started.
First of all you can see here a couple of
simple numbers.
First we define a couple of numbers.
Unsigned and signed, integers and floating
numbers.
And different sizes with uint32 or uint64.
The latter is important, because normal Integers
might have a different size depending on 32bit
or 64bit, so it can lead to bugs.
So better use datatypes you are guaranteed
to get a certain size.
If you want to learn more about how to program
C properly, there is a great blog entry called
“How to C in 2015”.
After that we create an array with 32bit unsigned
integers, and we access one element of this
array.
Then we look at a single character.
And then also a string.
And maybe you know that a star * means “pointer”
in C. So we define a variable that is pointing
to a string.
I have added a Makefile, so you can simply
type `make` into the terminal to compile all
files.
Or make clean to remove the binaries.
This will create a 32bit and a 64bit version
of the variables program.
But as you can see, I get an error trying
to compile a 32bit version with -m32 in this
64bit machine.
So I have to install the 32bit libraries first,
to be able to build the code.
After installing those, the build works fine.
A Makefile is just a little script that defines
how a project has to be compiled.
So let’s open the code, 32bit and 64bit
version next to each other in gdb and disassemble
main.
And also open the code.
Ok now let’s look at the first integer examples
with negative values and signed and unsigned
values.
First of all, all those local variables are
stored somewhere on the stack, you can see
that because they are referenced relative
to the base-pointer.
Then you notice that the assembler code doesn’t
know negative numbers.
They are fff something.
If you are interested how negative numbers
are displayed, watch my 10th episode about
numbers.
And also there is no difference between variables
that are signed or unsigned.
But there is one difference between the 32bit
and the 64bit code.
Because we defined one number to be 64bit
long, but on 32bit the registers are only
32bit.
So if you want to write full 64bit, you have
to write two times.
The floating point numbers are also interesting.
Because they got stored somewhere else in
the program.
And that value is then moved into the local
variable.
The array is also interesting.
We created an array with 10 values but only
set the first 5 values to a default value.
As you can see those values are stored on
the stack.
And then it is moved from that location on
the stack to the real array location.
Instead of writing it directly to the array
it does it this way.
No idea why.
And you can see down here when we reference
the 3rd entry.
So you can see that this is the real location
of the array on the stack.
Next come the strings.
You can see that a character is just a byte.
It doesn’t matter if we have an unsigned
int with 8bit or a char.
It’s the same.
And strings are also referenced over an address.
So the local variable is not an array of charactes.
the local variable contains an address pointing
to a string.
Now let’s have a look at the control_flows.
Open it in radare.
Analyse all, seek to main function and enter
Visual mode.
First we set a variable to zero.
And then comes the if.
This is done by loading this local variable
in a register and comparing to hex ff.
And then jump if it was less or equal.
So you can see which branch it may take.
Then comes a while loop.
We load the local variable again in a register,
compare it to a value, and either jump inside
the block or leave.
And inside the block we load this value again,
increment it and write it back.
Now compare it to the foor loop.
It’s basically the same!
We start by setting the variable to 0.
Then we compare if the loop condition is still
true.
And inside the loop block, we can see our
NOP.
And at the end of the block we increment the
variable by 1.
Exactly the same like the while loop.
So you can see that a for and a while loop
in C are basically the same.
Next let’s have a look at how functions
are called.
Again open both the 32bit and 64bit version.
First thing you notice that the 64bit version
moves a 0 in eax.
No idea why.
Otherwise the function call looks the same.
Except look at the addresses.
If you have no ASLR, then 64bit code is generally
at hex 40 something.
While 32bit code is at hex 80 something.
Knowing stuff like that is helpful, because
if you see an address with 40 something, you
know immediately that it’s pointing into
your code.
So the next function returns a value and we
save it in a variable.
And you can see that in both cases, the value
is taken from the eax register.
Ok, so apparently return values are handled
via eax.
Now function 3 is interesting, because we
pass a parameter to it.
In 32bit you can see that the value is loaded
from somewhere and then stored on top of the
stack.
And then the function is called.
But on 64bit we see that the value is loaded
into the edi register.
This is our first big difference.
Functions in 64bit seem to be called with
parameters in registers, while in 32bit the
parameters are stored on the stack.
Next function uses 2 parameters.
And again, you can see how 32bit just places
the value on the stack.
First parameter on top of the stack, the second
a bit further down.
But in 64bit you can see that it uses esi
and edi for that.
Now we get curious.
What does 64bit do when we have so many parameters,
that we cannot keep them all in registers?
First of all 32bit code again.
You can see how the parameters are stored
on the stack.
And the first parameter is on top of the stack,
and the last value moved.
That’s what we would expect.
In 64bit we can see that the first couple
of parameters are stored in registers edi,
esi, edx, and so forth.
But from the 7th parameter on, they get stored
on the stack as well.
Awesome!
Now you can identify all kind of different
assembler patterns.
You don’t need a decompiler all the time.
You can do this all in your head.
And when you reverse more and more programs,
those patterns become more easy to recognize,
and you will not feel overwhelmed again with
the mass of weird instructions.
You will be able to scan over a function and
say: “ah here is a local variable.
Then calls this other function with this variable
as parameter.
And the return value is used in a loop”.
And you can use the same method to understand
how different disassemblers like hopper, radare,
gdb display code.
Or for example how different the at&t assembler
syntax is from the intel syntax.
I hope you have a lot of fun next time reversing
a program.
﻿We have already had many episodes where we
read assembler code and reverse engineered
how a program works.
And we even have written our first exploit
by using a buffer overflow vulnerability in
a program written in C.
In this episode I want to show you how you
can learn how to read assembler produced by
C code yourself.
The idea is simple.
Just write some C code with different C language
features, and then look at the assembler code
that is produced by compiling it.
This is often part of normal research.
For example listen to what Ian Beer from google
project zero says during a talk about his
research on Inter Process Calls on OSX.
One approach to reversing, or to understanding
how this kind of thing works would be to sit
in IDA and just reverse the serialization
and deserialization code, and slowly build
up a picture of how it works.
But another kind of quite nice way to do it,
is just, write a test program to send little
messages and then find the right place using
lldb to break and just start dumping hex.
So, because he had to understand a fairly
complex data structure, he simply wrote a
test program to analyse it, instead of reversing
a full application.
Or there was was a talk and paper from blackhat
USA in 2007 about how to reverse C++ programs,
by looking at C++ concepts and how they look
like in assembler.
So now I have created three different C code
testcases and you can find them in my github
repository, or just write it yourself.
One is about variables and datatypes.
One is about function calls.
And one is about control flow stuff like loops
and ifs.
So let’s start with the variables.c.
First thing I want to point out are those
triple Xs.
Those triple Xs are defined as an assembler
NOP instruction.
The reason for that is, later when we look
into the disassembly, we can find those NOPs
which are separating our tests, and that is
pretty neat.
So this makes it easier to see which line
of C Code is responsible for which lines in
assembler.
I will not go over every single test, this
is something you could do yourself.
Simply pause the video at certain points or
clone the repository.
Anyway.
Let’s get started.
First of all you can see here a couple of
simple numbers.
First we define a couple of numbers.
Unsigned and signed, integers and floating
numbers.
And different sizes with uint32 or uint64.
The latter is important, because normal Integers
might have a different size depending on 32bit
or 64bit, so it can lead to bugs.
So better use datatypes you are guaranteed
to get a certain size.
If you want to learn more about how to program
C properly, there is a great blog entry called
“How to C in 2015”.
After that we create an array with 32bit unsigned
integers, and we access one element of this
array.
Then we look at a single character.
And then also a string.
And maybe you know that a star * means “pointer”
in C. So we define a variable that is pointing
to a string.
I have added a Makefile, so you can simply
type `make` into the terminal to compile all
files.
Or make clean to remove the binaries.
This will create a 32bit and a 64bit version
of the variables program.
But as you can see, I get an error trying
to compile a 32bit version with -m32 in this
64bit machine.
So I have to install the 32bit libraries first,
to be able to build the code.
After installing those, the build works fine.
A Makefile is just a little script that defines
how a project has to be compiled.
So let’s open the code, 32bit and 64bit
version next to each other in gdb and disassemble
main.
And also open the code.
Ok now let’s look at the first integer examples
with negative values and signed and unsigned
values.
First of all, all those local variables are
stored somewhere on the stack, you can see
that because they are referenced relative
to the base-pointer.
Then you notice that the assembler code doesn’t
know negative numbers.
They are fff something.
If you are interested how negative numbers
are displayed, watch my 10th episode about
numbers.
And also there is no difference between variables
that are signed or unsigned.
But there is one difference between the 32bit
and the 64bit code.
Because we defined one number to be 64bit
long, but on 32bit the registers are only
32bit.
So if you want to write full 64bit, you have
to write two times.
The floating point numbers are also interesting.
Because they got stored somewhere else in
the program.
And that value is then moved into the local
variable.
The array is also interesting.
We created an array with 10 values but only
set the first 5 values to a default value.
As you can see those values are stored on
the stack.
And then it is moved from that location on
the stack to the real array location.
Instead of writing it directly to the array
it does it this way.
No idea why.
And you can see down here when we reference
the 3rd entry.
So you can see that this is the real location
of the array on the stack.
Next come the strings.
You can see that a character is just a byte.
It doesn’t matter if we have an unsigned
int with 8bit or a char.
It’s the same.
And strings are also referenced over an address.
So the local variable is not an array of charactes.
the local variable contains an address pointing
to a string.
Now let’s have a look at the control_flows.
Open it in radare.
Analyse all, seek to main function and enter
Visual mode.
First we set a variable to zero.
And then comes the if.
This is done by loading this local variable
in a register and comparing to hex ff.
And then jump if it was less or equal.
So you can see which branch it may take.
Then comes a while loop.
We load the local variable again in a register,
compare it to a value, and either jump inside
the block or leave.
And inside the block we load this value again,
increment it and write it back.
Now compare it to the foor loop.
It’s basically the same!
We start by setting the variable to 0.
Then we compare if the loop condition is still
true.
And inside the loop block, we can see our
NOP.
And at the end of the block we increment the
variable by 1.
Exactly the same like the while loop.
So you can see that a for and a while loop
in C are basically the same.
Next let’s have a look at how functions
are called.
Again open both the 32bit and 64bit version.
First thing you notice that the 64bit version
moves a 0 in eax.
No idea why.
Otherwise the function call looks the same.
Except look at the addresses.
If you have no ASLR, then 64bit code is generally
at hex 40 something.
While 32bit code is at hex 80 something.
Knowing stuff like that is helpful, because
if you see an address with 40 something, you
know immediately that it’s pointing into
your code.
So the next function returns a value and we
save it in a variable.
And you can see that in both cases, the value
is taken from the eax register.
Ok, so apparently return values are handled
via eax.
Now function 3 is interesting, because we
pass a parameter to it.
In 32bit you can see that the value is loaded
from somewhere and then stored on top of the
stack.
And then the function is called.
But on 64bit we see that the value is loaded
into the edi register.
This is our first big difference.
Functions in 64bit seem to be called with
parameters in registers, while in 32bit the
parameters are stored on the stack.
Next function uses 2 parameters.
And again, you can see how 32bit just places
the value on the stack.
First parameter on top of the stack, the second
a bit further down.
But in 64bit you can see that it uses esi
and edi for that.
Now we get curious.
What does 64bit do when we have so many parameters,
that we cannot keep them all in registers?
First of all 32bit code again.
You can see how the parameters are stored
on the stack.
And the first parameter is on top of the stack,
and the last value moved.
That’s what we would expect.
In 64bit we can see that the first couple
of parameters are stored in registers edi,
esi, edx, and so forth.
But from the 7th parameter on, they get stored
on the stack as well.
Awesome!
Now you can identify all kind of different
assembler patterns.
You don’t need a decompiler all the time.
You can do this all in your head.
And when you reverse more and more programs,
those patterns become more easy to recognize,
and you will not feel overwhelmed again with
the mass of weird instructions.
You will be able to scan over a function and
say: “ah here is a local variable.
Then calls this other function with this variable
as parameter.
And the return value is used in a loop”.
And you can use the same method to understand
how different disassemblers like hopper, radare,
gdb display code.
Or for example how different the at&t assembler
syntax is from the intel syntax.
I hope you have a lot of fun next time reversing
a program.
﻿We have already had many episodes where we
read assembler code and reverse engineered
how a program works.
And we even have written our first exploit
by using a buffer overflow vulnerability in
a program written in C.
In this episode I want to show you how you
can learn how to read assembler produced by
C code yourself.
The idea is simple.
Just write some C code with different C language
features, and then look at the assembler code
that is produced by compiling it.
This is often part of normal research.
For example listen to what Ian Beer from google
project zero says during a talk about his
research on Inter Process Calls on OSX.
One approach to reversing, or to understanding
how this kind of thing works would be to sit
in IDA and just reverse the serialization
and deserialization code, and slowly build
up a picture of how it works.
But another kind of quite nice way to do it,
is just, write a test program to send little
messages and then find the right place using
lldb to break and just start dumping hex.
So, because he had to understand a fairly
complex data structure, he simply wrote a
test program to analyse it, instead of reversing
a full application.
Or there was was a talk and paper from blackhat
USA in 2007 about how to reverse C++ programs,
by looking at C++ concepts and how they look
like in assembler.
So now I have created three different C code
testcases and you can find them in my github
repository, or just write it yourself.
One is about variables and datatypes.
One is about function calls.
And one is about control flow stuff like loops
and ifs.
So let’s start with the variables.c.
First thing I want to point out are those
triple Xs.
Those triple Xs are defined as an assembler
NOP instruction.
The reason for that is, later when we look
into the disassembly, we can find those NOPs
which are separating our tests, and that is
pretty neat.
So this makes it easier to see which line
of C Code is responsible for which lines in
assembler.
I will not go over every single test, this
is something you could do yourself.
Simply pause the video at certain points or
clone the repository.
Anyway.
Let’s get started.
First of all you can see here a couple of
simple numbers.
First we define a couple of numbers.
Unsigned and signed, integers and floating
numbers.
And different sizes with uint32 or uint64.
The latter is important, because normal Integers
might have a different size depending on 32bit
or 64bit, so it can lead to bugs.
So better use datatypes you are guaranteed
to get a certain size.
If you want to learn more about how to program
C properly, there is a great blog entry called
“How to C in 2015”.
After that we create an array with 32bit unsigned
integers, and we access one element of this
array.
Then we look at a single character.
And then also a string.
And maybe you know that a star * means “pointer”
in C. So we define a variable that is pointing
to a string.
I have added a Makefile, so you can simply
type `make` into the terminal to compile all
files.
Or make clean to remove the binaries.
This will create a 32bit and a 64bit version
of the variables program.
But as you can see, I get an error trying
to compile a 32bit version with -m32 in this
64bit machine.
So I have to install the 32bit libraries first,
to be able to build the code.
After installing those, the build works fine.
A Makefile is just a little script that defines
how a project has to be compiled.
So let’s open the code, 32bit and 64bit
version next to each other in gdb and disassemble
main.
And also open the code.
Ok now let’s look at the first integer examples
with negative values and signed and unsigned
values.
First of all, all those local variables are
stored somewhere on the stack, you can see
that because they are referenced relative
to the base-pointer.
Then you notice that the assembler code doesn’t
know negative numbers.
They are fff something.
If you are interested how negative numbers
are displayed, watch my 10th episode about
numbers.
And also there is no difference between variables
that are signed or unsigned.
But there is one difference between the 32bit
and the 64bit code.
Because we defined one number to be 64bit
long, but on 32bit the registers are only
32bit.
So if you want to write full 64bit, you have
to write two times.
The floating point numbers are also interesting.
Because they got stored somewhere else in
the program.
And that value is then moved into the local
variable.
The array is also interesting.
We created an array with 10 values but only
set the first 5 values to a default value.
As you can see those values are stored on
the stack.
And then it is moved from that location on
the stack to the real array location.
Instead of writing it directly to the array
it does it this way.
No idea why.
And you can see down here when we reference
the 3rd entry.
So you can see that this is the real location
of the array on the stack.
Next come the strings.
You can see that a character is just a byte.
It doesn’t matter if we have an unsigned
int with 8bit or a char.
It’s the same.
And strings are also referenced over an address.
So the local variable is not an array of charactes.
the local variable contains an address pointing
to a string.
Now let’s have a look at the control_flows.
Open it in radare.
Analyse all, seek to main function and enter
Visual mode.
First we set a variable to zero.
And then comes the if.
This is done by loading this local variable
in a register and comparing to hex ff.
And then jump if it was less or equal.
So you can see which branch it may take.
Then comes a while loop.
We load the local variable again in a register,
compare it to a value, and either jump inside
the block or leave.
And inside the block we load this value again,
increment it and write it back.
Now compare it to the foor loop.
It’s basically the same!
We start by setting the variable to 0.
Then we compare if the loop condition is still
true.
And inside the loop block, we can see our
NOP.
And at the end of the block we increment the
variable by 1.
Exactly the same like the while loop.
So you can see that a for and a while loop
in C are basically the same.
Next let’s have a look at how functions
are called.
Again open both the 32bit and 64bit version.
First thing you notice that the 64bit version
moves a 0 in eax.
No idea why.
Otherwise the function call looks the same.
Except look at the addresses.
If you have no ASLR, then 64bit code is generally
at hex 40 something.
While 32bit code is at hex 80 something.
Knowing stuff like that is helpful, because
if you see an address with 40 something, you
know immediately that it’s pointing into
your code.
So the next function returns a value and we
save it in a variable.
And you can see that in both cases, the value
is taken from the eax register.
Ok, so apparently return values are handled
via eax.
Now function 3 is interesting, because we
pass a parameter to it.
In 32bit you can see that the value is loaded
from somewhere and then stored on top of the
stack.
And then the function is called.
But on 64bit we see that the value is loaded
into the edi register.
This is our first big difference.
Functions in 64bit seem to be called with
parameters in registers, while in 32bit the
parameters are stored on the stack.
Next function uses 2 parameters.
And again, you can see how 32bit just places
the value on the stack.
First parameter on top of the stack, the second
a bit further down.
But in 64bit you can see that it uses esi
and edi for that.
Now we get curious.
What does 64bit do when we have so many parameters,
that we cannot keep them all in registers?
First of all 32bit code again.
You can see how the parameters are stored
on the stack.
And the first parameter is on top of the stack,
and the last value moved.
That’s what we would expect.
In 64bit we can see that the first couple
of parameters are stored in registers edi,
esi, edx, and so forth.
But from the 7th parameter on, they get stored
on the stack as well.
Awesome!
Now you can identify all kind of different
assembler patterns.
You don’t need a decompiler all the time.
You can do this all in your head.
And when you reverse more and more programs,
those patterns become more easy to recognize,
and you will not feel overwhelmed again with
the mass of weird instructions.
You will be able to scan over a function and
say: “ah here is a local variable.
Then calls this other function with this variable
as parameter.
And the return value is used in a loop”.
And you can use the same method to understand
how different disassemblers like hopper, radare,
gdb display code.
Or for example how different the at&t assembler
syntax is from the intel syntax.
I hope you have a lot of fun next time reversing
a program.
﻿The qualification round for RHme3 is over,
so we can have a look now at the challenges
you had to solve to qualify. I really enjoyed
the exploitation challenge, because it was
pretty straight forward. And you have had
a good chance to solve it yourself, if you
are familiar with my exploitation videos.
So let’s check it out.
“This binary is running on pwn.rhme.riscure.com.
Analyze it and find a way to compromise the
server. You’ll find the flag in the filesystem.”
When you try to access this domain via the
browser it doesn’t work. But we are given
two files and I’m sure we can reverse engineer
the binary to figure out how to interact with
the server.
the fact that they give you a libc is already
a good hint. Let me tell you what I think
when I see it.
First, the target system will be a typical
modern linux system, so no executable stack
or heap and thus we have to do ROP or return
to libc. And in order to do that successfully,
you have to know where ROP gadgets or libc
functions are. But if you use your local libc,
then the offsets are probably different. Some
CTFs don’t give you a libc, this means it’s
harder because you first have to somehow leak
the server libc or guess it based on addresses
you leak. But yeah.
And a typical exploit for a CTF challenge
is to simply call the libc function system()
with “/bin/sh” as a parameter, to get
a shell. So I already expect that I probably
want to overwrite some entry in the global
offset table and point it to system(). This
means I’m kinda looking at this challenge
from the reverse. I know, or at least guess
what I want to do, and to achieve this I’m
looking for a way to write into the global
offset table, or overwrite some other function
pointer, for that matter.
Only if after a while I realize that that
attempt would fail, I consider other possible
techniques.
So let’s have a look at the binaries. The
main.elf file is not stripped, which means
it will have all the symbol names in there,
which makes reversing really easy.
But when we try to execute it, it doesn’t
seem to work. And I saw some people complain
that it doesn’t work. BUT, what does “doesn’t
work” mean. That’s one of my “pet peeves”.
We have to be more careful with our observations.
We don’t see any obvious errors. So for
example if I just rip out the start of the
binary and try to execute that I get very
obvious execution errors. That’s not what
we see. So we have to investigate why it immediately
exits. Really good tools to get a general
first impression of what is happening, is
strace and ltrace. And when you run the binary
with it, you first of all see that it does
in fact run, so it works, it just exits for
some reason.
ltrace will show you all library calls, so
you can see it executes “getpwnam” before
exiting. And the man page tells us that it
tries to get information about a user from
/etc/passwd. And the user was pwn. P W N.
So I guess it expects this user to be there.
Let’s add this user. Oh and also a good
idea is to switch now to root. Because it
looks like the binary wants to mess with user
permissions.
So we add this user, enter some random info
and there we go. When we now execute it we
get further! This time it builds a path, and
this path obviously doesn’t exist. So let’s
maybe create that one as well. Maybe it wants
that path.
One other thing that happens is the fork().
And fork means it creates a new process. So
we should use the -f flag, to follow also
any children processes.
AHA! And now it tries to create a socket and
open a port 1337.
Also we can now connect to this port and interact
with the program. And that is also the port
for the remote server.
I heard several people patched the binary
to get around all those checks, but it’s
not necessary, the program just expects certain
things about the environment. But whatever,
your solution worked too.
So now that we can see what the child process
calls with ltrace, we can explore the functionality.
And at the same time see the libc calls. This
is super helpful to maybe even find issues.
Anyway.
As you can see this program is a team manager
where you can add players, remove players,
edit a player or show the whole team. So I
obviously started by adding a player
And entered a format string as the name, to
check if it’s a format string vulnerability,
but it was not. All outputs properly print
it. But I still quickly found the bug. Because
I noticed I first have to select a player
before I can show this player. And when I
do this and then delete the player I selected,
I can still show the player. And now the values
are weird. So obviously when you delete the
player you have selected, you shouldn’t
be able to show the player anymore. This means,
we have a classical use-after-free condition.
A reference to the deleted player was not
removed.
Next I wanted to see how the heap looks like
when creating players. Basically I want to
know what the player structure is.
But before we get there, let’s open the
binary in a disassembler. You will immediately
notice that the binary contains all symbols,
because it was not stripped. So that is really
nice.
For example here are daemonize, background_process
and serve_forever functions, which do all
this, well, background process and listening
forever on a port, stuff.
But more interesting right now are the menu
functions, including the edit, show and set
functions.
And to look at the player structure, we could
look into the show_player_func. The cool thing
is, it is also used in show_team. So everytime
player information is printed, it would call
this function here. Useful to dump some debug
info.
And in show_player_func it looks like there
is a parameter rdi that is used to pass in
the player address. So let’s write a gdbinit
file that helps us debugging. First I copy
the default gdbinit to not loose peda and
then we set the follow-fork-mode to child,
so gdb will follow the child process upon
a fork. Then we set a breakpoint in show_player_func
and use rdi to print some memory.
Silent so we don’t see gdb info messages
and continue afterwards, so we just print
the memory but don’t actually interrupt.
And then we can start gdb with -x to specify
this gdbinit file, which sets the breakpoint
with commands and runs the binary. Then we
can use our other window to connect with netcat
to the local port and add a player using a
name we can recognize in memory. And when
we then show the team, thus call show_player_func,
our breakpoint will be hit and print the memory.
And that worked great!
Let’s add a second player, also with unique
data, B B B B as name and 5 6 7 8 for the
stats. Then we select show team and we have
a look at the memory.
So.
We can clearly see 4 32bit integers containing
our stats. It was 1 2 3 4 for the first player
and 5 6 7 8 for the second player. Then we
seem to have a fifth value, which is an address
or pointer into the heap. Infact this heap
chunk is right after this initial structure.
So this is just a string, the name.
So to summarise, we have a player structure
with 4 32bit integer stats and a pointer to
a char array or string. Which is also allocated
on the heap.
And now we come back to our goal, we would
like to overwrite an entry in the global offset
table. If we could control this pointer somehow
and point it into the global offset table,
we maybe could use the edit name functionality
to write a new name, or the address of another
function, into the global offset table. Right?
That sounds like a good plan.
As the video gets longer than I expected,
I will have to split it in two parts. Maybe
with the knowledge now of how to debug it
and some hints on what we want to do, you
could try to do it yourself. And then in a
few days I will tell you how I did it.
﻿So recently I was invited to give a talk at
fsec in croatia.
And I met some of you and that was awesome.
During the conference there was also a CTF,
I think all challenges were actually created
by Miroslav Stampar, the author of sqlmap.
Also let’s try something new for this video.
Let’s see if we can mix challenge write-up
and story telling.
Let me know if it sucks or makes it more fun
to watch.
Web150.
Hard times.
Javascript + Form = Challenge.
Let’s have a look at it.
So there is a simple form for a password and
a button to check it.
But when you enter anything nothing happens.
And when you open the developer tools you
immediately trigger a debugger breakpoint.
It looks very similar to the anti debugging
mechanism of the popunder stuff we had a look
at.
We can also go one up in the callstack and
see that the javascript code is obfuscated.
Those functions return the actual identifier,
for example “debugger”.
By the way it was my first time in croatia
and I really liked it.
Fsec was held in Varaždin, and the town was
really pretty and especially the building
of the conference was this old theatre and
it was just a gorgeous location.
Look at these rooms.
Tonimir, the main organiser, also wanted to
take a picture of me.
As much as I enjoy conferences, I do need
my alone time and so I looked for a quiet
place and worked on the challenge.
As a next step we can download the html and
look at it locally.
So the code is obviously not formatted.
Actually I spent quite some time making it
pretty and defeating the anti debugging statement,
but I skip all of that because at some point
I realised there is a much easier way.
So for the form button there is an onclick
handler defined, the btn_click function.
So this chunk here is the function.
So whatever we are looking for, it should
be here.
Let’s beautify that part.
So immediately you can find some functions
that implement simple operations to obfuscate
more of the code.
This can be easily reversed.
We can use the developer toolbar to evaluate
those other functions for us.
The debugger statement paused the script,
but we can still use the console.
So this first string for example was 3,2,0,1,4.
And this function down here results in the
congratulation string.
Then we have this big while loop with different
cases inside.
The switch case depends on g, and g comes
from here.
Let’s check what this here stands for.
This is the function split.
And this was our first string from up there.
So this just splits the string in 3,2,0,1,4.
Ok so we have a loop that executes these operations
in sequence.
So it was just obfuscating the order a little
bit.
Case 0,2 and 3 just initialize local variables
with 0.
We can also clean up case 1 a little bit in
the same way we did before.
Just evaluate those functions with the developer
console.And so this function is a for loop
over the length of a.
And a is the password input.
So this loops over each character of our password.
It sums up all ascii values in e, and xors
every value in f.
Also d is set based on some calculations of
the char values.
So this is definitely part of the password
check.
Some values are calculated based on the input
string and probably later checked.
Like I said, I was invited to fsec to give
a talk.
I spoke about some CTF stuff.
The talk got recorded so I will share it once
it’s edited.
I also used the opportunity during lightning
talks and threw together a few slides to promote
the streaming and video community.
Sorry if I forgot somebody, I literally only
had a few minutes to prepare.
The main part of the challenge is this big
if case here.
So we should probably clean that one up next.
It’s a bit tedious but fairly straight-forward.
Just always look up what something evaluates
to and make some notes or replace it.
Let me fast forward that.
So you can see how slowly the rules for the
password check appear.
And I also rename the password charCodeAt
into pw with brackets, because that’s python
syntax and I’m more comfortable to read
it.
You know the goal for me right now is not
to have running javascript code, but just
to understand the algorithm.
And I want to get rid of anything that I find
distracting so I can focus on what’s important.
Ok cool.
So first of all you can see here e, f and
d compared to a constant.
Those were calculated based on our input characters.
Then we compare a lot of different characters
in the password with each other.
So for example the first character ascii value,
minus the second one, has to be 4.
.
And if all those cases are true, we have here
an alert and everything is correct.
Ok!
That’s it.
We just have to find a password now that fits
those conditions.
Let’s do an example.
We just had this one case where the first
character ascii value minus the second character
has to be 4.
And the first check here with the regex makes
sure that only those characters are allowed
for the password.
So we can quickly check all options we have.
We just write two loops over the alphabet,
subtract the ascii values and if it’s 4
we print the two.
And it turns out, there is only ONE valid
case.
So we already know, our password must start
with PL.
We can also see that character at offset d
and e have to be the same, or 2 and 8 and
7 and b.
We also know that the character at position
c has to be equal to the length shifted by
two.
That could be useful to figure out what are
valid lengths for the password.
We can again write a loop.
So the password can be 12, 17, 19 or 20 characters
long and depending on which length we assume,
we already know the value of the 12th character.
When you keep doing that and lower the search
space, you still end up with a huuuge amount
of possible password combinations.
And actually the d variable is the hardest
one to reverse in such a way.
So you can write a brute force algorithm that
takes these restrictions into account.
And you can really optimise that.
But I didn’t want to do that and was hoping
I could use z3 for that.
Z3 or any other SAT solver are the go to tools
for problems like that.
And a lot of challenges are really easy with
it.
So with z3 you can just specify a few conditions
and rules like we just found and then ask
“what input satisfies those rules”.
And then there are fancy algorithms that can
solve such an equation system and provide
possible inputs.
But the larger the rules are, the longer it
takes and might even become impossible to
do in a short time.
So for example obviously you can’t use it
to reverse a SHA hash with it.
And the d variable is such a condition which
quickly explodes into a huge equation.
Actually the challenge author told me afterwards
that he tried to make it such that it’s
infeasible to do with z3 and that you have
to create your own custom optimised brute
force algorithm.
But I thought I try a combination.
Mostly because I was lazy.
So I thought I could let z3 generate valid
password that fulfil some conditions, at least
the easy ones, and then bruteforce the difficult
condition like d.
So here is my z3 code.
Let’s jump right to the rules.
As you can see not much is different, the
rules are like we saw them in javascript.
But for example the rule we looked at earlier
with first minus second character equal to
4, I remove, because only one combination
P,L is valid, thus the rule is unnecessary
and we can already make those fixed.
Here I have a helper function that takes in
a character and tells z3 that the character
has to be one of those values.
And we apply that to each character of the
password.
The main function itself also takes in the
length of the password and generate the z3
bit vectors dynamically with this length.
And at the bottom we have a typical z3 snippet
to check if it’s even solvable and then
we generate some valid passwords.
We print the password we found and also calculate
d for it and check if it’s what we expect.
That’s basically the bruteforce part because
z3 can’t easily solve that for us.
And then we add the password we just found
as a rule to not appear again, then z3 will
find another valid password that is not one
of the previous ones.
And we check again if it satisfies the d constant.
So when we run it we get a lot of valid passwords
but none fit d.
But we can already see that the password could
start with PLAY.
That would be a valid word, so we can take
a guess and add more constraints, saying that
the password starts with PLAY.
And then it could be PLAY underscore, or PLAYing.
And so forth and I just start playing around
with this and see if I can generate meaningful
valid passwords.
And after a little bit I have narrowed it
down so much, that actually one password is
found that matches d.
And this is the valid password.
Playing and Loosing.
Also Tonimir told me that I think some of
his students asked him if I’m playing the
conference CTF and suspected me of hoarding
flags?
Because I was not winning?
What?
I thought they watch my videos and see how
much I struggle.
Wtf I’m not some CTF machine.
I don’t know how to solve all of these challenges
either.
I know a 10minute video writeup looks impressive
but obviously it takes me hours when I actually
look at it the first time.
Though, I hope I make that clear in my videos.
I really don’t want to pretend I’m some
kind of hacking god.
You should checkout the recent popunder livestream
because there you can see how terrible and
slow I really am.
Just wanted to mention that.
Anyway, thanks again for having me Fsec, it
was great.
Food was good.
And hopefully we meet again another time.
﻿Welcome to another video covering the riscure
embedded hardware ctf.
Basically it’s about hacking an embedded
device as part of a competition, and if you
want more details about it, checkout the introduction
video and the playlist.
Also at the time of releasing this video,
the competition is over and the sources should
be available and you can setup your own arduino
nano board to follow along.
You find some links in the description.
But now let’s checkout the challenge.
So now that we solved the first two easy challenges,
and Jumpy was already pretty hard for me,
I decided to write a little program that crawls
the current scoreboard and counts which challenges
have the most solves.
This way I can see which challenges I should
be capable of solving.
And it looks like Photo Manager will be our
next target.
It’s another exploitation challenge.
The story here doesn’t really tell us any
technical information, so let’s head right
into it, download the .hex file, flash it
onto the board and start a screen session
to interact with it.
So… the first time I approached this challenge
I didn’t really follow a structured path
and basically just played around with it.
I found the bug quickly, but when I tried
to actually solve it with the bug I found,
I didn’t really have a good mental picture
on how to move forward.
Basically all my information was jumbled up.
It’s difficult to explain what I mean, because
my solving attempt itself, was so messy that
it’s not possible to explain my thought
process - because there was none.
Sometimes that approach is ok, because it
can be very quick if you get lucky or know
what you do, but here I failed.
I wasted actually like 2 hours on that until
I decided, scrap all that, I start over again.
Which was the right decision.
I kept turning in a circle.
For the second attempt I didn’t try to rush
the solution but properly structure the attack.
Basically we follow the scientific method.
First we observe behaviour, then build a mental
model of the system, on which we can create
certain assumptions that we can try to proof
or get them disproven and adjust the mental
image.
This means, we go step by step.
First, what can we can we actually do?
We see a menu with 2 options.
Login and Memory manager.
With login we can apparently enter some token,
of the length 8, that contain these letters.
If we do that we get a welcome message and
those 8 characters back.
There is also a memory management option,
that displays the total memory space and the
currently used space.
So in our mental model we can take note, that
the login name seems to be our only input
we have, so whatever our attack will be, it
is very likely that it will at least start
with some, login input.
The memory management seems odd for now, but
probably might be important information, why
else would it be there.
We can also enter some more characters, this
time less than 8, and notice that the previous
As are still there and were simply overwritten.
Interesting.
Maybe useful, maybe not.
It also didn’t change our memory usage.
We can also try what happens when we enter
more than 8 characters, in this case I tested
16, it did overwrite the As, but still only
8 characters are printed.
And again, memory usage is not affected by
this.
Ok, so we can assume some kind of fixed global
buffer for the input, because we always overwrite
and work on the previous entered data.
So if this is some limited memory space, let’s
see what happens when you enter a lot of data.
I keep the letter a pressed to send a lot
of letters, and suddenly we get a stack cookie
corrupted message.
Awesome, so the buffer we operate on seems
to be on the stack and has a cookie at the
end.
A stack cookie is a simple buffer overflow
mitigation, which means you place a random
value after your data, which is checked before,
for example, the current function returns.
And if the value is still the same, the cookie
was not overwritten right?
SO no buffer overflow took place.
But in this case, the application doesn’t
quit or reset, and thus maybe not regenerate
the cookie.
This means we can slowly bruteforce the correct
value.
Even if the cookie were always random, it
might only be one or two bytes long, which
can be simply guessed correct by chance, because
we can automate it and let it run for a while.
So to explore the stack cookie further, we
first need to know how long the input has
to be to overwrite it.
Let’s write a script.
We can copy some code we have written before
to interact with the board.
Because we still don’t know what the memory
usage is for, we better not ignore it completely,
but keep that information with us.
So we select menu option two and read that
data.
Then we select option 1 to login, and simulate
the keeping a key pressed by always only sending
one character.
After each character we check if the board
sent us the corrupted cookie alert, and if
that is the case, we break.
We leave the loop.
Otherwise we increment the counter, which
counts how many characters we have sent.
At the end we can print the used memory and
the length we need to overwrite the cookie.
When we now run it, and you paid attention,
you might notice that the used memory number
changed.
Actually it changes every time when we make
a new connection with the board.
And not only that, now we see that the length
that is required to hit the stack cookie also
varies.
Doing some simple math reveals that the memory
usage and the length required for the overflow
is correlated.
This means by knowing the used memory we can
calculate now how long the input has to be
to overflow the cookie.
Cool.
So let’s write a loop that bruteforces the
cookie value.
We don’t know yet how many bytes the cookie
will be, so let’s start by bruteforcing
the first byte, and then go from there.
Basically we loop over every possible byte
value and then wait for the menu to be written,
select option 1 to login, and send enough
As to fill the buffer plus the character that
will overwrite the cookie.
Actually had that calculation here wrong,
because it never found a correct value.
I sent one A too much.
Anyhow, once we would find a character that
did return a corrupt message, we can stop
the loop and use that to explore the next
byte.
Also the loop should not start at 0, and also
not include newline or carriage return, which
is 0xa and 0xd, because they probably end
our output prematurely, and we don’t want
that.
So once we find a valid cookie, we can then
basically use the same loop again, and bruteforce
the next byte after the cookie.
Obviously we don’t know yet what the next
byte means, maybe the stack cookie is two
bytes long, or maybe something else.
So let’s remove the break here and let us
see the response for ALL possible bytes.
When we run this now, we will find the valid
cookie quickly, and then go on to overwrite
the byte afterwards.
And that byte seems to control the length
of the input.
See how overwriting it with a 1 only outputs
1 A. Or overwriting it with 8 will have 8
As.
And you see that after 8, it will start to
complain and say that the input is now too
long, and it is exactly the byte value again.
So this byte controls the length.
Interesting.
No idea yet what that could be used for, but
we can update our mental model of how the
memory layout looks like.
Maybe we have to explore a couple of more
bytes and find something that could be used
for an attack.
Eh… wat?
The flag?
Our loop finished, and it looks like the highest
value for that byte, hex ff, or 255 in decimal
triggered the flag output.
That was unexpected, but I take it.
This challenge was really a good reminder
for myself, that I should not approach a challenge
without a plan, but follow a structure, make
notes, and really think about what I’m doing.
Once I did that, it wa really straight forward,
there was not even ambiguity in our mental
model.
Each step was a logical progression from the
one before, so it’s like a very simple sudoku
where you don’t have to precalculate multiple
steps in your head in order to figure out
if a value is correct or not.
You just keep going forward, step by step..
﻿We have already come a long way in trying
to understand how we can exploit programs
through memory corruption.
We have covered a wide variety of examples,
including basic buffer overflows, format string
exploits and even heap exploits.
And a lot of you might already find it quite
complex.
But if you put it into the context of history
we are still like 16 years behind.
The last examples we have explored from exploit-exercises.com
introduced techniques that were state-of-the-art
in like 2001.
While it still directly applicable to shitty
cheap embedded devices, like some IoT stuff,
it’s very important to lay a foundation.
But before we start talking about all these
modern exploit mitigations and how we can
bypass them, I think it would be a good idea
to try putting what we have learned in more
abstract terms.
And try to get a feeling or an intuition about
exploiting binaries.
Let’s try to create a mental model of exploitation.
But let’s first introduce some constraints,
otherwise it will be too abstract.
Let’s focus on programs like we have interacted
before.
this means intel architecture and on linux.
Ok.
Let’s start at the beginning.
We want programs to execute on our CPU.
That’s why a program contains assembler
code - machine code.
And machine code is just like any other data
in our computers.
It’s basically just bits.
0 and 1s.
A lot of times we combine them into bytes.
And a CPU can interpret a byte as an instruction.
Or multiple bytes can be interpreted as an
instruction.
And some crazy digital hardware magic in the
CPU knows that this particular value stands
for “add the values stored in two registers
and put the result in the first register.
And registers are just like small memory cells
in the CPU, which fullfil different purposes.
And different architectures might have different
registers for different purposes.
But on intel we have for example the general
purpose registers like eax, and ebx, that
a programmer is free to use however he wants
to.
But there are also special registers, like
EIP, the instruction pointer.
That one simply contains the address, which
points to memory, where the next instruction
will be.
And there is also this stack pointer ESP,
which points to the top of the stack, and
the base pointer EBP, which together with
the stack pointer define a stack frame.
And for beginners this might already feel
complicated.
There is code, there is data, there is a stack,
there is a heap.
There are functions you can call.
Functions can return.
Somehow there is like a return pointer on
the stack you can overwrite with a buffer
overflow.
There are a lot of different terms that we
use.
But it’s a lot less complex as it may sound.
Because essentially there are just two parts
that are important
we have memory, which is just a huuuuuuge
space of bits that can be 1 or 0.
Usually we group them in bytes or words.
And there is a CPU, which has a well defined
deterministic behaviour that operates on this
memory.
It’s really that simple.
Well.
The devil is in the practical details, but
essentially, when the CPU is turned on, it
will start at some defined address.
This could be 0, but could also be defined
to be something else.
It request that memory content from some RAM,
looks at the value stored at that address,
and performs the action according to whatever
that value represents.
Now when we want to execute a program, you
can’t just write your code directly into
RAM, and restart the CPU at address 0.
Because if your program would cause an endless
loop, the whole system would stop working.
But when you program an arduino, a little
microcontroller, that’s basically what you
do.
But that’s why some people developed something
like the Linux kernel.
Which abstracts away the direct hardware for
you and makes sure, that if your program sucks,
you don’t kill the whole system.
That’s why a program is not just plain assembler
code, but it’s a fairly complex file format.
An ELF file.
Which does contain your raw code, but also
a lot of other information.
And when you execute this program, the linux
system will actually open the ELF file, read
and interpret all the necessary metadata and
setup the execution environment for you, and
then jumps to the start of your actual code.
So how does the execution environment look
like?
That’s important to picture, because in
that environment, you try to exploit a program,
you need to understand it.
And in some way it’s actyually very simple.
Again, the devil is in the practical details,
but it will make sense.
Let’s say the CPU is just about to execute
your first instruction.
This means the kernel and the hardware magic
has already set up everything.
And this is how it looks like.
You have a big blob of memory.
It ranges from 0, to ffffff.
In reality you don’t really have that much
memory, that’s why we call it virtual memory.
It looks like you own all this memory, but
hardware magic only makes you think you have
it.
But in anyway, the CPU now executes your program
which is somewhere in that huge memory.
Let’s have a look at how this memory is
divided up in a real program.
So for example here, we see that from this
starting address, to this end address, your
program is mapped.
We say mapped, because it’s not really physically
at this address, but it’s there if you would
read the value from that address, in your
assembler code.
So ignore the underlaying physical reality,
and just acccept that there is this huge range
of memory you can work with.
And infact the stack is also just here.
It’s also just defined as starting from
this address and ends at this address.
So the stack is not really growing or shrinking,
that’s just the computer theoretical model
of a stack.
But how is the stack actually defined?
Well the CPU has the stack register, ESP,
and it would contain an address pointing into
this area here.
So could you just point the stack pointer
somewhere else.
Like into your code?
Yeah!
You absolutely could.
The stack pointer is nothing really special,
it’s just a register that contains an address,
and it could contain any address.
What makes ESP actually special is just that
it does some fancy stuff based on instructions.
So for example a pop eax instruction, would
look up what value is stored at the location
where ESP points to, usually that’s the
stack, but doesn’t have to.
And then writes the value from that location
into the eax register.
And you can absolutely abuse that in an exploit.
For example if you find a bug that allows
you to set the stack pointer to a different
value, you could create a fake stack on the
heap, and just point ESP there.
Often times referred to as a stack pivot.
So lose the mental image of a stack that grows
and shrinks that you learned in computer science,
and just think of it what it really is.
It’s just some memory where the ESP register
points to.
And instructions cause interesting effects
based on that register.
And in the same sense the instruction pointer
is not special.
Usually it points into your code, but it doesn’t
have to.
If you manage to control EIP somehow, you
can just point it to other memory.
For example the stack, which we have used
in previous exploits.
Because we placed data that is actually valid
assembler code onto the stack.
You know it as shellcode.
The CPU doesn’t care.
The EIP register points into some memory,
and the CPU just happily does what those values
say.
And well, that is just half true.
Because as you may know, on modern systems
the stack is not executeable anymore, so the
CPU does kinda care, but also not really.
It just means that certain areas in this memory
can have different permissions.
Certain areas have the executable flag which
means the CPU allows EIP to point there and
is happy to interpret the values as instructions,
but other areas like the stack don’t have
it.
And then the CPU refuses to interpret it as
instructions.
Now when we look a bit closer to what kind
of data is included in all those different
memory areas, we can try to come up with creative
ways of how to abuse the.
One example is the typical stack structure.
When the CPU executes a call instruction it
places the current instruction pointer value
at the address where the stack pointer points
to.
It places it ontop of the stack.
And when the function returns it takes the
value where the stack pointer points to and
sets the instruction pointer to it.
So if you somehow manage to modify this value
on the stack, you can control to what EIP
will be set to when the function returns,
and thus you can decide what will be execute
next.
That’s a classical buffer overflow.
Another interesting data structure is the
global offset table, which is basically just
an area in memory containing pointers to functions,
if you overwrite an entry there, you can also
control what will be executed if a function
is called that references an address from
this table.
I mean oftentimes you cannot directly overwrite
these values, but that just means you have
to become creative.
For example think of two objects on the heap.
A user object and a name object, and the user
object has a pointer to the name object.
And when you want to change the name of this
user, the code would follow the pointer and
write the new name to that location, which
means if you can somehow overwrite that pointer,
you can control where it would write the name
to.
So we could overwrite the name pointer with
an address on the stack, and when we write
the new name for the user, we will actually
overwrite the stored instruction pointer on
the stack.
See what I try to get at?
There is memory that contains data.
Some restrictions apply, like certain memory
areas are not writeable, others are not executable.
And there is a CPU that is very dumb and just
executes whatever EIP points to.
And there is a program in the memory, which
the CPU executes.
And this code uses the memory to do whatever
it is supposed to do.
And it trusts in a certain integrity of the
data in memory.
But if there is a bug, that allows you to
change a value in memory, which the program
did not intend to be modifiable, amazing things
could happen.
And what can happen, that’s just limited
by your creativity and imagination.
One changed byte here in memory, might cause
a certain piece of code to write to an unintended
location, which overwrites a function pointer
of an object, which another part of the code
wanted to use, and suddenly executes something
very different.
And all these techniques we assigned names
to, like stack buffer overflow, heap fengshui,
ROP, use-after-free, are all just creative
ways to screw with data in memory and how
the program executed by the CPU reacts to
it.
I understand that this episode might not have
contained actual useful information to you.
But I kinda wanted to get it out there, because
maybe somebody didn’t quite picture programs
and exploits in this way.
But I hope you can see the value in this way
of thinking about it.
I think it takes some away some of the fear
that it all looks so complicated.
I’m really interested to hear your critical
opinion about this.
So comment here on youtube or on the reddit
thread linked below.
But nevermind if you liked this or not, we
will continue soon our path to learn about
more advanced memory corruption techniques.
So, stay curious, and see you next time.
﻿Let’s have a look at another ffmpeg vulnerability.
Again Paul will walk us through the vulnerability
that he found together with Emil and I try
to understand it and add some comments.
Hopefully to make it a bit easier to understand.
In the previous issue we achieved code execution
quite easily, this time we will have to be
much more accurate during exploitation.
This crash was found during fuzzing the RTMP
protocol.
This protocol is binary, so let’s open this
open up in my favourite hex editor called
radare2.
I like to use it when viewing binary files,
because it has a very shiny UI.
Nothing too special here, just some binary
data.
So let me tell you something about this protocol,
while I am launching the binary once again.
RTMP stands for Real Time Messaging protocol,
actually it was developed by Adobe for real-time
streaming of audio and video.
The protocol has actually a lot of stuff inside
and I had to spend some time learning the
specs before getting into exploitation.
All you need to know about the RTMP protocol
so far is that it does a handshake first and
then it starts to transfer data in small chunks
and maximum size of each chunk is one hundred
and twenty eight bytes.
Now, let’s dig up into the source code once
again.
So after passing the version check and doing
some handshakes we end up in packet read function
in rtmppkt.c . This function simply reads
one bytes of the header and then call the
most important function in a loop.
And this is the function which does all the
parsing of the protocol.
There are a lot of structures, functions and
allocations and all of them are important.
As you can see each chunk has the channel_id.
It is basicly identifier of each RTMPPacket
in the array, which corresponds to its own
buffer.
One channel may be filled by multiple chunks,
because maximum size of each chunk is hundred
twenty eight bytes and packet data might be
much larger.
Each chunk has fields like size, type, header,
timestamp and some extra data.
So if the current channel does not exist yet,
RTMPPacket structure is filled in the array
and a buffer is created for it.
So the av_realloc function with NULL pointer
means simply, do the allocation ofthe corresponding
size, Otherwise data is just filled in the
existing structure and the buffer.
So if you will pay enough attention, you may
notice an issue there, when the structure
is filled for the second time, there is not
check that the buffer size passed for the
second time is actually the same that the
size of the allocation made the first time.
And this how we manage to overflow the heap.
Ah yeah this makes sense.
So the packet contains a channel ID read from
the header.
And if this packet was not seen before it
will alocate it with the size.
But if an atatcker sends the packet with the
same packet id again with a different size
it will not be reallocated.
Let’s visualize that.
If we send a packet with id 1 and size 0xa0
it will get allocated.
Then we can send another packet with id 2
and the size 0x80 and it will get allocated
after the first one.
Now we send again a packet with id 1 and a
much larger size, like 0x200.
Now we overflow stuff on the heap.
Awesome.
Let’s try to gather some primitives from
the source code.
So we could allocate a data chunk by sending
a new channel ID.
We could overflow the chunk next to it by
changing the size
And we could also trigger the reallocation
inside the rtmp_check_alloc_array function.
If we send a channel_id large enough we will
trigger the reallocation of the control structure
and it will be positioned right after our
buffer we can overflow..
By doing this little heap magic we overflow
the pointer to the data and get arbitrary
write.
That’s a super easy plan.
We just force the reallocation of the array
that contains the pointers to the data chunks,
and thus the array will be allocated now after
the one data packet we have.
And then we send again a packet with this
id to overflow into this array.
And thus control the address of those data
chunks and can point it anywhere we want and
thus also write there.
So I already did some preparations before
and wrote a little proof of concept, because
most of the work here was counting the offsets.
So there are the functions I wrote.
These are lambdas for packing our integers
using little endian.
create_payload function helps me to pack data
into the RTMP protocol.
And create_rtmp_packet function will help
me to create fake rtmp structure on the heap.
Now let’s take a look at the main code.
So here is the handshake happens.
After the handshake I send first payload with
size just a bit bigger than 80 bytes in hex,
and some ‘A’s and the channel_id number
4.
I do this, to create control structure on
the heap.
Next I send some data with larger channel_id
to trigger the reallocation of the control
structure.
Next I overflow the next heap chunk, which
happens to be the control structure and fix
it’s size, so that I will have no problems
with the heap when I will be allocating more
data.
I position the fake chunk on the place of
RTMPPacket with second channel_id.
As you can see there I position a realloc@got.plt
instead of data pointer, so I will be able
to write to it.
As my last steps I write to got.plt with some
data, and after I use the big channel_id once
again to trigger the realloc function.
All of this should give us control of RIP
register.
Let’s see.
Super straight forward exploit, right?
If you can overwrite an addresses in the control
structure, in this array, you can point it
anywhere and write data to it.
So here is ffmpeg in gdb with the triggered
segfault.
And it does, because we have successfully
overwritten the .got.plt section.
Achieving code execution should be easy from
now on.
I hope that this video motivated you a little
bit and shown, that real-life exploitation
may be rather simple and this will encourage
you to make your own research.
Good luck.
That is a really great example.
Thank you so much Paul for sharing this with
us and all the work you have put into recording.
Make sure to follow him on twitter and check
the description for some links.
And don’t forget to checkout the podcast
episode with Paul, if you haven't listened
to it yet.
﻿Another easy challenge seems to be here in
the reverse engineering category.
The desert of reversing.
BTW, whoever did the drawings for this CTF,
I really appreciate it.
It looks awesome.
In this category we have to reverse engineer
the programs that run on this arduino board.
So before we checkout the next challenge,
let’s try to learn more about this plattform.
First of all we know that the microcontroller
used on this arduino board is an ATmega 328P.
So we can google this name and find the official
atmel website where we can download the official
datasheet for this chip.
Ok.
So we got here a microcontroller that is based
on the AVR® enhanced RISC architecture.
That’s our first piece of information.
That chip can execute AVR code.
That is very different from what we use on
our PCs or Laptops.
Those are usually intel based 32 or 64bit
machines and use intel assembly.
I can read intel disassembly okayish, but
I have never read AVR disassembly.
So I’m new to this, like some of you.
Also RISC means reduced instruction set.
Which is a simplified assembler.
At first that sounds cool, but to be honest
it’s harder to read I think.
At least for me coming from x86.
Which is CISC, a complex instruction set.
Basically the difference is that, eh… this
is not a real example but just to give you
an idea.
A CISC architecture might have a multiply
instruction that works directly on memory
addresses.
And all the memory magic is done by the hardware.
But on a RISC architecture you might first
have to load the one value from memory, then
the other value, then multiply them and then
write back the result.
So 4 instructions vs. 1.
You have to learn less instructions on RISC,
but once you know them you will always have
to read more lines for the simple things.
In reality both architectures have absolutely
their value and good reason.
Just for me, coming from x86 and having no
experience, it probably gonna be a bit of
a rough ride.
But before we look at AVR assembler, let’s
continue with getting a broader overview of
the device.
So on embedded devices, or generally very
low level computing you want to interact with
hardware.
Obviously there is no special instruction
called TURN LED ON.
Usually this is done with something called
memory-mapped I/O.
It’s pretty much hardware magic.
From the perspective of a programmer we have
a big chunk of memory we can use.
You know, from address 0 to like 0xffff.
But not each memory address is the same.
There are regions.
For example a certain part of this abstract
memory model could indeed map to some memory,
some flash, where you can read and write values
to.
Like we would expect.
But another address might map to an actual
output pin.
And you could define that writing a 0 to that
address will output a 0, and writing anything
but 0 would mean the pin will output a logical
1, or in reality something like +5V.
So if we think of our board what kind of inputs
and outputs we have, we know that there are
multiple pins available, AND we know that
there is a serial uart interface that allows
us to send data via RX and TX.
And especially in our case, where we interact
with this board via serial, we are very interested
in how that is done, so we can identify in
the disassembly (that we eventually will reverse
engineer) what code is interacting with us.
Is reading input.
So I was very interested in looking up the
memory map of this microcontroller.
For example address 0x2d00 could map to serial
input, and then we could maybe search in the
disassembly for a read from this address.
Ok so I search for memory map.
And then I get confused.
This one here only shows the application and
bootloader flash region?
There is no memory mapped I/O?
How does this work?
But continue the search and I find finally
a memory map that shows I/O stuff.
Wait.
That is weird.
This memory goes from address 0 to address
0x3fff, and this memory goes from 0 to 0x08ff.
What?
Then the bootloader and application code would
overlap with the I/O that doesn’t make any
sense.
That stumped me for quite a while.
I was not expecting that and obviously I didn’t
read the documentation too carefully.
I hate myself for how long that took me to
figure out.
It turns out, AVR uses a harvard architecture.
And if you ever wondered, why you had to learn
weird things like harvard vs. von neumann
architecture in computer science classes,
well, here is a good example.
If I had never had that in school, I probably
would not know about this.
So in the intel world, everything is just
one big chunk of memory, program code lives
in the same memory as does data do.
Thus we can do crazy exploits where we overflow
stack data and jump into the stack and execute
code.
On harvard, this doesn’t work.
The data is separated from code.
So the CPU reads instructions from one memory
area, executes those, and those instructions
work with the data memory.
So you can never jump into data and execute
code there, because that just doesn’t work
that way.
Anyway.
I wanted to look at the memory stuff to figure
out how the serial connection might work.
So let’s look in the datasheet for that.
There is a section called USART, basically
UART that I breifly mentioned before, it stands
for
Universal Synchronous Asynchronous Receiver
Transceiver.
Apparently it’s a highly flexible serial
communication device.
We are on the correct track.
So here we have a block diagram that apparently
describes this thing.
Let’s see if we can make some sense of it.
Here is the RX and TX output, at least something
we kinda know about.
There is also a clock, which has something
to do with the baudrate.
Also kinda makes sense.
We can also see that RX and TX use a shift
register, which means the code doesn’t have
to actually speak the serial dataformat bit
by bit, but can simply load the shift register,
and with the help of the clock it will slowly
get shifted out as a serial output.
And same with reading, it slowly fills up
the shifft register and we can then read the
whole result.
And there is an interesting note saying: Refer
to the Pin Configurations and the I/O-Ports
description for USART pin placement.
We look that up in a second.
There is a lot more information here but let’s
scroll a bit further down to see the receiving
examples.
If we read that, and we completely don’t
understand it, we might have to go back and
read a bit more.
That’s just how researching and learning
new stuff works.
Ok so here we have an example written in AVR
assembler and equivalent C code.
The following code example shows a simple
USART receive function based on polling of
the Receive Complete (RXC) Flag.
And for the assembly code, the received data
will be stored in R16 after the code completes.
So it reads from a memory location called
UCSR0A with the IN instruction.
And then uses “skip if bit is set” and
checks if the RXC bit or flag is set in that
previous value.
If it’s not set it will execute the jump
afterwards to loop back up.
But if it was complete, it would read from
a memory location called UDR0 into register
r16.
Which means it received a byte from the serial
communication.
We can also quickly check the sending site
and see that it basically works the same,
it also uses the UDR0 location, just this
time to send data - with the OUT instruction.
So what is UDR0.
When we search for it we find this huge table
which is a register summary and apparenly
UDR0 is at offset 0xc6.
UDR0 stands for USART I/O Data Register 0
The description says that as the USART Transmit
Data Buffer Register and Receive Data Buffer
Registers share the same I/O address referred
to as UDR0.
The Transmit Data Buffer Register (TXB) will
be the destination for data written to the
UDR0 Register location.
Reading the UDR0 Register location will return
the contents of the Receive Data Buffer Register
(RXB).
And the data memory map from before shows,
that the external I/O registers are between
0x60 and 0xff, and the UDR0 register is at
offset 0xc6.
So it’s called a register, but it’s also
just an address in memory, a very low address,
0xc6.
This means, if we find a read or write to
address 0xc6, we have the address where serial
data is handled.
At this point I won’t go into further detail.
But I think this video is a great introduction
on how you can approach a new unknown field.
I condensed in this video hours of research
and I read small snippets here and there that
will help me getting a better and better understanding
of this architecture.
Besides the official datasheet, I also googled
a lot and read forum posts.
The arduino platform has a big community,
so you find a lot of discussions that help
you understand some weird AVR things.
But one of the most helpful other resource
I found, are slides from an AVR workshop with
radare2 which was extremely helpful.
For example when I started debugging and reversing
the first AVR binary I was confused about
weird stuff in IDA and when I read the slides
I learned that yeah, there are addressing
issues with AVR in IDA.
Really annoying.
And there are more small things like that.
So thank you a lot dark_k3y and dukeBarman
for sharing your knowledge with us.
You saved me from hours of frustration.
﻿In this video we will script radare2 in python
with r2pipe to extract the encrypted code
and recover the flag.
Last video we reverse engineered the algorithm
that is used to verify the input key (the
flag) with binary ninja and gdb.
The challenge is called Zwiebel from the TUM
CTF 2016, and that’s the german name for
onion.
We learned that the binary will decrypt itself
layer for layer and check different bits of
the input during each step.
Now we want to create an automated script
that performs the tedious reverse engineering
task for us.
First make sure that your radare2 installation
is up to date.
Always work with the repository and not install
it from a package manager.
Then simply run sys/install.sh which will
update to the latest commit.
And make sure you have r2pipe for python installed.
Now we can access radare from python.
The API is super simple.
After opening a file you simply execute commands
as you would with the radare commandline.
So let’s get started.
Open the binary with radare2.
Then use doo, which reopens the binary in
debugging mode.
Then I take the address of the call r14 and
set a breakpoint with db.
With dc we can continue the process execution
which will for the input key.
After that we hit the breakpoint.
Now let’s do the same in our script.
First we need to import r2pipe and then we
can open the executable with radare.
Then we can simply execute those commands
with the cmd() function.
It’s that easy.
Here is what I try to do.
I will write the script here and in this small
window I try to show you the radare command
descriptions and what it does.
Then I hope it’s easier to follow.
So the first command was doo, which reopens
the binary in debug mode.
After that we want to add the first breakpoint.
Which is db.
Then we resume/continue the process with dc
which should hit the breakpoint.
At this point we should be just about to execute
the call to r14.
Which is the actual code doing the checks
and deecryption loops.
So we want to do a step forward of one instruction
into that code.
I think we will single step a few times, so
let’s define a helper function step(), which
will execute ds, which is a single step.
When you execute a single step, then obviously
the instruction pointer of the CPU moves on,
but the current address of radare does not
update.
So we want to also seek to the new address.
We can use sr rip, which will seek to the
value of the register rip.
Cool.
We will use that function in a moment.
So now we can start writing the loop that
will perform the same steps over and over
again.
So our first step is to extract the current
bit checking rule.
How does this look like.
We can scroll back up to where we looked at
this in gdb and look at how this looked like
in assembler.
So we are somewhere before this code, and
what we want is to now extract all those lines
of assembler until we reach that jump-equal.
So we define a list disass, which will hold
each line.
Then we do the following loop.
We first step one instruction forward, and
then use pd, which prints the disassembly
of one instruction at the current address
of radare.
That’s why we seek to RIP in the step function().
But actually we will do pdj, because that
outputs json information instead of just a
text line.
And in python we can call this now with cmdj,
which will automatically return a python dict
to easily access the JSON data.
Let’s quickly see if our script works by
opening a python shell and copy the code.
Looks pretty good?
Or no.
Somehow it all hangs.
Mh.
We kind of forgot to handle the input.
The process is currently waiting for a key,
which we can’t enter.
I started to google a bit and found this.
So I created a rarun profile that specifies,
that the process shall receive this string
as input.
We can set this profile through radare’s
environment variables.
So we add this command to our script.
Then we can try to run it again, and indeed,
it now proceeds and the breakpoint after the
key input is hit.
Now let’s continue with the script.
Let’s add the current instruction opcode
to the list.
Pdj returns a list of instructions.
So we get the first element.
And then we get the “opcode” value of
the dictionary.
Then we also check if the instruction type
is a conditional jump.
Cjump.
If that is the case we reiched the jump-equal.
This means we reached the end.
If the bit check was ok, it will continue
to the decrypt loop afterwards.
This means, after we break out of this loop,
we have a list of instruction and the last
one is the jump-equal.
And the one before is the binary and value.
And the one before that is the mov that get’s
the character at a certain offset.
So the first instruction is the character
offset.
The syntax of the mov opcode has the offset
+ something after rax.
So this is ugly python, but it get’s the
job done.
We split the string at “rax”.
And the second element of the result, minus
the last character is our offset value as
a hex string.
Though, sometimes the first character is references,
then it doesn’t have a + hex 0.
So if we got an empty string, we simply set
the offset by hand to 0.
Then we can convert the hex offset value to
an integer number.
Next instruction is the binary and value.
Which will tell us which bit is checked.
Similarely like before, we can take the opcode
string and split, after the comma.
And that is the hex value which we can convert
to an integer.
Cool.
One more thing we need now is a variable to
build our flag.
I’d suggest we simply make a long list of
numbers, which we then can add the single
bit informations we extract to.
I initialize it to hex 20, which is the ascii
space.
So once we got this info, we can simply update
the flag at the offset and set this particular
byte with a binary or operation.
After that we can write some code to print
the current state of the flag.
We loop over each number, if it is between
a certain printable ascii range we convert
it to the ascii character, otherwise we append
a space to the output.
With sys.stdout.write we can directly write
to the output, because python print appends
a newline.
This way we can use \r instead, which makes
the script look really cool.
The next step in our script will be to perform
the decryption.
If you remember, after the loop instruction
we have the jump into the decrypted code.
So we could simply perform single steps forward
and check after each step the opcode of the
current instruction.
And if we found the loop instruction we can
stop.
The instruction afterwards is the jump, so
we can use pdj 2, to get the current and the
next instruction.
And from the next instruction we can take
the address where it wants to jump to.
We can extract that value easily thanks to
the json data, and then add a breakpoint at
this new address.
Next we simply continue.
I think we are bsically done.
Let’s test it.
No syntax errors, but something else seems
wrong.
It stops way too quickly after only a few
rounds.
Let’s add some debugging output that displays
us some of the instructions.
When we run it now, we get the instruction
that check the bits.
And when you look closely you can see, that
it’s not always jump-equal.
There are actually some jump-not-equal.
So that is the inverse of the check we know.
The normal one, checked if a character has
a certain bit set to 1.
the jump-not-equal check will make sure that
a certain bit is NOT set.
So it’s 0.
And we don’t have this logic yet.
Let’s write that code.
We can simply check the last opcode if the
jump was jump-equal and then set the bit to
one, with the binary OR that we already know.
Or if we have a jump-not-equal, we set the
bit in the flag to 0.
That’s a bit more tricky, but basically
you use a binary AND, with a bit sequence
of all ones, except the one bit you want to
set to 0.
To get this binary sequence you can take hex
FF, which is all 1s and XOR it with the bit
you want to set to zero, this will produce
the bit sequence with that one bit 0.
Just play it through on a paper it becomes
clear.
But there is another problem, which is our
input flag.
because we specified in the rarun profile
that it’s a fixed “AAAAA” string, which
will eventually fail the bit checks.
And that’s the real reason why it stopped.
But we could add some code that bypasses this
check and always continues to the next layer.
These conditional jumps je, and jne are sometimes
also called jump if zero and jump if not zero.
The CPU has a register that contains flags
and one of those flags is the zero flag, which
will be 1 if the previous calculation resulted
in a 0.
And it will be 0 if the result was non-zero.
This makes sense, because if you want to compare
two values you can simply subtract them from
another and if the result is 0, they were
the same and the zero flag will be set.
This means we always want to make sure the
zero flag is set to 0 or 1, whatever makes
the code continue.
We can set those registers in radare during
debugging with dr, and then set zf, zero-flag
to 0, so the jump-equal will not jump.
And we can set it to 1, so the jump if not
equal will not jump.
Oh and we should remove our debug output.
Now let’s run it and see what will happen.
Urgh ehm.
Radare outputs everytime we hit a breakpoint.
That’s not pretty.
But it does it on the standard error out.
So we can simply redirect the stderror to
/dev/null.
Now we have a very pretty output.
The program is running, decrypts each layer,
extracts the rules, updates the bits in the
flag and display it to us.
It slowly recoveres the flag now.
Looks so 1337!
And there we have it!
I hope you didn’t peel the onion by hand!
Awesome!
﻿We have played the game pwn adventure 3 a
little bit, we have set up our own server,
and we investigated the game from a higher
level perspective which lead us to discover
a libGameLogic binary.
Which is a dynamic library loaded by the game
and sounds important.
So now we go another layer deeper, we get
our hands dirty and open a disassembler.
So which disassembler should we use?
There is binary ninja, which is developed
by the creators of this game.
Unfortunately the DEMO version does not support
64bit, so you have to have a regular license.
But it costs just like as much as 3 video
games, so it’s not too bad.
Then recently IDA released a new freeware
version with 64bit support, and that’s awesome
and definitely something you should try, then
there is also hopper and radare.
I will mostly use binary ninja and IDA for
this project now, but in general, as you know
from my videos, I use them all.
As I’m not doing professional work with
reverse engineering, my experience on this
topics is very limited.
I just try to make things work.
If you have tips and tricks and advice how
to do things better, let me know, I most certainly
would like to get better.
So let’s open the libGameLogic in binary
ninja and ida.
It takes a few seconds to analyze and process
the binary but very quickly we can see that
it identifies a lot of interesting symbol
names.
You might have also noticed that there are
some very weird function names.
This is immediately telling me that this is
a C++ program.
These are so called mangled names and we can
demangle them.
This crypting string encodes a much more complex
name including the types.
If you carefully analyse it and play around
with it you can figure some things out about
the format.
For example the number here is the length
of the name, while the small c stands for
char.
Changing that into an i makes the argument
an integer instead.
And so this demangled representation is much
more readable, and also unveils classes.
So there exists a GameAPI class, which has
a function with the name GetSpawnPoints and
that function takes a constant character pointer,
that’s basically a string.
This information, these names, are included
because they are exported symbols and the
binary is not stripped.
So it’s super awesome and easy for us to
explore the functionalities and capabilities
of the client.
But before we go on with this I want to make
two points.
1.
This game was part of a CTF that was running
for maybe 2 days, so giving out the names
of these functions is a huge speed boost.
This makes it much easier for people to understand
the game and allows them to focus on the actual
challenges, rather than having to spend a
lot of time on intensive reversing.
Which leads me to my second point, yes it
would be easy to make it more time consuming,
and thus maybe harderr for “attackers”
if the binary would be stripped.
Because that is a significant time sink.
But a group doing reverse engineering can
recover all of this class information, obviously
not the exact names, but they will understand
everything as if they had the names, it just
takes time.
And by that I mean hundreds or maybe thousands
of man hours.
But it’s a one-time investment.
Once a group has reverse engineered the internal
class structures, then they essentially are
at the point where we are now.
So even it it might be a bit unrealistic that
we have this debug information, it just safes
us time.
It doesn’t mean it were impossible otherwise.
And to be honest, it might not be that unrealistic
after all.
For example a popular MMORPG had an open beta
before their launch where they shipped a debug
build of the game including all the information.
And yes, for the release they stripped out
all of the stuff, which made the game also
run faster but at this point the “attackers”,
I don’t wanna call them attackers, they
don’t try to attack, they just research
how the game works, had all the information
they needed.
Of course over the time the binary changed,
and also classes changed a lot, new features
were added or removed, but that is extremely
valuable information that helps with future
reversing.
And even now when you get a crash in that
game you often get an assert condition which
reveals some internal code information.
And these asserts are embedded in the game
binary, so it’s super easy to map out what
functions do based on that.
So my point is, if you try this on another
game, you might not have all these class names
included, which doesn’t make it impossible,
it just means you have to do a lot of work
first.
Anyway.
This is not about doing anything to real games,
we are just having fun with an intentionally
vulnerable game hacking challenge.
Let’s go back to the disassembler and keep
looking around.
There is sooo much to learn here.
So many interesting classes and function.
For example there is a SubmitDLCKey function.
Remember the chest on the pirate ship?
That wanted a DLC key?
Let’s check the boat.
Is that a chest as well?
I don’t trust it!
Oh.
heh.
DLC.
I’m sure that is the function that is handling
that.
By the way, the orange color is how the game
would call a function.
It’s from the procedure linkage table.
What that is I have touched on in the video
linked here.
You see it’s just a jump to an address contained
in the global offset table.
The actual implemented code is in the white
colored version here.
So here is the SubmitDLCKey function from
the GameServerConnection class.
And it seems to get a function pointer to
sth and calls ServerConnection::ServerEnqueue,
so sounds like it places this action into
a queue to be then sent to the server.
And yeah, the server enqueue function just
acquires a lock, to prevent race conditions
on the queue, and then pushes a new item into
that queue.
So somehwere is a consumer of that queue,
and based on the class name ServerConnection,
I’m sure it will build a packet to send
to the server.
You can easily spend a couple of hours just
learning about different functions and objects
and it’s really fun.
You should try it yourself.
I won’t tell you each discovery, but here
for example we have a class for Magmarok,
that was that boss monster in that cave which
healed itself.
And in the function GetDisplayName it references
a fixed string as name.
And that name lead me into a section with
lots of other strings of the game.
And there it says: “find all of the golden
eggs”.
Interesting.
So there are golden eggs somewhere.
Let’s compare a little bit how this looks
like in IDA.
So Ida also demangles these names.
For example there is a ClientHandler that
seems to be responsible for handling chat
messages?
We can also look at the exports specifically,
sort by name, and get a nice list of all the
stuff that exists.
IDA also can detect these structures, so for
example here it found an actor class.
So ida says it’s a struct not a class, but
classes are essentially just made out of structs.
If you program C++ and C they might feel very
different, especially with inheritance, and
public/private visibilities and methods and
attributes, but in the end, the underlying
implementation is essentially just a struct,
with some more information like a vtable pointer.
And it found some attributes like id, target,
health and more.
It even found some cross references from some
code.
IDA also found some enums, for example ItemRarity
and DamageTypes.
So after just scrolling around and reading
a lot of class names and functions I decided
to look at this in gdb.
So I launch the game, head into the game so
that everything would be loaded.
And then I attach gdb to it.
In gdb we can also list all the running threads
and we could even do info variables, to get
all available variable names.
Or info functions or info types.
But this is a huge program so there is just
ENDLESS amounts of data, which makes it super
difficult to find useful stuff.
But from the disassemblers we know a lot of
interesting functions.
For example there were functions related to
Jumping.
Like the GameServerConnection::Jump.
And we can set a breakpoint there.
When we now jump in game, the breakpoint is
hit.
And we also see the call stack.
At least partially for the functions we know
inside of libGameLogic.
So the actual game client called Player::SetJumpState,
which called then ClientWorld::Jump, which
triggered a server connection regarding the
jump.
Probably informing the game server, that we
pressed jump.
Super cool huh?
We can also use some other cool gdb features,
such as ptype.
Print type.
So print the type of Player.
And Player is a class that we know exists.
And gdb prints the whole Player class.
So we can see that the class Player inherits
from Actor and IPlayer, which probably stands
for InterfacePlayer?
And the Player class itself has a playername,
a team name and much much more.
So now you can explore all these classes easily
with gdb ptype.
Here is the GameServerConnection class, which
inherits from ServerConnection class.
And in the ServerConnection class we can see
the ServerEnqueue function again, which takes
the function pointer we mentioned earlier.
Pretty neat!?
One other thing I discovered was in the data
section of the binary.
There is a global variable called GameWorld.
Along with some other very interesting variables
called g_items and g_eggs and so forth.
We can then print that in gdb.
Print GameWorld shows that this variable is
a pointer to a World object.
And if we dereference that pointer, we get
the actual World object and gdb prints that.
So we have here the World object.
Which does included for example a list of
players, but currently there is only one.
Me.
There is also a vptr to ClientWorld.
That’s a vtable pointer.
That’s what I briefly mentioned before.
So i think this object here is in fact not
a World object but a ClientWorld object.
We can also access attributes of the World
object.
For example the players list.
Or we can cast the World pointer to a ClientWorld
pointer and dereference that.
Which is basically the same, it’s of course
similar to a World Object, but we also get
a variable activePlayer.
And that variable was only part of ClientWorld.
So I guess that is us!
And again we can print the class definition
of this with ptype.
And you see here, there is a private attribute
called activePlayer.
Which is from this type ActorRef.
So I guess an Actor reference?But with the
underlying type IPlayer?
I don’t know why it’s programmed that
way, but essentially it’s a reference to
our player object.
And you know what we can do?
We can now extract all of these classes from
gdb, and create a C++ header file called libgameLogic.h
which we can then use for creating our first
actual game hack.
But that has to wait for next video.
﻿In the previous video I showed you a dumb
design decision of a Guild Wars 2 Trading
Bot author, who decided it was a good idea
to leak the API keys from all bot users.
These API keys can be used with the Guild
Wars 2 API to get all character information.
I have written a small script that has collected
data on all active bot users along with their
wealth, for the past three months.
And so I wanna have a look at this data and
also talk about the threat model of botting
in MMORPGs
Before we get into the data, let’s talk
about botting itself.
I try to approach this topic as if I would
design an MMORPG and I’m well aware of the
threat that somebody could hack the client
or automate and bot certain aspects of the
game.
For me MMORPGs have two major concerns they
need to control in order to have a healthy
game.
One is the player satisfaction.
This is purely subjective, it’s about feelings
players have that are often completely separate
from reality.
And the other one is keeping inflation of
the ingame currency under control.
If you ever played a game with rapid inflation,
it’s basically unplayable as a new player
and it’s just a terrible experience.
And there are many many game design decisions
that you can make that affect these things.
For example a very typical thing games do
is to have a gold sink.
That means there are very expensive luxury
items that just pull out masses of currency
or items to fight against inflation.
Items can become character bound so they are
removed from the economy and much more.
So what does this have to do with botting.
So when most people imagine botting in an
MMORPG game, they imagine bots that run around,
kill monsters to level or collect items and
gold.
So why is this bad for agame?
First, with each kill, gold or items are generated
out of thin air.
More gold available in the economy, can lead
to a higher inflation.
And because botting can be scaled to hundreds,
thousands or even way more, this can really
destroy the economy.
This is the main reason why botting is so
bad for a game.
Another issue is, that when regular players
encounter botters, it has a negative emotional
effect on them.
They feel cheated, maybe even their kills
get snatched away, they can’t buy stuff
anymore because of inflation and they can’t
find real players to chat and go on adventures
together.
So if we design a game to defend against this
threat, what can we do?
Should we invest into obfuscating the client,
making the network protocol super complex,
implement or buy scanning solutions that behave
like anti-virus software trying to identify
bots or hacking tools through heuristics?
But those are all terrible solutions, because
they are expensive and ineffective.
A dedicated botter can always bypass those
locally running scanning tools.
It just slows them down and maybe prevents
simple people from doing it, but professionals,
that earn money from botting, they will find
ways around it.
Much more elegant solutions are solving this
through game design.
For example Guild Wars 2 doesn’t have a
concept of kill, experience, loot or resource
stealing.
Everything is shared.
So players wont have a bad experience with
bots stealing their kills.
You can also design your game and server logic
in a way that you completly don’t trust
the client.
For example let’s say you have a dungeon
and at the end is a reward.
Instead of spawning the reward chest at the
start and having closed doors preventing access,
you can have a mission timer or different
checks before the server spawns it at the
end.
Thus if sb has a client-side wallhack or even
control over the communication protocol they
can’t just access the chest rightaway.
You can also implement more complicated boss
fight mechanics that require dodging and positioning,
so that bots have to be really really smart
in order to farm it.
You can also make a lot of resources account
bound, so that a lot of the good loot can’t
even be traded or sold by the bot owners.
You can also have instanced MMOs, because
then bots can do everything without ever being
seen from players, thus it helps against a
bad perception of the game.
It’s kind of fun trying to think of systems
that make bots less effective to protect the
game, isn’t it?
But what about a trading bot.
Because this is a little bit different.
I claimed earlier that the ingame economy,
mainly the inflation is a crucial part to
keep a game healthy.
So how does a Guild Wars 2 Trading bot affect
the game?
First I have to explain how the tradingpost
works.
When you have an item you can list it for
a price.
Listing an item costs 5% of the price you
choose.
That is paid right away.
Then if somebody buys the item, another 10%
of the gold is taken away.
Basically you have a 15% sales tax on each
trade.
And placing a buy order does not cost anything.
So this means that a trading bot instead of
printing ingame money.
It actually removes gold from the economy.
15% at a time.
So a trading bot is in a weird way actually
HELPING to fight inflation.
Also I would claim, that the casual regular
player, likes to buy items when they need
it from the trading post, and sell items right
away to sb who offered to buy it.
That’s not the most efficient way, but the
most comfortable way.
And so a bot, who is constantly trying to
overbid on items so they get buy orders filled
raise the price a casual player can sell an
item for right away, and at the same time
try to undercut when listing the item, so
their sell listing is sold quicker.
Which pushes the price down for casual players
that just want to buy an item.
So it even has another positive effect.
However there are also two major negative
points.
A trading bpt is competing with all the players
who would like to maximize their profits,
or engage in trading too.
The undercutting and overbidding minimizes
the profit a regular player can have.
It also lowers the bots own profit, but a
bot can obviously do a lot more trades than
a human and can thus justify lower profit
margins.
And another issue is, that if players feel
like there are bots trading it can have a
very negative emotional effect.
A feeling of unfairness and so forth - even
though maybe objectively a trading bot is
not bad, regular players will not see it that
way.
So I believe a trading bot is unfair, though
it’s not bad or dangerous for the game,
as long as players don’t see them.
So let’s have a look at the data I have
collected.
I’m using a jupyter notebook to work with
the data and used it to create all the graphs.
The code is terrible, please ignore it.
I have not included the API keys so you can’t
find out which players were doing this, but
you can find all graphs in the description
below and so you can have a look yourself.
First of all, over the roughly three months
of collecting data, I have seen 94 unique
Guild Wars 2 API keys.
So I guess almost 100 people have downloaded
the bot, executed it and entered their API
key.
However when you look at the graphs you will
see that many have not actively used the bot.
Next let’s look at the activity graph.
At the bottom you can see the time span of
the data collection.
It started on 12 of november and went up to
the 7th of februrary.
My crawler checked the API every hour, so
each point represents a bot being registered
online and having some sell or buy data.
You might wonder why there are only 76 bots
and not 94.
That’s because 18 people basically didn’t
do ANYTHING.
These 76 however started the bot for a brief
period.
But even though they used it, there are still
several that were basically never reallya
ctive.
So for example user number 72 downloaded and
ran the bot for a couple of hours on the 23.
November.
After after that, never again.
In contrast to that user 25 has basically
a bot running 24/7 for the whole period.
BTW this gap over here was my fault, my crawler
died and I didn’t realize it quickly enough.
And then there is user 55, who used it fairly
actively, but then stopped in december, maybe
went home for christmas without their PC and
then restarted the bot again when they returned
in january.
These graphs tell a lot of interesting stories.
Now let’s have a look at individual bot
graphs.
I think number 25 is awesome, it’s a really
active bot.
I think it’s actually the most active one
that I have recorded.
So You can see here dots with several colors.
Orange is the gold they have in their wallet
or inventory.
Blue is the gold trapped in items they have
listed for sale.
So blue is a theoretic gold value they would
get if they would sell the items.
But now that I think about it again, I think
I forgot to deduct the 10% trading post tax
from that.
Anyway, blue should be a bit lower overall.
Red are the buy orders they have, so that’s
money that is waiting in the tradingpost for
somebody who sells the item for this price.
And black is the “net worth”, basically
it’s just the sum of gold, value of the
items listed for sale and the buy orders.
It’s the theoretic gold wealth of this account
at that moment in time.
So if we look at the start of this graph we
can see that the bot has constantly 400 to
1300 with up to 1700g in buy orders.
So hoping to get cheap items.
And blue are the items being sold.
So these items wait for a buyer.
And as you can see their price is always going
up and down meaning that new items are being
listed for sale and that people buy items.
Now I think that there is always a dip down
on weekends?
Which could mean that because on the weekend
more players are playing, more items are being
bought from this player.
So the money in listed items goes down.
But I can’t really explain myself those
big jumps.
So black is the overall “net worth” and
I think there are clear upward trends visible
here, with around maybe 750 to almost 1000g
per week?
But remember a lot of the wealth is kept in
items that might never get sold, so it’s
not all just raw gold.
But here with those big jumps I think maybe
my calculation fails a bit and actually the
user cancelled all buy orders and so forth
and then moved gold away.
Also there is a fairly sudden drop in value
of listed items, so maybe the person even
cancelled a lot of listed items and relisted
them lower or just outright sold them to the
highest bidder?
Maybe?
Well i don’t know, speculating here.
This trend here I think is awesome.
The listed items are slowly being sold off,
which increases the available gold.
However the gold is immediatly put back into
ordering new items, so more and more gold
is now in the ordered items.
Overall, because by selling those items and
ordering new ones, the bot made a profit and
thus the overall net worth is slowly increasing.
But the trading strategy during this time
is also ineffective, because ideally the listings
wouldn’t go down, they should be at least
stable or rising with the wealth.
But like I said, that’s a very active bot
and probably the most successful one.
We can also use gw2efficiency with the API
key to spy a little bit what this player traded.
So here they are, these are the secret items
that apparently are very profitable to trade.
The most money was apparently made with the
black Poly-luminescent trinket.
The War God skins are also good.
BTW if you are wondering why the listings
are flatlining starting around the 9th of
january, this can be seen also on other graphs.
Unfortunately this is an issue with the guild
wars 2 API.
The listings are not updated, so the data
there is faulty.
Another very active bot, number 3, seems to
be less successful.
Here the networth is pretty constant.
So kinda useless to let the bot run.
Bot 30 looks awesome, but don’t get fooled
by the slope and look at the y axis steps.
Here the bot started with around 200g and
made maybe 500g in about 3 weeks.
That’s also not very great.
And those drops look really like the person
pulled out winnings into another account.
Unfortunately this user’s API key is invalid.
Maybe they got banned?
Or maybe they just removed the API key because
they stopped using the bot.
So is this bot worth it?
I’d say clearly no.
A lot of the graphs are pretty much just a
flat line, so they users don’t choose good
items to trade.
And you have to include the electricity cost,
hardware cost and game key cost PLUS the subscription
for the bot.
I think it’s a complete waste of money and
is better spent on buying gem cards.
Also should the average Guild Wars 2 player
be outraged over these unfair bots?
No, absolute not.
Those are small fish, they don’t really
make a lot of gold, always risk getting banned
and it’s just a handful of people.
This is not a problem you should worry about
and like I outlined earlier I don’t think
it has any negative effects on to the game.
And as long as you don’t cause an unjustified
player uprising, this is just fine.
Btw. if sb from ArenaNet wants the API keys
to hand out some 7 day warning bans, send
me an email.
﻿So I wanna show a few more things about the
i.onik wifi cloud hub router thing.
The previous video was more light hearted,
less about the security issues and more like
a sketch.
So I wanna use this video to focus a bit more
on the security issues.
First of all, when you simply unbox this device
and start using it, it will create an unprotected
Wifi for anybody to connect to.
And as you have seen in the last video, anybody
can then easily connect to it and get code
execution.
Generally we want products to be secure by
default, because most people don’t want
to bother, or simply don’t have the knowledge
to secure it themselves.
Thus this is a huuuge issue.
Regular home wifi routers, at least in germany,
come with a long random wifi password by default.
Obviously it’s a good idea to change it
anyway, because you trust the manufacturer
and so forth, but first of all you are safe
from just random people abusing your open
wifi for malicious activity.
And it’s also not a default key shared between
all devices.
And of course, something like this costs a
lot of money during manufacturing, because
each device has to be personalized.
It’s just an additional step you don’t
want if you produce low-end consumer electronics.
But let’s explore a few more things.
Last video we have seen an admin interface
that allows executing system commands.
So it was absolutely easy mode to get root
on this device.
But just for showing off some other techniques,
let me show another way how you can execute
system commands.
As you know there is a webserver running on
port 80, which can execute programs via CGI.
And this web server allows access to browse
files on the USB stick.
I found it by reviewing the webserver configs
after I already got root access, but you could
figure this out by either unpacking the firmware
or checking out the android application, which
has the URL for where you can find the USB
stick content in there.
And you probably know already where this is
going.
We can simply create a shell script that can
execute system commands and put it onto a
USB stick.
We can do this by first specifying what interpreter
is used for this file, in this case it’s
a shell script, and then we read from stdinput
a string, and execute it.
And the result will be simply printed to stdout
with echo.
CGI defines how programs interface with HTTP
requests, and the POST data, which is basically
the body of an HTTP request is passed to a
program as stdinput.
Thus we can simply send the command we want
to execute as POST data.
And the output of the program will be send
back as a HTTP response.
We have that now on the USB stick, plug the
USB stick into the device, and then simply
access this file from the URL, which will
cause it to be executed.
Now we just have to simply send a command
with the POST request, and we get the result
back.
Another basic root shell.
If you remember from last video, there was
also a root user with a password that we didn’t
know.
I tried to use hashcat to bruteforce the hash
in /etc/passwd, but I had not much luck.
My one graphics card is not that good.
So I tweeted and asked if anybody has better
luck cracking the hash, and who would have
thought, a little bit later @dissect0r comes
back with the password.
His rig was way faster than mine.
So thank you very much for helping out!
This means we can use this password now to
login via telnet, and we don’t need the
exploit from last video to change the root
password.
And every one of these devices shares this
root password.
So no need for an exploit, just login as root
with this password.
You could call this a backdoor, or being less
paranoid, a simple developer debugging credentials
left on there carelessly.
Either way.
It’s bad.
But let’s take one step further and look
at the device as if a user would have enabled
encrypted wifi.
Because all these attacks require you to have
network access to the device.
You could argue that these are all trusted
services locked behind a secure wifi.
BUT, being only connected to this wifi is
really annoying, because you don’t have
any internet connection.
Except you have a second connection to some
other network from your computer.
But the device can also act as an access point.
The wifi list with the XSS issue is actually
intended to connect it to another wifi.
If you do that, there are two ways you can
use the device.
If the device is connected to another wifi,
and you connect to the wifi of the device,
it’s basically a router, you can get now
access to the internet through it.
This means all traffic going through it can
be analysed, so it could be an easy device
to open an unencrypted wifi, let victims use
the internet through it, and you can man in
the middle all the traffic.
The other way to use it when it’s connected
to another wifi, is to be in that other wifi,
and now access the device via its assigned
IP.
And here is the issue, even if the device’s
WIFi is protected, it doesn’t matter, because
anybody on this side of the network can still
access it.
And it’s badly configured, because it exposes
all ports and services on that interface as
well.
This means, when you use this device in ANY
untrusted network, or have an open wifi, it
can be easily taken over.
There is one last thing I wanna show.
All those web interfaces don’t have a CSRF,
cross site request forgery protection.
This means we could build a website, that
when visited, will send the request to execute
a system command.
Basically what we have done with our python
exploit in the last video.
To do this, we first start with a html file
that contains a form.
This form will target the URL that is responsible
to execute system commands.
And we can set the HTTP method to POST.
And if you remember, the command is sent simply
as command.
So we add a hidden form element for the POST
data.
I think it would be fun to overwrite the index.html
with a string that we hacked it.
Our plan is to use this form, to submit a
POST request to the admin backend when a victim
opens a website we control.
And to do this I create another html file,
that will be the actual landing page, and
then use an iframe to embed the attack html
site with the form.
And then we can use some CSS to hide the iframe
from the victim.
Now we can simply add a short script to the
attack html code, which will automatically
submit the first form on this site.
So it will trigger the POST request.
We can use a simple php debug local webserver
to test this.
So now we can access this website in the browser
via localhost on port 8080.
Now the site loads, it loads the hidden iframe,
the hidden iframe will then auto submit the
form, but we run into the issue, that the
admin backend requires a username and password.
But that’s not a problem, we can simply
add those credentials into the URL.
Now it should not bother us.
So.
If we reload the page now, the loaded hidden
iframe will submit the form, which will issue
a POSt request with a command that should
overwrite the index page of the wifi hub router.
Mh. didn’t work.
Oops, the main index.html page is actuall;y
in the /Control/ subdirectory.
So let’s fix that.
Do it again.
And now instead of showing the administration
interface, it says that the device got hacked.
Nice.
Also changing this admin password wouldn’t
help in this case, because remember, the form
to change the admin password is not password
protected.
So we can do the technique we just used, cross
site request forgery, to change the admin
password first, and then issue the code execution
command.
Fancy Pantsy.
I think in the next video we are going to
have a closer look at the hardware.
﻿This video will be about the powerful technique
called Cross site request forgery, CSRF.
In the last videos we have explored XSS - Cross-site-scripting
- which allows us to execute javascript in
the context of a user’s session.
This allows us to perform any actions the
user could do.
Thus we can use it to send messages to other
users on the platform without the victim noticing,
or injecting fake news article into a site
or simply defacing it.
But if a site implemented user input securely,
properly escapes the strings, then you are
out of luck.
One might wonder why you cannot simply run
javascript on your own site that you control
and perform the same requests and actions.
Well the security model of the browser prevents
that.
This security model is called the same-origin
policy.
Whatever is running on my liveoverflow.com
domain is not allowed to access resources
cross-origin.
You will get an error.
BUT WAIT!
That doesn’t make sense…
How can the reddit domain access resources,
namely images, from this other origin imgur.com?
Does that not violate the same-origin policy?
You are so smart for asking this question!
The same-origin policy is obviously a little
bit more complex and there are a lot of different
cases you have to consider.
Let’s do some examples so you just see how
diverse it is.
I’m here on reddit.com.
It has the origin https://reddit.com
Over here I have https://imgur.com.
So on reddit I can easily use an HTML image
tag and load the image resource.
As you can see the browser did the request
without complaining.
On reddit you can get a lot of data in JSON
format.
That’s a neat trick if you didn’t know
about that.
Question.
Can imgur.com access those JSON responses?
It’s a simple GET request like the image
too, right?
And we were able to display the image, so
we should be able to get the content of this
request as well, right?
We can use XMLHTTPRequest to perform a GET
request.
Looks like it worked, but the response is
empty JSON, and doesn’t contain the data
we expected.
Let’s have a look at the network tab to
see what happened.
We first notice there is more than one simple
request.
The first one here got a response from the
reddit server with a Location: header.
The browser receiving this header will now
perform a redirect to this new location.
And this new location is /login.
Ahhhh!
That makes sense.
When we look closely, we don’t see any cookies
being sent along with this request.
Like it did when we simply opened this URL
on reddit.
A quick google search will tell you that you
can include the cookies by setting withCredentials
to true before sending the request.
But nope.
Now it doesn’t work.
Now the browser complains that you are violating
the same origin policy.
The domain imgur.com is not allowed to perform
a GET request to reddit.com with cookies.
This makes it kinda useless for an attack.
Because as an attacker we would like to extract
private user data, but without cookies it
will never contain private stuff.
Let’s try something else.
Let’s use an image tag like earlier and
load this .json file.
We look into the network tab and WTF.
It did send the cookies with this request.
So did we just find a bypass to the same-origin
policy?
Well… no.
You see, we can’t access the response of
this request.
We cannot access the json content, thus we
cannot access the private user data.
Ok.
So it looks like the same-origin policy is
pretty good.
It prevents us from accessing private data
cross origins.
Of course there are some technical possibilities
to loosen up this policy.
And chrome even tells you about it in the
error message.
With this special response header, that could
be set by the reddit server, this could be
allowed.
But one thing is still fishy.
With the image source we just performed an
authenticated, meaning cookies were included,
request to the other domain.
We don’t get the response, but could this
be exploited in any meaningful way?
Yes it can!
Let’s see.
You remember the different HTTP methods.
Like GET and POST. generally GET requests
are intended to fetch.
To get.
a resource.
And nothing else.
While POST is used by forms to submit data.
Like POSTing in a new thread.
POST-ing.
Get it?
Hehe.
This means GET requests generally don’t
affect the site at all, while POST requests
potentially change a user’s data.
So performing an authenticated GET request
should generally be safe, except when a site
is developed badly and a URL accessible via
GET performs an actual action.
If that is the case, you have found your first
cross-site-request-forgery, CSRF vulnerability.
So if there is for example a url that deletes
a user, like /profile/delete, and you embed
that as an image on your website, then every
user visiting your site will delete their
profile without them noticing it.
Okay, but let’s say a developer follows
this design and there are no state changing
GET requests.
Is the site safe?
Well here is another technique for POST requests.
I can create a form with the method POST and
the action aiming at the other domain, and
when the submit the form, it will perform
a POST request WITH the cookies.
So yes, we can perform an authenticated POSt
request as well.
Though, the site also redirected now to the
other domain.
But we can hide that from the user.
Or don’t care, because the attack is then
over anyway.
But how do I get a user to click?
Well a user doesn’t have to click, you can
simply auto-submit this form with javascript.
Just to make it clear, the same-origin policy
is not violated here, because our origin does
not get access to the resources, the response,
the data of this other domain.
So how do we protect from this kind of attack?
One approach would be, to compare a legitimate
request from our domain with an illegitimate
request from another domain and see if there
are differences that we could check for.
And yeah, we could check for the Origin header,
which is definitely different.
This might sound good.
It certainly prevents some kind of Cross site
request forgery attacks.
But for example sites like forums allow users
to embed their own pictures.
And if this forum is vulnerable to a GET CSRF
attack, then users could simply embed that
URL as an image into a message.
And then the request would come from the same
domain.
So this is not a bullet proof protection.
There are also some other kind of mitigations,
for example form post requests always send
the data URL-encoded.
you may have found this old stackexchange
thread telling you that a cross-domain request
with the content-type json are impossible.
And your endpoint could only accept JSON data
- and this might prevent some noobs from exploiting
it.
But your trust into this protection is flawed.
Down here, hidden in a comment, you find information
about a trick using navigator.sendBeacon.
It’s a super awesome trick.
And little tricks like that make the difference
between a normal web penetration tester and
a great one.
Anyhow, as you can see, this is also not bullet-proof.
So then what can we do?
The solution is a called CSRF token.
CSRF tokens can be implemented in a few different
ways, but generally you want a secret random
value to be set by the server in a way, that
it’s only accessible to the website running
on the same domain.
And this secret value has to be included in
every POST request to the server, otherwise
it will refuse to react to your request.
And that works, because the same-origin policy
prevents other domains accessing your data,
thus cannot get the secret CSRF value, but
the legit original domain can.
Obviously if you find a way to leak the CSRF
token, then you defeat the CSRF protection.
Now, this token doesn’t have to change with
every request.
But the idea is that it’s hard to predict.
So it shouldn’t be valid for forever.
ALSO, very very important, CSRF tokens have
to be BOUND to a user’s session.
Otherwise I could for example collect valid
CSRF tokens with one account, and then use
them in the CSRF attack against other accounts.
Cross site request forgery can be extremely
powerful and bypassing a weak CSRF protection
can be super fun.
But make no mistake, just because a website
has a vulnerable endpoint doesn’t mean it’s
a critical issue.
https://twitter.com/tqbf
Before we finish this here, I want to stimulate
your creativity a little bit by giving you
an example in how you can turn a few low severity
bugs into a cool attack.
Se here is the recipe.
First low-severity issue, is a stored self-XSS
vulnerability.
Self-XSS means that we can inject a javasript
payload into the website, for example a personal
notebook on that site, but it only affects
our own user account.
We can’t trick anybody else in executing
this javascript payload, because we are the
only one seeing our personal note.
So it’s useless, right?
Or is it.
Next issue is a logout cross-site-request
forgery.
This allows us to logout anybody visiting
our evil page.
The last issue is a login cross-site-request
forgery.
So this allows us to send the login credentials
to authenticate with that website.
But what the hell would we use that for?
Well, here is our attack plan.
First we create a new account and add the
self-XSS.
Maybe the payload can create a fake login
prompt telling the users to reenter their
password - so we can steal it.
Then we build an attack site that will execute
the following two things in order.
First it will make sure the victim is not
logged into the site, by using the logout
CSRF.
And then we perform a login CSRF with the
account credentials of our self-XSSed account.
Now we simply have to redirect the victim
back to the site, and the victim will be authenticated
with our account executing the self-xss, asking
for the password.
Beautiful phishing attack.
﻿In the last video we had our first example
of cross site scripting due to a shitty php
app.
But at the end we fixed our php code, by escaping
the user supplied string.
But I got this code from this tutorial website
- and that one is still vulnerable.
So let’s play around with that one.
The code here is loaded in an iframe below.
An iframe is like another webpage embedded
in this main webpage.
With right click we can investigate this iframe
and for example display it’s source code.
Now we also know the direct URL to this example.
So last time we tried to put a script tag
with alert into the name field.
But when we do that there will be no alert
popup box and we get an error in the Javascript
console, showing us that the Chrome XSS Auditor
prevented the execution of it.
The XSS Auditor is special to chrome.
Not every browser has such a protection.
For example Firefox does not have an equivalent
and will happily execute the alert.
But we want to dig deeper.
We want to not give up because of something
like this.
So let’s try to bypass the XSS Auditor of
chrome.
In this case we do not only have one GET parameter
that reflects input.
Infact there is this second one the age parameter.
And once there are multiple inputs, the XSS
Auditor is basically broken.
So what we can try is, to split up our XSS
payload.
The first parameter name will open the script
tag and start the alert but end at the quote.
Now we expect a string.
And For the age we start with a quote, close
the alert function parentheses and finally
close the script tag.
And when we submit this, we get an alert box
displaying us “br, you are”.
Let’s see what happened.
When we look at the html source, we can see
that we simply wrapped the text between the
two outputs into a string, and use it as a
parameter for alert.
And this is already enough to confuse the
XSS auditor.
As soon as you have multiple injection points
you can try to get really creative to fool
the Auditor.
Let’s try to push this one step further
and replace this first alert with something
silent, so we can put an alert with our content
afterwards.
One way is to still wrap the text in quotes,
but instead of using it as a parameter we
assign it to a variable a.
And afterwards we can still write our javascript
code and do the alert with something we want.
Okay.
Neat.
In the last video I briefly mentioned that
there are different context for XSS and each
might come with it’s own challenges or tricks.
So I made here a simple test php page where
you can play around with some XSS attempts.
So there is the normal HTML context, where
it simply echos into the page.
But then also two test cases where the echo
is inside of an attribute, one with quotes
around, the other doesn’t have quotes.
And then a script context, where the echo
is inside of script tags.
At the end I have a small little XSS auditor
trick which is quite fun.
Anyhow.
So.
We basically covered the first injection already
with the last video.
So let’s directly move on to the Attribute
context.
The first one is handled with parameter b.
Let’s open this page in the source view,
so we can see the resulting html, which makes
it easier to work with.
The parameter b is currently XSS, which we
can see got placed inside of the source attribute
of this image.
Theoretically we could now set b to an image
URL, and we would get an image displayed.
But can we also execute javascript here?
Well what we can try to do is to inject a
quote, which would end this attribute, then
we could inject a tag closing greater than
sign and then include a script tag.
That looks good, that could work, but unfortunately
the XSS Auditor caught this attempt as well.
So this doesn’t work on chrome, but generally
it would be an XSS.
For example in Firefox.
Also the red highlighting makes it super cool
to see if our attempts injected valid javascript.
So that’s cool.
Would this still work with htmlspecialchars
which we used to fix the code in last video?
We can test that with the parameter bb.
Nope.
Doesn’t work.
The double quote and the greater than sign
get encoded, so this looks safe.
But there is a third test.
What about the single quotes?
Didn’t work.
No. wait.
The single quote did not get encoded?
Maybe we can still turn this into an XSS.
We just can’t use the greater than sign.
Luckily image tags have an event handler that
fires if an image couldn’t get loaded.
This means we can inject an onerror attribute
that calls alert.
And yeah, that worked.
Chrome recognized the attempt of executing
javascript.
Awesome.
So htmlspecialchars does not protect you in
every case.
For example in the attribute context with
single quotes it’s note nough.
The php manual documents this, it says you
have to specifically set the `ENT_QUOTES`
flag, otherwise single quotes are untouched.
Another lessons learned in - read the frckn
documentation!
Let’s move on to the next one.
This one is easy.
Like the previous example we are in the attribute
context, and now we even don’t have to take
care of quotes.
So even if single quotes are escaped, you
just simply don’t use any quotes in the
attributes.
So the injection with onerror works great
with and without htmlspecialchars.
Now the last example is the script tag context.
This looks even more simple.
Just write alert(1) and it should get executed.
Looks good, but the XSS auditor did not catch
this one.
If we try this in normal view we trigger the
xss.
And this obviously also works despite htmlspecialchars.
So those examples showed you that using htmlspecialchars
is not enough everytime.
There are many places where things can go
wrong.
So be careful.
And BE AWARE in what context you output user
supplied strings.
But now whats up with those tricks down here.
The first Trick is just an example how somebody
might try to prevent xss.
It replaces all occurences of script.
In the last video we had our first example
of cross site scripting due to a shitty php
app. But at the end we fixed our php code,
by escaping the user supplied string.
But I got this code from this tutorial website
- and that one is still vulnerable. So let’s
play around with that one. The code here is
loaded in an iframe below. An iframe is like
another webpage embedded in this main webpage.
With right click we can investigate this iframe
and for example display it’s source code.
Now we also know the direct URL to this example.
So last time we tried to put a script tag
with alert into the name field. But when we
do that there will be no alert popup box and
we get an error in the Javascript console,
showing us that the Chrome XSS Auditor prevented
the execution of it.
The XSS Auditor is special to chrome. Not
every browser has such a protection. For example
Firefox does not have an equivalent and will
happily execute the alert.
But we want to dig deeper. We want to not
give up because of something like this.
So let’s try to bypass the XSS Auditor of
chrome. In this case we do not only have one
GET parameter that reflects input. Infact
there is this second one the age parameter.
And once there are multiple inputs, the XSS
Auditor is basically broken.
So what we can try is, to split up our XSS
payload. The first parameter name will open
the script tag and start the alert but end
at the quote. Now we expect a string. And
For the age we start with a quote, close the
alert function parentheses and finally close
the script tag.
And when we submit this, we get an alert box
displaying us “br, you are”. Let’s see
what happened. When we look at the html source,
we can see that we simply wrapped the text
between the two outputs into a string, and
use it as a parameter for alert. And this
is already enough to confuse the XSS auditor.
As soon as you have multiple injection points
you can try to get really creative to fool
the Auditor. Let’s try to push this one
step further and replace this first alert
with something silent, so we can put an alert
with our content afterwards. One way is to
still wrap the text in quotes, but instead
of using it as a parameter we assign it to
a variable a. And afterwards we can still
write our javascript code and do the alert
with something we want.
Okay. Neat.
In the last video I briefly mentioned that
there are different context for XSS and each
might come with it’s own challenges or tricks.
So I made here a simple test php page where
you can play around with some XSS attempts.
So there is the normal HTML context, where
it simply echos into the page. But then also
two test cases where the echo is inside of
an attribute, one with quotes around, the
other doesn’t have quotes.
And then a script context, where the echo
is inside of script tags.
At the end I have a small little XSS auditor
trick which is quite fun.
Anyhow. So. We basically covered the first
injection already with the last video. So
let’s directly move on to the Attribute
context. The first one is handled with parameter
b.
Let’s open this page in the source view,
so we can see the resulting html, which makes
it easier to work with. The parameter b is
currently XSS, which we can see got placed
inside of the source attribute of this image.
Theoretically we could now set b to an image
URL, and we would get an image displayed.
But can we also execute javascript here? Well
what we can try to do is to inject a quote,
which would end this attribute, then we could
inject a tag closing greater than sign and
then include a script tag. That looks good,
that could work, but unfortunately the XSS
Auditor caught this attempt as well. So this
doesn’t work on chrome, but generally it
would be an XSS. For example in Firefox. Also
the red highlighting makes it super cool to
see if our attempts injected valid javascript.
So that’s cool.
Would this still work with htmlspecialchars
which we used to fix the code in last video?
We can test that with the parameter bb. Nope.
Doesn’t work. The double quote and the greater
than sign get encoded, so this looks safe.
But there is a third test. What about the
single quotes?
Didn’t work. No. wait. The single quote
did not get encoded? Maybe we can still turn
this into an XSS. We just can’t use the
greater than sign. Luckily image tags have
an event handler that fires if an image couldn’t
get loaded. This means we can inject an onerror
attribute that calls alert. And yeah, that
worked. Chrome recognized the attempt of executing
javascript. Awesome. So htmlspecialchars does
not protect you in every case. For example
in the attribute context with single quotes
it’s note nough. The php manual documents
this, it says you have to specifically set
the `ENT_QUOTES` flag, otherwise single quotes
are untouched. Another lessons learned in
- read the frckn documentation!
Let’s move on to the next one. This one
is easy. Like the previous example we are
in the attribute context, and now we even
don’t have to take care of quotes. So even
if single quotes are escaped, you just simply
don’t use any quotes in the attributes.
So the injection with onerror works great
with and without htmlspecialchars.
Now the last example is the script tag context.
This looks even more simple. Just write alert(1)
and it should get executed. Looks good, but
the XSS auditor did not catch this one. If
we try this in normal view we trigger the
xss. And this obviously also works despite
htmlspecialchars.
So those examples showed you that using htmlspecialchars
is not enough everytime. There are many places
where things can go wrong. So be careful.
And BE AWARE in what context you output user
supplied strings.
But now whats up with those tricks down here.
The first Trick is just an example how somebody
might try to prevent xss. It replaces all
occurences of script. This means you cannot
inject a a script tag. There are two possibilities,
first one is simply not use a script tag.
For example use the image payload we used
above. An image tag with onerror attribute
to fire an alert. Though the issue is that
the XSS Auditor catches that. But there is
a way around it. We can use the lame attempt
of XSS prevention by replacing script, to
our advantage.
We can randomly place script inside of our
image tag payload. And the occurrences of
script will be removed. And now the URL parameter
does not resemble anything that is found on
this page. Thus Chrome cannot guess that this
parameter is responsible for this image tag
here. So this bypassed the XSS Auditor.
The second trick here is fun. So first we
have to understand this Javscript code. First
a variable ASD is initialized and set. And
then this script checks if ASD exists. If
the variable ASD does not exist you would
execute the alert.
But how could you redirect code execution
of this javascript so that it would execute
this alert? I give you a second to think about
this….
Okay. here is the solution. We abuse the XSS
auditor, who would have thought. We use a
fake parameter with the first script as value.
Now Chrome thinks that this parameter is responsible
for this script tag, and it will disable it.
Prevent it’s execution. Thus ASD never got
initialized and we successfully redirected
code execution to trigger the alert.
Without the source view we can see the alert
popping up.
Amazing. That’s so cool.
﻿This video is the third and final video where
we will now finish the exploit for stack level
0 from protostar, which we have compiled on
a modern system.
In the first part we got a general overview
of what has changed when the code is compiled
with a more modern compiler and looked more
closely at the stack cookie.
In the second part we then ignored the cookie
for now and identified a few more exploitation
mitigations and developed a bypass for them.
So only one thing is left.
Finally defeating the stack cookie.
Like we talked about in the first video, we
can bruteforce a stack cookie if the binary
is a 32 bit binary.
There are around 16 million possible values
for a stack cookie.
That’s not that much, but 16 million executions
is maybe a number where you start want to
optimize a bit.
While I’m not an expert in super fast computing,
I decided I didn’t want to write a potentially
slow python script, but write some C code.
But like I said I’m not an expert in what
is the fastest and I actually suspect that
maybe the bottleneck here would not be a slow
script, but the kernel which has to do a lot
of stuff to execute the program over and over
again.
So maybe it’s unnecessary to write C code
and maybe my C code is very bad too.
But I just wanted to mention it that it’s
not always easy to decide what is the best
approach.
Now that we said that, let’s try to approach
this step by step.
First.
How do you execute a program in C. Well, there
is a system call for it called exec.
But usually we never call syscalles ourselves
directly, but use wrapper functions provided
by something like libc.
So libc offers a few different versions of
exec, but they are ultimately all using the
same exec syscall underneath.
It says here in the man page:
“The exec() family of functions replaces
the current process image with a new process
image.”
I think when you never thought about how a
program is executed before, this sounds really
weird.
“Why do you replaced the current process
and not just execute it?
That’s so weird”.
Well that’s just how it works, that’s
the execution model of Linux.
And so in our case we don’t just want to
exec and thus replace our program, but we
want to execute the stack0 binary as a new
process over and over again.
To spawn a new process we have to fork the
process before we exec.
fork() creates a new process by duplicating
the calling process.
The new process is referred to as the child
process.
The calling process is referred to as the
parent process.
And maybe also interesting is this down here:
Difference between C library function and
the actual kernel.
Since version 2.3.3, rather than invoking
the kernel's fork() system call, the glibc
fork() wrapper [...] invokes clone(2) with
flags that provide the same effect as the
traditional system call.
So what you do to execute the process over
and over is to:
First fork our current process.
now we have a child.
An actual new separate process.
And you have to imagine this code is now dooplicated,
we have two processes running the same code,
just one runs as the child and one runs as
the parent.
And you can check the return value of fork
which process you are.
In the parent process you get the pid of the
child.
In the child it’s just 0.
And then in the child process we can call
exec, to replace the current process with
stack 0.
Now in our case we want to communicate with
the child.
Meaning we want to write the exploit input
to it, and read the output of it, to determine
if we were successful.
Usually you would do this by creating pipes.
pipe() creates a pipe, a unidirectional data
channel that can be used for interprocess
communication.
The array pipefd is used to return two file
descriptors referring to the ends of the pipe.
pipefd[0] refers to the read end of the pipe.
pipefd[1] refers to the write end of the pipe.
Data written to the write end of the pipe
is buffered by the kernel until it is read
from the read end of the pipe.
Basically the same pipe you can use on the
commandline.
You pipe stdout from one program, cat, into
the stdin of another program, grep.
That’s why we call this character a “pipe”.
So for basic stdin and stdout communication
you would create two pipes.
And then when you fork, because you clone
the process, the child and the parent have
access to the same pipe.
Now obviously depending on if you are the
parent or the child, you use one or the other
side of it.
And in case of the child, we are actually
going the replace the default stdin and stdout
now with those pipes.
By calling dup2.
The dup2() system call performs the same task
as dup(),
And The dup() system call creates a copy of
the file descriptor.
After a successful return, the old and new
file descriptors may be used interchangeably.
They refer to the same open file description
and thus share everything.
But dup2, instead of using the lowest-numbered
unused file descriptor as dup(), it uses the
descriptor number specified in newfd, the
second paramenter.
If the descriptor newfd was previously open,
it is silently closed before being reused.
So dup2 closes the current stdin and stdout
of the child, and plugs in the new pipe we
created.
And when we exec, the stack0, and replace
the current process with the new one, stuff
like open fildescriptors stay in tact.
So the new process will use the pipes we just
connected for reading input and writing output.
And then in the parent we can simply read
and write to the other end of the pipe and
thus communicate with the child process stack0.
A nice thing to do is to close the ends of
the pipes you are not using in either process.
So for example we don’t need the reading
side of the stdin pipe because we want to
write, send data, to the child process.
Ok.
Once we have written our buffer overflow input,
we can wait for the child process to finish
and read the output to see if we were successful.
Now here is a first big issue.
Buffering.
Libc will buffer output you write.
So the output of the child process is buffered
in the process.
And you can imagine, that if we do a buffer
overflow, screw with the stack and get a segfault
this buffer is lost.
The program is just dying horribly.
But maybe you think that doesn’t make much
sense, because we showed in part 2, that our
exploit theoretically works and we see the
output on the shell.
We saw the modified variable message.
SO how how does it make sense that the shell
would see the output but I’m telling you
now, we won’t see it with the code we just
have written?
Well.
There is a difference to how libc buffers
output depending on what kind of pipe it’s
connected to.
And in our case we have just used regular
pipes and libc will buffer the output data
until the process calls flush(), or maybe
until it’s filled nicely, maybe after 1024
bytes or so.
I don’t know.
But we have neither, the output is super short
and the child process never calls flush().
So what’s different on the shell.
Well programs executed by the shell are not
connected via regular pipes, but are connected
to a pseudo terminal.
Pty.
And when libc sees.
That the output is written to a pty, pseudo
terminal, then it will flush() the buffer
upon a newline.
Because newlines are like the ultimative indication
that you want to print a new line (laugh)
on the terminal output.
I think it’s like speed thing, you don’t
want to flush if not necessary, but on the
terminal you want to see outputs after a newline.
This means, we could also execute the stack0
program in the context of a pty, so that we
fool libc into flushing on every newline.
And there is a convinient libc function that
does that for us.
Called forkpty()
The forkpty() function combines openpty (open
pseudo terminal), fork(2) (which we know),
and login_tty() to create a new process operating
in a pseudoterminal.
The file descriptor of the master side of
the pseudoterminal is returned in amaster.
So that’s really cool.
We fork a child process and already get the
filedescriptor so we can communicate with
the child process.
Then I disable a few options of the terminal,
for exampel I don’t want to echo the input
again.
For example if you watch my embedded hardware
security CTF videos you notice that usually
whenever I type something on the shell to
the board, I don’t see the characters I
type, that’s because I didn’t configure
the terminal to echo back the characters.
While it would have been nice there, I don’t
need it here.
And there are a few other options that could
screw with what we want to do.
And then we also don’t have to fiddle with
pipes.
So the child is just exec now.
In the parent we define our bufferoverflow
input, that’s basically the one we developed
last video, and then also add some random()
function to get three random bytes for the
cookie.
And place those into the buffer overflow string.
A simple ugly loop to avoid newlines, because
that would indicate the end of our input,
and we dont’ want that.
Then we write the bufferoverflow string to
the master filedesriptor of our pseudo terminal
and stack0 will read it and will get exploited.
Then I create a short loop to check the status
of the child, but I don’t want to block
and wait for it, because the child could horribly
die or not die because of the buffer overflow,
so I just check the status a few times in
a loop and if the child is dead, we continue,
If we waited already a few times we decide
to kill the child process,
And otherwise we sleep a bit.
Usually it shouldn’t loop much, as the child
program is very short, but it’s a safety-net.
BTW. program ids, pids, are prone to race
conditions in linux.
You see we don’t have some kind of handle
direclty pointing to the child process, we
only have the number.
And numbers can be reused.
So theoretically our child could have died,
another process like a webserver could have
been executed and assigned our old pid, and
then we kill it here.
And there is no better way, linux is just
really ugly some times.
Anyway.
One other thing I want to add now is a signal
handler, which will be notified if the child
dies or so.
We could just read the output after the wait,
but we don’t know why and how the child
might die and so forth, and I also found it
to be a third slower if I do that.
So used the signal handler instead.
This handler function is called to notify
us if anything happens to the child.
So when it receives a SIGCHLD.
And in the handler function we then read from
the terminal the output of stack0.
First we read the “Try again?”
message.
And then potentially read the stack smashing
detected error, OR maybe the successful modified
variable message.
Or maybe nothing.
Then I do an ugly check of the second output
to see the success message.
If that’s the case we print it and we are
done.
So now it’s basically ready.
I add some more debug output to see whats
going on, add an argument to supply a seed.
and then we can compile it.
Because we want to use forkpty, we have to
also link the utils library.
Here you can see how many executions we get
per second per process.
This machine has only one CPU, so this will
take a while, let’s come back later.
Let’s see.
Mhhm… nothing happened yet.
Maybe let’s rent a bigger server for a few
hours with more CPU cores.
Mmh maybe this one.
Now to run it I do some ghetto parallelisation.
But oh what.
Only 9 executions per second, what kind of
crap is that?
If you look at the processes you can see something
called apport.
Apport is a system which:
intercepts crashes right when they happen
the first time,
gathers potentially useful information about
the crash and the OS environment,
Ah, so because we constantly crash a process
this thing is gatehring information and slowing
everything down.
Let’s disable this service.
And then let’s wait for a bit.
AWWW YEAH!
See, one process output the modified variable
message.
How amazing is that.
I admit not the most reliable exploit, but
it worked.
I’m happy.
If you have a better exploit strategy for
this here, please share it with us.
I’m really curious what other techniques
could be used to exploit this program in a
more reliable way.
Thanks guys, see you next time.
﻿Let’s do another trip to the United Exploitation
country. We already visited the casino and
the photo manager, so let’s continue this
road and head to the animals.
This is a 200 points exploitation challenge
and it doesn’t provide us anything to reverse
engineer. So we must be able to blindly exploit
this.
The description reads:
After decades of research, we finally managed
to catalogue all the animals on the planet
earth. Including very rare pictures!
Often times the text can contain hints, but
this one is so short and generic, that it
probably doesn’t really include anything.
So let’s load the challenge onto the board,
and get started.
Let’s quickly checkout the functionality.
We see here a menu and a prompt where we can
enter characters, The menu items indicate
that we can enter a c to print a cat or a
d to print a dog or a m to print a mouse.
We can also try to enter some more characters.
Like write “cat”, and while it still just
prints what the first character says, it’s
interesting that we can enter more characters
and get the whole string.
So we could definitely try and see what happens
when we enter more characters and you might
already notice some odd behaviour, but let’s
not get ahead of ourselves, this was the mistake
I first made when approaching this challenge.
Let’s do this systematically.
I decided to use a whiteboard to visualize
what goes on in my head as well as to document
each discovery. Especially with blind challenges
like this you need to build a good mental
model of the program running there. And taking
notes is crucial.
So I start with writing down what I know.
That there are three different characters
in the menu. M, C and D, so I wonder, is there
maybe a hidden menu option?
Let's find out. Let's write some code that
tries out every character and we look at the
response.
By now you already know this code, this just
sets up the serial connection with the board
and some helper functions.
So first we read until we get the menu enter
promot so we can send a character, and it
makes sense to put this into a loop. So now
we print the last output, construct our payload,
which is just one character and enter it into
the menu. Then we read the result, and try
the next character.
When we try to run it it doesn’t find serial,
I forgot to enter the virtual environment.
If you do any python programming make sure
to checkout virtualenv. So now it works and
it tries every character. But it’s a a lot
of output, I think it’s better if we remove
all the newlines and also show the raw bytes
with repr(). Now it’s easier to spot stuff.
When you now look through here, we notice
that some characters, for example the percentage
sign are turned into a null-byte. There are
a couple of them. No idea if it’s important
in some way or not, but let’s make sure
to note these down. It’s important to not
ignore an oddity like this.
But besides that we didn’t find any secret
menu option. So let’s think of something
else we could try. How about trying out different
lengths of input. Let’s modify our code
to test that. So instead of using the loop
number as a character, we use it to change
the length of the input. And we just try it
with some As.
When we run it we can observer multiple things.
First of all, the input seems to be capped
at like 59 or 60 characters. Our input keeps
growing, but the output stops. So let’s
take notes of that.
The first shorter lengths happened obviously
very quickly so if we look there again more
closely, we notice that with the 11th character
we screw with something and suddenly leak
a lot of bytes.
Let’s write it down.
So that’s very interesting, what is so special
at this last character position. We can write
some code to explore that further. Let’s
enter a couple of Cs and then play with this
exact value.
And here is a very interesting result. You
see we always enter a bunch of Cs but it only
prints the amount of bytes we specify. So
nullbyte will print nothing and 3 will print
3 characters. And so when we get to high byte
values, like actual ascii characters, we obviously
leak like 30 or mroe bytes. It doesn’t leak
up to 255 bytes, so there is a limit, but
we can write this down. And we can change
from 11 chars dumps some memory, to that the
11th char controls the output lenght.
So now we now that we have this big range
of memory we can write to to, and certain
positions can contain important information.
So for example the 11th character is the print
length. And to take notes we can enter the
bytes that we leak into this long array.
Also the ascii character number 7, hex 37,
prints the maximum amount of output. After
that the output doesn’t grow, that’s why
I write a 7 here.
So no we wonder, what could other positions
in this memory here mean.
When we fuzzed the input length we used the
character A, so I’m wondering, what if you
used a character that actually prints a picture,
like c. The cat. So modify the code slightly
and then let’s see what happens. And very
quickly the cat disappeared.
And if you do the same thing for dog, the
dog picture disappears a little bit later.
So you can write down how many characters
it takes to reach a point where a particular
picture is not shown anymore. That’s very
interesting. What could we possibly overwrite
in that memory that causes this behaviour?
Look at the memory we leaked and mark the
apparently interesting offsets. It’s clear
that these bytes must mean something. these
bytes have something to do with cat. So let’s
modify the code. So I add the three bytes
I know are the correct value, but replace
the first one to try different bytes.
But it doesn’t do anything. It seems like
there is only one correct value that leads
to printing the cat. In retrospect it’s
probably like a stack cookie. We must use
that one particular value.
So let’s move on to the next byte. Do the
same thing. And this time it does print the
cat more often. But it’s a bit weird. I
have strong feeling that it is part of an
address, but I don’t know.
Let’s move on to the third byte. Oh holy
crap! This shifts the rat. This clearly moving
the cat around. So that is definitely part
of the address, or offset into memory where
the cat is stored.
Also it’s very interestign to see some weird
characters before and afterwards. It’s not
just 0 and cleary not just random garbage.
So that’s something we shouldn’t ignore.
But we still didn’t get the big breakthrough.
But if you look at the leaked memory dump,
you will notice that the dog and mouse seem
to have 4 interesting bytes, while the cat
only ahs three. Maybe the 4th byte of the
cat just happens to be 0, but actually it
also has 4 byte. Ignore some of the notes
here, I was just exploring some random ideas.
Anyway, let’s try the 4th byte.
wooooh. This output is damn interesting. This
is gold.
If you look very closely, you notice that
these weird characters have indeed a pattern.
Doesn’t this look like the dog? The shape
is there, just the wrong characters.
And here this looks like the mouse.
This reaaaaly stinks like XOR. The pattern
is there, just the characters have to be transformed
into something else.
Si let’s write a simple python script that
tries out all different XOR keys, applies
them to the leaked character output and prints
it. And when we now look through the possible
outputs, we find a cleartext mouse!
So to recap, We have a big chunk of memory.
And at certain offsets we know there is some
kind of information regarding the animal pictures.
At least the last two bytes affect what we
read from memory. We were able to extract
an XORed picture from the mouse by changing
the bytes of waht corresponded to the cat.
So we clearly control here the location of
memory we read.
But the output is XORed.
So now, we have a first serious shot at getting
the flag.
Let’s modify our loop to iterate over all
2 byte values. Then we take the leaked memory
output, pass it to a function that brute forces
all possible XOR keys. And our assumption
is, that some memroy location will contain
the flag, just XORed, so if we find the word
FLAG in any of the decrypted memory leaks,
we won.
Makes sense, right?
So let’s try that! Oh man, I did first make
here a mistake. I meant to brute force the
3rd and 4th byte, but if you look closely
I brute force the 2nd and third. Obviously
that didn’t work. So after fixing that and
some other minor mistakes I let it run, and
it pretty much immediately outputs the flag.
Let’s hand it in and collect our 200 points.
﻿A7 - gee cue elle was a hard misc challenge.
It combines a database query injection with
optimizing the algorithm to perform the attack.
So also partially a programming or computer
science challenge.
When I first read the title I mispronounced
it as “gi que elle”, so a more german
pronunciation and I totally didn’t get what
it tried to hint at.
But more about that later.
Let’s get started.
A7 - gi que elle,
We installed a fancy automatic attack protection
system to be more secure against automated
attacks from robots and hackers, so it can
be fully A7 compliant.
And a hint with .yaml tilde.
So the first thing I did was look up a7 again.
because of the “fully a7 compliant” comment,
I immediately thought it’s probably that
OWASP thing.
So what is it again?
OWASP Top 10.
A7 insufficient attack protecion….
Ohhhh that thing.
What a bullshit item on that owasp list.
If you want to read about some infosec drama,
search for a7 controversy.
And this challenge is certainly a reference
to that.
Anyway, I took this as a hint that I should
use some automated attack tool.
Which in retrospect I think was wrong.
But whatever.
The description has a few more hints, but
we will get back to that in a minute.
Let’s first check out the site.
The challenge here links a .html file with
the following content.
So part of the subdomain can be random.
It’s obviously to give every player a unique
site.
We will see that come up later.
On the site itself we can find a simple login
field and when we inspect the html, we see
a validation pattern that tells us the username
has to be admin and the password has to follow
a more complex pattern.
It’s basically a valid flag pattern.
CTF curly braces then some characters that
start with quotas, and if you paid attention
you can see that the subdomain is basically
that part here, and then followed by 64 characters.
So it seems like if we find the correct password
for the admin user, we have found the flag.
Like I said I though the a7 hint meant to
tell me to use some tool, so I used nikto
which basically does something like dirbuster
and it found an app.yaml file.
It turns out I could have found that myself
if I had looked into the robots.txt, oh well.
That qa entry here threw me a bit off but
ignored it mostly.
And this is where the second hint comes into
play.
The yaml tilde.
So if you didn’t know what that means, some
editors such as emacs or maybe vim create
files to track your current progress in case
you don’t save and it crashes or so.
Then it can be recovered.
And some editors create a file with the same
name but append a tilde.
And that’s basically what happened here,
the developer apparently opened the file in
an editor and it created that tilde file and
for some reasons it didn’t get deleted.
The yaml file is really interesting, it’s
basically a web application config file for
google app engine and it tells us here where
the app that handles the page lives.
I might also google a little bit to learn
more about app engine to understand the structure
of this file.
So basically I’m hunting now for the application
sources.
In the google app engine docs I find a hello
world example using main.py, so I tried that.
And with the tilde there as well, I can leak
the content.
So now we got the sources.
The code doesn’t look too big, but there
are some dense areas.
A first thing you might notice is, that there
is something about quotas and an abuse detection
system.
Mhmh…
And when I looked at the code, there was a
lot of time calculations and I hoped I didn’t
have to understand that right now.
So I continued.
Here the login post request.
That must be a very important part.
And indeed, I immediately noticed a query
language injection.
You see this here the colon 1 together with
the parameter here is safe, but this direct
python string manipulation with percentage
s is unsafe.
We can inject another single quote and break
out of the string and screw with the query.
So is this an SQL injection?
Well.
kinda.
not really.
As you can see here in the function name it’s
gql.
Google query language.
At this point I still didn’t get that the
title of the challenge was supposed to hint
for that.
Gee cue elle.
But.
Oh well.
So what can we do with that, ideally we want
to be able to log in.
So what kind of features could we use in the
query language.
If you look up the grammar of the query language
it’s really short and there is not much
you can do.
So we are here in the WHERE condition and
all we can do is append more conditions with
AND.
There is not even an OR.
And we could sort or limit the result but
that’s not really useful.
So no SQL UNION SELECT to inject a password
we can control to bypass the authentication
or so.
The only output we have is either wrong username
or wrong password.
So it’s going to be a blind injection.
The idea is if we make the query return a
password, then the password we supply would
be wrong and if we make the query return no
password, we would get the wrong username
error.
We can play with this.
GQL doesn’t have advanced string stuff like
SQL.
For example there is no WHERE password Like
A%.
Where password like B%.
to slowly bruteforce the first character.
But we can basically simulate that with greater
or lower than.
So you can inject a compare if the password
is bigger than A, and if that’s the case
the query returns the password and we get
wrong password error.
But if the password was not bigger than A,
then the password might start with A or another
char that’s lower than that, then the query
would not return a password and we get the
wrong username error.
So we can in fact slowly bruteforce the password.
So I start writing some code to do that.
The comparison works by ascii value, so the
order of chars is how they appear in ascii.
So lowercase a is bigger than capital A.
So I was writing that code but I quickly ran
into the “Abuse detection system”.
I was banned for 90 seconds because I either
triggered two errors in 30 seconds, or made
more than 13 requests per 30 seconds or it
took me longer than 2240 seconds.
Oh damn.
Because with every request we get an error,
we can only perform one request every 15 seconds.
To not trigger the 2 errors in 30s rule.
And not only that, we only have 2240 seconds
time for that.
That’s only 150 requests.
But the flag is already at least 64 bytes
long.
We know parts of the password just not the
main part.
This means we have only like 2 requests per
character.
We will never bruteforce the password with
those restrictions.
So I started to review more of the code and
long story short, I couldn’t find a bypass
for the abuse detection system.
Also the password is dynamically generated,
but it’s safe.
It’s hmac with a secret key and the first
part of the hostname.
Which means if you know the secret key and
I give you a valid flag, you can verify that
it’s valid.
The first part generates the second part.
So also no tricks possible there.
Basically I had following options in mind:
Bypass detection system
Find an issue in the dynamic flag/password
generation
Better gql injection
Try to optimize the bruteforce
Like I said first one lead nowhere, second
one was also unlikely, third one too, the
query syntax is just so short, which means
the only viable way is optimization.
So an obvious first improvement to the bruteforce
with greater and lower is to do a binary search.
Basically we have an oracle that tells us
with a guess of the password if the real password
is greater or lower.
Which means we can lower the amount of requests
necessary.
My first implementation did this per character.
Each character has 64 options and with binary
search you can find the right guess in about
log N steps.
So about 4.1 steps necessary per character.
Which means we need roughly 262 steps in total,
which doesn’t work, because we only can
do up to 150 requests in the time we have.
So I was stuck there for a while.
A lot of time went into fixing programming
bugs and testing it and because it’s so
slow.
with 1 request every 15s it is just took ages.
But then when I did another round of auditing
the code I noticed something.
So error requests, of which you can only have
two every 30 seconds, are only counted on
exceptions.
And if you look closely in the login code
you can see that only a wrong password triggers
an exception.
Wrong username is just a regular request of
which you can have 13 per 30 seconds.
That’s the key!
We need to optimise the binary search to favor
wrong username over wrong password.
So how do we do that?
Well in binary search you always select the
center of your search area.
This means there is a 50:50 chance that your
item is either greater or lower.
So how can we skew that chance.
Well instead of picking the center, we pick
something more towards one side.
For example if we do a 75:25 split, we have
a much higher probability that our item is
going to be lower than that new index.
In our case we can have 13 requests in 30
seconds but only 2 of those can be errors,
so we have 2 divided by 13, roughly a 85 to
15% split.
Awesome.
Also I optimised the string generation by
working with numbers rather than a character
string.
So basically our string we want to brute force
has an alphabet of 64 characters.
So it’s like a base64 number system.
Which means we can convert between base10
and base64.
Don’t confuse it with base64 encoding, I’m
really talking here about the mathematical
numeral system base 64.
Maybe you had to convert base 10 to base 16
or base 3 in school, that’s basically what
I did.
So I created two functions to convert a base64
number to a base10 number and vice versa.
So now I can treat the binary search as a
search of a number.
The highest value is basically lowercase zzzzzz,
which is a huge number.
And this is the code I came up with.
I use the requests module to perform the gql
injection request.
Then I define the alphabet for the flag in
ascii order.
Here are my functions to convert from base64
to base10 and vice versa.
And a function to display a number line to
visualise the search.
And here are the important search variables.
At the beginning the highest number is basically
zzzzzzz
And lowest is obviously 0.
The current flag we will check, so the search
index is initialized with 85% from the top.
So that it’s skewed towards higher values
and our real password is probably lower.
And those are lists to count the exceptions,
so wrong passwords and regular requests I
make.
At the beginning of the search loop I have
a look at the lists that remember all exceptions
and requests and remove the requests that
are older than 30 seconds, because they don’t
matter anymore.
But if we have had more than 1 exception in
the past 30 seconds, or had more than 11 regular
requests, we are going to sleep for a second.
Then we clean up the list again and maybe
sleep again, until the condition is not true
anymore.
Then we are allowed to perform another request.
So we convert the current search index to
the flag string and perform the request.
Some nice log output
And then we check the result.
If it was wrong username, then our guess was
bigger than the real password, so we can set
the highest possible value to that and move
the search index down a little bit.
But always move it in the 85:15% ratio.
If we get wrong password, we get an exception,
so we rememebr the time we had the exception
and we also know our password was greater
than our guess, so we take the upper part
and move the search index higher.
And that’s it.
We just have to let it run now.
Doesn’t it look beautiful?
Here you can see how the search index, the
X always skews to the higher values and how
the search space is narrowed down.
And there is a nice ratio now of wrong username
and wrong password requests.
This takes now a while.
Basically 2240 seconds or 37 minutes.
But we will still just barely make it in that
time.
So I started many instances in parallel and
hoped that at least one will succeed.
And this is where I started to become nervous.
Because the end of the CTF was approaching
and I was not sure if it will work, I didn’t
have one successful run yet.
Will the flag I find work or will it break?
Will I do my calculations right?
Do I have bugs?
And about 10 minutes before the end two processes
approach the final guesses.
There we go, search space is apparently now
0.
We found our flag.
hopefully.
So I tried to enter the flag, super shaky
hands because I had to be fast with minutes
left but it didn’t work.
Wrong flag.
Also I couldn’t login with this flag.
It was not correct.
DAMN.
But I had a hunch what the problem was.
I probably didn’t quite get the calculations
correct, so I was probably 1 or 2 numbers
off.
So i just adjusted the last character of the
flag and after a few attempts, I got the right
flag.
Damn that was close.
But really happy at the end, because just
FYI, I spend probably like 12 hours on this
challenge.
﻿To be able to find security issues in software,
one has to understand how software is written.
It’s very helpful to explore different programming
languages to understand their differences
and similarities and to get into this special
way of thinking.
Often when I use a software I imagine how
a certain piece of it might have been implemented
- this makes me think about the software architecture
and potential difficulties the developers
may have had, which helps to find bugs that
can be exploited.
When I was younger I used programming to write
damage calculators for browser games or simple
chat programs that we could use at lan parties
to communicate. Nowadays I use programming
more as a tool to solve other problems or
help me with repetitive tasks.
To get a feeling what programming is like,
we will have a look at a very simple program
implemented in the very old and low level
language C and in the next video we use the
more modern scripting language python. You
will notice a lot of similarities in terms
of structure but also how different their
syntax looks like.
Let me first show you what our little program
will do. To execute it you simply have to
enter the path. Because we are in the same
folder we have to start the path with the
“dot”, which is an alias for the current
location. Maybe you are wondering why the
other programs like “LS” don’t require
a full path to execute them.
The reason for that is when you enter a command,
or generally speaking the name of a program,
the shell will look at the configured PATH
environment variable, which contains a list
of directories where to look for programs.
There are many different environment variables
that all have their purpose, but because we
are only interested in the PATH we can use
the pipe to redirect the output of env, into
another program called grep, which can filter
for lines that contain “PATH”.
I use grep to filter output of other programs
all the time. It’s one of the most useful
tools.
Another way to get the content of PATH is
to use echo to print the variable.
Now let’s use “whereis” to find the
location of the LS program, which shows us
that it is indeed in a location specified
by PATH. The paths are separated by the colon.
If we would want to execute our program from
every location like LS, we can simply add
this current directory to the PATH variable
with export.
A nice trick if you want to copy something
in the terminal is just to mark it, and then
press the mouse wheel. this will automatically
paste the marked text. Now add the user’s
home folder to the PATH and then you can execute
this program like any other.
Now let’s dive in.
C is over 40 years old and despite it’s
age it’s still used a lot. Its strength
is its simplicity - by that I mean that there
are not too many language features and thus
makes it easy to understand - at least once
you understand how a CPU works. Many beginners
feel that C is hard, because it feels unintuitive
and too low level at first, but you will notice
in later episodes that it is very close to
assembler, which is ideal to understand and
imagine how a computer works.
our goal is to look nerdy. So we obviously
will use a command line text editor called
vim. Joke aside, it really makes sense to
learn vim, because we actually need it a lot.
vi is already installed. But vim (which stands
for vi improved) is a little bit nicer and
is not yet there. But we get this nice little
suggestion to install it with sudo apt-get.
The sudo prefix is needed, because only the
root user can install new software. Enter
a Y to continue
Now enter vim and the filename to start editing.
Before you can type you have to enter the
“insert” mode by pressing i. Keep an eye
on the status bar at the bottom, which tells
you what you are doing. To exit the insert
mode hit escape. And then you can enter commands
with a colon such as colon w to save the file
or colon q to exit. or simply colon w q to
save and exit.
We don’t really have to know more features
than that for now, except maybe we want to
enable syntax highlighting and display line
numbers
:syntax on
:set number
First we want to use the include statement
to add the standard i/o (input output) functionality
to our program. Next we define the entry function
which is always called “main”. Every C
program has this function and this is where
our program starts to execute. A function
has a name and encloses code that belongs
to this function. The parameter variables
defined here are standardized. The first parameter
is an integer number called argc (which stands
for argument count). And the second parameter
is a list called argv (which stands for argument
vector). For now we will use array, list and
vector as synonyms. So those function parameters
are infact what we can pass to a program on
the command line. Just think of the “cat”
command. It takes a filename as first argument.
And if you would program cat yourself, you
would access the filename via argv.
Now let’s print something by using the printf
function and a string as parameter.
The backslash n is a special character which
stands for newline. We have seen it in the
last video already.
Let’s save this with ESC, colon, wq, Enter.
Just a friendly reminder, read the man page
of printf to learn more about this function.
To access the manual for the C function printf
you have to look in the 3rd section of the
manual. So man 3 printf.
To create a program from the text we have
to compile it. The compiler converts the text
into binary machine code that can be executed
by the CPU. We can use the gnu c compiler
gcc for that. “gcc”, filename of the code
and minus o to specify the output file name.
Ohh… I made a mistake. There is a conflict
for argv. So let’s quickly fix that by calling
this variable properly argc.
Now you can execute it. Awesome!
Let’s be a good programmer from the beginning
and use -Wall to enable all warnings. Now
we get a warning that at the end of the function
is no return value, despite having main defined
to return an integer number. So let’s fix
that by adding a return 0 at the end, 0 means
that the program exited without an error.
You can hit “o” instead of “i” to
enter the insert mode in vim, which automatically
creates a new line below. Maybe you start
to realise now how powerful vim can get when
you get familiar with the shortcuts.
And now it compiles just fine!
To make this program a bit more interesting
we will add an if-statement. We say that the
argument count has to be equal to two. And
if that is the case, we will print the same
phrase as before, just without a fixed name.
We can use this format string syntax of percentage
s to indicate that at this place belongs a
string. And as first parameter we specify
this string, which is the second element of
the arguments vector. Yes it says, 1, but
it is the second entry in this list, because
we always start counting at 0.
If we don’t have exactly two arguments,
we will print an error message. Good practice
is to print error messages not to the standard
output, but to the standard error. May seem
weird for now, but you will understand it
in the future. And instead of printing the
second argument, because in this else case
we might not have one, we will print the first
argument instead. We will also add a return
1 here, and the one indicates that the program
exited with an error.
Compile this code and test it. As you can
see if you don’t specify an argument, it
will display the usage error message with
the program name. The shell passes everything
you typed on the command-line seperated by
spaces to the program. And this means the
first argument will be your program name.
Now if you set the second argument, the personalized
message is printed. Also notice that when
you want to have a string with spaces, you
have to put it in quotes to indicate that
it belongs together.
With dollar questionmark you can display the
exit-code of the previously ran program, which
is either 0 or 1 depending on if we got an
error or not.
Now let’s play a little bit with this program.
We already scratched the topic of environment
variables. If you look at them again, you
can find the $USER variable, which contains
your username. So when we execute the program
with dollar USER, it will print liveoverflow.
But what if we actually want to print dollar
User?
To achieve that we have to escape the dollar.
The dollar has a special meaning on the command
line. When you enter this text the shell will
read what you typed and once it reads the
dollar, it knows that the next characters
will be the name of a variable. It will then
look up the value of this variable and replace
it.
But if we use a backslash before the dollar,
the shell will first read the backslash and
knows, that if a dollar is following, it will
not treat it as a special character anymore.
Wouldn’t it be cool to always get greeted
when you open a terminal? Browse to your homefolder
again and checkout the dotfiles there. There
is one file called bashrc, which is a special
file that will be loaded once you open a terminal,
and it can contain commands that are executed
everytime. Open it in vim, and go to the bottom
of the file with shift G switch to the insert
mode with “i” or “o”.
Now we can add the export command from earlier,
but because we now know about environment
variables and how they are recognized and
replaced, we can use this better technique
to change the PATH.
And on the next line we add our program with
the user variable as argument.
Escape to enter command mode, colon, w save
it.
Open another terminal and be excited!
This obviously could have also been easier,
by just using echo instead of a compiled C
program. But it doesn’t matter. We learned
something. As an exercise you should add an
alternative version with echo and the environment
variable to the bashrc. And you can also modify
the vimrc to always enable syntax highlighting
for vim.
I remove the export command again, because
I don’t want to have the home folder in
the PATH. Go to the line and press d two times
- you have to be in command mode, so hit ESC
if you are still in the insert mode.
And now I have to use the full path for our
program.
﻿In the last video we developed a TCP proxy
in python that allows us to now analyse the
network protocol of the game. I think the
code we have written is a really good example
of why you should know programming when you
are interested in IT security. While it does
require some experience in coding in the end
it was not much code. And the result is, that
we now have a fairly powerful tool on our
hands to reverse engineer the network packets.
So for now we don’t really have to touch
the main proxy code and we can focus on the
parser function that we can play with. This
function has three parameters, but the most
important one is data. This is where the TCP
payload that either the client or server sent
comes in. And last video we also implemented
some filters here to only look at data sent
by the client to the game server. And our
tool is so powerful, because we can now do
anything in here. And whatever we change here,
will affect the output of the proxy. So let’s
get started. A the end of last episode I already
hinted at this one packet that doesn’t change
when we stand still but changes in some parts
when we move around, and also changes in a
different part when we jump.
So… let’s collect some test data. We see
no data changes when we stand still… When
we walk forward or backward we see some changes.
Some Left and right walking… Then also jumping
up and down.
And notice that I didn’t move the camera,
so now also some looking around.
Which areas of the data was affected by what
action, was pretty obvious, but we need to
analyse this very accurately. So let’s copy
out some samples into our script and look
at them. So what can we see here?
First of all, all our actions that we did
were about moving around. And that packet
is also the one constantly being sent. So
it’s really not surprising and doesn’t
take much guessing that that will somehow
contain our position. We also can quickly
see that there seems to be two bytes at the
start that are fixed. Then when walking around
data changes in this region, and then also
back there. So this was forward and backwards
walking. The walking left and right here is
very similar, just the other byte here at
the end is changing. This is perfectly consistent
with a X and Y position in the world. Just
to make it clear, of course X and Y is changing
when we walk forwards and backwards or left
and right, because it’s unlikely that we
are aligned to the axis. In that case the
movement would only change one coordinate.
But what is bothering me a little bit is,
that the data that is changing is 14 hex digits,
so 7 bytes. That’s an odd number. We would
expect something like 8 bytes, 4 bytes per
coordinate or something like that. But let’s
continue with Jumping. Let’s take out the
two other packets. You see that they are longer
and have a different ID. So let’s deal with
that later.
When we jump, essentially moving up and down
on the Z axis, only this value changes.
And this is 8 digits, or 4 bytes. AS you know,
this is a hexdump, a hex representation of
the raw binary data of the packet, so two
hex digits are one byte.
And cutting the data here also now seems to
indicate that the previous two values should
indeed add up to 16 digits. So two times 4
bytes. That would also make much more sense.
The last test was looking around and there
only 4 bytes in the back are changing.
Now we can try to label everything with a
guess what the data could represent. We have
a constant ID that I think means “this is
a position packet”, we have probably X Y
and Z coordinates, as well as some kind of
looking around data, two constant zero bytes
and then something that indicates which key
we pressed.,
Cool! So let’s implement a parser for that.
I will be using python struct a lot, which
can unpack different types from raw binary
data. So let’s start by unpacking the packet_id.
To do that we simply call struct.unpack with
capital “H” as a format character which
indicates we want to interpret 2 bytes as
an unsigned short integer number. And you
can see how cool it is to just write something,
save the file and see the changes. This way
it’s super easy to learn more about the
data. So here is the integer number in regular
base 10 of our first two bytes, but when we
print it as hex, it’s not quite what we
expect. We expected to see 6d76, but instead
we got 766d. So this is now a question of
how you want to interpret the raw bytes. Either
as little-endian or big-endian. For the packet
ID it doesn’t matter and I think it’s
a bit more comfortable to read the id when
it says 6d76, so let’s change it to big-endian
indicated by the greater than sign. Cool.
We will probably get a lot of other packets
later, so I thought it would be a good design
to define a handler for different packets.
So I create a python dictionary with one element
so far, and that is supposed to be a function.
So h_position is a function that will get
the data as parameter.
Oh and also a noop, a no operation, function
would be cool. Bear with me it makes sense
in a second. Because now we can simply try
to get the function defined in the handler
for a given packet_id, and if it doesn’t
exist the default value, in this case the
noop function will be returned, and then the
function is given the data starting after
2 bytes. So we cut off the packet_id, because
now we selected the correct function to handle
the data.
Mh, maybe we implement an “unknown packet”
output in h_noop and then we can also test
that. So this output is coming from inside
our position handler function, but when we
jump, and we get these other packets we haven’t
looked at yet, we see an unknown packet message.
Cool!
Now let’s carve out the X, Y and Z position.
Each of them are 4 bytes large. So it could
be a signed or unsigned integer, or a float.
Now if we look at the data again, we can see
that it changes quite dramatically, even though
we moved just a little bit. If it were an
integer I would suspect much smaller changes.
So maybe it’s a float? But in the end it’s
just a guess and you can quickly test it.
If the output makes sense it was probably
correct, if not, then try something else.
But I think float is absolutely a reasonable
assumption here.
So we can write X, Y and Z and get the value
of struct.unpack. BTW if something returns
multiple values in python, you can automatically
unpack them into individual variables like
this. So our unpack will unpack 3 floats,
indicated by fff, which would be 3 * 4 bytes
long. So 12 bytes.
And then we can print the data nicely with
float format modifiers to only show 2 digits
after the comma.
Now the moment of truth, let me hit the save
button. BOOM! Amazing, look at that. Now let’s
move around a bit in game. And yeah, the data
changes reasonably. And when we jump, or fly,
we see that unknown packet for the jump and
we see the Z value change. Amazing!
We reverse engineered part of our first packet.
Now to be honest with you, I’m not sure
how the looking direction could be encoded
as it’s also 4 bytes but it must be more
than one number? But I ignore it for now.
Let’s do the easier stuff first.
How about we have a look at the jumping packet.
That’s an unknown packet for us right now.
Again, let’s collect a few samples and format
them so that we can try to recognize patterns.
One thing you might already notice is that
when you press space, then you send a 1, and
when you release space again you send a 0.
Oh by the way, the packet id is missing here
because we cut it off when we handed it to
the noop function where we printed the data.
So we can extract that one byte with struct.unpack
using the B format string for one byte. And
print it along the remaining data that we
don’t know what it means yet. And we can
test it again. We jump a bit, and here we
go. So what could the remaining packet data
mean. WAIT! Isn’t that the packet ID of
our position packet? The length of the data
would also match. Ohhhh…. So the network
protocol is not just sending a single packet
with information every time when something
happens, it might bundle multiple packets
together. So when we jumped it sent jump information
together with position information.
This means we have to change some stuff of
our parser. You can do this in many different
ways, I chose to just return the data that
doesn’t belong to the currently interpreted
data. So for example for the jump handler
I cut away the first byte and return anything
starting with the second byte. For the position
it’s a bit more tricky, we have to quickly
count how many bytes that is, so that would
be 20. So I cut away the first 20 bytes. And
for noop, let’s just cut away a single byte.
Now we have to place our parsing into a while
loop where we always check the length of data,
and we constantly change data to what the
handler functions returns. And at some point
the parsers has fully consumed the data.
Let’s continue reversing more packets with
the same methodology. But I also think I wanna
make some changes to the code. Like I said
multiple times it’s an explorative process
and so our tools develop with us, once we
figure out new stuff. So I decided to comment
out the position print, so we don’t spam
the output so much.
And to not print unknown packets in the noop
function, but instead check if the packet_id
is defined in the handler, and if not we print
the packet. And we can also I noticed another
unknown packet when switching the weapon.
And when shooting the fireball.
But isn’t it weird that we see slowly consuming
unknown packet data by our loop, when shooting
a fireball, but not with the weapon switch?
Even though both are unknown packets?
Well if you look closely, then you see that
the weapon switch is also just one byte indicating
the selected slot. Which is consumed by noop.
And then after that we find the packet_id
of the position packet again and fully parse
that. Cool, huh?
So let’s quickly create a handler function
for weapon select, which is basically like
the jump handler, just a byte. Cool! Another
packet reversed.
Now what’s going on with shooting of the
fireball? Let’s take an example packet shooting
the fireball, StaticLink, and the RemoteExploit
Sniper Rifle. And then compare them. One really
odd thing is that the fireball packet is longer.
Before that all packets had a defined size,
so how do we know that fireball is larger
than the Static link or sniper rifle? So the
first two bytes are again the packet_id, so
we know this must be indicating that we are
using a weapon or spell.
And then we have what looks like a byte with
a value that is always different. 0x10, 0xa,
0xd. Then comes a 0 byte and then what looks
like the start of some data. And that data
is very different. Though when you peak at
the end of the packet, you notice that they
are the same. So let’s try to lign that
up. OH! That is another position packet! We
didn’t move between shooting, so we know
how to parse that data and can ignore it.
When looking very closely and comparing the
packets I noticed more similarities. It’s
here sarting with 82b, and ending in 535.
And ligning that up looks like this. Because
we know that a positon packet would start
here after these two 535, we can conclude
that that is definetly an end of another packet.
Which means this 6672 is another small 1byte
large packet. And StaticLink, is like jump,
an action that can be started and held for
a bit and released again. So it’s probably
related to that. Let’s create a short handler
for that.
THen back to our weapon data. At first I didn’t
know what that part stands for, but when I
looked in another direction and fired another
fireball, and compare that data, I noticed
that this part changed. So that’s probably
also some kind of shooting direction data.
But still, how do we deal with the different
length packets. Well we know there is a number
at the start that is different for all three
of them. The largest one is 0x10 and is also
the longest packet, then comes the second
longest packet with 0xd and the shortest one
is 0xa. And when you count the bytes it suddenly
makes sense! This is the length.There are
10 bytes, here are 13 bytes and here 16. And
the trained eye might have also already recognised
that that is ascii text. When you read a lot
of hex values for example because you play
too much CTFs and spend time in debuggers,
you start to recognise when data is text.
It’s just a skill you develop over time.
So let’s implement that handler, first we
extract the length. I assume that the length
is actually not just a single bytes but a
short, so two bytes unpacked with “H”.
Then we know that the name starts after the
second byte up to the length.
We can use our awesome proxy to immediately
test that. When we shoot something we see
the name, but of course the data parsing is
still missing the last 12 bytes of data. So
we don’t really know how to interpret the
direction yet, might be same as the position
data rotation, or looking direction, but we
just ignore it for now and return the data
after all of that. And when we test that,
we get a beautiful output when using a weapon.
Also you can see now very well how the static
link is toggled on and off depending on how
long you hold the mouse button. Awesome! We
just parsed a variable length packet.
Before we end I just would like to mention
something. Maybe you find it weird how I so
quickly understand how to parse that data.
But you know there are not that many options
how it can be done. If you ever think about
how you would implement it on this low level,
then this is pretty much the only option you
have. You know the basic data types like integers,
floats, ascii characters, and out of these
you build more complicated structures. And
then there are also typical intuitive and
very obvious techniques such as type-length-value
encoding. And this is pretty much what we
had here. The packet_id is indicating the
type of data, so like a weapon_shoot type
and because of the name that can have different
lengths we need also sth that tells us the
length, and then the data itself. you just
have to think about it for a bit and then
I think it’s super obvious. At least when
there is no addditional crypto or compression
layer involved.
See you next video where we will explore some
more things with the proxy.
﻿Welcome to LiveOverflow. Here you can find
videos about computer internals, with a focus
on hacking and security concepts. I also record
myself solving hacking challenges - it might
be a bit boring to watch, but if you always
wondered how other people work and think,
it might be interesting for you.
Now let me tell you a short story about why
I am doing this here.
I was too young in the 90s and didn’t exist
in the 80s to be part of the seemingly golden
age of the hacker culture. When I was a teenager
I loved taking apart electronics and looking
at the green circuit boards wondering with
what kind of magic it is imbued with. Once
my dad brought home our first computers and
we got access to the internet, I found myself
being fascinated with “hacking” and wanted
to learn more about it. But all I found was
crap, people trying to sell old information
or fake products. So I never got into hacking
until much later. I started programming in
Visual Basic and made my first websites with
html. Eventually I moved on to php and other
programming languages. Some years pass and
I moved out to another city to go to university.
One day I was sitting in front of my computer
coming across this hacking game by stripe.
A CTF where one level was to exploit a buffer
overflow. I knew what a stack was. And I was
able to read simple assembler code from university
classes. But not until I saw the shell popping
up, my mind being blown and struck in awe,
I realized I was at a position in life where
I can pursue a dream I had as a kid. And I
still wear the T-Shirt I got from the stripe
CTF with pride. At the same time I had the
opportunity to join a hackerspace where I
met so many intelligent people and I went
down a rabbit hole.
Not many years have passed since then. And
I still feel I have only explored a tiny fraction
of what is out there.
The content I am creating here is an attempt
to give anybody who want’s to understand
the world better, an opportunity to start
somewhere. I want to give to others, what
I wish I found when I was a teenager sitting
in the basement typing into google “how
to hack”.
At the same time I see more and more people
making tutorials on how to use certain hacking
tools, rather than explaining the underlying
concepts. I understand that it looks cool,
and that you can feel very powerful. But there
is more to hacking than that.
Understanding concepts, understanding how
your phone and laptop do stuff, understanding
on a technical level how you are able to watch
this video right now. That is amazing. There
is so much awesome stuff to discover and break.
So I invite you to join me on this adventure
and “Hack the Planet!”.
﻿Welcome to LiveOverflow. Here you can find
videos about computer internals, with a focus
on hacking and security concepts. I also record
myself solving hacking challenges - it might
be a bit boring to watch, but if you always
wondered how other people work and think,
it might be interesting for you.
Now let me tell you a short story about why
I am doing this here.
I was too young in the 90s and didn’t exist
in the 80s to be part of the seemingly golden
age of the hacker culture. When I was a teenager
I loved taking apart electronics and looking
at the green circuit boards wondering with
what kind of magic it is imbued with. Once
my dad brought home our first computers and
we got access to the internet, I found myself
being fascinated with “hacking” and wanted
to learn more about it. But all I found was
crap, people trying to sell old information
or fake products. So I never got into hacking
until much later. I started programming in
Visual Basic and made my first websites with
html. Eventually I moved on to php and other
programming languages. Some years pass and
I moved out to another city to go to university.
One day I was sitting in front of my computer
coming across this hacking game by stripe.
A CTF where one level was to exploit a buffer
overflow. I knew what a stack was. And I was
able to read simple assembler code from university
classes. But not until I saw the shell popping
up, my mind being blown and struck in awe,
I realized I was at a position in life where
I can pursue a dream I had as a kid. And I
still wear the T-Shirt I got from the stripe
CTF with pride. At the same time I had the
opportunity to join a hackerspace where I
met so many intelligent people and I went
down a rabbit hole.
Not many years have passed since then. And
I still feel I have only explored a tiny fraction
of what is out there.
The content I am creating here is an attempt
to give anybody who want’s to understand
the world better, an opportunity to start
somewhere. I want to give to others, what
I wish I found when I was a teenager sitting
in the basement typing into google “how
to hack”.
At the same time I see more and more people
making tutorials on how to use certain hacking
tools, rather than explaining the underlying
concepts. I understand that it looks cool,
and that you can feel very powerful. But there
is more to hacking than that.
Understanding concepts, understanding how
your phone and laptop do stuff, understanding
on a technical level how you are able to watch
this video right now. That is amazing. There
is so much awesome stuff to discover and break.
So I invite you to join me on this adventure
and “Hack the Planet!”.
﻿Welcome to LiveOverflow. Here you can find
videos about computer internals, with a focus
on hacking and security concepts. I also record
myself solving hacking challenges - it might
be a bit boring to watch, but if you always
wondered how other people work and think,
it might be interesting for you.
Now let me tell you a short story about why
I am doing this here.
I was too young in the 90s and didn’t exist
in the 80s to be part of the seemingly golden
age of the hacker culture. When I was a teenager
I loved taking apart electronics and looking
at the green circuit boards wondering with
what kind of magic it is imbued with. Once
my dad brought home our first computers and
we got access to the internet, I found myself
being fascinated with “hacking” and wanted
to learn more about it. But all I found was
crap, people trying to sell old information
or fake products. So I never got into hacking
until much later. I started programming in
Visual Basic and made my first websites with
html. Eventually I moved on to php and other
programming languages. Some years pass and
I moved out to another city to go to university.
One day I was sitting in front of my computer
coming across this hacking game by stripe.
A CTF where one level was to exploit a buffer
overflow. I knew what a stack was. And I was
able to read simple assembler code from university
classes. But not until I saw the shell popping
up, my mind being blown and struck in awe,
I realized I was at a position in life where
I can pursue a dream I had as a kid. And I
still wear the T-Shirt I got from the stripe
CTF with pride. At the same time I had the
opportunity to join a hackerspace where I
met so many intelligent people and I went
down a rabbit hole.
Not many years have passed since then. And
I still feel I have only explored a tiny fraction
of what is out there.
The content I am creating here is an attempt
to give anybody who want’s to understand
the world better, an opportunity to start
somewhere. I want to give to others, what
I wish I found when I was a teenager sitting
in the basement typing into google “how
to hack”.
At the same time I see more and more people
making tutorials on how to use certain hacking
tools, rather than explaining the underlying
concepts. I understand that it looks cool,
and that you can feel very powerful. But there
is more to hacking than that.
Understanding concepts, understanding how
your phone and laptop do stuff, understanding
on a technical level how you are able to watch
this video right now. That is amazing. There
is so much awesome stuff to discover and break.
So I invite you to join me on this adventure
and “Hack the Planet!”.
﻿exploit-exercises/protostar offers a linux
image with several challenges to learn binary
exploitation. But a lot has changed over the
years and if you compile these challenges
yourself on a modern system it’s not as
easy anymore. I already showed you that in
the previous videos about the stack challenge.
I had to make a 3 part video series to explain
how we can still do it. And that also only
on 32bit. So if you are just starting out,
make sure that you use the Linux image that
you can download here and don’t compile
it yourself. Otherwise all the tutorials about
it won’t work. And now for this video, let’s
continue with some other challenge. We compile
them on a current Ubuntu version, without
any compile flags and see what we get.
Obviously the rules of the game, that is hacking,
are, that maybe there are techniques I just
don’t know about. I don’t really know
the edge cases in exploitation, I mostly know
the general techniques and I think I have
some reasonable amount of creativity. But
I don’t know everything. So it’s likely
that there are people out there that could
exploit it. In that case, I’d love to see
a PoC for that. That being said, let’s continue
with format0.
So what is this challenge about? The attacker
can pass in an argument, that argument is
then being passed as the string variable to
the format parameter of sprintf. So we can
inject stuff like %d or %s.
It’s also vulnerable to a buffer overflow,
because sprintf, does not print to the console,
to stdout, like regular printf, but prints,
or stores the formatted string, in buffer.
And the buffer is only 64 bytes long.
Now when you attack this on the VM that you
can download here that has these challenges
precompiled, the target variable would be
placed after the buffer so that you can overflow
the buffer, and write into target. And then
you have target modified and when you make
it so that it’s overflown with 0xdeadbeef
you pass this check.
So enter 64characters, and 0xdeadbeef and
you won.
But the challenge here also said, try it with
less than 10 bytes. And you would do that
by abusing format string modifiers that would
stretch the formatted output to for example
64 characters, and then you can simply enter
0xdeadbeef afterwards. So for example %64d
would output a number with a up to 64 character
padding. And so 64 characters plus 0xdeadbeef
are written into buffer and you win.
Well is that still possible?
First we have to install gcc and gdb on this
fresh maschine and I’m also going ahead
to install peda, a gdb extension that makes
things look nicer.
So let’s start with the simple buffer overflow
example. But first let’s set a breakpoint
in vuln() before we compare deadbeef. Then
let’s start the binary and pass in an input
that is much larger than 64bytes. Okay.
So we hit the breakpoint and it compares eax
with 0xdeadbeef. But eax is 0. How can that
be? Didn’t we overflow the stack?
Well, we certainly did, the issue is that
the target variable doesn’t come after the
buffer. It is before, so we can write as much
data as we want, we won’t overwrite target.
You can also see this here. Eax is loaded
from base pointer - 0x54, while the address
for the string is loaded from basepointer
- 0x50, so it’s located after target.
Well does this mean it’s not exploitable?
mmhh... So if you are familiar with format
string exploits, you also know that you can
write data with it, by abusing the %n modifier
which writes the amount of already printed
characters to an address on the stack. And
we can overflow the stack, so we could place
an address there and then carefully construct
the number of characters printed before, such
that it writes 0xdeadbeef to an address. And
so we could write to target, and win that
way, right?
But ASLR is our problem. Let me add a printf
to the code to print the address of target.
ampercant target returns the reference of
a variable, so that’s the address.
And when we compile it and run it in a nice
while true loop, you see how crazy the address
of target changes. Target is a local variable
so it’s located on the stack. So this is
also a stack address.
But how much does it change? It always starts
with 0x7ff and ends in a C. And this one nibble
here only appears to be C,D,E or F. That’s
a huge number. It’s over 1 billion. but
maybe in this case actually doable. Just takes
some time. Maybe a day or so. I just like
to refer to the previous three part video
where we bruteforced a 3 byte stack cookie,
that was roughly 16 million possible options.
And so here, 260 million, is in reach, I would
say. At least for a very small binary like
this. The execution speed is quite fast.
Let’s see how it looks like on 32bit. We
have to install the gcc multilib to do that.
And then we can compile it with -m32.
When we execute it a few times, you can see
that it obviously has less randomness than
on 64bit. It’s only two full bytes and then
again a nibble. That’s about 1 million attempts
to hit it. So definitely even more in reach.
But of course it’s only feasible if you
can do millions of attempts reasonably fast,
for example locally. If this were an application
that takes longer to start or a remote service,
then that would probably mean you couldn’t
really do it.
How to create a format string exploit and
how that exactly works with %n you can watch
in multiple other videos that I have done.
But there is one additional trick that comes
to mind we could look out for. So to write
with %n we expect the target address to be
on the stack. In a classic format string exploit
you would use your input that is maybe also
placed on the stack and reference itself.
But nobody says it has to be an address you
place there, the stack is full of values,
maybe you get lucky. If we look on the stack
when we are at the 0xdeadbeef compare in the
execution flow, you can see a lot of stack
addresses. And so these would always be valid
stack addresses even with ASLR. Now if one
of those would magically point to target,
then we could just reuse it. We could just
reference that address.
But if we check the address we know of target,
we can see that it doesn’t show up. Oh well.
But you see how creative you can get with
exploitation. We could have been lucky.
But let’s actually continue that train of
thought.
Ok we don’t have the whole target address
on the stack, but we do have a lot of other
stack addresses. And we have an overflow,
so we can overflow into the addresses. And
just overwrite some low bytes and keep the
whole front.
Let’s add another printf to print the target
value. And print the resulting formatted buffer.
And let’s play with that. Here you can see
the sprintf formatted result.
Let try to find AAAABBBB on the stack by consuming
values from the stack with someformat modifiers.
I wanna find the offset where on the stack
this value is placed, and we can explore that
with %lx and the dollar notation.So at stack
offset 1 it’s not, at offset 2 it’s not
at offset 3 it’s not. And so forth. But
here at offset 9 we now printed the hex value
of our input.
Now let’s look at the stack layout for a
nice stack address we could partially overwrite.
Ok so down here is one, let’s see what offset
that has. Let’s keep going.
There it is, at offset 19.
Which also means from the start at offset
9 to offset 19 we have 10 groups of 8 bytes,
so 80 bytes to fill and reach this value.
We can achieve that with a format string that
pads a number to 80 bytes, and then some input
to proof that we overflow.
And when we now execute it, we see that the
end of our address that got printed by our
19 lx, got overwritten with As.
If you paid attention you saw that target
is always at an offset with a c, so we can
choose some input that ends’ with a C as
well to overwrite it. For example L, that
is 0x4c.
Let’s execute that now, and you can compare
what address we got now through the overwrite
with L, and what target really was. You see
that often it’s not the same, but eventually,
it will match.
And so if we replace the %lx to print a 8
byte hex value to %n, then we will WRITE to
that address.
So now we are writing the amount of printed
characters, 81, because 80 + the single L
to this address. And maybe at some point we
hit target. Let’s keep trying.
BOOM! There we hit target, we wrote 0x51 to
it, which is 81 in decimal. And that works
fairly reliably, we can try those few attempts
by hand.
And I think that’s awesome, unfortunately
it’s not quite the solution, because target
has to be 0xdeadbeef. And that’s 3 billion
in decimal. So with this technique we would
have to first print 3 billion characters before
we can do %n, and that’s not possible.
Anyway I think you can see how much exploitation
can become a puzzle that you slowly try to
piece together. In the end I didn’t manage
to solve it but exploring this was really
fun.
I really wonder if somebody is able to make
a semi reliable exploit for this.
﻿In this video we are going to recover a private
crypto key inside the arduino just by observing
it’s power consumption.
We are going to perform a differential power
analysis attack on an AES implementation.
In the previous video we have introduced what
power analysis is, and how you can prepare
the arduino board to do those measurements.
And now we are going to actually solve the
first side channel challenge of the riscure
embedded hardware CTF.
Piece of scake.
S-C-A.
Side channel analysis.
100 points.
So this is really a low amount of points and
I do have a lot of … ehm… opinions about
that.
You will see.
This is an easy SCA challenge using a cipher
implementation without any SCA, so side channel
analysis, countermeasures.
Find the key used to encrypt and decrypt messages.
attacks.
To encrypt a message, send the letter ‘e’
followed by 16 bytes.
To decrypt a message send the letter ‘d’
followed by 16 bytes.
This sounds really easy.
Should be a straightforward thing.
Remember from last video how you can break
a terrible RSA implementation by identifying
the square and, square and multiply operations
in a power trace and simply read the bits
of the private key?
That’s like the simple go-to example when
introducing side channel analysis, because
its so simple.
so from the beginning I set my mind to RSA.
This is gonna be RSA.
I just send a decrypt command via serial to
the board, trigger the oscilloscope at the
right moment, basically trigger power consumption
data collection after I sent the data to decrypt,
and then the board will use the private key
for the decryption and I can just read the
bits from the trace.
After the multiple days of fighting with the
setup, soldering, knowing about groundloops
and capacitors you should remove and requiring
all this fancy equipment, I was sure this
is what I gotta do.
I will be rewarded for learning all this with
a simple challenge.
It’s the introductory side-channel challenge
anyway.
Gosh was I wrong.
So I’m sitting there, staring at the oscilloscope.
Zooming around trying different methods to
acquire the data.
Like averaging traces or different resistors.
I just didn’t see what I would expect in
an RSA power trace.
This killed already multiple evenings for
me.
Until I was more or less told, this is not
RSA… this is AES.
Fuck my life.
Also makes sense with the 16 bytes of data
to encrypt or decrypt.
That’s the AES blocksize.
A rollercoaster of emotions.
Happiness of learning something new, followed
by pure rage and frustration.
So here is the thing.
I knew the FAQ introduced differential power
analysis.
DPA.
I also larned about this in a hardware security
class at university.
So I knew that it’s a thing.
And I knew what kind of equipment I need to
do this.
But I did not expect this to be the case for
the first 100 point challenge.
In a few minutes you will see why they gave
it 100 points, from a certain point of view
it makes sense.
But I completely disagree with it.
So what is DPA.
Differential power analysis is a more advanced
form of power analysis which can allow an
attacker to compute the intermediate values
within crypto computations by statistically
analysing data collected from multiple crypto
operations.
These were introduced in the open crypto community
in 1998 by a company called Cryptography Research.
And they are filthy rich now for discovering
this and creating a consultancy research company
around it.
I mean they deserve it I guess.
It’s a pretty crazy attack.
With simple power analysis we assumed that
the implemented algorithm will perform different
operations depending on the private key and
thus show a different power footprint.
But in case of the shitty RSA implementation
you could just multiply and square in EVERY
iteration and just keep the result of whatever
the current bit was.
Thus no difference anymore.
BUT there is a deeper layer than that.
The power consumption directly comes from
the single bits, the transistors.
So even if the algorithm performs the same
operations independent from the private key
bits, those bits would still cause a very
very tiny different power consumption.
This sounds even more crazy than the simple
RSA example.
Because these bit changes are soooo small.
That’s why you do a smart statistical analysis
on a lot of collected traces.
I actually don’t wanna explain this method
in detail, because it’s fairly complicated
and there is a good video by Colin O’Flynn
doing exactly the AES example.
But the gist is, that you collect a lot of
power traces from random input you encrypt.
Then you make a guess on what the first byte
of the private key could be.
And then you perform part of the encryption
algorithm as if that was the correct key,
and given the random input valuesand that
key guess, it would lead to different intermediate
values.
Then you take the traces where this intermediate
value is the same for further analysis.
If the key guess is correct, the power traces
should all have correlation of power usage
in that point in time.
If the key guess was wrong, the traces you
selected based on that would have completely
different intermediate values, thus random
power consumption and nothing would correlate.
It would cancel out.
So you do this for each possible key and for
each possible byte.
And in the end you should find the correct
key.
But how do you actually do this now.
I knew I did not want to implement this math
myself.
Also I would have to write my own tools to
automatically collect these traces from my
oscilloscope, and the USB or networking API
seemed horrible.
I wasted some time with that but then gave
up.
I knew what I needed.
It was a ChipWhisperer.
It’s a piece of hardware that is specifically
designed for doing this.
And it comes with a software that has all
these attacks already implemented.
I thought about buying one initially, but
I assumed an oscilloscope would be more flexible
and I could learn more with it.
I know some players bought a ChipWhisperer
because it was recommended to use it for these
hardware attacks.
And it costs a bit money.
But I think without additional equipment like
an extra oscilloscope it’s hard to debug
issues.
Anyway, I’m happy with my purchase choice.
But I still wanted that ChipWhisperer for
this challenge and I knew where to get one
from.
Some of you know that I’m still a student
at the Technical University of Berlin.
I’m still working on my masters degree and
we do have a small group at the university
that does hardware security research.
That’s where most of my theoretical knowledge
about these attacks comes from and I have
a fairly good relationship with them.
And they obviously have a ChipWhisperer in
their lab.
So I wrote one of the PhD students and asked
if I can come over and play with it.
And that’s the awesome thing about a university,
you can get access to awesome equipment as
well as help and advice.
So I encourage every student to take advantage
of these things.
That’s one of the reasons why university
can be really awesome.
So when I used it the first time, I just followed
the example.
Which is a DPA attack on the test board that
comes with the Chip Whisperer.
Everything is already set up for you.
The test board has a connector for the probe.
This is the measurement probe.
And another broad connector which carries
the power as well as the RX and TX lines for
serial communication.
Then you use the example script, which implements
the serial protocol to talk to the test board.
Basically it also sends 16 bytes that should
be encrypted.
And with a click on start, it starts collecting
power traces.
The trigger for the power measurement and
all the other parameters are already set to
the correct values.
Then you let the attack script run, it does
the DPA and after a minute or so it finds
the key where the power spikes correlated.
And you can look at all these fancy graphs
and you can feel really cool that you just
broke AES with DPA, without knowing shit.
And this is why this challenge only gives
100 points.
Because in the end it’s just putting in
the correct parameters and clicking GO. and
then the secret key falls out.
Well, there is a bit more to that challenge.
But essentially that’s all it is.
So I took the ChipWhisperer home and spend
the next few days trying to do this on the
CTF board.
There were so many fails.
I will tell them now in sequential order,
but you have to imagine that they were all
intertwined and only slowly I found all these
mistakes.
It was not a clear progression of “find
error”, “fix it”, “find next error”,
“fix it”.
I tried a lot of things and spend hours over
hours until I discovered the issues.
So while I make it sound straightforward,
it was absolutely not.
It was hell.
Ok first of all I had to learn how this ChipWhisperer
framework works.
I realized that the test board is just a little
bit different from the CTF board.
So I only have to change things like how to
trigger encryption or decryption.
But before the Chipwhisperer could communicate
via serial with the baord, I had to solve
the issue of different voltage levels.
The Arduino Nano board runs with 5V, while
the ChipWhisperer uses 3 volt.
So I had to build a unidirectional level converter
to convert the 3 v signal to 5v, and the 5v
signal to 3 volt.
But that worked surprisingly quickly.
So this is the setup.
Serial connection via the level converter.
And then using a RIGOL probe to measure the
voltage after the resistor.
I was so happy and felt really smart for using
the Rigol probe because it fit onto the plug.
Then I copied the code for the example script
and spend some hours modifying that and I
was able to collect traces and run analysis.
I thought the difficult part was now to find
the correct moment in time where the crypto
is happening.
At some point I realized that one of the LEDs
flashes just before the crypto starts, so
you could use that as a trigger for the Chipwhisperer.
Again, don’t forget the unidirectional level
converter.
But after a few days of not being able to
find correlations in my captures I was so
frustrated and I finally decided to look into
the serial communication.
And I realized that I did not send the raw
data I wanted to encrypt, but I sent it as
a hex string.
This was obviously completely fucking wrong.
No wonder no analysis worked, because the
data was just wrong.
So at some point I had fixed that, but stuff
was still not working.
And it’s really hard to figure out whats
going on.
The traces I took on the oscilloscope looked
really good.
I was able to easily see where the crypto
is happening.
AES has 10 rounds of crypto, and you can clearly
see them.
They are right there.
So my trigger was at the right moment.
But when I took traces with the chipwhisperer,
I didn’t see that.
After many many more hours and days I realized
the RIGOL probe is the issue.
You know these probes are not just plain metal
wires, they have some components in there.
In fact this probe is a 10:1 probe.
So on the oscilloscope you actually have to
set a 10x multiplier for it.
And the ChipWhisperer was not compatible with
that.
Once I realised that I was about to jump off
the next building.
What the hell.
Then I replaced the nice professional probes
with a simple wire.
And suddenly the measurements were great.
Another challenge I had was to set the sampling
rate high enough, because you want to sample
a lot faster than the clock of the microcontroller.
But setting that is super janky for the chipwhsiperer.
And a looot of other small issues.
The software constantly stopped working, I
think it’s a memory issue.
I had to guess what certain parameters are
for.
And you can imagine with all the issues I
just told you about and not really knowing
what’s causing it, it was overall a damn
frustrating experience.
Is it the capacitors, is something broken,
is it interference, is the script wrong, are
the aprameters wrong, am I collecting not
enough traces, am I at the wrong point in
time, is the trigger working, is the data
even random, I don’t know.
Oh.
And I also lifted a second pin of the atmega
up, because there are two VCC connections
and I didn’t know if that was maybe an issue.
It was hell.
RERECORD HERE
Anyway.
Once the whole setup was correct and working,
and I clicked start to collect the traces
it started to look really good.
Once you have a nice set of traces you have
to allign them, because the trigger is not
perfect in time.
But there are modules for that.
Like pattern matching.
And then you can run the analysis, and the
key magically poppes out.
There it is.
I transcribe the key, and hand it in.
100 points.
100 points for hundredes of euros I spent
on equipment and days of work.
100 points.
I’m so so so depressed.
I also have to give credits to Andres Moreno
from riscure who despite my constant ranting
and cursing still listned and helped me a
lot.
Thank you so much!
Also thanks to my friend at the TU Berlin
and others from the riscure IRC channel.
I needed a lot of help for this challenge.
But regardless of my hate for this challenge,
I’m also really proud for having done it.
It was so clearly above my skill level and
in the end I succeeded.
And I learned a lot.
﻿We are going to solve the reversing challenge
Zwiebel from the TUM CTF 2016 by creating
a dynamic analysis script with radare.
Before I knew I would write a script for radare,
I had to figure out what the binary is doing.
So after I downloaded the binary and checked
that it’s a 64bit linux binary, I made sure
my vagrant Linux VM is running and opened
the binary for a first analysis in Binary
Ninja.
Let’s head to main and start reversing.
So first we have a printf() that is asking
for the Input key.
The valid input key is probably also our flag.
The fflush() just makes sure that the output
is displayed and not held in a buffer.
After that we have an fgets(), which means
here the input key string is read.
The rdi register is commonly used as the Destination,
so this memory with the flag symbol name is
probably where our input key is stored.
Funnily we can also see that it’s not just
0, but already initialized with some fake
flags.
Then we see an mmap().
Which is directly followed by a memcpy.
Which means that the program want’s a new
memory segment for something and copies some
data to that new segment.
Because we have a reversing challenge it’s
not unlikely that it might have some self-modifying
code that uses this new memory.
It looks like it is copying shc, which probably
stands for shellcode to this new address,
which is in register r14.
Now when you look at shc, you can see this
chunk of pretty random looking data.
And it’s also pretty long.
Mh.
After it copied this long memory to the new
mmaped memory segment, it will perform a call
to r14.
And r14 contains the address of the new memory
segment.
So it will jump to this code.
This means that shc contains actually some
assembler code.
So we can go there and press P to tell binary
ninja it should make this an assembler procedure.
Switch to graph view to make it easier to
understand the flow.
The first meaningful instruction here is the
mov from rbx to rax.
And if you paid attention to the mov before
the call to r14, you know that rbx contains
the address to our input key.
This means that rax points to that address
and it will get the first byte of it in al.
Then it will perform a binary and with 0x40.
Let’s have a look at 0x40 in binary.
You can see it has only one bit set.
So if our input character has this bit set,
the result will be non-zero, thus the je (jump
equal) (which is the same as jump if zero),
will not jump and continue over here.
So if the input character would not have this
bit set, it would jump to the left and perform
two syscalls.
A write and then an exit.
So this is not where we want to go.
This means the first character has to have
this bit set to 1.
In this branch we immediately notice a loop,
which contains an xor.
Inside of this loop, memory at the location
of rsi is xored with whatever is in eax.
Then the address is incremented.
And we repeat the whole thing.
After that we jump somewhere.
The jump target here looks a bit meaningless,
but that’s probably because it’s not the
real code yet.
This loop seems to decrypt the next layer
of assembler and then jumps there.
Layer.
Get it?
Zwiebel is german for onion, so looks like
we removed the outer layer of the onion.
We could now use the XOR key and decrypt the
code and proceed, but at this point I decided
that I want to see it executing.
So I copy the binary to the shared folder
so I can access the executable in the Linux
VM.
Then I connect to the linux system with ssh
and execute it.
So we get the Input key prompt, and the sad
smiley for failing the key check.
Now let’s open it with gdb.
But if we run it in gdb, it imediatly gives
us a sad smiley without asking for the key.
What’s going on?
When we execute it with strace, we get a bit
more information.
If we look closely, we can see a failed ptrace
in there.
This looks like a typical anti-debugging trick.
How is this an anti-debugging trick?
See, when gdb is debugging another process,
or strace collecting a syscall trace, they
both use the ptrace syscall to observe and
control the execution of another process.
But if the process is already traced by something,
the kernel will return an error on calling
ptrace.
So the binary executes ptrace, basically trying
to debug itself, and if that syscall fails,
it knows that it is being debugged by something.
So it will commit suicide.
This is usually easy to defeat.
So let’s look for this in binary ninja.
We notice here on the left, that indeed, the
binary uses ptrace.
If we follow the cross references we find
this function using it, which has two options.
One kills itself, the other just returns.
So we can just nop this code here so it will
always return and we should have defeated
this anti-debugging trick.
This is very easy with binary ninja.
And we can simply save the modified binary
and call it zwiebel2.
When we now run it in gdb we will get the
key input prompt and it seems to work well.
Great.
Now we can continue with what we wanted to
do.
Let’s set a breakpoint before we follow
the call to r14, so we can observe the decryption.
Now we can step single instructions forward.
Awesome.
Here at the mov to al we can see that it references
the flag which has our input AAAAA.
And we can see the and happening.
Because character capital A is he 41, the
binary and result will be non zero and we
continue to the decryption loop.
If you look closely at where the jumpa fterwards
would go, you see that when we execute the
XOR decryption the code is changing.
So it really is decrypting the next layer.
Let’s set a breakpoint after the decryption
loop, before we jump into the new code, and
continue.
Then we hit that breakpoint and we can single
step forward and look at the new decrypted
code.
HUGH!
That looks interesting… look at that…
it again loads the flag into rax.
But instead of loading the first character
into al, it loads the character at offset
0x1d.
Then it again performs a binary and operation,
this time with 2.
2 in binary also has only one bit set.
So this is also a check if a certain character
has a certain bit set.
And following this check we see another xor
decrypt loop.
Basically the same thing like before.
So we can set another breakpoint after the
loop and see how that decrypted code looks
like.
And what a surprise.
It’s basically the same thing over again.
Another character is taken, checked if a certain
bit is set.
And then continues with another decrypt loop.
We slowly peel that onion layer by layer and
we get an idea what it is doing.
So let’s back off for a second and recap.
The code performs the same actions over and
over again.
It will first check a certain character if
a bit is set.
If that bit is set, it will decrypt the next
layer.
In that new decrypted layer, it checks another
character’s bit.
Decrypt the next layer.
And so on.
Based on the 2 layers we have already seen
we know that the first character has to have
bit 6 set to one.
And character 29 (0x1d) has to have the bit
1 set.
We can imagine now that this will go on for
quite a while and it slowly tells us all the
bits it checks.
So if we collect all those rules we can recover
an input that passes all those checks.
Now we have to think about how we could do
that.
There are multiple options and I have thought
about what could be the fastest during the
CTF.
But it kind of depends on what you know.
If you are very good at binary ninja plugins,
you could build a static analysis tool that
decrypts everything and then you simply extract
the disassembled code.
But I don’t have that experience yet.
So I chose radare2.
Because radare2 is super simple to script
with python and r2pipe.
So the plan is to debug the binary with radare,
like we did with gdb.
And then always extract the bit rule.
Find the jump address after the decrypt loop,
let it decrypt and continue to the next rule.
To get this started, make sure your radare
is up-to-date.
Always run sys/install.sh.
It takes a while but radare is so heavily
developed, that if you have any issues, don’t
bother asking people if you are not on the
latest commit.
After that you can install r2pipe for python
with “pip install r2pipe”.
Now you can import r2pipe in python and use
it like you would use radare.
In the next video we will create the script
that will extract all rules and recover the
flag.
﻿Welcome back, let me quickly recap what we
learned from Paul last video.
We first downloaded and compiled the vulnerable
ffmpeg version from github and then used address
sanitiser to look at the first crash example.
The crash was caused because of a -1 as the
HTTP chunk size.
In the code we see that ffmpeg simply reads
this chunk size as a string and converts it
to an integer, without checking if it’s
negative.
And in the end this negative size ends up
as the length in a memcpy.
Now that doesn’t really help us and just
cuases memcpy to write data until it writes
into bad memory and segfaults.
However Paul already raised the question at
the end of last episode, what if we can somehow
get into the else case of this if.
Because here maybe the negative size number
can lead to an actual exploitable condition.
And here it gets a bit fuzzy what exactly
happens.
At least I’m not 100% sure.
And for Paul it has also been a while since
he looked into it.
So this read function reads bytes into a buffer.
At least as long as there is data available.
And so if the end of the buffer is reached,
indicated by this calculation, if the ptr
into the buffer reaches the end, then we get
into the other case.
And then we execute ffurl_read, which calls
retry_transfer_wrapper.
So I think this is basically called when not
all data has been received yet by ffmpeg and
it basically retries to read more data.
And apparently in that condition you trigger
then a heap overflow.
So this ascii picture here this should give
you an idea on how we are gonna avoid calling
memcpy with -1 as size.
If there is nothing to be read, the buf_ptr
will be equal to buf_end and so we will fall
through to another branch in the http_buf_read
function.
And so what paul did, to not fall into the
segfaulting memcpy condition, he delays sending
the response, so that the following data is
handled by a different function.
Because ffmpeg consumes the data first and
then reaches the end and retries to read more.
So this vulnerability has even a timing compo
nent to it.
You can’t send the data all at once.
So let’s rewrite our response server a bit
with all things we know for now, and see how
it all works out.
I will try to add a sleep function after sending
chunksize for FFmpeg to copy the contents
into the buffer, fix the buf_ptr so it will
be equal to buf_end pointer, so on the next
attempt to call http_buf_read function we
will fall through another branch to trigger
the read function trying to retrieve more
data.
Let’s set a breakpoint in the retry function
to see what kind of function is called here.
So let’s rerun ffmpeg, continue a bit.
Now it is waiting for the 5 second sleep we
have in the server waiting to receive more
data.
And boom, we get a crash.
And when we look back up at the retry function,
we were calling tcp_read.
So that was called before we were waiting
for more data of the server.
And tcp read is called also with -1 as a size.
And tcp read is very simple, it simply calls
recv.
So it calls recv with a huge number.
So it can read a huuuge amount of data into
a buffer.
That already looks bad.
And I think paul told me that this is not
quite where the exploitable heap overflow
happens, because there is another function
that trusts this buffer and copies from it
into another buffer, and this is then where
we overflow.
By analyzing a lot of source code I was able
to recon that the buffer was allocated along
with it’s context in the libavformat/aviobuf
file.
Yeah clearly Paul had to read a lot to figure
this out.
I was not able to get it in a short time.
But you see that all these functions operate
on this context and that’s a structure that
just holds a lot of relevant data for this
data processing.
And apparently it’s allocated close to the
buffer that is holding the data we receive.
So The buffer was allocated in this function.
So here it is.
This is the buffer we write into.
And here is our context allocated.
Which means the context is allocated after
we have an allocated buffer and if we get
a bit lucky the buffer might be before the
context structure.
So if we have indeed a heap overflow, we could
maybe overwrite the context structure.
So if we get lucky enough they will be allocated
on heap in the right order, and we actually
will be overflowing the context structure
itself.
Let’s look inside it.
So here is av_mallocz called.
And it’s actually a wrapper to the regular
malloc function.
Let’s look inside AVContext, which members
it has.
Let’s check out other members of this structure.
We actually have some function pointers over
here, so if we overflow these pointers, we
will get immediatly control of RIP register,
which is very nice.
So a function pointer is just a variable that
contains an address of a function.
And if we overwrite that value, and the function
is called, it will call our overwritten address.
So paul figured out that there is a heap overflow
happening with the other code path.
The buffer is 32 kilobytes big and so we could
just send more than that and see what happens.
I will be sending 32 kilobytes of data, which
is exactly the buffer size, and a little bit
more to check if we managed to overflow the
context structure.
Launch the server in the background.
And launch gdb to check what happens.
So instead of expected reaction we have an
assertion error over here.
Let’s go up a little bit.
Let’s actually open this file to see why
this was triggered.c
So this assertation was actually triggered
by assuming that the length was more than
the original length.
So we probably have overflown the av context
structure.
But we didn’t overflowthe right fields.
So maybe if we form it somehow in a better
way, for example if we send nulls first, then
overflow the points with some As, we might
pass this assertation check.
And hopefully we get RIP control.
So let’s check it out.
Let’s launch gdb again.
And there it goes.
We have control over RAX and we are curently
on the instruction call rax, and we have control
of the first argument.
And once you have a control of RIP RDI registers
it is only matter of time until you find proper
gadgets to get stable ROP chain and achieve
code execution.
Unfortunately, this exploit is quite unstable,
because of the property called MTU, which
stands for the Maximum Transmission Unit.
It is made for optimizing data transferring
process through the network.
It breaks the large pieces of data into the
small packets and because of that, our read
function is not able to receive the whole
input, which is more than 32 kilobytes, in
one take to trigger the overflow.
You can actually get your exact MTU value
by typing ifconfig command.
For example, I have fifteen hundred, so that
means that all packets would be splitted by
1500 byte, and this exploit will not work
remotely as it is.
This is issue is resolvable in general case,
and you can practice solving it on your own.
There we have it.
A PoC exploit where we get control of the
instruction pointer awesome!
But paul has another vulnerability, which
we will look at next time.
﻿TROOPERS is a security conference in Heidelberg
Germany which I attended in 2017.
One fun event that happens there every year
is Packetwars, it’s kind of like a CTF competitions
during one evening, but only for a few teams.
And I didn’t have a group to play with.
But it was held in this restaurant we were
all at and the task was shown on a beamer.
This was one.
Battle I: Whale Spotting.
Identify the email address of @darealtrump
and achieve bonus objectives on the way.
We have 45minutes to solve it.
And we get points for various objectives.
some for the email address, for evidence of
whistleblower assassination and if we identify
a favorite coffee shop to organize a boycott.
So my friend TheVamp and I had nothing else
than our phone but we were really craving
to play.
So we tried it.
First we looked up the obvious twitter handle
and found this account.
Oh and this is all going to be screenshots
I made from my phone while playing.
The latest tweet we can find says that we
should ignore the tweet before, because it
was not relevant.
So obviously the first step is to look into
for example the web archive, because we hoped
it had saved the deleted tweet.
And yeah, there was.
It was a URL to some kind of report.
We clicked on it and downloaded the pdf.
Unfortunately certain parts were blacked out,
but I assumed they were just overlays, because
that’s such a typical pdf redaction fail.
So I simply tried to copy the whole page into
a notes app.
And yeah that worked, it revealed the text
underneath.
But it turned out that the text was actually
an image.
And it had this cipher text on it, which looked
like some kind of simple substitution cipher
like caesar or vigenere.
So we had to get the text out of the image
and we didn’t want to type it on the phone.
So we pulled up an online OCR service and
uploaded the image . And now we copied the
text into an online cipher solver, which bruteforces
the key and applying some heuristic if the
result sounds like valid english.
And we got this text out.
It’s not quite perfect because the key is
a bit jumbled and maybe OCR was also not perfect,
but you can guess most of the text:
After some further research, blah blah, and
eliminate them.
So that is evidence of assassination and we
solved that task.
But there were more tasks, so where is the
other stuff?
We checked back to the web archive and found
another entry of deleted tweets, with the
favorite coffee shop starbucks, which was
another task.
And what looks like login credentials.
So we logged into this account, I tweeted
that I was here, got the account’s email
from the settings and we solved the last part.
And now comes the not so humble brag.
We were faster than the actual teams!
I think the reason for that might be, that
with a phone you are sooo limited that you
can’t try out crazy stuff.
Steganography, metadata and so forth is just
out of reach, so we only tried what was possible
for us and got lucky.
I’m sure the other teams over complicated
things because they had laptops.
I think it’s something to keep in mind but
it was really fun to solve something like
this on just a phone.
Because we solved it first, the organizers
even gave us the flag for participating, even
though we were not officially part of packetwars.
So that was really awesome!
And we also got this awesome shout-out at
the end of the conference when they were announcing
the winners.
The actual first people to solve the first
challenge were the spectators.
So our players actually got off to kind of
a rough start.
Are those two guys out here?
That’s us!
We were sitting somewhere ther here in the
back.
OK!
Let’s hear it for those guys, because...
And they did a debrief much better than I
or mathias could ever do.
I think you gave me the debfrief and all the
proofs in about 45 seconds.
So I think you have a future in this sports!
I really appreciate it, that was really fun.
So i can only recommend the TROOPERS conference
in heidelberg.
It’s a solid conference and if you have
a chance to go there, you should.
Unfortunately it’s a professional conference
which means ticket prices are really high
and not something you generally buy privately,
but the cool thing is they have limited spots
available for students and you can write a
motivational letter and maybe get a free ticket.
So that’s really cool and I encourage you
to do that.`
﻿Last video we had a lame virtual lockpicking
challenge, but there was also a physical lockpicking
challenge.
On the table of the organizers was a sealed
package with a basic padlock that you had
to open.
The only tools available were paperclips - that’s
like how it is done in the movies.
I’m not explaining to you how basic lockpicking
works, I also don’t really know much about
it, and failed the challenge at first.
I didn’t know that I had turned the lock
in the wrong direction and I thought paperclips
are just too weak.
But I wanted to tell you a short cool story
about it.
So the guy who is filming right now, is in
fact int0x80 from Dual Core who makes nerdcore
music.
But he is not only a musician, but plays CTF
and even held a talk at BruCON about Forensics.
He was super nice and happy to lend me his
lock-picking set, and also told me I had to
turn the lock clockwise.
But it turns out the lock was a bit too small
for the picking set, so he showed me how,
I can use two coins to twirl the wire and
make the paperclip tools stronger.
And then I tried it again and succeeded.
It’s just so cool what kind of people you
can meet at conferences, and despite him clearly
being famous, doesn’t talk down to you,
helps you and just wants to play some CTF
with you.
So thanks int0x80, you are awesome.
Let’s have a look at a challenge I didn’t
solve.
OSINT.
The description says, “you have been associated
with this case!
Apparently a cybercriminal is planning a new
attack with a partner, we have a file with
an email header sent by the criminal.
This header was sent by the former investigator
on previous week to his disappearance.”
So the first reason I wanna talk about this
challenge, it’s a good example for how not
to design a challenge.
I have no idea what to do.
Apparently it’s about forensics, recon,
open source intelligence whatever, which probably
means I simply have to look around and try
to find something that looks like a flag.
But there is no goal.
Nothing to aim for, I can’t tell if I make
progress or not.
That challenge was very frustrating because
of this and eventually gave it up.
So when I had a first look at the provided
email, I wanted to know what the content says.
So I had to translate the subject and content.
Didn’t tell me much.
From the email headers I saw, that the email
was sent from this anonymous mail service
5ymail.
So the second reason why I wanted to show
you this challenge is, that because of this
task, I had a look at 5ymail and learned,
what an awful anonymous email service that
is.
That thing is rubbish.
The first thing I did was to send myself an
email with this service to have a look at
the headers.
When you send the anonymous email, it will
generate a username and password for you.
And now hold your hat, let’s have a look
at the email headers of that email.
The email listed in reply-to looks very similar.
Infact it contains the auto-generated username
and password.
What the fuck?!
At this moment I thought, WHOA this challenge
is cool, we are abusing this real service.
The plan was clear, I extract the password
and username from the header, log into that
servie and probably find the flag there.
But it turns out, you can’t login with those
credentials.
I asked one of the organizers if he can check
if the challenge still works.
Because somebody else could have changed the
password to block other players.
But he verified that it still works and I’m
on the wrong track… oh well…
Another small thing I learned about this service
is this weird endpoint that tells you the
subject of the last received emails.
WHAT THE FRKN HELL?
Isn’t this supposed to be like a private
anonymous mailer or whatever.
And to make things even worse, you can inject
XSS into the email subject.
What?
What?
I…
I.. don’t even understand.
Who?
What?
Whyyyyy?
The only good thing about this service is,
that based on the leak of this endpoint, I
learned, that this email service is not used
much.
Which makes me very happy.
So yeah, after all this I gave up on this
OSINT challenge.
To this day I have no idea what I have to
do.
If you know the solution, or if you figure
it out, please tell me.
This challenge makes me crazy.
Ok move on to another challenge.
This challenge is called “Selected Access”
and the description says, that the site only
allows entry to horses.
And we have to show that we are a horse.
There is also a hint saying that we should
have a look at index.bk.
So let’s get started.
This is the challenge url.
It says this is a test to verify if we are
a horse.
Okay, well then.
I started by looking into the HTML source,
to get a better feeling for what functionality
the page might have.
But turns out there is not much, besides this
picture in an html comment.
The picture is a decision graph that we can
follow to check if we are a horse.
And apparently there is no way for reaching
that conclusion, we will always be human.
Now when we look into the index.bk hint, we
can find some php code.
So that might be the source code of the other
page.
I copy the code into sublime to have some
syntax highlighting.
Let’s have a look at the code.
The code checks the question parameter, and
then the answer parameter, and then there
is a switch-case, that sets a certain URL
to be fetched with curl.
And the response will be embedded in this
page.
So I immediately thought I should go for the
“impossibru.php”.
I mean what other goal would there be other
than going for the impossible script?
This means I want question 5 with answer ‘no’.
Ok interesting.
We get an L-mayo and that horses don’t cheat.
That confused me.
And I even tried to use this sentence as a
flag.
But obviously that would have been too easy.
So what else could it be?
Always when I see a curl, I’m hunting for
Server-Side-Request-Forgery, or similar bugs.
Because if we could control the whole URL,
we could try to access some other service
only available from localhost.
Or maybe even a file from the system.
But that didn’t really work because we can
only append values to the urls.
We do control basically what we append, because
it takes the question number, for example
5, which would result in r5=, and then it
would append the answer to that, and we could
set the answer to anything we want.
But that doesn’t help us much.
I then started to head into the wrong direction
and I tried to figure out if there is a curl
bug that I’m not familiar with.
Turns out it’s really annoying to search
for php, curl, exploit, or similar searchterms,
because so many small exploits scripts are
written in php with curl, and that doesn’t
help me.
But after I put this challenge aside, I realized
I have been obsessed with the wrong strategy.
I don’t know why I had the revelation, but
at some point I realized, “The goal is to
not get impossibru, but pass the correct answer
to the 5.php script.
Duh…”
And that is fairly easy.
First of all, we have to make sure, that the
question will be 5, but the answer not “no”.
So what we can do is, we can simply inject
more parameters via the answer variable.
So I simply set the answer to yes, but followed
it up with another ampercant URL-encoded,
followed by the r5=no.
Now when the string is built, it will do r5=yes
& r5=no.
And that will be appended to the 5.php for
the curl request.
And yeah, the r5 parameter is there twice,
but that doesn’t matter, because the script
will only see the last one.
And this way we load the 5.php script that
gives us the flag: “I’m a beauty horse”.
Also while editing I realized, that a simpler
solution would have been to simply use r5=no
followed by an encoded ampercant.
Because then the answer would still be not
no, because it would be no&.
But the 5.php script requested via curl would
then only see the “no”.
That’s it for this video.
I think there will be one more brucon ctf
video write-up.
There was a challenge I really liked and I
wanted to show it.
﻿What does iOS 9.3 and the Nintendo Switch
have in common?
They both use the browser engine WebKit with
a version that is vulnerable to a known memory
corruption vulnerability.
Remember the news of the pegasus malware for
iOS, which was discovered when it was used
in a targeted attack against the human rights
activist Ahmed Mansoor?
That malware used a webkit exploit as the
first stage, to gain arbitrary code execution.
Qwerty and the pangu team then used this bug
in their jailbreakme website.
And it turns out, the browser of the Nintendo
Switch is so old, that is also has this bug.
And this is what a lot of people are using
right now as a first entry point in hacking
the switch.
Obviously the whole jailbreak is extremely
complex, even just getting code execution
is insane.
But I spent now quite some time understanding
the bug itself and the first crucial part
which creates an arbitrary read/write primitive.
So you can overwrite anything in memory, for
example function pointers or jitted code.
But let’s start at the beginning.
<intro>
First we need to figure out how to access
the browser in the switch.
You may have heard that the Nintendo Switch
doesn’t have a browser, so what the heck
am I talking about?
Well there is no good browser implemented,
but it turns out, that when you connect to
a wifi, which requires you to login in a captive
portal, it will use a browser view and load
that page for you.
A captive portal is common in hotels and airports
and stuff.
So we have to figure out how to load our own
website here.
When you look at the network settings, you
can specify a proxy server, which is great
because then I can run a proxy server on my
laptop and intercept all the traffic.
I use Burp Suite as my proxy server and just
have to make sure it listens on all interfaces,
so other devices on the same network can use
it.
So now we just have to enter the IP of this
laptop into the proxy settings of the switch.
When we now connect to the wifi, the switch
will establish connections through this laptop.
And we can see here in the Burp history view,
that the switch tried to contact conntest.nintendowifi.net
That site just responds with a simple string
that the connection works.
It uses this to check if you have internet
connection or not.
So, if this check fails, it will think you
first need to authenticate from a captive
portal.
So next we need to redirect this request to
a different page, basically our “captive
portal”.
We can do that by simply modifying the /etc/hosts
file, to point the conntest domain to another
IP.
For example localhost.
Then we spawn a simple webserver on our machine,
for example with php -S.
We can place a index.html file in here to
verify that this works.
And with a browser we can see that we have
now on localhost a webserver running.
So, when the switch now connects to the wifi,
it will try to contact conntest and it will
go through the proxy on my laptop.
My laptop sees in the /etc/hosts file what
the IP for conntest is.
So the proxy will connect to localhost instead,
which will access our index.html file.
Let’s try it.
We search for the wifi.
We connect to it.
It will check if there is access to the internet.
It didn’t get the expected result for conntest
back and tells you you have to login.
When we now press next, it will load what
it thinks is the captive portal.
Now we have access to a browser that loads
our website.
We can also have a look at the requests in
burp, which shows us the User Agent the switch
uses.
So now that we have that setup, let’s read
up a bit more on the webkit bug.
It was assigned CVE-2016-4657 and has the
description: “WebKit in Apple iOS before
9.3.5 allows remote attackers to execute arbitrary
code or cause a denial of service (memory
corruption) via a crafted web site.”
The description can be a bit misleading.
Makes it sound like it’s only an iOS issue,
but its generally a webkit bug, and would
affect anything that used that particular
webkit version.
In our case the nintendo switch.
Also this is not an exploit where you just
type into metasploit `use exploit/nintendoswitch/webkit`.
This is something where you actually have
to understand it quite in depth to be able
to use it.
Now let’s take qwerty’s jailbreakme code,
which uses the webkit bug, extract the first
relevant part and adapt it to the nintendo
switch.
I won’t go through all this process because
that took me ages to understand, but I want
to show and explain to you what I got now...
So let’s walk through it.
First we create a Typed Array of unisgned
32bit integers.
And in memory this will create a struct with
a couple of different values such as a JSCell
which contains a couple of interesting values
such as a structure ID that determines kind
of the type of this object.
We will look at that later again.
A butterfly pointer, which is used in a bit
more complex objects but not quite relevant
for us right now, a vector which contains
a pointer to a chunk of memory that represents
our array.
And the length of that memory.
So that array gives us basically access to
raw bytes in memory.
Obviously you can’t access beyond it’s
length.
Then we create a more flexible array.
A standard array like you might use it.
That array is a bit different, as it can contain
arbitrary types.
Any kind of objects.
So instead of just pointing to raw memory,
it points to more complex objects called JSValues.
And here is an example of the integer with
the hex value 41414141, it would store 0xffff0000
before it, to indicate the value is an integer.
Look at the amazing phrack paper if you want
to know more details about these JSValues.
In the case of the exploit it will set the
first element of the Array to a big ArrayBuffer
and the second to some number.
An Array Buffer is also access to raw bytes.
Basically different typed arrays can point
to the same buffer in memory.
Whatever, read the javascript reference.
So If I’m not mistaken, the first element
of the array is now a JSValue with a pointer
to an array buffer.
Next we create a simple Javascript Object
and overwrite its toString() function.
That function is called whenever you want
to get a string representation of that object.
So if I return 1337 object as a string, and
I would alert this object, it would call to
string and show me that one.
But in this case the function does a bit more.
It first sets the reference to the array we
just created to null, as well as setting another
property to null.
In a second you will see that this “stale”
property is also a reference to the arr array.
Theoretically now all references to the array
are gone, and the garbage collector can free
that array.
To force the garbage collector to kick in
right now, we can use the function which just
allocates and removes a lot of objects.
And when you do this a couple of times you
can be fairly certain that the garbage collector
did the work.
After the garbage collection the function
will now allocate a lot of new Uint32Arrays.
The reference to those are stored in buf,
so we can access those arrays.
And if everything goes well those arrays might
be allocated where the previous array was.
But how is this object with that toString
function used now.
We define an object that we use as properties.
And I think we allocate more than just two,
so the properties are not stored inline, but
I’m not 100% sure here.
Anyway, one of these properties is called
stale, and it is set to the array reference.
That is the property that the toString function
will set to null.
Another property is `length` which is set
to the not_number object.
Then we create a new empty array target and
apply those properties to it with Object.defineProperties.
This means all those properties we defined
will be set to the target array.
During this assignment, the toString() function
of not_number will be called and causes the
garbage collection of the array.
As well as the allocation of a lot of Uint32Arrays.
And this is where the bug happens.
Theoretically the stale property was set to
null, and should not be accessible.
But somehow the reference is still there.
Some stuff internally did not properly check
everything.
This means that we have a reference into some
memory where previously the arr array was
allocated.
And we also allocated a lot of Uin32Arrays
and we hope that these now overlap.
As I mentioned earlier, the Uint32Arrays allow
direct memory access, they can read and write
raw bytes.
While the arr array was a complex object,
with JSValues.
Now it’s already clear what you can do with
this.
You can use the Uint32Arrays, which are accessible
via buf.
To read and write raw bytes at the location
where the stale property thinks a standard
Javascript object is.
So first it has to find if and how the buf
and the stale array overlap.
To do this, we can simply add a number to
the first element of stale.
But what is the first element of stale now.
Isn’t that garbage memory?
well ideally, if everything works, it points
to where we created the uInt32Arrays, and
we populated that memory region with 0xffff000041414141,
which is a JSValue representing an integer.
In fact the number 0x41414141.
This means that now we add hex 101 to the
first element of the stale array, making it
0x41414242.
We can then simply search through the whole
uInt32Array memory looking for this 0x41414242.
Keep in mind that the buf has access to raw
bytes, so it will infact see the 0xffff0000
and the 0x41414141, while the stale array
things this is a javascript object, and only
uses the 0xffff0000 internally to determine,
that we have an integer and the value of it
is 0x41414141.
So what can we do with this now.
This is where exploitation really become creative.
The phrack article says that once you have
the ability to craft arbitrary javascript
objects, you could craft a Float64Array to
create a read/write primitive, but qwerty
used a Uint32Array.
To quote him, here is his reason:
“Easier than float to do math with.
Lol.”
And I guess he has a point.
Floating point values in raw bytes are really
annoying.
So first of all, why do we want to craft a
Uint32Array.
If you remember the basic structure of a Uint32Array,
it uses a vector to point to some raw memory.
If you control where this pointer points to,
you can control where you can read data from
and write data to it.
Because it thinks it points to the actual
array.
There is a super clever way how to craft this
array now.
Qwerty creates a new object with four properties.
A,b,c,d.
He probably just took that from the phrack
article, because when you look at how a simple
object with only four properties is stored,
it stores the values inline.
This is very helpful in a second.
As you see, the values set, like the hex 1337
are simply placed here in memory after eachother.
So that’s a very neat way to control a couple
of consecutive values in memory.
The two 64bit values are the JSCell and the
butterfly pointer.
The JSCell, or more specifically the structure
ID inside of the JSCell determines, what this
Javscript Object actually is.
In the phrack article it looks like, this
object here has the ID 136.
So in order to craft a Uint32Array, we would
have to know the structure ID of that.
According to the phrack article, this ID can
change sometimes, maybe at restart or between
different webkit builds.
But apparently it’s very common to be 105.
Nontheless, because my exploit was very unstable
I tried to see if the value is maybe different
and the phrack article shows a technique how
to do that.
Back to the new object for a second.
So this will allocate a new object with 4
properties that looks like this in memory.
0x69, or in decimal 105, then zero, the pointer
to the smash array, which we allocated way
at the beginning and 0x100.
The function u2d is a clever little helper.
As every number in javascript is basically
a float, we can create a new dataview of 16bytes,
so 64bit, set the high and the low 32bits
and return the float representation of those
bytes.
This new object creation will also overwrite
stale[0].
Just a few seconds ago I mentioned that stale[0]
points to a JSValue representing a number,
but now it was overwritten with a JSValue
representing a pointer.
A pointer to the JSObject that was just created.
This JSObject it points to is not very interesting
for us.
It’s not an arbitrary object we have crafted.
But remember, that the JSValue with the pointer
to this object is in the memory that is overlapped
by the buf.
This means we can use buf to manipulate the
pointer.
And what we do is, we add 0x10 or decimal
16, which moves the pointer into the properties
of the JSObject.
Now suddenly the 0x69 is the JSCell value.
And the zero here is the butterfly.
And the smsh address becomes the vector, the
pointer where the actual array is in memory.
To be clear this points into the similar struct
of that array, so this doesn’t point into
the memory location of that smash array, but
also into this JSObject struct with its vector
pointer and its length.
And 0x100 is the length of that array, which
is actually just the Object structure of the
smash array.
So now you know how we can misalign the pointer
to this object, which will interpret the properties
here as the actual object.
This means we can now try different structureIDs
in a loop and check with instanceof if we
have crafted a Uint32Array.
We remember the original stale[0] pointer
in stale[1], then missalign stale[0], then
we can check the type of the stale[0] object,
if it’s not correct, we increment our structureID
guess, and assign a new value to the stale[1]
‘a’ property, which will look like the
StructureID from the missaligned pointer in
stale[0].
What we basically created now is, we have
two pointers in stale.
Which slightly overlap in memory.
We also have somwhere an array called smsh.
We have also set the memory location for our
crafted array, the vector pointer, to point
to smsh.
To the smash structure, not the actual memory
location of the smash array.
This means we have another object that we
can fully control.
Stale is an array.
The first element of stale points to a crafted
Uint32Array.
So when we access the elements of that array,
we obviously access the 32bit values of the
smsh JSObject structure.
And as you know, the object contains 64bit
values, and the fourth 64bit value is the
length of the smsh array.
So stale[0] of [0] and [1] would be the first
64bit, 2,3 would be the second 64 bit, 4,5
would be the third 64bit and 6,7 would be
the 4th 64bit.
So with stale[0][6] we can overwrite the length
of the smash array.
And we can now check the length of the smsh
array.
Let’s try this on the switch.
We load the page and it might not immediately
work, but it will refresh and try again.
Ok so we triggered the bug and we found overlapping
memory by looking for the 0x41414242 value.
Now we check the current length of smash,
we craft our object, try to find the structure
id, we actually find it’s 105, so I didn’t
have to go through this trouble of iterating
over them, then we change the length of smsh
and print the smsh length again.
And it changed.
Isn’t this crazy!
So now we can just modify the vector where
the smash array points to in the exact same
way, and then simply read the raw data it
points to from the smsh array.
or write to the smash array.
It gives us super simple access to the whole
memory of the process.
Next steps could be to find the address of
the browser binary in memory to dump it.
Maybe find some function pointers in memory
you can overwrite, create a ROP chain or maybe
even shellcode because we should have jitted
code, I guess?
This video is already crazy long.
So let’s stop here for now.
I really learned a lot working through the
first part of qwerty’s exploit.
I hope this this also gives you a sense for
how frckn complicated these modern memory
corruption exploits are and what kind of work
and knowledge is required to do them.
I only scratched the surface here.
I hope this also increases your respect for
the people who do this kind of research.
At this point I also want to thank Retr0id
and Ando who I just met on IRC and were in
the same boat as me and we and we helped eachother
trying to figure how this works.
And also a huge thank you to qwerty, who answered
a lot of my noob questions and shared his
progress with me.
I really appreciate you supporting somebody
who tries to learn this!
If this sounds like fun to you, make sure
you read the phrack paper by samuel groß,
or saelo about “attacking javascript engines”,
which gives a way more in depth insight into
how this works.
There is also another article more specifically
about firefox, which is different from webkit,
but also gives you a better idea of how browsers
w ork.
Thank you very much, keep on hackin’ in
the free world, and doot doola doot doo.
﻿What does iOS 9.3 and the Nintendo Switch
have in common?
They both use the browser engine WebKit with
a version that is vulnerable to a known memory
corruption vulnerability.
Remember the news of the pegasus malware for
iOS, which was discovered when it was used
in a targeted attack against the human rights
activist Ahmed Mansoor?
That malware used a webkit exploit as the
first stage, to gain arbitrary code execution.
Qwerty and the pangu team then used this bug
in their jailbreakme website.
And it turns out, the browser of the Nintendo
Switch is so old, that is also has this bug.
And this is what a lot of people are using
right now as a first entry point in hacking
the switch.
Obviously the whole jailbreak is extremely
complex, even just getting code execution
is insane.
But I spent now quite some time understanding
the bug itself and the first crucial part
which creates an arbitrary read/write primitive.
So you can overwrite anything in memory, for
example function pointers or jitted code.
But let’s start at the beginning.
<intro>
First we need to figure out how to access
the browser in the switch.
You may have heard that the Nintendo Switch
doesn’t have a browser, so what the heck
am I talking about?
Well there is no good browser implemented,
but it turns out, that when you connect to
a wifi, which requires you to login in a captive
portal, it will use a browser view and load
that page for you.
A captive portal is common in hotels and airports
and stuff.
So we have to figure out how to load our own
website here.
When you look at the network settings, you
can specify a proxy server, which is great
because then I can run a proxy server on my
laptop and intercept all the traffic.
I use Burp Suite as my proxy server and just
have to make sure it listens on all interfaces,
so other devices on the same network can use
it.
So now we just have to enter the IP of this
laptop into the proxy settings of the switch.
When we now connect to the wifi, the switch
will establish connections through this laptop.
And we can see here in the Burp history view,
that the switch tried to contact conntest.nintendowifi.net
That site just responds with a simple string
that the connection works.
It uses this to check if you have internet
connection or not.
So, if this check fails, it will think you
first need to authenticate from a captive
portal.
So next we need to redirect this request to
a different page, basically our “captive
portal”.
We can do that by simply modifying the /etc/hosts
file, to point the conntest domain to another
IP.
For example localhost.
Then we spawn a simple webserver on our machine,
for example with php -S.
We can place a index.html file in here to
verify that this works.
And with a browser we can see that we have
now on localhost a webserver running.
So, when the switch now connects to the wifi,
it will try to contact conntest and it will
go through the proxy on my laptop.
My laptop sees in the /etc/hosts file what
the IP for conntest is.
So the proxy will connect to localhost instead,
which will access our index.html file.
Let’s try it.
We search for the wifi.
We connect to it.
It will check if there is access to the internet.
It didn’t get the expected result for conntest
back and tells you you have to login.
When we now press next, it will load what
it thinks is the captive portal.
Now we have access to a browser that loads
our website.
We can also have a look at the requests in
burp, which shows us the User Agent the switch
uses.
So now that we have that setup, let’s read
up a bit more on the webkit bug.
It was assigned CVE-2016-4657 and has the
description: “WebKit in Apple iOS before
9.3.5 allows remote attackers to execute arbitrary
code or cause a denial of service (memory
corruption) via a crafted web site.”
The description can be a bit misleading.
Makes it sound like it’s only an iOS issue,
but its generally a webkit bug, and would
affect anything that used that particular
webkit version.
In our case the nintendo switch.
Also this is not an exploit where you just
type into metasploit `use exploit/nintendoswitch/webkit`.
This is something where you actually have
to understand it quite in depth to be able
to use it.
Now let’s take qwerty’s jailbreakme code,
which uses the webkit bug, extract the first
relevant part and adapt it to the nintendo
switch.
I won’t go through all this process because
that took me ages to understand, but I want
to show and explain to you what I got now...
So let’s walk through it.
First we create a Typed Array of unisgned
32bit integers.
And in memory this will create a struct with
a couple of different values such as a JSCell
which contains a couple of interesting values
such as a structure ID that determines kind
of the type of this object.
We will look at that later again.
A butterfly pointer, which is used in a bit
more complex objects but not quite relevant
for us right now, a vector which contains
a pointer to a chunk of memory that represents
our array.
And the length of that memory.
So that array gives us basically access to
raw bytes in memory.
Obviously you can’t access beyond it’s
length.
Then we create a more flexible array.
A standard array like you might use it.
That array is a bit different, as it can contain
arbitrary types.
Any kind of objects.
So instead of just pointing to raw memory,
it points to more complex objects called JSValues.
And here is an example of the integer with
the hex value 41414141, it would store 0xffff0000
before it, to indicate the value is an integer.
Look at the amazing phrack paper if you want
to know more details about these JSValues.
In the case of the exploit it will set the
first element of the Array to a big ArrayBuffer
and the second to some number.
An Array Buffer is also access to raw bytes.
Basically different typed arrays can point
to the same buffer in memory.
Whatever, read the javascript reference.
So If I’m not mistaken, the first element
of the array is now a JSValue with a pointer
to an array buffer.
Next we create a simple Javascript Object
and overwrite its toString() function.
That function is called whenever you want
to get a string representation of that object.
So if I return 1337 object as a string, and
I would alert this object, it would call to
string and show me that one.
But in this case the function does a bit more.
It first sets the reference to the array we
just created to null, as well as setting another
property to null.
In a second you will see that this “stale”
property is also a reference to the arr array.
Theoretically now all references to the array
are gone, and the garbage collector can free
that array.
To force the garbage collector to kick in
right now, we can use the function which just
allocates and removes a lot of objects.
And when you do this a couple of times you
can be fairly certain that the garbage collector
did the work.
After the garbage collection the function
will now allocate a lot of new Uint32Arrays.
The reference to those are stored in buf,
so we can access those arrays.
And if everything goes well those arrays might
be allocated where the previous array was.
But how is this object with that toString
function used now.
We define an object that we use as properties.
And I think we allocate more than just two,
so the properties are not stored inline, but
I’m not 100% sure here.
Anyway, one of these properties is called
stale, and it is set to the array reference.
That is the property that the toString function
will set to null.
Another property is `length` which is set
to the not_number object.
Then we create a new empty array target and
apply those properties to it with Object.defineProperties.
This means all those properties we defined
will be set to the target array.
During this assignment, the toString() function
of not_number will be called and causes the
garbage collection of the array.
As well as the allocation of a lot of Uint32Arrays.
And this is where the bug happens.
Theoretically the stale property was set to
null, and should not be accessible.
But somehow the reference is still there.
Some stuff internally did not properly check
everything.
This means that we have a reference into some
memory where previously the arr array was
allocated.
And we also allocated a lot of Uin32Arrays
and we hope that these now overlap.
As I mentioned earlier, the Uint32Arrays allow
direct memory access, they can read and write
raw bytes.
While the arr array was a complex object,
with JSValues.
Now it’s already clear what you can do with
this.
You can use the Uint32Arrays, which are accessible
via buf.
To read and write raw bytes at the location
where the stale property thinks a standard
Javascript object is.
So first it has to find if and how the buf
and the stale array overlap.
To do this, we can simply add a number to
the first element of stale.
But what is the first element of stale now.
Isn’t that garbage memory?
well ideally, if everything works, it points
to where we created the uInt32Arrays, and
we populated that memory region with 0xffff000041414141,
which is a JSValue representing an integer.
In fact the number 0x41414141.
This means that now we add hex 101 to the
first element of the stale array, making it
0x41414242.
We can then simply search through the whole
uInt32Array memory looking for this 0x41414242.
Keep in mind that the buf has access to raw
bytes, so it will infact see the 0xffff0000
and the 0x41414141, while the stale array
things this is a javascript object, and only
uses the 0xffff0000 internally to determine,
that we have an integer and the value of it
is 0x41414141.
So what can we do with this now.
This is where exploitation really become creative.
The phrack article says that once you have
the ability to craft arbitrary javascript
objects, you could craft a Float64Array to
create a read/write primitive, but qwerty
used a Uint32Array.
To quote him, here is his reason:
“Easier than float to do math with.
Lol.”
And I guess he has a point.
Floating point values in raw bytes are really
annoying.
So first of all, why do we want to craft a
Uint32Array.
If you remember the basic structure of a Uint32Array,
it uses a vector to point to some raw memory.
If you control where this pointer points to,
you can control where you can read data from
and write data to it.
Because it thinks it points to the actual
array.
There is a super clever way how to craft this
array now.
Qwerty creates a new object with four properties.
A,b,c,d.
He probably just took that from the phrack
article, because when you look at how a simple
object with only four properties is stored,
it stores the values inline.
This is very helpful in a second.
As you see, the values set, like the hex 1337
are simply placed here in memory after eachother.
So that’s a very neat way to control a couple
of consecutive values in memory.
The two 64bit values are the JSCell and the
butterfly pointer.
The JSCell, or more specifically the structure
ID inside of the JSCell determines, what this
Javscript Object actually is.
In the phrack article it looks like, this
object here has the ID 136.
So in order to craft a Uint32Array, we would
have to know the structure ID of that.
According to the phrack article, this ID can
change sometimes, maybe at restart or between
different webkit builds.
But apparently it’s very common to be 105.
Nontheless, because my exploit was very unstable
I tried to see if the value is maybe different
and the phrack article shows a technique how
to do that.
Back to the new object for a second.
So this will allocate a new object with 4
properties that looks like this in memory.
0x69, or in decimal 105, then zero, the pointer
to the smash array, which we allocated way
at the beginning and 0x100.
The function u2d is a clever little helper.
As every number in javascript is basically
a float, we can create a new dataview of 16bytes,
so 64bit, set the high and the low 32bits
and return the float representation of those
bytes.
This new object creation will also overwrite
stale[0].
Just a few seconds ago I mentioned that stale[0]
points to a JSValue representing a number,
but now it was overwritten with a JSValue
representing a pointer.
A pointer to the JSObject that was just created.
This JSObject it points to is not very interesting
for us.
It’s not an arbitrary object we have crafted.
But remember, that the JSValue with the pointer
to this object is in the memory that is overlapped
by the buf.
This means we can use buf to manipulate the
pointer.
And what we do is, we add 0x10 or decimal
16, which moves the pointer into the properties
of the JSObject.
Now suddenly the 0x69 is the JSCell value.
And the zero here is the butterfly.
And the smsh address becomes the vector, the
pointer where the actual array is in memory.
To be clear this points into the similar struct
of that array, so this doesn’t point into
the memory location of that smash array, but
also into this JSObject struct with its vector
pointer and its length.
And 0x100 is the length of that array, which
is actually just the Object structure of the
smash array.
So now you know how we can misalign the pointer
to this object, which will interpret the properties
here as the actual object.
This means we can now try different structureIDs
in a loop and check with instanceof if we
have crafted a Uint32Array.
We remember the original stale[0] pointer
in stale[1], then missalign stale[0], then
we can check the type of the stale[0] object,
if it’s not correct, we increment our structureID
guess, and assign a new value to the stale[1]
‘a’ property, which will look like the
StructureID from the missaligned pointer in
stale[0].
What we basically created now is, we have
two pointers in stale.
Which slightly overlap in memory.
We also have somwhere an array called smsh.
We have also set the memory location for our
crafted array, the vector pointer, to point
to smsh.
To the smash structure, not the actual memory
location of the smash array.
This means we have another object that we
can fully control.
Stale is an array.
The first element of stale points to a crafted
Uint32Array.
So when we access the elements of that array,
we obviously access the 32bit values of the
smsh JSObject structure.
And as you know, the object contains 64bit
values, and the fourth 64bit value is the
length of the smsh array.
So stale[0] of [0] and [1] would be the first
64bit, 2,3 would be the second 64 bit, 4,5
would be the third 64bit and 6,7 would be
the 4th 64bit.
So with stale[0][6] we can overwrite the length
of the smash array.
And we can now check the length of the smsh
array.
Let’s try this on the switch.
We load the page and it might not immediately
work, but it will refresh and try again.
Ok so we triggered the bug and we found overlapping
memory by looking for the 0x41414242 value.
Now we check the current length of smash,
we craft our object, try to find the structure
id, we actually find it’s 105, so I didn’t
have to go through this trouble of iterating
over them, then we change the length of smsh
and print the smsh length again.
And it changed.
Isn’t this crazy!
So now we can just modify the vector where
the smash array points to in the exact same
way, and then simply read the raw data it
points to from the smsh array.
or write to the smash array.
It gives us super simple access to the whole
memory of the process.
Next steps could be to find the address of
the browser binary in memory to dump it.
Maybe find some function pointers in memory
you can overwrite, create a ROP chain or maybe
even shellcode because we should have jitted
code, I guess?
This video is already crazy long.
So let’s stop here for now.
I really learned a lot working through the
first part of qwerty’s exploit.
I hope this this also gives you a sense for
how frckn complicated these modern memory
corruption exploits are and what kind of work
and knowledge is required to do them.
I only scratched the surface here.
I hope this also increases your respect for
the people who do this kind of research.
At this point I also want to thank Retr0id
and Ando who I just met on IRC and were in
the same boat as me and we and we helped eachother
trying to figure how this works.
And also a huge thank you to qwerty, who answered
a lot of my noob questions and shared his
progress with me.
I really appreciate you supporting somebody
who tries to learn this!
If this sounds like fun to you, make sure
you read the phrack paper by samuel groß,
or saelo about “attacking javascript engines”,
which gives a way more in depth insight into
how this works.
There is also another article more specifically
about firefox, which is different from webkit,
but also gives you a better idea of how browsers
w ork.
Thank you very much, keep on hackin’ in
the free world, and doot doola doot doo.
﻿What does iOS 9.3 and the Nintendo Switch
have in common?
They both use the browser engine WebKit with
a version that is vulnerable to a known memory
corruption vulnerability.
Remember the news of the pegasus malware for
iOS, which was discovered when it was used
in a targeted attack against the human rights
activist Ahmed Mansoor?
That malware used a webkit exploit as the
first stage, to gain arbitrary code execution.
Qwerty and the pangu team then used this bug
in their jailbreakme website.
And it turns out, the browser of the Nintendo
Switch is so old, that is also has this bug.
And this is what a lot of people are using
right now as a first entry point in hacking
the switch.
Obviously the whole jailbreak is extremely
complex, even just getting code execution
is insane.
But I spent now quite some time understanding
the bug itself and the first crucial part
which creates an arbitrary read/write primitive.
So you can overwrite anything in memory, for
example function pointers or jitted code.
But let’s start at the beginning.
<intro>
First we need to figure out how to access
the browser in the switch.
You may have heard that the Nintendo Switch
doesn’t have a browser, so what the heck
am I talking about?
Well there is no good browser implemented,
but it turns out, that when you connect to
a wifi, which requires you to login in a captive
portal, it will use a browser view and load
that page for you.
A captive portal is common in hotels and airports
and stuff.
So we have to figure out how to load our own
website here.
When you look at the network settings, you
can specify a proxy server, which is great
because then I can run a proxy server on my
laptop and intercept all the traffic.
I use Burp Suite as my proxy server and just
have to make sure it listens on all interfaces,
so other devices on the same network can use
it.
So now we just have to enter the IP of this
laptop into the proxy settings of the switch.
When we now connect to the wifi, the switch
will establish connections through this laptop.
And we can see here in the Burp history view,
that the switch tried to contact conntest.nintendowifi.net
That site just responds with a simple string
that the connection works.
It uses this to check if you have internet
connection or not.
So, if this check fails, it will think you
first need to authenticate from a captive
portal.
So next we need to redirect this request to
a different page, basically our “captive
portal”.
We can do that by simply modifying the /etc/hosts
file, to point the conntest domain to another
IP.
For example localhost.
Then we spawn a simple webserver on our machine,
for example with php -S.
We can place a index.html file in here to
verify that this works.
And with a browser we can see that we have
now on localhost a webserver running.
So, when the switch now connects to the wifi,
it will try to contact conntest and it will
go through the proxy on my laptop.
My laptop sees in the /etc/hosts file what
the IP for conntest is.
So the proxy will connect to localhost instead,
which will access our index.html file.
Let’s try it.
We search for the wifi.
We connect to it.
It will check if there is access to the internet.
It didn’t get the expected result for conntest
back and tells you you have to login.
When we now press next, it will load what
it thinks is the captive portal.
Now we have access to a browser that loads
our website.
We can also have a look at the requests in
burp, which shows us the User Agent the switch
uses.
So now that we have that setup, let’s read
up a bit more on the webkit bug.
It was assigned CVE-2016-4657 and has the
description: “WebKit in Apple iOS before
9.3.5 allows remote attackers to execute arbitrary
code or cause a denial of service (memory
corruption) via a crafted web site.”
The description can be a bit misleading.
Makes it sound like it’s only an iOS issue,
but its generally a webkit bug, and would
affect anything that used that particular
webkit version.
In our case the nintendo switch.
Also this is not an exploit where you just
type into metasploit `use exploit/nintendoswitch/webkit`.
This is something where you actually have
to understand it quite in depth to be able
to use it.
Now let’s take qwerty’s jailbreakme code,
which uses the webkit bug, extract the first
relevant part and adapt it to the nintendo
switch.
I won’t go through all this process because
that took me ages to understand, but I want
to show and explain to you what I got now...
So let’s walk through it.
First we create a Typed Array of unisgned
32bit integers.
And in memory this will create a struct with
a couple of different values such as a JSCell
which contains a couple of interesting values
such as a structure ID that determines kind
of the type of this object.
We will look at that later again.
A butterfly pointer, which is used in a bit
more complex objects but not quite relevant
for us right now, a vector which contains
a pointer to a chunk of memory that represents
our array.
And the length of that memory.
So that array gives us basically access to
raw bytes in memory.
Obviously you can’t access beyond it’s
length.
Then we create a more flexible array.
A standard array like you might use it.
That array is a bit different, as it can contain
arbitrary types.
Any kind of objects.
So instead of just pointing to raw memory,
it points to more complex objects called JSValues.
And here is an example of the integer with
the hex value 41414141, it would store 0xffff0000
before it, to indicate the value is an integer.
Look at the amazing phrack paper if you want
to know more details about these JSValues.
In the case of the exploit it will set the
first element of the Array to a big ArrayBuffer
and the second to some number.
An Array Buffer is also access to raw bytes.
Basically different typed arrays can point
to the same buffer in memory.
Whatever, read the javascript reference.
So If I’m not mistaken, the first element
of the array is now a JSValue with a pointer
to an array buffer.
Next we create a simple Javascript Object
and overwrite its toString() function.
That function is called whenever you want
to get a string representation of that object.
So if I return 1337 object as a string, and
I would alert this object, it would call to
string and show me that one.
But in this case the function does a bit more.
It first sets the reference to the array we
just created to null, as well as setting another
property to null.
In a second you will see that this “stale”
property is also a reference to the arr array.
Theoretically now all references to the array
are gone, and the garbage collector can free
that array.
To force the garbage collector to kick in
right now, we can use the function which just
allocates and removes a lot of objects.
And when you do this a couple of times you
can be fairly certain that the garbage collector
did the work.
After the garbage collection the function
will now allocate a lot of new Uint32Arrays.
The reference to those are stored in buf,
so we can access those arrays.
And if everything goes well those arrays might
be allocated where the previous array was.
But how is this object with that toString
function used now.
We define an object that we use as properties.
And I think we allocate more than just two,
so the properties are not stored inline, but
I’m not 100% sure here.
Anyway, one of these properties is called
stale, and it is set to the array reference.
That is the property that the toString function
will set to null.
Another property is `length` which is set
to the not_number object.
Then we create a new empty array target and
apply those properties to it with Object.defineProperties.
This means all those properties we defined
will be set to the target array.
During this assignment, the toString() function
of not_number will be called and causes the
garbage collection of the array.
As well as the allocation of a lot of Uint32Arrays.
And this is where the bug happens.
Theoretically the stale property was set to
null, and should not be accessible.
But somehow the reference is still there.
Some stuff internally did not properly check
everything.
This means that we have a reference into some
memory where previously the arr array was
allocated.
And we also allocated a lot of Uin32Arrays
and we hope that these now overlap.
As I mentioned earlier, the Uint32Arrays allow
direct memory access, they can read and write
raw bytes.
While the arr array was a complex object,
with JSValues.
Now it’s already clear what you can do with
this.
You can use the Uint32Arrays, which are accessible
via buf.
To read and write raw bytes at the location
where the stale property thinks a standard
Javascript object is.
So first it has to find if and how the buf
and the stale array overlap.
To do this, we can simply add a number to
the first element of stale.
But what is the first element of stale now.
Isn’t that garbage memory?
well ideally, if everything works, it points
to where we created the uInt32Arrays, and
we populated that memory region with 0xffff000041414141,
which is a JSValue representing an integer.
In fact the number 0x41414141.
This means that now we add hex 101 to the
first element of the stale array, making it
0x41414242.
We can then simply search through the whole
uInt32Array memory looking for this 0x41414242.
Keep in mind that the buf has access to raw
bytes, so it will infact see the 0xffff0000
and the 0x41414141, while the stale array
things this is a javascript object, and only
uses the 0xffff0000 internally to determine,
that we have an integer and the value of it
is 0x41414141.
So what can we do with this now.
This is where exploitation really become creative.
The phrack article says that once you have
the ability to craft arbitrary javascript
objects, you could craft a Float64Array to
create a read/write primitive, but qwerty
used a Uint32Array.
To quote him, here is his reason:
“Easier than float to do math with.
Lol.”
And I guess he has a point.
Floating point values in raw bytes are really
annoying.
So first of all, why do we want to craft a
Uint32Array.
If you remember the basic structure of a Uint32Array,
it uses a vector to point to some raw memory.
If you control where this pointer points to,
you can control where you can read data from
and write data to it.
Because it thinks it points to the actual
array.
There is a super clever way how to craft this
array now.
Qwerty creates a new object with four properties.
A,b,c,d.
He probably just took that from the phrack
article, because when you look at how a simple
object with only four properties is stored,
it stores the values inline.
This is very helpful in a second.
As you see, the values set, like the hex 1337
are simply placed here in memory after eachother.
So that’s a very neat way to control a couple
of consecutive values in memory.
The two 64bit values are the JSCell and the
butterfly pointer.
The JSCell, or more specifically the structure
ID inside of the JSCell determines, what this
Javscript Object actually is.
In the phrack article it looks like, this
object here has the ID 136.
So in order to craft a Uint32Array, we would
have to know the structure ID of that.
According to the phrack article, this ID can
change sometimes, maybe at restart or between
different webkit builds.
But apparently it’s very common to be 105.
Nontheless, because my exploit was very unstable
I tried to see if the value is maybe different
and the phrack article shows a technique how
to do that.
Back to the new object for a second.
So this will allocate a new object with 4
properties that looks like this in memory.
0x69, or in decimal 105, then zero, the pointer
to the smash array, which we allocated way
at the beginning and 0x100.
The function u2d is a clever little helper.
As every number in javascript is basically
a float, we can create a new dataview of 16bytes,
so 64bit, set the high and the low 32bits
and return the float representation of those
bytes.
This new object creation will also overwrite
stale[0].
Just a few seconds ago I mentioned that stale[0]
points to a JSValue representing a number,
but now it was overwritten with a JSValue
representing a pointer.
A pointer to the JSObject that was just created.
This JSObject it points to is not very interesting
for us.
It’s not an arbitrary object we have crafted.
But remember, that the JSValue with the pointer
to this object is in the memory that is overlapped
by the buf.
This means we can use buf to manipulate the
pointer.
And what we do is, we add 0x10 or decimal
16, which moves the pointer into the properties
of the JSObject.
Now suddenly the 0x69 is the JSCell value.
And the zero here is the butterfly.
And the smsh address becomes the vector, the
pointer where the actual array is in memory.
To be clear this points into the similar struct
of that array, so this doesn’t point into
the memory location of that smash array, but
also into this JSObject struct with its vector
pointer and its length.
And 0x100 is the length of that array, which
is actually just the Object structure of the
smash array.
So now you know how we can misalign the pointer
to this object, which will interpret the properties
here as the actual object.
This means we can now try different structureIDs
in a loop and check with instanceof if we
have crafted a Uint32Array.
We remember the original stale[0] pointer
in stale[1], then missalign stale[0], then
we can check the type of the stale[0] object,
if it’s not correct, we increment our structureID
guess, and assign a new value to the stale[1]
‘a’ property, which will look like the
StructureID from the missaligned pointer in
stale[0].
What we basically created now is, we have
two pointers in stale.
Which slightly overlap in memory.
We also have somwhere an array called smsh.
We have also set the memory location for our
crafted array, the vector pointer, to point
to smsh.
To the smash structure, not the actual memory
location of the smash array.
This means we have another object that we
can fully control.
Stale is an array.
The first element of stale points to a crafted
Uint32Array.
So when we access the elements of that array,
we obviously access the 32bit values of the
smsh JSObject structure.
And as you know, the object contains 64bit
values, and the fourth 64bit value is the
length of the smsh array.
So stale[0] of [0] and [1] would be the first
64bit, 2,3 would be the second 64 bit, 4,5
would be the third 64bit and 6,7 would be
the 4th 64bit.
So with stale[0][6] we can overwrite the length
of the smash array.
And we can now check the length of the smsh
array.
Let’s try this on the switch.
We load the page and it might not immediately
work, but it will refresh and try again.
Ok so we triggered the bug and we found overlapping
memory by looking for the 0x41414242 value.
Now we check the current length of smash,
we craft our object, try to find the structure
id, we actually find it’s 105, so I didn’t
have to go through this trouble of iterating
over them, then we change the length of smsh
and print the smsh length again.
And it changed.
Isn’t this crazy!
So now we can just modify the vector where
the smash array points to in the exact same
way, and then simply read the raw data it
points to from the smsh array.
or write to the smash array.
It gives us super simple access to the whole
memory of the process.
Next steps could be to find the address of
the browser binary in memory to dump it.
Maybe find some function pointers in memory
you can overwrite, create a ROP chain or maybe
even shellcode because we should have jitted
code, I guess?
This video is already crazy long.
So let’s stop here for now.
I really learned a lot working through the
first part of qwerty’s exploit.
I hope this this also gives you a sense for
how frckn complicated these modern memory
corruption exploits are and what kind of work
and knowledge is required to do them.
I only scratched the surface here.
I hope this also increases your respect for
the people who do this kind of research.
At this point I also want to thank Retr0id
and Ando who I just met on IRC and were in
the same boat as me and we and we helped eachother
trying to figure how this works.
And also a huge thank you to qwerty, who answered
a lot of my noob questions and shared his
progress with me.
I really appreciate you supporting somebody
who tries to learn this!
If this sounds like fun to you, make sure
you read the phrack paper by samuel groß,
or saelo about “attacking javascript engines”,
which gives a way more in depth insight into
how this works.
There is also another article more specifically
about firefox, which is different from webkit,
but also gives you a better idea of how browsers
w ork.
Thank you very much, keep on hackin’ in
the free world, and doot doola doot doo.
﻿What does iOS 9.3 and the Nintendo Switch
have in common?
They both use the browser engine WebKit with
a version that is vulnerable to a known memory
corruption vulnerability.
Remember the news of the pegasus malware for
iOS, which was discovered when it was used
in a targeted attack against the human rights
activist Ahmed Mansoor?
That malware used a webkit exploit as the
first stage, to gain arbitrary code execution.
Qwerty and the pangu team then used this bug
in their jailbreakme website.
And it turns out, the browser of the Nintendo
Switch is so old, that is also has this bug.
And this is what a lot of people are using
right now as a first entry point in hacking
the switch.
Obviously the whole jailbreak is extremely
complex, even just getting code execution
is insane.
But I spent now quite some time understanding
the bug itself and the first crucial part
which creates an arbitrary read/write primitive.
So you can overwrite anything in memory, for
example function pointers or jitted code.
But let’s start at the beginning.
<intro>
First we need to figure out how to access
the browser in the switch.
You may have heard that the Nintendo Switch
doesn’t have a browser, so what the heck
am I talking about?
Well there is no good browser implemented,
but it turns out, that when you connect to
a wifi, which requires you to login in a captive
portal, it will use a browser view and load
that page for you.
A captive portal is common in hotels and airports
and stuff.
So we have to figure out how to load our own
website here.
When you look at the network settings, you
can specify a proxy server, which is great
because then I can run a proxy server on my
laptop and intercept all the traffic.
I use Burp Suite as my proxy server and just
have to make sure it listens on all interfaces,
so other devices on the same network can use
it.
So now we just have to enter the IP of this
laptop into the proxy settings of the switch.
When we now connect to the wifi, the switch
will establish connections through this laptop.
And we can see here in the Burp history view,
that the switch tried to contact conntest.nintendowifi.net
That site just responds with a simple string
that the connection works.
It uses this to check if you have internet
connection or not.
So, if this check fails, it will think you
first need to authenticate from a captive
portal.
So next we need to redirect this request to
a different page, basically our “captive
portal”.
We can do that by simply modifying the /etc/hosts
file, to point the conntest domain to another
IP.
For example localhost.
Then we spawn a simple webserver on our machine,
for example with php -S.
We can place a index.html file in here to
verify that this works.
And with a browser we can see that we have
now on localhost a webserver running.
So, when the switch now connects to the wifi,
it will try to contact conntest and it will
go through the proxy on my laptop.
My laptop sees in the /etc/hosts file what
the IP for conntest is.
So the proxy will connect to localhost instead,
which will access our index.html file.
Let’s try it.
We search for the wifi.
We connect to it.
It will check if there is access to the internet.
It didn’t get the expected result for conntest
back and tells you you have to login.
When we now press next, it will load what
it thinks is the captive portal.
Now we have access to a browser that loads
our website.
We can also have a look at the requests in
burp, which shows us the User Agent the switch
uses.
So now that we have that setup, let’s read
up a bit more on the webkit bug.
It was assigned CVE-2016-4657 and has the
description: “WebKit in Apple iOS before
9.3.5 allows remote attackers to execute arbitrary
code or cause a denial of service (memory
corruption) via a crafted web site.”
The description can be a bit misleading.
Makes it sound like it’s only an iOS issue,
but its generally a webkit bug, and would
affect anything that used that particular
webkit version.
In our case the nintendo switch.
Also this is not an exploit where you just
type into metasploit `use exploit/nintendoswitch/webkit`.
This is something where you actually have
to understand it quite in depth to be able
to use it.
Now let’s take qwerty’s jailbreakme code,
which uses the webkit bug, extract the first
relevant part and adapt it to the nintendo
switch.
I won’t go through all this process because
that took me ages to understand, but I want
to show and explain to you what I got now...
So let’s walk through it.
First we create a Typed Array of unisgned
32bit integers.
And in memory this will create a struct with
a couple of different values such as a JSCell
which contains a couple of interesting values
such as a structure ID that determines kind
of the type of this object.
We will look at that later again.
A butterfly pointer, which is used in a bit
more complex objects but not quite relevant
for us right now, a vector which contains
a pointer to a chunk of memory that represents
our array.
And the length of that memory.
So that array gives us basically access to
raw bytes in memory.
Obviously you can’t access beyond it’s
length.
Then we create a more flexible array.
A standard array like you might use it.
That array is a bit different, as it can contain
arbitrary types.
Any kind of objects.
So instead of just pointing to raw memory,
it points to more complex objects called JSValues.
And here is an example of the integer with
the hex value 41414141, it would store 0xffff0000
before it, to indicate the value is an integer.
Look at the amazing phrack paper if you want
to know more details about these JSValues.
In the case of the exploit it will set the
first element of the Array to a big ArrayBuffer
and the second to some number.
An Array Buffer is also access to raw bytes.
Basically different typed arrays can point
to the same buffer in memory.
Whatever, read the javascript reference.
So If I’m not mistaken, the first element
of the array is now a JSValue with a pointer
to an array buffer.
Next we create a simple Javascript Object
and overwrite its toString() function.
That function is called whenever you want
to get a string representation of that object.
So if I return 1337 object as a string, and
I would alert this object, it would call to
string and show me that one.
But in this case the function does a bit more.
It first sets the reference to the array we
just created to null, as well as setting another
property to null.
In a second you will see that this “stale”
property is also a reference to the arr array.
Theoretically now all references to the array
are gone, and the garbage collector can free
that array.
To force the garbage collector to kick in
right now, we can use the function which just
allocates and removes a lot of objects.
And when you do this a couple of times you
can be fairly certain that the garbage collector
did the work.
After the garbage collection the function
will now allocate a lot of new Uint32Arrays.
The reference to those are stored in buf,
so we can access those arrays.
And if everything goes well those arrays might
be allocated where the previous array was.
But how is this object with that toString
function used now.
We define an object that we use as properties.
And I think we allocate more than just two,
so the properties are not stored inline, but
I’m not 100% sure here.
Anyway, one of these properties is called
stale, and it is set to the array reference.
That is the property that the toString function
will set to null.
Another property is `length` which is set
to the not_number object.
Then we create a new empty array target and
apply those properties to it with Object.defineProperties.
This means all those properties we defined
will be set to the target array.
During this assignment, the toString() function
of not_number will be called and causes the
garbage collection of the array.
As well as the allocation of a lot of Uint32Arrays.
And this is where the bug happens.
Theoretically the stale property was set to
null, and should not be accessible.
But somehow the reference is still there.
Some stuff internally did not properly check
everything.
This means that we have a reference into some
memory where previously the arr array was
allocated.
And we also allocated a lot of Uin32Arrays
and we hope that these now overlap.
As I mentioned earlier, the Uint32Arrays allow
direct memory access, they can read and write
raw bytes.
While the arr array was a complex object,
with JSValues.
Now it’s already clear what you can do with
this.
You can use the Uint32Arrays, which are accessible
via buf.
To read and write raw bytes at the location
where the stale property thinks a standard
Javascript object is.
So first it has to find if and how the buf
and the stale array overlap.
To do this, we can simply add a number to
the first element of stale.
But what is the first element of stale now.
Isn’t that garbage memory?
well ideally, if everything works, it points
to where we created the uInt32Arrays, and
we populated that memory region with 0xffff000041414141,
which is a JSValue representing an integer.
In fact the number 0x41414141.
This means that now we add hex 101 to the
first element of the stale array, making it
0x41414242.
We can then simply search through the whole
uInt32Array memory looking for this 0x41414242.
Keep in mind that the buf has access to raw
bytes, so it will infact see the 0xffff0000
and the 0x41414141, while the stale array
things this is a javascript object, and only
uses the 0xffff0000 internally to determine,
that we have an integer and the value of it
is 0x41414141.
So what can we do with this now.
This is where exploitation really become creative.
The phrack article says that once you have
the ability to craft arbitrary javascript
objects, you could craft a Float64Array to
create a read/write primitive, but qwerty
used a Uint32Array.
To quote him, here is his reason:
“Easier than float to do math with.
Lol.”
And I guess he has a point.
Floating point values in raw bytes are really
annoying.
So first of all, why do we want to craft a
Uint32Array.
If you remember the basic structure of a Uint32Array,
it uses a vector to point to some raw memory.
If you control where this pointer points to,
you can control where you can read data from
and write data to it.
Because it thinks it points to the actual
array.
There is a super clever way how to craft this
array now.
Qwerty creates a new object with four properties.
A,b,c,d.
He probably just took that from the phrack
article, because when you look at how a simple
object with only four properties is stored,
it stores the values inline.
This is very helpful in a second.
As you see, the values set, like the hex 1337
are simply placed here in memory after eachother.
So that’s a very neat way to control a couple
of consecutive values in memory.
The two 64bit values are the JSCell and the
butterfly pointer.
The JSCell, or more specifically the structure
ID inside of the JSCell determines, what this
Javscript Object actually is.
In the phrack article it looks like, this
object here has the ID 136.
So in order to craft a Uint32Array, we would
have to know the structure ID of that.
According to the phrack article, this ID can
change sometimes, maybe at restart or between
different webkit builds.
But apparently it’s very common to be 105.
Nontheless, because my exploit was very unstable
I tried to see if the value is maybe different
and the phrack article shows a technique how
to do that.
Back to the new object for a second.
So this will allocate a new object with 4
properties that looks like this in memory.
0x69, or in decimal 105, then zero, the pointer
to the smash array, which we allocated way
at the beginning and 0x100.
The function u2d is a clever little helper.
As every number in javascript is basically
a float, we can create a new dataview of 16bytes,
so 64bit, set the high and the low 32bits
and return the float representation of those
bytes.
This new object creation will also overwrite
stale[0].
Just a few seconds ago I mentioned that stale[0]
points to a JSValue representing a number,
but now it was overwritten with a JSValue
representing a pointer.
A pointer to the JSObject that was just created.
This JSObject it points to is not very interesting
for us.
It’s not an arbitrary object we have crafted.
But remember, that the JSValue with the pointer
to this object is in the memory that is overlapped
by the buf.
This means we can use buf to manipulate the
pointer.
And what we do is, we add 0x10 or decimal
16, which moves the pointer into the properties
of the JSObject.
Now suddenly the 0x69 is the JSCell value.
And the zero here is the butterfly.
And the smsh address becomes the vector, the
pointer where the actual array is in memory.
To be clear this points into the similar struct
of that array, so this doesn’t point into
the memory location of that smash array, but
also into this JSObject struct with its vector
pointer and its length.
And 0x100 is the length of that array, which
is actually just the Object structure of the
smash array.
So now you know how we can misalign the pointer
to this object, which will interpret the properties
here as the actual object.
This means we can now try different structureIDs
in a loop and check with instanceof if we
have crafted a Uint32Array.
We remember the original stale[0] pointer
in stale[1], then missalign stale[0], then
we can check the type of the stale[0] object,
if it’s not correct, we increment our structureID
guess, and assign a new value to the stale[1]
‘a’ property, which will look like the
StructureID from the missaligned pointer in
stale[0].
What we basically created now is, we have
two pointers in stale.
Which slightly overlap in memory.
We also have somwhere an array called smsh.
We have also set the memory location for our
crafted array, the vector pointer, to point
to smsh.
To the smash structure, not the actual memory
location of the smash array.
This means we have another object that we
can fully control.
Stale is an array.
The first element of stale points to a crafted
Uint32Array.
So when we access the elements of that array,
we obviously access the 32bit values of the
smsh JSObject structure.
And as you know, the object contains 64bit
values, and the fourth 64bit value is the
length of the smsh array.
So stale[0] of [0] and [1] would be the first
64bit, 2,3 would be the second 64 bit, 4,5
would be the third 64bit and 6,7 would be
the 4th 64bit.
So with stale[0][6] we can overwrite the length
of the smash array.
And we can now check the length of the smsh
array.
Let’s try this on the switch.
We load the page and it might not immediately
work, but it will refresh and try again.
Ok so we triggered the bug and we found overlapping
memory by looking for the 0x41414242 value.
Now we check the current length of smash,
we craft our object, try to find the structure
id, we actually find it’s 105, so I didn’t
have to go through this trouble of iterating
over them, then we change the length of smsh
and print the smsh length again.
And it changed.
Isn’t this crazy!
So now we can just modify the vector where
the smash array points to in the exact same
way, and then simply read the raw data it
points to from the smsh array.
or write to the smash array.
It gives us super simple access to the whole
memory of the process.
Next steps could be to find the address of
the browser binary in memory to dump it.
Maybe find some function pointers in memory
you can overwrite, create a ROP chain or maybe
even shellcode because we should have jitted
code, I guess?
This video is already crazy long.
So let’s stop here for now.
I really learned a lot working through the
first part of qwerty’s exploit.
I hope this this also gives you a sense for
how frckn complicated these modern memory
corruption exploits are and what kind of work
and knowledge is required to do them.
I only scratched the surface here.
I hope this also increases your respect for
the people who do this kind of research.
At this point I also want to thank Retr0id
and Ando who I just met on IRC and were in
the same boat as me and we and we helped eachother
trying to figure how this works.
And also a huge thank you to qwerty, who answered
a lot of my noob questions and shared his
progress with me.
I really appreciate you supporting somebody
who tries to learn this!
If this sounds like fun to you, make sure
you read the phrack paper by samuel groß,
or saelo about “attacking javascript engines”,
which gives a way more in depth insight into
how this works.
There is also another article more specifically
about firefox, which is different from webkit,
but also gives you a better idea of how browsers
w ork.
Thank you very much, keep on hackin’ in
the free world, and doot doola doot doo.
﻿What does iOS 9.3 and the Nintendo Switch
have in common?
They both use the browser engine WebKit with
a version that is vulnerable to a known memory
corruption vulnerability.
Remember the news of the pegasus malware for
iOS, which was discovered when it was used
in a targeted attack against the human rights
activist Ahmed Mansoor?
That malware used a webkit exploit as the
first stage, to gain arbitrary code execution.
Qwerty and the pangu team then used this bug
in their jailbreakme website.
And it turns out, the browser of the Nintendo
Switch is so old, that is also has this bug.
And this is what a lot of people are using
right now as a first entry point in hacking
the switch.
Obviously the whole jailbreak is extremely
complex, even just getting code execution
is insane.
But I spent now quite some time understanding
the bug itself and the first crucial part
which creates an arbitrary read/write primitive.
So you can overwrite anything in memory, for
example function pointers or jitted code.
But let’s start at the beginning.
<intro>
First we need to figure out how to access
the browser in the switch.
You may have heard that the Nintendo Switch
doesn’t have a browser, so what the heck
am I talking about?
Well there is no good browser implemented,
but it turns out, that when you connect to
a wifi, which requires you to login in a captive
portal, it will use a browser view and load
that page for you.
A captive portal is common in hotels and airports
and stuff.
So we have to figure out how to load our own
website here.
When you look at the network settings, you
can specify a proxy server, which is great
because then I can run a proxy server on my
laptop and intercept all the traffic.
I use Burp Suite as my proxy server and just
have to make sure it listens on all interfaces,
so other devices on the same network can use
it.
So now we just have to enter the IP of this
laptop into the proxy settings of the switch.
When we now connect to the wifi, the switch
will establish connections through this laptop.
And we can see here in the Burp history view,
that the switch tried to contact conntest.nintendowifi.net
That site just responds with a simple string
that the connection works.
It uses this to check if you have internet
connection or not.
So, if this check fails, it will think you
first need to authenticate from a captive
portal.
So next we need to redirect this request to
a different page, basically our “captive
portal”.
We can do that by simply modifying the /etc/hosts
file, to point the conntest domain to another
IP.
For example localhost.
Then we spawn a simple webserver on our machine,
for example with php -S.
We can place a index.html file in here to
verify that this works.
And with a browser we can see that we have
now on localhost a webserver running.
So, when the switch now connects to the wifi,
it will try to contact conntest and it will
go through the proxy on my laptop.
My laptop sees in the /etc/hosts file what
the IP for conntest is.
So the proxy will connect to localhost instead,
which will access our index.html file.
Let’s try it.
We search for the wifi.
We connect to it.
It will check if there is access to the internet.
It didn’t get the expected result for conntest
back and tells you you have to login.
When we now press next, it will load what
it thinks is the captive portal.
Now we have access to a browser that loads
our website.
We can also have a look at the requests in
burp, which shows us the User Agent the switch
uses.
So now that we have that setup, let’s read
up a bit more on the webkit bug.
It was assigned CVE-2016-4657 and has the
description: “WebKit in Apple iOS before
9.3.5 allows remote attackers to execute arbitrary
code or cause a denial of service (memory
corruption) via a crafted web site.”
The description can be a bit misleading.
Makes it sound like it’s only an iOS issue,
but its generally a webkit bug, and would
affect anything that used that particular
webkit version.
In our case the nintendo switch.
Also this is not an exploit where you just
type into metasploit `use exploit/nintendoswitch/webkit`.
This is something where you actually have
to understand it quite in depth to be able
to use it.
Now let’s take qwerty’s jailbreakme code,
which uses the webkit bug, extract the first
relevant part and adapt it to the nintendo
switch.
I won’t go through all this process because
that took me ages to understand, but I want
to show and explain to you what I got now...
So let’s walk through it.
First we create a Typed Array of unisgned
32bit integers.
And in memory this will create a struct with
a couple of different values such as a JSCell
which contains a couple of interesting values
such as a structure ID that determines kind
of the type of this object.
We will look at that later again.
A butterfly pointer, which is used in a bit
more complex objects but not quite relevant
for us right now, a vector which contains
a pointer to a chunk of memory that represents
our array.
And the length of that memory.
So that array gives us basically access to
raw bytes in memory.
Obviously you can’t access beyond it’s
length.
Then we create a more flexible array.
A standard array like you might use it.
That array is a bit different, as it can contain
arbitrary types.
Any kind of objects.
So instead of just pointing to raw memory,
it points to more complex objects called JSValues.
And here is an example of the integer with
the hex value 41414141, it would store 0xffff0000
before it, to indicate the value is an integer.
Look at the amazing phrack paper if you want
to know more details about these JSValues.
In the case of the exploit it will set the
first element of the Array to a big ArrayBuffer
and the second to some number.
An Array Buffer is also access to raw bytes.
Basically different typed arrays can point
to the same buffer in memory.
Whatever, read the javascript reference.
So If I’m not mistaken, the first element
of the array is now a JSValue with a pointer
to an array buffer.
Next we create a simple Javascript Object
and overwrite its toString() function.
That function is called whenever you want
to get a string representation of that object.
So if I return 1337 object as a string, and
I would alert this object, it would call to
string and show me that one.
But in this case the function does a bit more.
It first sets the reference to the array we
just created to null, as well as setting another
property to null.
In a second you will see that this “stale”
property is also a reference to the arr array.
Theoretically now all references to the array
are gone, and the garbage collector can free
that array.
To force the garbage collector to kick in
right now, we can use the function which just
allocates and removes a lot of objects.
And when you do this a couple of times you
can be fairly certain that the garbage collector
did the work.
After the garbage collection the function
will now allocate a lot of new Uint32Arrays.
The reference to those are stored in buf,
so we can access those arrays.
And if everything goes well those arrays might
be allocated where the previous array was.
But how is this object with that toString
function used now.
We define an object that we use as properties.
And I think we allocate more than just two,
so the properties are not stored inline, but
I’m not 100% sure here.
Anyway, one of these properties is called
stale, and it is set to the array reference.
That is the property that the toString function
will set to null.
Another property is `length` which is set
to the not_number object.
Then we create a new empty array target and
apply those properties to it with Object.defineProperties.
This means all those properties we defined
will be set to the target array.
During this assignment, the toString() function
of not_number will be called and causes the
garbage collection of the array.
As well as the allocation of a lot of Uint32Arrays.
And this is where the bug happens.
Theoretically the stale property was set to
null, and should not be accessible.
But somehow the reference is still there.
Some stuff internally did not properly check
everything.
This means that we have a reference into some
memory where previously the arr array was
allocated.
And we also allocated a lot of Uin32Arrays
and we hope that these now overlap.
As I mentioned earlier, the Uint32Arrays allow
direct memory access, they can read and write
raw bytes.
While the arr array was a complex object,
with JSValues.
Now it’s already clear what you can do with
this.
You can use the Uint32Arrays, which are accessible
via buf.
To read and write raw bytes at the location
where the stale property thinks a standard
Javascript object is.
So first it has to find if and how the buf
and the stale array overlap.
To do this, we can simply add a number to
the first element of stale.
But what is the first element of stale now.
Isn’t that garbage memory?
well ideally, if everything works, it points
to where we created the uInt32Arrays, and
we populated that memory region with 0xffff000041414141,
which is a JSValue representing an integer.
In fact the number 0x41414141.
This means that now we add hex 101 to the
first element of the stale array, making it
0x41414242.
We can then simply search through the whole
uInt32Array memory looking for this 0x41414242.
Keep in mind that the buf has access to raw
bytes, so it will infact see the 0xffff0000
and the 0x41414141, while the stale array
things this is a javascript object, and only
uses the 0xffff0000 internally to determine,
that we have an integer and the value of it
is 0x41414141.
So what can we do with this now.
This is where exploitation really become creative.
The phrack article says that once you have
the ability to craft arbitrary javascript
objects, you could craft a Float64Array to
create a read/write primitive, but qwerty
used a Uint32Array.
To quote him, here is his reason:
“Easier than float to do math with.
Lol.”
And I guess he has a point.
Floating point values in raw bytes are really
annoying.
So first of all, why do we want to craft a
Uint32Array.
If you remember the basic structure of a Uint32Array,
it uses a vector to point to some raw memory.
If you control where this pointer points to,
you can control where you can read data from
and write data to it.
Because it thinks it points to the actual
array.
There is a super clever way how to craft this
array now.
Qwerty creates a new object with four properties.
A,b,c,d.
He probably just took that from the phrack
article, because when you look at how a simple
object with only four properties is stored,
it stores the values inline.
This is very helpful in a second.
As you see, the values set, like the hex 1337
are simply placed here in memory after eachother.
So that’s a very neat way to control a couple
of consecutive values in memory.
The two 64bit values are the JSCell and the
butterfly pointer.
The JSCell, or more specifically the structure
ID inside of the JSCell determines, what this
Javscript Object actually is.
In the phrack article it looks like, this
object here has the ID 136.
So in order to craft a Uint32Array, we would
have to know the structure ID of that.
According to the phrack article, this ID can
change sometimes, maybe at restart or between
different webkit builds.
But apparently it’s very common to be 105.
Nontheless, because my exploit was very unstable
I tried to see if the value is maybe different
and the phrack article shows a technique how
to do that.
Back to the new object for a second.
So this will allocate a new object with 4
properties that looks like this in memory.
0x69, or in decimal 105, then zero, the pointer
to the smash array, which we allocated way
at the beginning and 0x100.
The function u2d is a clever little helper.
As every number in javascript is basically
a float, we can create a new dataview of 16bytes,
so 64bit, set the high and the low 32bits
and return the float representation of those
bytes.
This new object creation will also overwrite
stale[0].
Just a few seconds ago I mentioned that stale[0]
points to a JSValue representing a number,
but now it was overwritten with a JSValue
representing a pointer.
A pointer to the JSObject that was just created.
This JSObject it points to is not very interesting
for us.
It’s not an arbitrary object we have crafted.
But remember, that the JSValue with the pointer
to this object is in the memory that is overlapped
by the buf.
This means we can use buf to manipulate the
pointer.
And what we do is, we add 0x10 or decimal
16, which moves the pointer into the properties
of the JSObject.
Now suddenly the 0x69 is the JSCell value.
And the zero here is the butterfly.
And the smsh address becomes the vector, the
pointer where the actual array is in memory.
To be clear this points into the similar struct
of that array, so this doesn’t point into
the memory location of that smash array, but
also into this JSObject struct with its vector
pointer and its length.
And 0x100 is the length of that array, which
is actually just the Object structure of the
smash array.
So now you know how we can misalign the pointer
to this object, which will interpret the properties
here as the actual object.
This means we can now try different structureIDs
in a loop and check with instanceof if we
have crafted a Uint32Array.
We remember the original stale[0] pointer
in stale[1], then missalign stale[0], then
we can check the type of the stale[0] object,
if it’s not correct, we increment our structureID
guess, and assign a new value to the stale[1]
‘a’ property, which will look like the
StructureID from the missaligned pointer in
stale[0].
What we basically created now is, we have
two pointers in stale.
Which slightly overlap in memory.
We also have somwhere an array called smsh.
We have also set the memory location for our
crafted array, the vector pointer, to point
to smsh.
To the smash structure, not the actual memory
location of the smash array.
This means we have another object that we
can fully control.
Stale is an array.
The first element of stale points to a crafted
Uint32Array.
So when we access the elements of that array,
we obviously access the 32bit values of the
smsh JSObject structure.
And as you know, the object contains 64bit
values, and the fourth 64bit value is the
length of the smsh array.
So stale[0] of [0] and [1] would be the first
64bit, 2,3 would be the second 64 bit, 4,5
would be the third 64bit and 6,7 would be
the 4th 64bit.
So with stale[0][6] we can overwrite the length
of the smash array.
And we can now check the length of the smsh
array.
Let’s try this on the switch.
We load the page and it might not immediately
work, but it will refresh and try again.
Ok so we triggered the bug and we found overlapping
memory by looking for the 0x41414242 value.
Now we check the current length of smash,
we craft our object, try to find the structure
id, we actually find it’s 105, so I didn’t
have to go through this trouble of iterating
over them, then we change the length of smsh
and print the smsh length again.
And it changed.
Isn’t this crazy!
So now we can just modify the vector where
the smash array points to in the exact same
way, and then simply read the raw data it
points to from the smsh array.
or write to the smash array.
It gives us super simple access to the whole
memory of the process.
Next steps could be to find the address of
the browser binary in memory to dump it.
Maybe find some function pointers in memory
you can overwrite, create a ROP chain or maybe
even shellcode because we should have jitted
code, I guess?
This video is already crazy long.
So let’s stop here for now.
I really learned a lot working through the
first part of qwerty’s exploit.
I hope this this also gives you a sense for
how frckn complicated these modern memory
corruption exploits are and what kind of work
and knowledge is required to do them.
I only scratched the surface here.
I hope this also increases your respect for
the people who do this kind of research.
At this point I also want to thank Retr0id
and Ando who I just met on IRC and were in
the same boat as me and we and we helped eachother
trying to figure how this works.
And also a huge thank you to qwerty, who answered
a lot of my noob questions and shared his
progress with me.
I really appreciate you supporting somebody
who tries to learn this!
If this sounds like fun to you, make sure
you read the phrack paper by samuel groß,
or saelo about “attacking javascript engines”,
which gives a way more in depth insight into
how this works.
There is also another article more specifically
about firefox, which is different from webkit,
but also gives you a better idea of how browsers
w ork.
Thank you very much, keep on hackin’ in
the free world, and doot doola doot doo.
﻿What does iOS 9.3 and the Nintendo Switch
have in common?
They both use the browser engine WebKit with
a version that is vulnerable to a known memory
corruption vulnerability.
Remember the news of the pegasus malware for
iOS, which was discovered when it was used
in a targeted attack against the human rights
activist Ahmed Mansoor?
That malware used a webkit exploit as the
first stage, to gain arbitrary code execution.
Qwerty and the pangu team then used this bug
in their jailbreakme website.
And it turns out, the browser of the Nintendo
Switch is so old, that is also has this bug.
And this is what a lot of people are using
right now as a first entry point in hacking
the switch.
Obviously the whole jailbreak is extremely
complex, even just getting code execution
is insane.
But I spent now quite some time understanding
the bug itself and the first crucial part
which creates an arbitrary read/write primitive.
So you can overwrite anything in memory, for
example function pointers or jitted code.
But let’s start at the beginning.
<intro>
First we need to figure out how to access
the browser in the switch.
You may have heard that the Nintendo Switch
doesn’t have a browser, so what the heck
am I talking about?
Well there is no good browser implemented,
but it turns out, that when you connect to
a wifi, which requires you to login in a captive
portal, it will use a browser view and load
that page for you.
A captive portal is common in hotels and airports
and stuff.
So we have to figure out how to load our own
website here.
When you look at the network settings, you
can specify a proxy server, which is great
because then I can run a proxy server on my
laptop and intercept all the traffic.
I use Burp Suite as my proxy server and just
have to make sure it listens on all interfaces,
so other devices on the same network can use
it.
So now we just have to enter the IP of this
laptop into the proxy settings of the switch.
When we now connect to the wifi, the switch
will establish connections through this laptop.
And we can see here in the Burp history view,
that the switch tried to contact conntest.nintendowifi.net
That site just responds with a simple string
that the connection works.
It uses this to check if you have internet
connection or not.
So, if this check fails, it will think you
first need to authenticate from a captive
portal.
So next we need to redirect this request to
a different page, basically our “captive
portal”.
We can do that by simply modifying the /etc/hosts
file, to point the conntest domain to another
IP.
For example localhost.
Then we spawn a simple webserver on our machine,
for example with php -S.
We can place a index.html file in here to
verify that this works.
And with a browser we can see that we have
now on localhost a webserver running.
So, when the switch now connects to the wifi,
it will try to contact conntest and it will
go through the proxy on my laptop.
My laptop sees in the /etc/hosts file what
the IP for conntest is.
So the proxy will connect to localhost instead,
which will access our index.html file.
Let’s try it.
We search for the wifi.
We connect to it.
It will check if there is access to the internet.
It didn’t get the expected result for conntest
back and tells you you have to login.
When we now press next, it will load what
it thinks is the captive portal.
Now we have access to a browser that loads
our website.
We can also have a look at the requests in
burp, which shows us the User Agent the switch
uses.
So now that we have that setup, let’s read
up a bit more on the webkit bug.
It was assigned CVE-2016-4657 and has the
description: “WebKit in Apple iOS before
9.3.5 allows remote attackers to execute arbitrary
code or cause a denial of service (memory
corruption) via a crafted web site.”
The description can be a bit misleading.
Makes it sound like it’s only an iOS issue,
but its generally a webkit bug, and would
affect anything that used that particular
webkit version.
In our case the nintendo switch.
Also this is not an exploit where you just
type into metasploit `use exploit/nintendoswitch/webkit`.
This is something where you actually have
to understand it quite in depth to be able
to use it.
Now let’s take qwerty’s jailbreakme code,
which uses the webkit bug, extract the first
relevant part and adapt it to the nintendo
switch.
I won’t go through all this process because
that took me ages to understand, but I want
to show and explain to you what I got now...
So let’s walk through it.
First we create a Typed Array of unisgned
32bit integers.
And in memory this will create a struct with
a couple of different values such as a JSCell
which contains a couple of interesting values
such as a structure ID that determines kind
of the type of this object.
We will look at that later again.
A butterfly pointer, which is used in a bit
more complex objects but not quite relevant
for us right now, a vector which contains
a pointer to a chunk of memory that represents
our array.
And the length of that memory.
So that array gives us basically access to
raw bytes in memory.
Obviously you can’t access beyond it’s
length.
Then we create a more flexible array.
A standard array like you might use it.
That array is a bit different, as it can contain
arbitrary types.
Any kind of objects.
So instead of just pointing to raw memory,
it points to more complex objects called JSValues.
And here is an example of the integer with
the hex value 41414141, it would store 0xffff0000
before it, to indicate the value is an integer.
Look at the amazing phrack paper if you want
to know more details about these JSValues.
In the case of the exploit it will set the
first element of the Array to a big ArrayBuffer
and the second to some number.
An Array Buffer is also access to raw bytes.
Basically different typed arrays can point
to the same buffer in memory.
Whatever, read the javascript reference.
So If I’m not mistaken, the first element
of the array is now a JSValue with a pointer
to an array buffer.
Next we create a simple Javascript Object
and overwrite its toString() function.
That function is called whenever you want
to get a string representation of that object.
So if I return 1337 object as a string, and
I would alert this object, it would call to
string and show me that one.
But in this case the function does a bit more.
It first sets the reference to the array we
just created to null, as well as setting another
property to null.
In a second you will see that this “stale”
property is also a reference to the arr array.
Theoretically now all references to the array
are gone, and the garbage collector can free
that array.
To force the garbage collector to kick in
right now, we can use the function which just
allocates and removes a lot of objects.
And when you do this a couple of times you
can be fairly certain that the garbage collector
did the work.
After the garbage collection the function
will now allocate a lot of new Uint32Arrays.
The reference to those are stored in buf,
so we can access those arrays.
And if everything goes well those arrays might
be allocated where the previous array was.
But how is this object with that toString
function used now.
We define an object that we use as properties.
And I think we allocate more than just two,
so the properties are not stored inline, but
I’m not 100% sure here.
Anyway, one of these properties is called
stale, and it is set to the array reference.
That is the property that the toString function
will set to null.
Another property is `length` which is set
to the not_number object.
Then we create a new empty array target and
apply those properties to it with Object.defineProperties.
This means all those properties we defined
will be set to the target array.
During this assignment, the toString() function
of not_number will be called and causes the
garbage collection of the array.
As well as the allocation of a lot of Uint32Arrays.
And this is where the bug happens.
Theoretically the stale property was set to
null, and should not be accessible.
But somehow the reference is still there.
Some stuff internally did not properly check
everything.
This means that we have a reference into some
memory where previously the arr array was
allocated.
And we also allocated a lot of Uin32Arrays
and we hope that these now overlap.
As I mentioned earlier, the Uint32Arrays allow
direct memory access, they can read and write
raw bytes.
While the arr array was a complex object,
with JSValues.
Now it’s already clear what you can do with
this.
You can use the Uint32Arrays, which are accessible
via buf.
To read and write raw bytes at the location
where the stale property thinks a standard
Javascript object is.
So first it has to find if and how the buf
and the stale array overlap.
To do this, we can simply add a number to
the first element of stale.
But what is the first element of stale now.
Isn’t that garbage memory?
well ideally, if everything works, it points
to where we created the uInt32Arrays, and
we populated that memory region with 0xffff000041414141,
which is a JSValue representing an integer.
In fact the number 0x41414141.
This means that now we add hex 101 to the
first element of the stale array, making it
0x41414242.
We can then simply search through the whole
uInt32Array memory looking for this 0x41414242.
Keep in mind that the buf has access to raw
bytes, so it will infact see the 0xffff0000
and the 0x41414141, while the stale array
things this is a javascript object, and only
uses the 0xffff0000 internally to determine,
that we have an integer and the value of it
is 0x41414141.
So what can we do with this now.
This is where exploitation really become creative.
The phrack article says that once you have
the ability to craft arbitrary javascript
objects, you could craft a Float64Array to
create a read/write primitive, but qwerty
used a Uint32Array.
To quote him, here is his reason:
“Easier than float to do math with.
Lol.”
And I guess he has a point.
Floating point values in raw bytes are really
annoying.
So first of all, why do we want to craft a
Uint32Array.
If you remember the basic structure of a Uint32Array,
it uses a vector to point to some raw memory.
If you control where this pointer points to,
you can control where you can read data from
and write data to it.
Because it thinks it points to the actual
array.
There is a super clever way how to craft this
array now.
Qwerty creates a new object with four properties.
A,b,c,d.
He probably just took that from the phrack
article, because when you look at how a simple
object with only four properties is stored,
it stores the values inline.
This is very helpful in a second.
As you see, the values set, like the hex 1337
are simply placed here in memory after eachother.
So that’s a very neat way to control a couple
of consecutive values in memory.
The two 64bit values are the JSCell and the
butterfly pointer.
The JSCell, or more specifically the structure
ID inside of the JSCell determines, what this
Javscript Object actually is.
In the phrack article it looks like, this
object here has the ID 136.
So in order to craft a Uint32Array, we would
have to know the structure ID of that.
According to the phrack article, this ID can
change sometimes, maybe at restart or between
different webkit builds.
But apparently it’s very common to be 105.
Nontheless, because my exploit was very unstable
I tried to see if the value is maybe different
and the phrack article shows a technique how
to do that.
Back to the new object for a second.
So this will allocate a new object with 4
properties that looks like this in memory.
0x69, or in decimal 105, then zero, the pointer
to the smash array, which we allocated way
at the beginning and 0x100.
The function u2d is a clever little helper.
As every number in javascript is basically
a float, we can create a new dataview of 16bytes,
so 64bit, set the high and the low 32bits
and return the float representation of those
bytes.
This new object creation will also overwrite
stale[0].
Just a few seconds ago I mentioned that stale[0]
points to a JSValue representing a number,
but now it was overwritten with a JSValue
representing a pointer.
A pointer to the JSObject that was just created.
This JSObject it points to is not very interesting
for us.
It’s not an arbitrary object we have crafted.
But remember, that the JSValue with the pointer
to this object is in the memory that is overlapped
by the buf.
This means we can use buf to manipulate the
pointer.
And what we do is, we add 0x10 or decimal
16, which moves the pointer into the properties
of the JSObject.
Now suddenly the 0x69 is the JSCell value.
And the zero here is the butterfly.
And the smsh address becomes the vector, the
pointer where the actual array is in memory.
To be clear this points into the similar struct
of that array, so this doesn’t point into
the memory location of that smash array, but
also into this JSObject struct with its vector
pointer and its length.
And 0x100 is the length of that array, which
is actually just the Object structure of the
smash array.
So now you know how we can misalign the pointer
to this object, which will interpret the properties
here as the actual object.
This means we can now try different structureIDs
in a loop and check with instanceof if we
have crafted a Uint32Array.
We remember the original stale[0] pointer
in stale[1], then missalign stale[0], then
we can check the type of the stale[0] object,
if it’s not correct, we increment our structureID
guess, and assign a new value to the stale[1]
‘a’ property, which will look like the
StructureID from the missaligned pointer in
stale[0].
What we basically created now is, we have
two pointers in stale.
Which slightly overlap in memory.
We also have somwhere an array called smsh.
We have also set the memory location for our
crafted array, the vector pointer, to point
to smsh.
To the smash structure, not the actual memory
location of the smash array.
This means we have another object that we
can fully control.
Stale is an array.
The first element of stale points to a crafted
Uint32Array.
So when we access the elements of that array,
we obviously access the 32bit values of the
smsh JSObject structure.
And as you know, the object contains 64bit
values, and the fourth 64bit value is the
length of the smsh array.
So stale[0] of [0] and [1] would be the first
64bit, 2,3 would be the second 64 bit, 4,5
would be the third 64bit and 6,7 would be
the 4th 64bit.
So with stale[0][6] we can overwrite the length
of the smash array.
And we can now check the length of the smsh
array.
Let’s try this on the switch.
We load the page and it might not immediately
work, but it will refresh and try again.
Ok so we triggered the bug and we found overlapping
memory by looking for the 0x41414242 value.
Now we check the current length of smash,
we craft our object, try to find the structure
id, we actually find it’s 105, so I didn’t
have to go through this trouble of iterating
over them, then we change the length of smsh
and print the smsh length again.
And it changed.
Isn’t this crazy!
So now we can just modify the vector where
the smash array points to in the exact same
way, and then simply read the raw data it
points to from the smsh array.
or write to the smash array.
It gives us super simple access to the whole
memory of the process.
Next steps could be to find the address of
the browser binary in memory to dump it.
Maybe find some function pointers in memory
you can overwrite, create a ROP chain or maybe
even shellcode because we should have jitted
code, I guess?
This video is already crazy long.
So let’s stop here for now.
I really learned a lot working through the
first part of qwerty’s exploit.
I hope this this also gives you a sense for
how frckn complicated these modern memory
corruption exploits are and what kind of work
and knowledge is required to do them.
I only scratched the surface here.
I hope this also increases your respect for
the people who do this kind of research.
At this point I also want to thank Retr0id
and Ando who I just met on IRC and were in
the same boat as me and we and we helped eachother
trying to figure how this works.
And also a huge thank you to qwerty, who answered
a lot of my noob questions and shared his
progress with me.
I really appreciate you supporting somebody
who tries to learn this!
If this sounds like fun to you, make sure
you read the phrack paper by samuel groß,
or saelo about “attacking javascript engines”,
which gives a way more in depth insight into
how this works.
There is also another article more specifically
about firefox, which is different from webkit,
but also gives you a better idea of how browsers
w ork.
Thank you very much, keep on hackin’ in
the free world, and doot doola doot doo.
﻿What does iOS 9.3 and the Nintendo Switch
have in common?
They both use the browser engine WebKit with
a version that is vulnerable to a known memory
corruption vulnerability.
Remember the news of the pegasus malware for
iOS, which was discovered when it was used
in a targeted attack against the human rights
activist Ahmed Mansoor?
That malware used a webkit exploit as the
first stage, to gain arbitrary code execution.
Qwerty and the pangu team then used this bug
in their jailbreakme website.
And it turns out, the browser of the Nintendo
Switch is so old, that is also has this bug.
And this is what a lot of people are using
right now as a first entry point in hacking
the switch.
Obviously the whole jailbreak is extremely
complex, even just getting code execution
is insane.
But I spent now quite some time understanding
the bug itself and the first crucial part
which creates an arbitrary read/write primitive.
So you can overwrite anything in memory, for
example function pointers or jitted code.
But let’s start at the beginning.
<intro>
First we need to figure out how to access
the browser in the switch.
You may have heard that the Nintendo Switch
doesn’t have a browser, so what the heck
am I talking about?
Well there is no good browser implemented,
but it turns out, that when you connect to
a wifi, which requires you to login in a captive
portal, it will use a browser view and load
that page for you.
A captive portal is common in hotels and airports
and stuff.
So we have to figure out how to load our own
website here.
When you look at the network settings, you
can specify a proxy server, which is great
because then I can run a proxy server on my
laptop and intercept all the traffic.
I use Burp Suite as my proxy server and just
have to make sure it listens on all interfaces,
so other devices on the same network can use
it.
So now we just have to enter the IP of this
laptop into the proxy settings of the switch.
When we now connect to the wifi, the switch
will establish connections through this laptop.
And we can see here in the Burp history view,
that the switch tried to contact conntest.nintendowifi.net
That site just responds with a simple string
that the connection works.
It uses this to check if you have internet
connection or not.
So, if this check fails, it will think you
first need to authenticate from a captive
portal.
So next we need to redirect this request to
a different page, basically our “captive
portal”.
We can do that by simply modifying the /etc/hosts
file, to point the conntest domain to another
IP.
For example localhost.
Then we spawn a simple webserver on our machine,
for example with php -S.
We can place a index.html file in here to
verify that this works.
And with a browser we can see that we have
now on localhost a webserver running.
So, when the switch now connects to the wifi,
it will try to contact conntest and it will
go through the proxy on my laptop.
My laptop sees in the /etc/hosts file what
the IP for conntest is.
So the proxy will connect to localhost instead,
which will access our index.html file.
Let’s try it.
We search for the wifi.
We connect to it.
It will check if there is access to the internet.
It didn’t get the expected result for conntest
back and tells you you have to login.
When we now press next, it will load what
it thinks is the captive portal.
Now we have access to a browser that loads
our website.
We can also have a look at the requests in
burp, which shows us the User Agent the switch
uses.
So now that we have that setup, let’s read
up a bit more on the webkit bug.
It was assigned CVE-2016-4657 and has the
description: “WebKit in Apple iOS before
9.3.5 allows remote attackers to execute arbitrary
code or cause a denial of service (memory
corruption) via a crafted web site.”
The description can be a bit misleading.
Makes it sound like it’s only an iOS issue,
but its generally a webkit bug, and would
affect anything that used that particular
webkit version.
In our case the nintendo switch.
Also this is not an exploit where you just
type into metasploit `use exploit/nintendoswitch/webkit`.
This is something where you actually have
to understand it quite in depth to be able
to use it.
Now let’s take qwerty’s jailbreakme code,
which uses the webkit bug, extract the first
relevant part and adapt it to the nintendo
switch.
I won’t go through all this process because
that took me ages to understand, but I want
to show and explain to you what I got now...
So let’s walk through it.
First we create a Typed Array of unisgned
32bit integers.
And in memory this will create a struct with
a couple of different values such as a JSCell
which contains a couple of interesting values
such as a structure ID that determines kind
of the type of this object.
We will look at that later again.
A butterfly pointer, which is used in a bit
more complex objects but not quite relevant
for us right now, a vector which contains
a pointer to a chunk of memory that represents
our array.
And the length of that memory.
So that array gives us basically access to
raw bytes in memory.
Obviously you can’t access beyond it’s
length.
Then we create a more flexible array.
A standard array like you might use it.
That array is a bit different, as it can contain
arbitrary types.
Any kind of objects.
So instead of just pointing to raw memory,
it points to more complex objects called JSValues.
And here is an example of the integer with
the hex value 41414141, it would store 0xffff0000
before it, to indicate the value is an integer.
Look at the amazing phrack paper if you want
to know more details about these JSValues.
In the case of the exploit it will set the
first element of the Array to a big ArrayBuffer
and the second to some number.
An Array Buffer is also access to raw bytes.
Basically different typed arrays can point
to the same buffer in memory.
Whatever, read the javascript reference.
So If I’m not mistaken, the first element
of the array is now a JSValue with a pointer
to an array buffer.
Next we create a simple Javascript Object
and overwrite its toString() function.
That function is called whenever you want
to get a string representation of that object.
So if I return 1337 object as a string, and
I would alert this object, it would call to
string and show me that one.
But in this case the function does a bit more.
It first sets the reference to the array we
just created to null, as well as setting another
property to null.
In a second you will see that this “stale”
property is also a reference to the arr array.
Theoretically now all references to the array
are gone, and the garbage collector can free
that array.
To force the garbage collector to kick in
right now, we can use the function which just
allocates and removes a lot of objects.
And when you do this a couple of times you
can be fairly certain that the garbage collector
did the work.
After the garbage collection the function
will now allocate a lot of new Uint32Arrays.
The reference to those are stored in buf,
so we can access those arrays.
And if everything goes well those arrays might
be allocated where the previous array was.
But how is this object with that toString
function used now.
We define an object that we use as properties.
And I think we allocate more than just two,
so the properties are not stored inline, but
I’m not 100% sure here.
Anyway, one of these properties is called
stale, and it is set to the array reference.
That is the property that the toString function
will set to null.
Another property is `length` which is set
to the not_number object.
Then we create a new empty array target and
apply those properties to it with Object.defineProperties.
This means all those properties we defined
will be set to the target array.
During this assignment, the toString() function
of not_number will be called and causes the
garbage collection of the array.
As well as the allocation of a lot of Uint32Arrays.
And this is where the bug happens.
Theoretically the stale property was set to
null, and should not be accessible.
But somehow the reference is still there.
Some stuff internally did not properly check
everything.
This means that we have a reference into some
memory where previously the arr array was
allocated.
And we also allocated a lot of Uin32Arrays
and we hope that these now overlap.
As I mentioned earlier, the Uint32Arrays allow
direct memory access, they can read and write
raw bytes.
While the arr array was a complex object,
with JSValues.
Now it’s already clear what you can do with
this.
You can use the Uint32Arrays, which are accessible
via buf.
To read and write raw bytes at the location
where the stale property thinks a standard
Javascript object is.
So first it has to find if and how the buf
and the stale array overlap.
To do this, we can simply add a number to
the first element of stale.
But what is the first element of stale now.
Isn’t that garbage memory?
well ideally, if everything works, it points
to where we created the uInt32Arrays, and
we populated that memory region with 0xffff000041414141,
which is a JSValue representing an integer.
In fact the number 0x41414141.
This means that now we add hex 101 to the
first element of the stale array, making it
0x41414242.
We can then simply search through the whole
uInt32Array memory looking for this 0x41414242.
Keep in mind that the buf has access to raw
bytes, so it will infact see the 0xffff0000
and the 0x41414141, while the stale array
things this is a javascript object, and only
uses the 0xffff0000 internally to determine,
that we have an integer and the value of it
is 0x41414141.
So what can we do with this now.
This is where exploitation really become creative.
The phrack article says that once you have
the ability to craft arbitrary javascript
objects, you could craft a Float64Array to
create a read/write primitive, but qwerty
used a Uint32Array.
To quote him, here is his reason:
“Easier than float to do math with.
Lol.”
And I guess he has a point.
Floating point values in raw bytes are really
annoying.
So first of all, why do we want to craft a
Uint32Array.
If you remember the basic structure of a Uint32Array,
it uses a vector to point to some raw memory.
If you control where this pointer points to,
you can control where you can read data from
and write data to it.
Because it thinks it points to the actual
array.
There is a super clever way how to craft this
array now.
Qwerty creates a new object with four properties.
A,b,c,d.
He probably just took that from the phrack
article, because when you look at how a simple
object with only four properties is stored,
it stores the values inline.
This is very helpful in a second.
As you see, the values set, like the hex 1337
are simply placed here in memory after eachother.
So that’s a very neat way to control a couple
of consecutive values in memory.
The two 64bit values are the JSCell and the
butterfly pointer.
The JSCell, or more specifically the structure
ID inside of the JSCell determines, what this
Javscript Object actually is.
In the phrack article it looks like, this
object here has the ID 136.
So in order to craft a Uint32Array, we would
have to know the structure ID of that.
According to the phrack article, this ID can
change sometimes, maybe at restart or between
different webkit builds.
But apparently it’s very common to be 105.
Nontheless, because my exploit was very unstable
I tried to see if the value is maybe different
and the phrack article shows a technique how
to do that.
Back to the new object for a second.
So this will allocate a new object with 4
properties that looks like this in memory.
0x69, or in decimal 105, then zero, the pointer
to the smash array, which we allocated way
at the beginning and 0x100.
The function u2d is a clever little helper.
As every number in javascript is basically
a float, we can create a new dataview of 16bytes,
so 64bit, set the high and the low 32bits
and return the float representation of those
bytes.
This new object creation will also overwrite
stale[0].
Just a few seconds ago I mentioned that stale[0]
points to a JSValue representing a number,
but now it was overwritten with a JSValue
representing a pointer.
A pointer to the JSObject that was just created.
This JSObject it points to is not very interesting
for us.
It’s not an arbitrary object we have crafted.
But remember, that the JSValue with the pointer
to this object is in the memory that is overlapped
by the buf.
This means we can use buf to manipulate the
pointer.
And what we do is, we add 0x10 or decimal
16, which moves the pointer into the properties
of the JSObject.
Now suddenly the 0x69 is the JSCell value.
And the zero here is the butterfly.
And the smsh address becomes the vector, the
pointer where the actual array is in memory.
To be clear this points into the similar struct
of that array, so this doesn’t point into
the memory location of that smash array, but
also into this JSObject struct with its vector
pointer and its length.
And 0x100 is the length of that array, which
is actually just the Object structure of the
smash array.
So now you know how we can misalign the pointer
to this object, which will interpret the properties
here as the actual object.
This means we can now try different structureIDs
in a loop and check with instanceof if we
have crafted a Uint32Array.
We remember the original stale[0] pointer
in stale[1], then missalign stale[0], then
we can check the type of the stale[0] object,
if it’s not correct, we increment our structureID
guess, and assign a new value to the stale[1]
‘a’ property, which will look like the
StructureID from the missaligned pointer in
stale[0].
What we basically created now is, we have
two pointers in stale.
Which slightly overlap in memory.
We also have somwhere an array called smsh.
We have also set the memory location for our
crafted array, the vector pointer, to point
to smsh.
To the smash structure, not the actual memory
location of the smash array.
This means we have another object that we
can fully control.
Stale is an array.
The first element of stale points to a crafted
Uint32Array.
So when we access the elements of that array,
we obviously access the 32bit values of the
smsh JSObject structure.
And as you know, the object contains 64bit
values, and the fourth 64bit value is the
length of the smsh array.
So stale[0] of [0] and [1] would be the first
64bit, 2,3 would be the second 64 bit, 4,5
would be the third 64bit and 6,7 would be
the 4th 64bit.
So with stale[0][6] we can overwrite the length
of the smash array.
And we can now check the length of the smsh
array.
Let’s try this on the switch.
We load the page and it might not immediately
work, but it will refresh and try again.
Ok so we triggered the bug and we found overlapping
memory by looking for the 0x41414242 value.
Now we check the current length of smash,
we craft our object, try to find the structure
id, we actually find it’s 105, so I didn’t
have to go through this trouble of iterating
over them, then we change the length of smsh
and print the smsh length again.
And it changed.
Isn’t this crazy!
So now we can just modify the vector where
the smash array points to in the exact same
way, and then simply read the raw data it
points to from the smsh array.
or write to the smash array.
It gives us super simple access to the whole
memory of the process.
Next steps could be to find the address of
the browser binary in memory to dump it.
Maybe find some function pointers in memory
you can overwrite, create a ROP chain or maybe
even shellcode because we should have jitted
code, I guess?
This video is already crazy long.
So let’s stop here for now.
I really learned a lot working through the
first part of qwerty’s exploit.
I hope this this also gives you a sense for
how frckn complicated these modern memory
corruption exploits are and what kind of work
and knowledge is required to do them.
I only scratched the surface here.
I hope this also increases your respect for
the people who do this kind of research.
At this point I also want to thank Retr0id
and Ando who I just met on IRC and were in
the same boat as me and we and we helped eachother
trying to figure how this works.
And also a huge thank you to qwerty, who answered
a lot of my noob questions and shared his
progress with me.
I really appreciate you supporting somebody
who tries to learn this!
If this sounds like fun to you, make sure
you read the phrack paper by samuel groß,
or saelo about “attacking javascript engines”,
which gives a way more in depth insight into
how this works.
There is also another article more specifically
about firefox, which is different from webkit,
but also gives you a better idea of how browsers
w ork.
Thank you very much, keep on hackin’ in
the free world, and doot doola doot doo.
﻿So I was browsing reddit, and this new CTF
for beginners popped up.
Obviously I had to check it out and directly
head to my favorite category, the binary exploitation
stuff.
And of course there is a server you can connect
to as a regular user, and when you exploit
a challenge you will elevate privileges to
another user to gain access to the secret
flag.
But the biggest challenge of all, and I couldn’t
find rules that would forbid this, would be
to gain root.
So let’s do that.
Remember my dirty cow explanation video?
Let’s use the proof of concept exploit that
we had there and test if it works on this
server.
So we can simply copy this code to a file
in tmp and compile it.
To test if we can overwrite files that don’t
belong to us, without overwriting critical
root owned files, we log in as another challenge
user on the system, create a file with some
content.
And then we go back to the first user, execute
dirty cow on that file and attempt to write
some other characters to it.
And when we check, we can see that it works.
At this point I wrote the author a message
on reddit to inform him that the server is
vulnerable and he should quickly update.
But now we need a plan what root file we could
overwrite to become root ourselves.
Our restriction is, that we have to overwrite
something in a file, we can’t append or
prepend anything.
The first obvious idea would be a setuid binary,
but the issue is that in order to write a
backdoor shell to the binary, we would have
to parse the elf file format and figure out
where the entry point is.
An easier strategy is to overwrite data in
a text file.
And I chose /etc/passwd.
You can see here the user id of the users,
and if we would change the uid of the pwn1
user to 0, we would login as root.
So.
The dirty cow proof of concept writes to the
beginning of the file.
So first we have to figure out the offset
inside of /etc/passwd.
We can use hexdump for that and count a little
bit.
So pwn1 user is at offset hex 4c0 plus a little
bit.
I use python as a caluclator and modify the
exploit code to write to a fixed offset.
I think here would be a good plan.
And you have to be very very careful with
choosing these offsets and choosing what to
write, because you can screw up the whole
system if you don’t.
So I copy /etc/passwd to try what I want to
do before doing it to the real binary.
And of course, my first attempt would have
wrecked the system.
So adjusting the offset a bit and also appending
a newline at the end is finally successful
and I write to the real /etc/passwd.
Now when we switch to pwn1 or ssh login to
pwn1, we get a root shell.
Then we can read out all flags.
Once we are done, we revert back /etc/passwd
to the original state.
Some important notes.
Be very very careful what you overwrite with
an exploit like this.
Just one byte miscalculated, and you might
destabilize, crash, DoS the system or simply
lock yourself out.
Also if you find a server vulnerable, think
about the impact or context you are in.
This small private CTF server project, that
is intended to be hammered is different from
a webserver you exploited from some random
company.
So don’t go around and try this if you have
no permissions or you could cause a lot of
damage.
Make an ethical decision.
Be aware of the risk you are taking.
And thanks to maro for being cool about this
and allowing me to make a video about it.
Good luck with your plattform.
﻿Let’s have a look at list0r.
It’s a 400 point web challenge so it should
be really really hard.
Though we got lucky, because as far as I know
all web challenges were broken in various
ways and had way easier solutions than planned.
The description doesn’t give us a lot of
information, just that its some webapp to
manage lists.
So let’s have a look at it.
Generally for web testing it’s a good idea
to use an http proxy to analyze the requests.
Using browser developer tools also works,
but programs like fiddler for windows or burp
offer a lot of convinience.
So I setup firefox to use a proxy and start
burp.
Now we see all browser requests in there.
So here is the landing page.
“Bored in life?
Create some lists” whooop ok.
First we need an account to login, so we register
one.
And you can check the burp history to see
the HTTP requests, like the register POST
request that sent the form data.
We can already see that generally the page
seems to not use single .php files, but uses
a GET parameter page to decide the functionality.
So let’s login, and we can create some lists
here.
Like with the hohoho challenge before, I didn’t
work on this at this point.
So other from the team started to analyse
the functionality.
Played around with the forms.
Maybe tried some XSS or SQL injection.
One interesting functionality seems to be
the profile edit page.
Because here you can supply a URL to upload
a picture.
That smells like server side request forgery.
You can use a service like requestbin to see
the HTTP request issued by the web application.
So we use the requestbin tracking URL and
enter it into the avatar URL field, and then
we can see the HTTP request.
But nothing special here, no flag sent along
the request or anything.
But we know, that there might be a Sever Side
request forgery.
We can also now use burp to explore that a
little bit more.
We can do a rightclick->send to repeater,
and now we can modify the raw HTTP request
and resend it.
This allows us to play with the request that
will trigger the Server side request forgery.
You can for example try if you can use the
file protocol to leak local files, but it
doesn’t work.
You can try to bypass the check for a host.
But nothing really yields, but we keep that
part in mind.
It’s probably here for a reason.
Next up was to test the page parameter.
Maybe it uses the parameter to include arbitrary
files.
We don’t specify the .php at the end, so
if it’s a simple include it would append
.php to it.
And a nullbyte to bypass that is not a thing
anymore in 2017.
Nullbytes only work in old php versions.
So whatever we inlcude must end in .php.
A common thing to check for are php filter
wrappers.
It’s a snippet you can keep around.
You can research the exact features of that
yourself, but what we will use is a php filter,
to convert something to base64.
And what file is converted is specified by
the resource parameter.
So if this works, it should open the index.php
file, convert it to base64, and pass that
to the include.
And that works.
See this big base64 chunk.
We can decode it and get the php code from
index.php.
And here you can also see the vulnerable include.
Now we can start to dump more code.
For example the functions.php and header.php
file.
In the functions.php file we find this get_contents
function, which takes a url and is probably
the part that fetches the image in the profile.
While some were exploring the sources, another
guy realized that the login is broken.
You can simply login as any user without a
password.
We thought that was part of the challenge,
but turns out it was also a mistake.
You shouldn’t have been able to login as
admin this way.
But this quickly revealed a secret URL, which
is only accessible from localhost.
And this is where now the server side request
forgery comes into play.
If we can abuse the image URL upload and request
that path, we get the url.
So let’s review the php code again.
We can see here several URL checks.
First it decocdes the url and checks for a
host.
If you used a domain it will query the dns
server for the IP, and verify that you don’t
try to access stuff like localhost.
Dangit.
And then it uses curl to perform the request.
For us it was very suspicious to see the option
to enable ALL protocols except file and scp.
File would obviously allow to load local files,
and scp can also be used to work with local
and possibly remote files.
The list of obscure protocols supported is
long, but we didn’t have much experience
with them but we had a hunch that the trick
lies in there.
Though while that turned out to be part of
the intended solution, we found (like many
other teams) a much easier one.
And the issue lies in the last option line.
The comment says, no dns rebinding plz.
The option should enable that a certain domain
resolves to a specific IP.
Remember that up here the domain was resolved
to an IP and then verified that it’s not
localhost.
In a DNS rebinding attack you would abuse
a time of check time of use race.
Where this check would resolve the domain
to a valid IP, and then you quickly change
the DNS record and when curl then tries to
open the URL further down, it now points to
localhost.
And that option is supposed to prevent that.
It would force the domain to be resolved to
the original IP from earlier, and ignore any
DNS server changes.
I joined the challenge around this time here
and helped testing.
I extracted the part that requests the image
and put it in a simple test script.
Added some additional debugging output and
so forth.
So that I can quickly test stuff.
And we can play around with it now.
For example when we try to query localhost,
php will parse the URL and then perform this
in_cidr test and eventually stops.
But I noticed that when I try to query my
website, that the dns entry for my domain
returns 2 entries.
The DNS server advertises two IPs for this
domain.
And the php code just uses the first entry.
This will come in handy in a second, but first
another idea.
We also played around with parser differentials
in curl and php.
For example we found this here: when we place
ip and port in front of the domain with a
questionmark and @ , parse_url from php will
think that the IP is a username and port-questionmark
is a password.
Because those are seperated by a colon infornt
of the domain with @. And thus the dns query
will interpret liveoverflow.com to be the
host name.
But curl on the other hand sees the questionmark
and thinks that here the GET parameters will
start and the host is obviously then localhost
127.0.0.1.
And it really does query now localhost.
We bypassed it.
But the issue is, that we can’t specify
any path.
We can only get a request out for the top
root path, so no luck for getting the flag.
Though I’m pretty sure if you spend more
time on this, you figure out a better bypass.
Anyway, I trusted the challenge author that
the dns rebinding was implemented properly.
EVENTHOUGH I saw the warning that it couldn’t
parse the resolve option.
I’m such a naiv idiot.
After an hour or so of playing with this,
a friend reminded me again: “hey, did you
see that the dns rebinding option doesn’t
work?
The syntax is wrong?”
And I was like.
Eh fuck….
Why did I ignore this for so long.
And yeah, it turned out to be another unintended
bug which allows an easier solution.
And here is where we get back to the fact
that a DNS entry can return two IPs.
I setup a domain, densrebind.com to return
2 IPs. 8.8.8.8 and localhost.
In the same way how liveoverflow is setup.
So when we now use that domain and request
the image from that domain, it might get the
localhost as a response and give you an error,
but when you try it again it might now get
the valid IP first, and curl will use localhost.
And this will successfully request that path
and provide us with the flag.
Lessons learned for me, don’t ignore warnings.
And look into the gopher protocol.
Because that was apparently the way to fake
an HTTP request and query the flag.
No idea how to get access to the admin list
entry with the secret path though.
I have to read some writeups.
I hope you will do the same.
﻿Final level 1 has a format string vulnerability
that can be exploited remotely.
Over the past few videos we have learned how
to talk to these programs over a TCP network
connection and how to debug them, so we are
all set to go.
Like all previous challenges, the program
is running as a network daemon in this case
on port 2994.
So we can use netcat to connect to this service
which displays a final1 prompt.
But when we enter something we don’t see
anything.
Mh.
Also because we already know it will be about
a format string vulnerability, we can try
to inject some characters such as %x, but
again, nothing happens.
We could also try %s, because if you remember,
it will take values on the stack as the address
location of a string, thus if values on the
stack do not point into valid memory, the
program should crash, which would be another
indication of a format string vulnerability.
But nope.
Also doesn’t do anything.
We could also try to send a very long string,
just to see if there is a buffer overflow
that would crash the program, but also doesn’t
work.
You can see that the prompt got returned now
multiple times, which is an indication that
the program always reads a limited amount
of characters, and you sent so many at once,
that the read loop was able to read many times.
So I guess it’s time to have a look at the
source code.
Main calls two functions after setting up
all the networking stuff.
The first one is getipport(), and the second
one is parser().
Getipport calls the function getpeername(),
so let’s see what that is about.
getpeername() returns the address of the peer
connected to the socket sockfd, in the buffer
pointed to by addr.
We can see that it also defines a struct sockaddr_in
which apparently will then contain the source
ip address and source port by the client that
connected to the socket.
You can also look up how the struct exactly
looks like on the man page for ip.
So it will basically contain the port number,
and the ip address, and the ip address is
a 32byte integer.
And sprintf will write this constructed string
into hostname, which is a global variable.
Ok so once this function is complete, the
code will call parser().
And parser will print the final1 prompt we
already know.
Then it uses fgets to read 128 bytes into
the line buffer.
After that it uses trim, which looks for the
first occurrence of a newline or linefeed
and replaces it with a 0.
Basically cutting the string at these positions.
Then it will check if the string you entered
starts with “username”, or “login”.
Ahh, ok, so there are special commands for
that prompt.
If you enter username, it kinda expects additional
data after it, because it string copies anything
after the “username” part into the global
variable username.
If you would use the command “login”,
it would check if you specified a username
before, if not it tells you you follow a wrong
protocol.
But if you specified a username before, it
will call logit, with a pointer into the string
after login, because it expects a password
there.
The password is not used in logit, it’s
just a mockup for the challenge, but in there
it uses a buffer and writes to it with snprintf.
Basically creating a line for a log entry,
that says that there was a login attempt from
a certain client for a specific user with
a certain password.
And then this string logged in the system
log.
Then this function returns and it will print
“login failed”.
Armed with this knowledge we can try to use
the prompt again.
And it does what we expect.
Now this failed login attempt should have
been logged in the syslog.
So let’s check it out.
Note you have to be root to read that file.
So tail, to only get the last few lines, of
/var/log/syslog
And there it is, final1 Login attempt from
this source IP and source port, as LiveOverflow
with the password.
Okay.
But where the heck is the format string vulnerability?
There is no printf where we controlled the
format parameter.
Why am I so hasty?
We don’t even fully understand the code
yet, do we?
We read this code with certain assumptions
without questioning if they are true.
The meaning of hacking, if anything, is about
understanding computers on a deeper level.
But there is one function where we got lazy
and brushed over, because we assumed it does
it’s job.
If you take anything away from the stuff I
create, then it shall be, don’t be satisfied
with what you think you know, challenge your
beliefs.
Ok, well that rant was a bit overplaying it.
But we did not look into this new function
we encountered - syslog.
I guess what I’m saying is, when you solve
these simple challenges, you reach a point
where you think you know every dangerous function,
but that’s not true.
So don’t get lazy, and read the man page.
If we look at the man page of syslog we will
see that the second parameter is a format
parameter.
syslog() generates a log message, which will
be distributed by syslogd(8).
The priority argument is formed by ORing the
facility and the level values (explained below).
The remaining arguments are a format, as in
printf(3)
Syslog works like printf.
And buf in logit(), is the format parameter.
And buf will simply contain the username and
password we entered, and thus we can inject
format characters.
Let’s try it.
Let’s login with %x stuff.
Login failed, check the syslog.
And there it is.
In brackets you can see the leaked values
from the stack.
Perfect, now we have identified the bug.
And from earlier format string exploit videos
we learned that a good strategy is to overwrite
an address in the global offset table with
another function, like system to execute commands.
Let’s think about what function would be
convenient to overwrite.
I think, the strncmp is a cool function, because
we control the first parameter.
The line.
And system uses the first parameter for the
string to execute stuff.
So if we replace strncmp with system, we can
simply type in a line and execute a shell
command.
Ok, so let’s construct our exploit.
We import what might be important, and setup
the remote socket connection like we are used
to.
And maybe we create a new function called,
read_until.
Which is very useful in these kind of remote
service challenges.
So read until shall fill up a buffer with
single character reads, until the buffer contains
the magic string specified by read_until.
And then we can simply write,
read_until the final1 prompt.
And then we can do our stuff.
So first we specify a username.
Read until next prompt, then we specify the
login password, and read again until next
prompt.
Another trick I use is the function raw_input(),
which is actually to read input from the user
in python, but is very convenient to kinda
pause the script, until we hit enter.
So when we execute this now, we connect to
the service and then we wait until we hit
enter in the script.
When we now check the running processes for
final, we see two.
If you remember the one is the parent daemon,
and the new one (with the higher process id)
is the spawned child that is handling our
client connection.
So we can attach gdb to that process and start
collecting addresses of important symbols.
So first let’s figure out the address of
strncmp in the global offset table.
With info functions and a search term we can
find the function trampoline in the plt quickly.
We can disassemble those instructions and
we quickly see that it jumps to the address
stored here.
And this points into the global offset table,
and will obviously contain the real address
to strncmp in libc.
So that is our target address we want to overwrite.
Next is the address of system.
System is part of libc and we can quickly
get the address of it here.
Note, usually libc is randomized due to ASLR
nowadays, but on this old linux system, or
on embedded devices, it still works this way.
On a real modern system you would first have
to leak addresses from memory in order to
calculate offsets and break ASLR.
Ok, so we have our target and we have the
address that we want to write to it.
Also the resulting log message will contain
your source IP and port, which might vary
in length.
Coming from localhost will be different than
coming from a remote host.
So we should add this into our exploit to
be reliable.
The challenge used getpeername to get the
ip and port of it’s peer.
So we can use the equivalent to get your own
name.
With getsockname().
Now we also know the source ip and port and
can write code to adapt accordingly.
Also, I’m sorry, the code is really awful
to read this way.
I don’t know why I never bothered to turn
on syntax code highltighing.
So here we go.
Better late than never.
Syntax on.
Let’s have a look again at the logged line
from earlier.
These characters here at the end look suspiciously
like ascii, and when we convert them we see
that they spell “Login from… and so forth”.
Let’s do this again with some recognizable
characters to find the username.
And there it is.
So it took roughly 14 pops of the stack to
reach the username with the AAAA.
You can see that the A’s don’t perfectly
align, and they even might shift around because
of the length of the IP and port.
Thus first step is to make this constant by
adapting the amount of As such that afterwards
it will be a known aligned offset.
So in this case the hostname was 15 characters
long.
And one more A would have filled up and alligned
the memory.
So let’s think about what the shortest and
longest hostname could be.
Shortest would be 9, longest 21.
Because we prefer multiples of four to be
32bit aligned, we decide to pad to 24 characters.
Thus we take the length of the hostname, subtract
it from 24, and then we know how many A’s
we need.
Let’s try this again with some %x in the
username.
Oh and we must not forget the newline at the
end of our test inputs.
Oh, doesn’t work?
What did we do wrong?
Ahh… we forgot the username and login command.
Still doesn’t work…
Oh, the line can only be 128 bytes long, but
we send a lot more with 28 of these %x…
See, so many small things that can go wrong
and slow you down.
Now we get the login failed.
And looking into the syslog and searching
for the Bs, we see that… god dammit… we
forgot to add the padding with the As.
Ok, there we go...
the Bs are now perfectly aligned.
Awesome.
Now it doesn’t matter what IP or port you
have, it will always be exactly there.
And we can count the words on the stack and
get the offset 17.
So now we can move on and use a single %x
with the dollar notation to refer to the 17th
parameter, the 17th value on the stack.
So for example we can now place the address
of the global offset table entry for strncmp
here into the string, and then use %n to write
to that address.
So now we only need to figure out how big
of a padding we need to write the values we
want.
If that confuses you, rewatch the old format
string stuff.
So before we run it now, add another raw_input
so that the script doesn’t exit and then
we run it, attach to it with gdb, and observe
the GOT entry for strncmp, we see that after
the login attempt it got overwritten.
Our goal is the lower part of the system address,
which is 0xffb0.
So now we can calculate the correct number
of characters we need to print.
And this is basically how the process now
works.
We write with %n to the address, check the
number, calculate how much is missing or how
much we are overshooting, correct the number
of characters we print and repeat until we
have constructed the full address for system.
That is super annoying, it’s fiddly and
takes some time, but once you got it, it’s
so cool.
So now I got the offsets right and the address
is overwritten with the address of system.
Now we can add the telnetlib trick with interact
to our program and theoretically, at this
point all calls to strncm would call system
instead.
And if you look into the code and think about
that, simply writing something on the prompt
should result in command execution.
So let’s try it.
We get a prompt, and now we can type commands
as if we were in a real shell.
Every loop the program reads our line, calls
strncmp, which in reality calls system and
executes our commands.
And again, we can copy the exploit to our
windows machine, change the ip address to
the VM and then get a remote shell.
Awesome!
﻿Let’s continue with our work on the keygen
for the last Pwn Adventure 3 challenge.
Pirate’s treasure.
Last video we found the key verification implementation
in the shared libGameLogic library and started
to reverseengineer it.
We were able to understand the first two loops.
Just as a quick reminder, the first loop ignore
spaces and dashes, as well as counts the amount
of valid characters.
And valid characters were defined by this
alphabet.
It also creates a new array mapping each input
character to a number, basically the index
in the alphabet.
So the string input “123ABC” would be
encoded as the raw numbers 1, 2, 3, 10, 11,
12.
We also looked at that with gdb and printed
that array, so we know it’s stored as a
local variable on the stack at `rbp-0x30`.
I call this new array now `key24`.
key
After that a checksum is calculated by simply
summing up the values of the first 24 characters
and compare it to the 25th character.
Which means we can ignore the last character
from now on, and work with the actual important
remaining 24 values.
So let’s look at the next loop.
Before we head into the next loop we can see
another obfuscated function call.
lrKmtLet.
It appears to take three parameters.
I assume this, because this is a 64bit program
and the typical intel 64bit calling convention
on linux is, to start using registers for
parameters, and only if there are too many
parameters, start pushing them on the stack.
That’s different to 32bit because there
parameters are always pushed onto the stack.
So this function takes an address to a buffer
on the stack, you can see that because it
uses `lea` load effective address of rbp-0x5f.
So it basically just puts the result of `rbp-0x5f`
into rdi.
You could have also moved rbp into rdi, and
then subtract 0x5f from it, but using `lea`
that is shorter and more expressive.
So let’s go into that function and we immediately
see that it’s a super simple loop.
Here are our parameters coming in via the
registres and stored in local variables on
the stack.
So rdi was our pointer to a buffer, esi was
set to 0, but then moved here into al, so
al is just a single null byte in this case.
And edx was the 0xf.
And that is moved into here, which is then
used in a comparison down here.
And that is obviously the loop condition.
If the tested value in eax is greater or equal
than that 0xf we exit the loop.
And eax is coming from this variable, which
was set to 0 initially and incremented down
here.
So this is clearly a for loop.
And our 0xf was obviously a length.
So we have for, i=0, loop condition is i < length
and increment i.
And in each loop iteration we load the single
byte, in our case the nullbyte into al, then
load the current i iteration value into rcx
and the address of our target buffer into
rdx.
Then we move the null-byte into our buffer
at offset rcx.
So basically we have this for loop here.
Loop over the whole length and always set
the i-th element of the buffer to the single-byte,
in our case null.
So can you guess the well known function that
is implemented here?
This is memset.
It will write the single value into the buffer
with the given length.
So it just makes sure that the buffer is completely
erased set to 0.
Next we have another very obvious for-loop.
Here we set i to 0, here we check if i is
above or equal to 0x18, that’s 24 in decimal,
so this loop will most likely loop over our
new key24 array.
And a quick peek into the loop, yep there
it is referenced.
But it also references our new buffer that
we just made sure to be empty with memset
before.
And from the memset parameter we also know
the size of this buffer, which is 0xf, so
15.
So how does the 24 large key24 array relate
to the new 15 byte large buffer?
Well, we are about to find out.
If we look a bit more careful at the call
flow, we can see that we have an outer loop
that is using i, but there is a nested for
loop as well.
A super clear for-loop again, initialise to
0, the condition is smaller than 5 and down
here is the increment.
So I call this inner iteration variable j.
So i of the outer loop will walk over the
24 entries in the array and the inner loop
will always loop 5 times.
So what does it do 5 times for every entry
in key24?
Well… we have to understand this part now,
but assembler instructions are so limited
that it’s not super easy to read and understand.
At least I’m certainly not looking at this
and can read it like I can read a well written
python program.
So I have to read over this multiple times
with different approaches until “I get it”.
So let me walk you through how I do it here.
When I read this for the first time, I start
by reading out loud each line and see what
it does.
Of course I’m narrating now this video,
but I would actually whisper this or just
say it in my head.
So let’s go.
We move a 1 into eax.
Then we load the outer loop iterator i into
rcx, then we load a byte from the key24 array
with the offset of rcx, so it get’s the
i-th character of key24.
Then we load the inner loop iterator j.
We move j into esi, then move it back into
ecx.
No sure yet why it does that, but it means
esi AND ecx contain now the iterator j.
Then we shift left eax, which is 1 by cl,
which is the inner loop j.
So for each loop iteration we shift the 1
either by 0, by 1, by 2, by 3 or by 4.
And then we do a logical AND with the current
key24 value.
The result is then compared to 0.
What it does here is basically check each
bit of the key24 value.
For example in the third iteration, eax with
the 1 would be bit shifted by 2.
So this byte in raw bits is now 0000 0100.
The one got shifted by 2.
And then when we do a logical AND with the
key24 value, the result is only 1 where both
were one.
So for example the key24 value 3 wuld be 0000
0011 in binary, thus the result would cancel
out all bits and it is 0.
But if it was a 12, or in hex 0xC, then its
0000 1100, which means the 3rd bit is now
1 in both.
The result will be non zero, in fact it will
be 4.
So now we know that the outer loop loops over
each entry in the key24 array and then for
each entry we go through the 5 possible bits.
As you know our alphabet has only 32 symbols,
and the key24 array will only contain the
index into that alphabet, so we only can have
numbers from 0 to 31, and 31 fits into 5 bits.
That’s why we only go over 5 bits in this
inner loop.
Anyway.
So this if checks a bit and see if it’s
set or not.
If it’s not set we just skip this part and
go to the next bit.
But if the bit was set, then it goes into
this part.
eax is loaded again with a 1 and then i is
multiplied by 5 and the result stored in rcx.
And then j is added to it.
So (i*5 + j).
And then a logical AND is performed with 0x7.
7 in bits is 0000 0111, so it basically erases
all the higher bits and just keeps the lower
3.
The result is then in rcx and also copied
into edx.
THEN eax, the 1 is shifted by this result.
Because we just did the logical and with 0x7,
the result can never be larger than 7.
So we basically set one bit in a byte.
Then we calculate again (i*5 + j), but this
time shift it TO THE RIGHT by 3.
This means it will kind of delete the last
3 bits because it pushes them them out to
the right.
And the result is then used as an offset into
the 15 byte buffer to load a value from it
into edx.
The result from earlier is then combined with
this value, through a logical OR.
So this means it will make sure the bits for
this value are set from the previous result.
And then this byte is moved back into the
buffer.
Done.
That maybe sounds very weird.
Like, how does this even make sense.
But it will make total sense in a minute.
Let’s reimplement this in python where we
can print it in a pretty way to make it very
clear.
So here I’m just transcribing the assembler
code 1-to-1.
You don’t even have to think much to transform
this into working python code.
But of course it’s not that pretty.
But it works.
Let’s try it.
Oh… somehow this doesn’t look quite right.
Why is it 0 at the end?
Shouldn’t the buffer be filled completly?
AHHHH the outer loop is only looping for 15.
I mixed it up.
Of course the outer loop has to loop over
all 24 characters of the key input.
Now the output looks better.
Okay…
This works, but let’s clean up the code
and make it more readable.
Now that we write python we have a bit more
freedom than with assembler instructions.
For example the index for si we could combine
that and call it buf_index.
We also don;t have to load, modify and write
back the value, we can just write it like
that.
And we can also condense the ax calculation
with the shift.
For example use 1 directly instead of via
the register.
This looks much better already, so let’s
continue doing that.
When we addressed everything we can run it
again to verify that it produces the same
output.
Okay looks like we didn’t make a mistake.
So now you would say, this still doesn’t
look better.
This is still crazy code.
Weird caclulations, logical ands and ors.
Bit shifts.
That’s not easier.
Well, sure.
If you haven’t seen this kind of code a
lot then it looks complicated.
But this is very typical code when you work
on the bit level.
And we can use python now to visualize a bit
more the steps that it’s doing.
Then it becomes very intuitive.
So I have added here a bit of debug output.
We print the current key24 index and the key
input value of it in decimal, hex and binary.
And then inside the smaller loop we print
the logical AND operation.
So first the key value as binary, then the
shifted by j 1 and then the result.
Let’s check it out.
So you see here, the first entry in our key
was just 0, which is a bit boring but look
at the shifted 1.
With each loop iteration it just has the 1
in a different place.
It just moves the 1.
Let’s go to the A, so 10.
Here our key input has two bits set.
1010.
So now we move again through every bit and
perform a logical AND.
The first one is 0 and 1 is 0, 1 and 0 is
0, 0 and 0 is 0 and so forth.
But in the second iteration the bit is in
the second position and now we have two bits
set, so the result also has a 1 here.
So this time it would enter the if case.
So we can already understand what this means.
We are looping over each bit of the key input
array.
And perform a certain action if a bit is set,
and do nothing if it was 0.
Okay…
So the real magic happens when a bit is set
and we enter this if case.
I remove part of the output again and print
instead the buf_index that indicates which
entry in the 15byte array is modified if the
input key had the bit set.
We ignore that for now, and just want to see
how the buf_index is iterating over the 15
byte buffer while the outer loop loops over
the 24 long key.
Look at this for a second.
If you ignore the key24 iteration you see
that the buf always increments after 8 steps.
Let me make a small modification to our code.
The shift right by 3 is equivalent to division
by 8.
And obviously keeping it an integer and ignore
the fractions.
Now let’s add the bit_shift to the output
as well.
We print the binary representation of the
bitshift, and the value of how much it was
shifted.
We run it.
And see that beautiful line pattern?
Eh, I remove the key24 output for a second.
Now look.
We are looping over all bits of the 15 bytes
buffer.
Now this logical OR here will set bits.
Right?
For example if we have the value 0000 and
we do OR with 0010, then the result will be
0010.
And when we then OR again 1000, the result
will be 1010.
So OR can be used to set bits.
And this loops over all bits in the buffer
array, right?
So it would set all bits, if it weren’t
for the if-case before.
And this if case depends on bits set in key24.
While working on a nicer output I realized,
“wait, I said we do this if when the bit
is set, but I wrote here equal to 0.
Oooops!”.
That has to be not equal to 0.
If you paid attention this much that you saw
this error earlier, good job, you are crazy.
Anyway, now look at this correct output.
The first key input was all 0, so no bit is
set.
But then the second key input has one bit
set.
Which means we enter the IF case and set the
6th bit in the first buffer byte.
So you see we iterate over all bits in the
buffer, but only set it when the key value
bit was also set.
You can see that the key value bits exactly
match when we set the bit in the buffer.
Loooong story short.
This is a custom encoding.
This is like base64.
But not with 64 symbols but with only 32.
So it’s like base32.
But not like the real base32 because it assembles
the bits slightly differently but basically
this is how encoding works.
The input key we give, the array has only
values from 0 to 31.
So it maps this 24 large array with values
between 0-31 into tightly packed 15 byte buffer.
So we are basically doing here a custom base32
decode.
Our input key is 24 characters long and is
then decoded into 15 raw bytes.
And those 15 raw bytes will be the new buffer
we will work with.
Oh… one last thing I just remembered.
Here, the logical AND with 7, in binary 111,
is actually equivalent to a modulo 8.
So maybe that makes it a bit easier for you
to understand.
The the divide by 8 covers the large increments
to the next byte, and the modulo picks up
the 8 remainders in each iteration to get
to each bit in that byte.
Awesome.
So this is a simple step that we can reverse.
We just have to implement the base32 encode
to reverse this.
So we still haven’t seen where this key
verification get’s actually difficult but
let’s see.
We are moving to this crazy looking block,
next time.
﻿Okay,
So last video I showed you this programming
language I made, ugly but works.
And we compiled this into this weird binary
format.
And then you pass this binary file to this
program called invoice, and it executes our
program.
In the last video I also showed you, that
the beginning of this binary format actually
triggers a buffer overflow and overwrites
the return pointer on the stack.
And at that point you might have thought that
our programs are simply shellcode, so assembler
code, that we inject and then jump to, with
the buffer overflow.
But that is not even possible, because the
stack is not executable.
So even though we cannot inject actual assembler
instructions to execute, we somehow were still
able to execute my programs.
And at this point it’s pretty clear, that
this is possible thanks to return-oriented-programming.
So let’s examine how this works.
But I warn you.
You really need to get your brain into an
abstract philosophical thinking mode.
This will get weird.
And maybe you have to rewatch it some time
in the future, maybe checkout some more “normal”
Return Oriented Programming tutorials and
then come back to this.
But if you get this video, I think it will
add to a much greater and deeper understanding
for you.
So just try...
Anyway.
Let’s head in.
So in x86 assembler there is an instuction
called “call”.
And call actually does two things.
First it pushes the return address (which
is the address immediately after the CALL
instruction) on the stack.
And then it changes EIP, the current instruction
pointer, to the call destination.
So the CPU continues execution there.
Now when we in C call a function, this will
be compiled to an assembler call instruction.
But to understand return-oriented-programming,
you have to forget this.
Ignore the concept of calling functions.
Simply remember that this instruction pushes
the address immediately after the call instruction
onto the stack, and then set instruction pointer
to the target address.
And the return instruction behaves in the
same way.
YES ret is compiled from a return in C. But
forget this connection.
A RET simply pops an address, we call it the
return address, off the stack and sets the
instruction pointer back to that.
And “pooping a value” from the stack is
also already again an abstract interpretation.
What it literally means is, it looks at the
stack pointer register, follows that address,
takes that value.
And then it increments the stack pointer register.
It increments because the stack grows downwards.
So if we shrink it, when we POP a value, we
increase it.
So it gets closer to the highest address again.
Anyway.
This is what ret does.
It’s taking this value where the stack register
points to, increments the stack pointer address,
and then uses the value it got, to set the
instruction pointer.That’s how we “return”
(in quotation marks).
So this was lesson one.
Ignore the name of the instruction or it’s
typical meaning and typical usage, just understand
what the instruction itself does.
So again, remember what the “ret” (the
return) instruction does.
First look at the stack register, follow this
address and take that value.
Increment the stack pointer.
Set the instruction pointer to that value.
Done.
Now let’s think about something else.
What does it mean for a machine to execute
instructions?
A CPU is a piece of hardware that executes
instructions.
Those instructions are machine code or assembler
code, right?
How does that in an abstract sense work?
Well there is memory, where instructions are
stored, and this memory has addresses.
Then the CPU has an instruction pointer register,
that contains an address that points to memory
with the next instruction to execute.
So if it’s 0, it will execute this.
And then it does whatever this instruction
is defined to do.
Not that important what this instruction exactly
does.
But by executing any instruction, the instruction
pointer is simply incremented and moved forward
to point to the next instruction.
ANd then that gets executed and the instruction
pointer will be updated to point to the next
one.
And so forth.
Of course that changes with instructions like
jumps, or calls, or returns, where the instruction
pointer is directly updated.
But you get it.
A computer, really in the abstract sense,
is a machine that given instructions computes
or executes those instructions.
So the CPU is a machine implemented in hardware.
But of course there are also virtual machines.
So machines implemented on top of our CPU
machines.
And for example the JVM, the Java Virtual
Machine behaves in the same way.
It is a machine.
So there is bytecode somewhere in memory,
and the software, the JVM has an instruction
pointer, or there called programm counter
pc, that points to the next instuction, or
there called opcode.
And when the JVM executes one opcode it also
has to update the program counter and move
it to the next one.
Here I looked up the source code for that.
So here is the OpenJDK source code
And there you see an UPDATE_PC_AND_CONTINUE
macro, where it literally adds the size (or
length) of the current opcode onto the program
counter, so this moves it forward.
Like the CPU would increment the instruction
pointer.
So this is lesson two.
A machine in an abstract sense is simple.
There is memory that holds code or instructions.
And the machine points to that code, takes
an instruction, executes it, and then updates
the program counter to point to the next one.
So what the f’ does this have to do with
return oriented programming?
Well last video I also introduced the concept
of a weird machine.
Somehow this invoice program implemented a
weird machine.
And I know, that concept was super confusing
but bear with me, it will make sense in a
moment.
If this invoice program implements a weird
machine, and you program that weird machine
with a technique called return-oriented-programming,
then you should ask yourself now.
where is the memory that contains our instructions,
where is the instruction pointer that points
to those instructions, and where is the logic
that executes whatever an instruction is defined
to do?
Well, luckily we have some example programs,
and we can debug this weird machine with GDB.
Let’s load the invoice program into GDB
and let’s learn how it executes.
I don’t want to explain buffer overflows
again, please checkout my binary exploitation
playlist for that.
But when you are familiar with it, you know
that we overwrote stuff on the stack.
If you look at the add_invoice function you
can find the dangerous functions gets() which
cause the buffer overflow.
So we can set a breakpoint here, and we set
one at the return.
Then let’s run the binary and as an input
we pass in the helloworld.binary.
And we know now that input triggers the buffer
overflow.
So here we hit the breakpoint at the gets.
If we execute the gets and examine th stack,
we can find all of our input here.
Here are all the As that fill up the buffer.
And then we have these randomly looking, but
actually carefully chosen values after it.
But let’s go forward to the return instruction.
So now we are about to execute the return,
and please remember what return means.
It looks at the address in the stack register,
so here this address points to this memory,
so this is the stack and that’s the top
element.
And the return instruction now takes that
value as an address, and sets the instruction
pointer to it.
And at the same time increments the stack
pointer.
So let’s do that.
Single step forward.
ANd now let’s compare before and after the
return.
It did exactly what we expected.
The stack pointer register was incremented
from 0x18 to 0x20, so move 8 bytes forward.
And the instruction pointer got set to the
value previously on top of the stack.
Btw... when we execute a “ret” we also
often use the phrase “we return into <something>”.
It doesn’t matter if we say “we returned
to”, say “we returned into” or say “we
continued execution here”.
It’s all the same.
Don’t get confused by the term “return”.
You know what the ret instruction really does.
It simply takes a value from the stack and
sets the instruction pointer to it.
Anyway.
So what happens now?
Where is our instruction pointer pointing
to?
It points here...
To this assembler code.
A pop rdx and a pop rbx.
Followed by another return?
So this means it takes one value from the
stack and puts it into rdx.
Increments rsp again.
Then takes the next value on the stack and
moves it into rbx.
Increments rsp and then we are at the return
again.
And now return takes the next value on the
stack and sets the instruction pointer to
it.
So where does it now continue executing?
Okay.
So now we are here?
Here we have a pop rdi.
So it takes the next value on the stack, moves
it into rdi.
And then comes ret, which takes the next value
and sets the instruction pointer to it.
So where are we now?
Now we execute a move.
We move edx, into the address pointed to by
rdi.
And remember when we set EDX?
The pop RDX at the beginning, set the value
of EDX to a value we had on the stack.
And RDI, the address where we now write to,
we also had on the stack and got it into RDI
with a pop RDI.
Think about what this code now did!
I know it looked weird, but all it did was
it moved a value we wanted into an address
we specified.
We moved a value into RDX, then an address
into RDI, and then we wrote that EDX value
to the address RDI points to.
Now look at the source code of the hello world
program.
Here the code said we move the string, “hell”
which is of course 4 bytes, into the variable
4.
And then store variable:4 in memory location
1.
And that is just another way of saying, we
move the string, or the 4 bytes, “hell”
into rdx.
And then we move rdx to a memory location
we specify in RDI.
Which memory location, and converting the
string “hell” to the four bytes is what
my compiler program does.
I know, maybe that is a bit too confusing,
maybe better just ignore my compiler shenanigans.
But if think about what we did.
We executed these few instructions that move
a value into some memory location.
And we did that by using super weird instructions,
which we usually refer to as “gadgets”.
To perform this memory write, we used three
gadgets.
First we used a “pop rdx, pop rbx” gadget,
then a “pop rdi” gadget and then a “mov
gadget”.
And see what all these gadgets have in common?
They all end with a return instruction.
Now bend you mind.
take what we just witnessed and try to fit
it into the concept of a machine executing
instructions.
First, we have memory, that is our stack.
On there we had all these addresses and values.
And in a weird fuckedup way the stack pointer
was our instruction pointer, right?
Our weird machine basically started with a
return opcode, which took the first address
on the stack and continued CPU execution there.
Then the stack pointer pointed to the next
value, we popped it and moved it to the next.
Pooped another value moved it to the next.
And then came another return which took the
value and let the CPU execute code there.
Moving the stack again to the next value.
So In a way those addresses on the stack,
when we have a return, define instruction
handlers, right?
You could say this address here is actually
the opcode, the instruction to perform a pop
rdx and then a pop rbx.
And this other gadget, this address here,
is the opcode for the move of edx into the
address of rdi.
Isn’t this basically the same thing how
a x86 assembler “call” instruction actually
means we push an address on the stack and
set the instruction pointer to the given destination.
How is that “call” x86 instruction different
from our weird machine gadget?
It isn’t!
Both define some action, what it does, and
then the machine moves to the next instruction.
The CPU does this by incrementing the instruction
pointer, the Java Virtual Machine does this
by simply incrementing the program counter,
and our weird machine does this by incrementing
the stack pointer.
I know, these gadgets are super weird instructions.
And each program, depending on how much code
it contains and what kind of functions were
written there, and where in the memory the
compiler places the code, changes what kind
of gadgets are available.
With the small tool ropgadgets we can actually
list all gadgets, so assembler snippets that
have this pattern of a few instructions followed
by a “ret”.
Basically these are all the weird instructions
that we can use to implement whatever we want
on this weird machine.
I know it’s crappy.
Nobody said that it has to be a well thought
out machine like the CPU or the Java Virtual
Machine.
But it’s enough to basically perform any
kind of computation.
It was enough for me to collect gadgets that
seemed useful and built a compiler that translates
this text representation to actual addresses
that point to those gadgets.
And that’s why each program with such a
vulnerability, accidentally crafts its own
weird machine.
Each vulnerable program will have it’s own
instruction set, it’s own collection of
gadgets.
And it’s own initialisation code that setups
that weird machine.
Basically the code that triggered our vulnerability
in the first place.
So writing such an exploit.
Is in essence the setting up and instantiation
of a weird machine by triggering the buffer
overflow.
And then we program that weird machine with
a rop-chain, a collection of gadgets chained
together that will be executed by our weird
machine, thanks to how the x86 “ret” instruction
together with the stack works.
And what we can program is just bound by our
creativity and availability of useful gadgets.
But if you have a large amount of gadgets
you can understand that you could implement
ANYTHING you want.
You just chain these small assembler snippets
together to build anything.
In an attack you usually try to create a remote
shell or something, but it could literally
be just a regular program.
Like I have created these rop-chains that
for example take two numbers as an input,
adds them together, and prints the result.
And that’s it.
That is return oriented programming explained
in a super confused way.
I know, this is maybe not the best ROP tutorial.
But there are so many “normal” tutorials,
that I just wanted to try something different
and I hope there are some of you where this
kind of different angle on the topic is mind
opening.
At least for me this was so mindblowing and
beautiful that, as you know, it became a slogan
for my channel.
Also I like to remind you to checkout the
papers and talks I have listed in the description.
Please read them even if you didn’t understand
this video.
They are maybe better, but certainly more
correct explaining this concept of weird machines
and exploit development.
Anyway… thanks for watching and maybe checkout
my Patreon and YouTube membership in the description.
﻿Fuzzing is a technique to automatically test
input to some software to see what happens.
This could be a crash or just general errors
or interesting behaviour.
Whatever you are looking for.
Now fuzzing is not easy.
There are a lot of different challenges like
speed, scalability, detecting errors or whatever
you look for, but also how do you even generate
these interesting input test cases in the
first place?
that’s basically the whole art of fuzzing.
For example if a software wants an integer
as input.
What kind of fuzzy tests would you like to
do.
Other numbers, leading spaces, small numbers,
large numbers, larger numbers, leading zeroes,
negative numbers, floats, text, long text,
arbitrary bytes?
There are so many options.
Now if you need a simple but fairly powerful
general-purpose fuzzer, then check out radamsa.
Radamsa is a test case generator for robustness
testing, a.k.a. a fuzzer.
It is typically used to test how well a program
can withstand malformed and potentially malicious
inputs.
It works by reading sample files of valid
data and generating interestringly different
outputs from them.
The main selling points of radamsa are that
it has already found a slew of bugs in programs
that actually matter, it is easily scriptable
and easy to get up and running.
Let’s revisit our example about this fictional
program that wants an integer.
And then we use radamsa by giving it one example
number, by piping it into the standard input
of radamsa.
And radamsa then prints a potential fuzzing
test case.
Now here it returned a huuuuge number.
Next it actually returned nothing.
So you would test an empty input
Then it returned a small number 2.
Then 256.
Now echo also adds a newline after the number
we pass in, so for this testcase radamsa simply
decided to remove this newline.
A few test cases later radamsa even introduced
some unprintable characters.
You see radamsa is pretty smart in generating
good fuzzing input.
It tries really hard to create useful input
that is not just random bytes but actually
has hopefully some meaning for the targeted.
Let’s even try it with a simple HTML string.
An svg tag with an onload javascript alert
attribute.
You can for example see here a testcase where
radamsa seems to be aware that that’s a
number and changed it, and here added some
arbitrary bytes before the equal sign, it
also constructs invalid HTML by repeating
opening or closing tags.
Now see we never gave it an empty opening
tag, but for some reason it still used one.
If you have an XML parsers this is really
good test input that stresses the hierarchical
structure of XML or HTML.
Radamsa is pretty smart and powerful but it’s
also so easy to use that you can rapidly prototype
a fuzzer for some software you want to test.
﻿Hey, welcome back.
So last video we started to reverse the exploitation
qualification challenge from RHme3 and we
had just figured out a rough plan for exploitation.
So rewatch this if you don’t know what’s
going on.
But we also pickup here just where we are
about to develop the exploit.
And while this is about a specific challenge,
the technique to get to the final shell, is
very similar for a lot of CTF challenges.
So even if you are not doing this challenge,
it could still show you some generic techniques.
Remember in the last video that at the start
I was already thinking of what probably our
goal is going to be?
So in the spirit of doing this whole challenge
from the reverse.
Let’s think about which Global Offset entry
we could overwrite.
Ideally I would love to overwrite a function
there with system(), which has a string for
the command to execute as first parameter.
So we are looking for another function that
has a similar pattern.
Some people contacted me and had issues once
they got so far to have an arbitrary write
and could overwrite an entry of the GOT, what
to do now?
They tried to use ROP gadgets and so forth,
but most of the time, at least for the eaiser
exploitation challenge, it’s mostly enough
to somehow execute /bin/sh to get a shell.
In a previous stream I did I showed how to
find a one-shot execve gadget that just calls
/bin/sh, so check that out, but another technique
is to just look for a fitting function.
So system() takes a string as the first parameter
as a command to execute.
So what would happen if you overwrite puts()
with system()?
Well then everytime the program would call
puts(), it would actually try to execute the
string as a system command.
Makes sense, right?
But it’s not really useful, so in our case
we are looking for functions that might have
a user controlled string as the first parameter.
Let’s see.
Strcpy could work in some cases.
Or strlen, or puts.
But also free could get passed a pointer that
coincidentally points to a string.
For example if the name is freed, and the
parameter would be a pointer to that name
string.
So there are a lot of options, and of course
it could break the program, so you have to
be a bit smart.
But I chose strlen in the end, as it’s getting
called on a string that is read by the user.
Infact it’s reading the name input here.
So that’s great.
So to recap.
We want to overwrite strlen with system, so
we can execute /bin/sh when we enter /bin/sh
as a name.
To do that we need an arbitrary write, and
the name pointer in the player structure could
do that for us, if we control it.
We also know we have a use after free, which
means we interpret a value on the heap as
a pointer, eventhough the player should be
freed.
So hopefully we find a way to overwrite that
freed memory with data we control, and thus
control the name pointer.
Sounds like we are almost there!
We just have to find a sequence of operations,
where we get control of this pointer.
In general this should happen when we create
some players, select one, remove some and
add some again.
So I just sat there for a bit and just played
around with different name lengths to somehow
make one name overlap with the pointer.
But it kinda didn’t work right away.
I think that’s because the modern heap uses
different kind of chunks, namely fastbins
and so forth.
And they are maintained differently.
So in many cases the malloc of a new chunk
would skip the freed space.
But I’m not 100% sure what exactly happened.
I just suspected that must influence it.
But if somebody could link me a writeup that
has a better understanding of the heap and
goes into that issue, I would love that.
Anyway, I guessed that this should still be
the solution, so I just have to find the correct
case where the overlap would happen.
And at some point I did!
So it happened when I register 2 players with
32 byte long names.
Selected the second one.
Deleted the 2nd and first one, then allocate
a new player, with 19 bytes.
And when we then show the selected player,
we get a segfault!
I got the 19 bytes from playing around with
the lengths and it perfectly overwrites the
name pointer.
You can see the segfault happened in printf,
probably because the pointer was pointing
into invalid memory.
Which would be a success.
But also you can see our debug prints before
the segfault and you can compare the state
of the memory where the player was selected
and still healthy, and the overwritten object
we now used.
So you see the name of the third player we
created smashed the stats and the name pointer.
From here on now it’s easy to write the
exploit.
We just have to do one minor thing, and that
is defeat ASLR of libc.
Because even if the binary is not using ASLR,
other system libraries on an ASLR enabled
system will have randomized addresses.
But that’s easy with the name pointer we
control, because we can not only use it to
write data, but also read memory when we show
the player and try to print the name.
So we can read a libc function address from
the global offset table and then calculate
offsets from there.
In our case I would like strlen, so we can
take the GOT address of strlen and use that
in the name we use to overwrite the name pointer.
But let’s just start developing the exploit.
I’m writing it in python.
So first I setup a socket to connect to the
port 1337.
I also implemented a recv_all function that
reads data until no data is read in a certain
timeframe.
So until there is a timeout.
Then we can simply send the inputs, that correspond
to the menu selections that trigger the bug.
So here.
add player.
Name. stats.
Select player.
Delete the two.
And then create a third player and include
the address we want to set the name pointer
to.
In our case the address of the global offset
strlen entry.
And then we send a 5, which does show_player,
thus printing wherever the name pointer points
to.
And then we do some stuff to extract those
raw bytes, because it should point into the
global offset table and print the address
of strlen.
After that we use the cool telnetlib trick,
that just simply hands over the socket to
us, so we can send and receive data.
And when we run it doesn’t crash and outputs
the strlen address.
We can also now press 5 again to see how the
player looks like.
And these weird bytes here are the address
of strlen.
And so we extract those.
Now we want to calculate the base address
of libc.
The address where the libc binary is loaded
to.
To do that we can simply open the provided
libc, or your local libc, depending on if
you develop the exploit locally or for the
remote server.
And then you look for strlen and copy the
address.
It’s different for not ASLR binaries that
have their loading address specified, but
in this case the addresses start at 0, so
this is the offset inside the binary where
this function starts.
So when we now take the absolute address that
we leaked from the server and subtract the
offset, we get the address where libc starts.
And then we look up the address or offset
for system, and when we add this offset to
the libc base, we get the absolute address
of system on the server.
We can run it, and there it is.
That’s the address of system on the server.
And then we can use the edit player, edit
name function, which will then change the
name, but the name is pointing into the global
offset table of strlen, so we will overwrite
that address.
Some of you might have thought that wouldn’t
work because you noticed a realloc on the
name, but in fact that realloc only happens
if the string you entered is longer than the
string already stored.
And the address of system is not longer than
the address of strlen, so we bypass the realloc
and just write to it.
And now next time we change the name, we can
enter for example /bin/sh, and then it will
call strlen on this input, but strlen was
overwritten with system in the previous name
change, and thus executes bin/sh.
And we drop into a shell.
So now we can simply find the flag file and
read the secret.
There we go.
Done.
﻿Nadim Kobeissi has written a paper called
“An Analysis of the ProtonMail Cryptographic
Architecture” where he says that “no end-to-end
encryption guarantees have ever been
provided by the ProtonMail service”.
This is quite a big and serious claim.
End-To-End encryption is the first feature
they list in their security details, along
Zero Access to User data, which means:
“[...] we don't have the technical ability
to decrypt your messages, and as a result,
we are unable to hand your data over to third
parties.
With ProtonMail, privacy isn't just a promise,
it is mathematically ensured”.
Protonmail has been around for quite some
time now, if something so fundamentally seems
wrong, it must be some kind of crazy complicated
crypto attack, right?
But if you read the paper, you will realise
it’s something fairly basic.
So in this video I want to explore one specific
thing from this paper.
This whole topic has caused quite some controversy
and before we head into this I think it’s
just fair to disclose that I have worked,
with nadim, many times professionally.
So you can accuse me of bias, but I don’t
think that this actually affects the content
of this video.
It was merely the reason why I paid attention
to this paper in the first place.
But let’s not waste more time, let’s head
into the paper.
Nadim first introduces some entities.
We need to know about a ProtonMail user A
and a ProtonMail user B.
We also consider a ProtonMail webmail server
P.
So we have two protonmail users A and B, and
they want to send an email to each other by
using protonmail webmail sever P. Because
Protonmail offers End-to-end encryption this
email will actually be encrypted with PGP.
And there is nothing wrong with PGP.
The only challenge with PGP here is the secure
exchange of the public key.
But we just assume keys were exchanged securely,
for example A and B met in person before.
So if user A encrypts the mail with the public
key from user B, and uses Protonmail to transfer
the mail to B, there is no security issue.
End-to-end encryption is working fine.
But then how can nadim claim that “no end-to-end
encryption guarantees have ever been
provided by the ProtonMail service”.
It looks all perfectly fine, right?
Well, the devil is in the real-world implementation
details.
You see this graph that describes the email
exchange assumes that User A and User B just
have trusted implementations of PGP.
The code that will do the encryption for them.
However in the web, just as matter of fact
how the web works, the program, the code that
implements the encryption, the webapp you
use, protonmail, is also delivered by the
protonmail server P.
And this can be seen here in Figure 2.a.
Before user A can PGP encrypt the email message
m, for the public key from user B, it has
to receive the code to do that in the browser.
This is indicated here by J. J refers to the
Javascript implementation of PGP that is served
by Protonmail.
And, we are done, that’s for me the important
part of the paper, so the conclusion is simple.
When Protonmail says:
“[...] we don't have the technical ability
to decrypt your messages”.
It’s kinda wrong, right?
Technically they can just deliver a malicious
javascript J-evil, that will just steal your
plaintext message before encryption, or just
straight up steal your private key…
The technical ability is absolutely there.
And so the claim that this “end-to-end encryption”
is not just a promise but “mathematically
ensured”.
seems objectively, false.
No?
So let’s have a look what Protonmail has
to say about that.
The key question being debated is whether
or not web applications can constitute end
to end encryption.
Nadim's opinion is that, as he writes, "no
webmail-style application could".
His viewpoint is that E2EE is not possible
with web clients, period, end of discussion.
This is a rather extreme position to take
as it would also apply to the web versions
of Whatsapp or Wire, for instance.
Like Whatsapp and Wire, we also offer a web
app.
The major opinion Nadim is expressing here
is that [...], you can't do end-to-end encryption
in a webapp.
Obviously Whatspp and Wire do not share this
opinion.
Signal coincidentally does share this opinion.
We do understand Nadim's arguments, and agree
that web-apps are less secure than say a native
iOS app.
Okay… so they do somewhat agree, however
they think it’s not that significant.
They use the fact that Whatsapp and Wire also
offer webapps, as an argument for their side
- but of course these are also other commercial
applications, that like protonmail have a
user demand and an economic incentive, to
offer web-app versions.
But for a moment, let’s go back to this
figure.
We say we have here a problem because Protonmail
Server P provides the javascript code, for
the browser and could thus provide malicious
code as well.
But then how is this different from a mobile
app.
Protonmail also provides the mobile app and
the automatic updates for it.
So protonmail could also just deliver an evil
app-update that steals the cleartext emails.
And you can now actually continue with this
rabbithole.
Apple offers iOS updates, which means they
push the code you run on your phone - they
could create an operating-system update that
specifically extracts the decrypted emails
from the protonmail app and sends it away.
And wait, you run this all on hardware that
you bought from somewhere and the CPU could
just once in a while jump to some secret malicious
code that could take the decrypted messages
out of the memory and steal it.
You see you can extend these circles quite
far.
However at some point it gets silly.
While technically your hardware could be backdoored,
that’s very unlikely.
Like the recent bullshit bloomberg story.
And yes, technically apple could push a malicious
operating system update, but that is also
super unrealistic…
But what about “protonmail creating a malicious
mobile-app update”?
Here we start to get into a bit more realistic
realms.
build servers or webservers that offer the
final softwares for download have been comproised
before and replaced with a trojanized version.
This is something we could be concerned about.
However we also know these compromised versions
are caught fairly quickly, because this attack
has quite some hurdles.
And Nadim shares an example about the delivery
process of android apps.
Simply speaking, in case of a mobile-app,
it’s not as simple as saying that Protonmail
server P delivers it, there are developers,
signing keys, app-stores, and everybody gets
the same new version.
So overall this is very unlikely.
So this leads us to typical web applications,
which are delivered from the server everytime
when you access protonmail.
We know for a fact that a lot of websites
get compromised and for example a cryptocurrency
coinhive miners get included in the javascript.
So we can already see that this is a more
realistic threat.
And the big danger here is also, that you
could carefully control which user gets delivered
which version.
You could only target a specific IP, a region,
a user.
And only deliver a malicious javascript J-evil
once.
And after that, all future requests are safe
again.
You see that is VERY different from a malicious
mobile app.
And so protonmail questions if the line that
nadim draws here reasonable.
Can we, for the current state of our technology
say, that webapps cannot implement End-To-End
encryption because the code is also always
delivered with HTTP requests?
Well, PotonMail’s argument against the paper
is saying, that this is just an opinion - saying
that nadim draws the line here arbitrarily.
Nadim's opinion is that, as he writes, "no
webmail-style application could".
But this is a bit unfair.
This quote is not the root of nadim’s argument
- it is quite an extreme positon to take.
But he takes this position as a result of
his argument, this is nadim’s conclusion.
And while I agree with conclusion, let’s
not get distracted by this.
Conclusions are more likely subjective and
thus Protonmail uses it to discredit him.
But nadim wrote a paper specifically about
Protonmail and we have to look at his actual
arguments regarding protonmail.
And more specifically the claims that protonmail
makes, and nadim uses to construct his argument.
So Protonmail attacks nadim’s general conclusion
but seems to ignore, and sidestep, the claims
that lead nadim there.
But I know why, because ProtonMail is in a
predicament.
They themselves acknowledge nadim’s threat
in their business paper “ProtonMail Security
Features and Infrastructure”, they write:
ProtonMail conservatively assumes that all
mail servers may eventually be compromised.
And even further into the paper where they
talk about how they want to protect passwords
(different story) they again refer to this
threat.
“If the server is compromised, whether from
malicious code injected onto the server or
due to a [blah blah unimportant]”
you can see Protonmail themselves claim that
the Protonmail Server P is untrustworthy.
And based on this claim nadim succesfully
makes the argument, well if Protonmail can
be compromised (which they say shouldn’t
be a problem), the javascript code delivered
is also compromised.
Protonmail does not make such claims about
the mobile app.
They don’t advertise a security model where
a compromised build queue including developer
signing keys is not a problem.
But they do say a compromised server P is
supposed to be safe.
So as it stands, ProtonMail does not meet
its self-professed security goals.
Which means, ProtonMail must overhaul its
existing specifications, documentation and
product presentation materials.
To reflect this matter of fact.
So It doesn’t mean that Protonmail is less
secure than alternatives, it simply means
Protonmail’s very high security-goals and
public marketing claims, specifically about
a compromised server, have been refuted.
Nothing more.
Nothing less.
And of course if for YOU personally a compromised
protonmail server is not in your threat model,
because you trust them, then you are also
fine.
So I hope that Protonmail can properly address
these very specific claims and admit that
in this case their claims fall a bit short.
It doesn’t have to be such a big deal.
But I personally would like to move away from
Protonmail now and rather generally ask, what
conclusion do you draw from this.
Do you agree with nadim’s radical(?) or
reasonable(?) view that end-to-end encryption
is simply not possible in this strong mathematical
sense as a web app?
﻿I have written a small C program. It’s supposed
to be a simple license check.
So you can execute it and you can supply a
key as argument and it will be checked.
Our goal is to crack this program so we don’t
have to use a valid license key. I have made
this program available through a github repository.
You can download it from github.com/liveoverflow/liveoverflow_youtube
or you can install ‘git’ with ‘sudo
apt-get install git’ and get the whole repository
with ‘git clone’ and the address you can
see on github. We will probably talk more
about what git is later. For now it’s enough
to know, that this is a way how developers
can program together on a project. And I use
it to share some stuff.
To have a look at the binary assembler code,
we can use a program called gdb. The GNU Debugger.
So type ‘gdb’ and the path to the binary.
So every C program has a main function, remember?
So let’s type in ‘disassemble main’
which will display all assembler instructions
from the main function. But urgh, do you see
how ugly that looks? That’s the horrible
at&t syntax. So type in ‘set disassembly-flavor
intel’. Remember that you can use tab completion
here as well. Now ‘disassemble main’ again,
and now it’s much more readable. Ok. So.
It looks complicated. But you can ignore most
of it. First of all get a high-level view
of it. It doesn’t make sense to start going
through this instruction by instruction. This
main function obviously calls other functions.
So just draw a mental picture of the rough
control flow.
I will actually print out this assembler code
and use a pen. That’s how I did it in the
beginning and still do it when I encounter
more complex code.
And remember to just ignore most of the stuff,
concentrate on the actual flow.
So at the start it arrives at a compare with
the number 2. And afterwards a ‘jump not
equal’. So something is checked if it is
2. If that is the case, we proceed to a ‘printf’.
Which we know is a function to display text.
Then comes a ‘strcmp’, if you don’t
know that function, read the man page of it.
‘man 3 strcmp’ - so this compares two
strings and returns 0 if both strings were
the same. After that call we see another ‘jump
not equal’ so if the zero flag is not set,
there will be a ‘puts’ call. Use the man
page to figure out what it does, but it just
prints text like printf. So if the original
compare with the number 2 was not true, then
it would jump to this address 0x400623, which
is at offset main+102. So in that case it
prints some other text with ‘puts’ and
exits. I always add the addresses, or at least
part of the address, from important locations,
so I know where I am. This will help you later
when we step through the program.
Now we have one branch missing. If this compare
was incorrect, this branch would jump to offset
main+90. Which also just prints text.
Some jumps are still missing, but you can
add them to get a nice control-flow graph.
Now let’s actually execute this and step
through it. You can then draw which path through
the graph you have taken on your paper.
To do do this we first set a breakpoint at
the start of main with ‘break *main’.
Breakpoint is set, now use ‘run’ to start
the program. Starting program and we hit the
breakpoint 1 at this address. A breakpoint
is a point where execution stops. Now look
at the registers with ‘info registers’.
Here you can see that RIP, the instruction
pointer, points to the first address in main.
Now use ‘si’ to step one instruction.
Now we are at a new address in main. ‘info
registers’ and you see the changed instruction
pointer. So now just step through it all and
follow the addresses in your control graph.
But use ‘ni’ instead of ‘si’, because
‘si’ would step into function calls. But
we only want to step through this main function
and not follow stuff like ‘puts’. Ok did
you notice when we jumped? The jump was at
5d0, and then the next instruction was at
623. So we followed the jump, which means
whatever was compared to 2, was not 2. And
then the program printed the Usage information
after 628, which was the last ‘puts’ call.
So we can write down, that this ‘puts’
prints the ‘Usage’ information. Now it’s
pretty clear, that we didn’t pass a key
to this program. Which means the check was
looking at the arguments if we supplied a
license key. So let’s run the program again,
but this time with a random license key. Yes
we want to start the program again.
Now do the same. ‘ni’, ‘ni’. Now we
are at 5d0 again, will we jump this time?
No! cool! So the next branch we expect is
at 609. Let’s ‘ni’ and see what happens.
AH! Another print text. So that ‘printf’
is the info that a license key will be checked.
‘ni’. Now comes the branch. Ok we arrived
at 609, let’s see where we are afterwards.
At 617. So we did jump, which means that the
strcmp failed. And when we continue with ‘ni’
we see that it’s wrong.
Ok. Let’s set a breakpoint just before the
last compare and run the program again. Remember
that you can easily copy&paste values in the
terminal by simply marking something and pressing
your mousewheel. Now ‘run’ again. Breakpoint
1. Now ‘continue’. This will run the program
normally again, until we hit the next breakpoint.
Now stopped before we execute the ‘test
eax, eax’. EAX just refers to the first
32bit of the 64bit RAX register. So it’s
value is hex 0xE. Let’s set this to 0, which
would indicate that the ‘strcmp’ was correct
and returned a 0. ‘set $eax=0’. ‘info
registers’ and you can see that it’s now
0. Now use ‘ni’ again to step and follow
your control path. ‘Access Granted!’ YAY!
We circumvented the license check!
It think that’s pretty cool! And you can
always write your own little C program trying
to make it more secure, and then crack it
yourself again. You will notice that it’s
impossible to make a program uncrackable.
Those kind of challenges are called ‘crackme’.
People create small programs that have to
be cracked. Or more often you have to create
a valid keygen. If you think something like
this is fun, checkout http://crackmes.de/.
Creating control graphs like we just did is
pretty useful. That’s why there are some
programs that do that for us. Here are three
different examples of this specific control
graph.
First is HopperApp, second is IDAPro and the
last one is from radare2.
See you hopefully next time when we use some
different tools to explore this licence check
binary a bit more.
Let’s figure out together the basic concepts
of a CPU. Computers have different memory
to store stuff - so first we need something
to store the machine code in. Let’s take
a spreadsheet and imagine that this is memory.
You can store values in it and each memory
cell has an address, which is the number on
the left. And I will use the 2nd column to
write some comments in there.
As you can see there are some hexadecimal
numbers stored in this memory. And at first
it looks very random, but that is our machine
code and soon you will understand this.
So the first thing the CPU needs to have is
something to keep track where in memory the
CPU currently is. Which means we shoud add
a little storage for our CPU and call it the
“Instruction Pointer”. This little storage
area will contain the address of memory the
CPU is looking at the moment. So obviously
our program starts from the top, so the address
will be 1.
Now let’s start the CPU, it looks at address
1 and reads 48, AA, 14. But what do those
numbers mean? The CPU knows that 48 means
it has to MOVE data around. The AA means the
destination of that move. and the 14 is the
source. So in address 14 we can see the number
42. And the destination is another small storage
unit inside the CPU. So the CPU will move
the 42 into it’s small storage area called
AA.
So this instruction is done, and the CPU increases
the Instruction pointer by one. And we start
over. The CPU reads the current value at the
address of it’s instruction pointer. So
it reads 48 again which means move, and this
time it’s moving the content of address
15 into the small storage BB. Notice how I
use brackets around the 15. This indicates
that 15 is an address, and we actually reference
the content of 15, which is 66. And not the
number 15 itself.
Instruction done, increase the Instruction
pointer.
The next address contains 83, AA and BB. The
CPU knows that 83 means COMPARE. And it compares
the values in AA and BB. Now it has to somehow
remember the result of this compare. So let’s
add another small storage that stores this
result. We call it Zero Flag.
You know what an intelligent way is to compare
two numbers? If you subtract them from each
other and their result is 0, they were the
same. If the result is not zero, they were
different. So this is what the CPU does. 66-42
is 24, so that’s not 0. So we set the zero
flag to false.
Instruction done, next one is at address 4.
The CPU reads a 75 and 07. 75 Stands for JUMP
If not equal. And 07 is the address where
to jump to. So the CPU checks the state of
the Zero Flag. And The Zero flag is set to
FALSE, so the previous compare was not equal.
Which means it jumps to the destination 07.
A jump is easy. The CPU just sets its Instruction
Pointer to 07.
Ok so the next instruction is at address 7.
And it reads E8 and 17. E8 In this case stands
for print a text. And the text can be found
at address 17. But 17 doesn’t contain text?
Well, for a computer everything is numbers.
Like those instructions the CPU executes,
they are just numbers. So text is made out
of numbers too. Remember how I brushed over
ASCII values in a previous video? Now it’s
the time to pull up the ascii man page again.
So type ‘man ascii’ In the terminal. Now
try to find hex 4E and 4F. Haa.. ok. So they
stand for ‘N’ and ‘O’. Which means
the computer will print ‘NO’.
So looks like this code simply compares two
numbers.
I will not go over the case when those two
numbers are the same, but you should try it
yourself.
That’s crazy, huh? CPU simply reads the
memory sequentially and does whatever it reads.
And programmers can build crazy complex stuff
with that.
Now let me change the text a little bit so
it reflects more the reality of how we write
assembler. Basically just abbreviation of
it. Also don’t get confused with the order
of parameters. simply think of it like a variable
assignment in programming.
This was a very simple example, but the real
world is not much different. People just came
up with a lot more instructions that might
be interesting and wrote complex code to solve
hard problems. But at their core they are
simple like that.
﻿In most of the other videos where we did technical
stuff, I have been recording and playing on
a ThinkPad with Linux that doesn’t have
the best graphics card.
So you had to endure this low FPS footage.
After editing last video I realized… wait…
I just developed a TCP network proxy, which
means I can run the game on any of my machines
and just have to make sure the traffic goes
through my proxy…
I’m an idiot!
So now I can just change the game server IP
on my windows gaming battlestation, to point
to where the proxy is running.
So enjoy these EPIC graphics for a bit!
So like last episode I continued to look at
a few more packets and implemented them.
Nothing special.
There is a sneaking toggle, weapon reload
and a respawn packet when you die and click
respawn.
And when you now play the game there are very
very few packets from the client to the server
that we don’t know about.
Pretty cool to see.
Btw, one of the bears dropped me an AK47.
Look at how cool that is.
But one of the more interesting packets we
haven’t looked at can be seen when we pick
up drops from those bears.
Like this blue one I forgot to pick up.
Which btw turns out to be the Zero Cool magic
spell.
In our Let’s Play we got that drop from
a boss spider in the Fire and Ice dungeon.
And if you don’t understand this reference?
Zero Cool - Mess with the best, die like the
rest.
Then please stop watching my video right now,
and instead watch the movie Hackers.
Anyway.
We gun down a few more bears with the AK.
And then we can collect a few more packet
samples.
Let me clean up the output really quick, and
remove the obvious and already known position
packet.
So this seems to indicate an item pickup.
One interesting and important observation
is, that one of the drops gave us two items,
but we still only saw one of these packets.
Also the amount that we got of something doesn’t
seem to be encoded in the packet either.
AND we also got sniper ammo twice, and still
the value is unique here.
All this evidence combined let’s me believe,
that this must be some kind of drop ID.
And the packet is something like, pickup the
drop with this ID.
And so here I implemented a parser function
for it.
And then we can test it.
Let’s hunt some bears!
And there are two more observations that we
can make with this now.
First, the ID seems to be predictable and
incremental.
And the second one is, which is actually something
I wanted to try and that is sending the same
packet multiple times.
I don’t know what happened, I assume it’s
a small bug of the client and some kind of
hiccup, that it sent it multiple times, but
it definitely didn’t result in us getting
the same item a few times.
I wanted to try that because I was wondering
if we can duplicate item drops that way.
But clearly the server doesn’t allow that
and the drop can only be picked up once.
However I wonder about another thing, but
for that we need a new feature of our proxy.
I want to be able to inject packets into the
communication.
We can use the little command loop we have
written here for that.
So far we only have a quit command, but now
I want to add a send to server and send to
client command.
To do that I define two commands that start
either with S or C, indicating where I want
to send it.
Then I have to look for a gameserver that
is connected.
To do that I add another attribute into the
proxy class that we can set to true when we
have a connection.
This allows us to loop over all game servers
and see which one has a client connected to
it.
And then we just, based on which direction
we want, have to get the reference to the
socket, on which we can then call sendall.
Now over the network we want to send raw bytes,
but our command line input has to be text.
So I think we can just make sure we enter
hex data and that is then decoded into raw
bytes and send to either the client or server.
I also make a small modification in the parser
so we can get the whole packet that was sent.
So let’s head ingame and shoot a fireball.
This is the packet we sent, you know how the
packet is structured from last video.
But now with our new feature we can simply
say, we want to send a packet to the server
with capital S, followed by this hex encoded
data.
And BOOM!
We just told the server to create a fireball!
Amazing, right?
Now let’s play with the item drops, we know
it’s easy to guess once we have a valid
ID.
So let’s kill some bears until we get a
drop, now we just have to collect it and look
at the ID.
Cool!
So now we just have to make sure we have a
few more drops laying around and then we just
try some other Item IDs in that range and
maybe we get lucky and get the correct item
ID.
LOOK!
We just picked that up by faking a packet
and didn’t have to walk to it.
We could create an auto loot feature if we
could figure out the ids of items.
Our client has to know somehow, right?
Well so far we have only looked at packets
from the client to the server.
And from what we have seen it’s actually
fairly simple what the client does.
A lot of the actions like which items we pickup,
if we killed something and so forth is all
calculated on the server.
We just say we want to pickup that drop, but
not “we want 6 sniper bullets”.
So the protocol is not designed too badly,
it doesn’t trust every fake info by the
client.
Except of course the position which we used
to fly and teleport around.
So I think it’s time to look at some server
packets.
For that we have to remove the filter to exclude
server packets.
And we get flooded with a lot more info.
Infact I noticed that when I walk here a few
steps back and forth, that here I only get
zeroes, nothing, and here, where I’m closer
to the forest with the bears, then I get a
lot of data.
Which goes away when walking back again.
So first of all we have a small 00 empty packet,
which we can add the parser.
But then what’s up with this data.
I assume what we witnessed here is a boundary
between zones.
And this is the zone with the bears, and this
one doesn’t have monsters.
So the server only sends us the monster information
if we are close.
And doesn’t when we are further away.
Saves traffic and also local computation on
the client to handle these actors in the world.
But in anyway, we can copy a few example of
these packets and quickly analyse it.
Of course the first two bytes is the packet
ID again and we can quickly see that it appears
multiple times in there.
And if we align them below eachother nicely,
we can also super easily see the format.
Packet ID, some kind of other ID, maybe monster
ID, and then this part here.
which was changing all the time when we saw
the data in realtime printed by the proxy,
It’s probably also position data.
So the XYZ position of the monster.
And then we have some other values that I
have no idea what they are for.
But whatever, let’s implement the parser
for what we got.
And that’s super simple, we extract the
ID as an integer, XYZ as float, and then for
the remaining data we also unpack it as integer
for now.
And then we print it.
And when we now go into that area, we see
a super awesome output of the actors in the
area.
So if my assumption that these are the bears
in this area is correct, we should be able
to kill one, and that should remove an entry
here.
So BOOM!
And quickly have a look and compare before
and after.
And yes!
There is one entry missing.
Awesome!
But does this list also contain item drops,
because the ID looks fairly similar.
Let’s pick up one item and look for that
item ID in our output.
So it looks like the ID of the item drop is
in kind of the same unique ID system as these
monsters, it would fit in here, but it’s
not there.
So this is really just monster data.
Mhmh… so where do we get the item drops.
I remove the output of the monster position
again, because it’s very spammy, this way
we can more easily catch new packets.
One unique packet I noticed was arriving right
when we join a game.
So let’s look at that one, it’s quite
big.
Again we can split and arrange the data based
on the first packet ID, and so there were
obviously a lot of them that look very similar.
And it looks kinda similar to the shooting
a weapon packet.
As there are ascii characters and so I guess,
here the length.
You can again look for similarities and lign
it up, and it becomes very clear.
What this data back here means, I don’t
know yet, but let’s explore what kind of
names there are and start implementing the
parser.
So I guess this is another ID, as it was incremental,
and again a length, some text, probably a
name of some sorts, and then at the end a
bit more stuff.
So let’s check it out, we relog into the
game, and LOOK AT THAT.
It contains initial actor information.
The bush from the spawn, some NPCs, but also
the Golden Eggs!
So if this is actor information, I’m wondering,
is the other data behind maybe again position
data?
So let’s parse that as floats and print
it too.
Relog again into the game, and here we go.
Awesome!
Look!
This is the real position of the eggs.
I recognise this one because I was using it
as the example when we reverse engineered
the setup in the disassembly.
Which is sooo awesome, because this is a third
option on how we could have gotten the position
of the eggs and solve it!
First we did it through dynamic analysis by
accessing the objects in memory with LD_PRELOAD
and hooking stuff, then we found it with static
analysis where they setup the eggs and use
hardcoded position values, and now we have
a third path through network traffic analysis.
I think that’s really awesome that there
are so many ways how you could have solved
it.
At least part of it.
For the ballmer's egg you would have had to
reverse engineer some of the code, probably.
Let’s see if the same packet is also used
when a dead monster drops items.
Let’s find a bear, kill it.
And there we go!
WhiteDrop!
And here we get the ID of the white drop.
Let’s implement auto looting with that,
we just have to send the pickup packet with
the item id.
But to do that we have to do some modification
of our proxy and parser for that, because
we don’t have a reference to the socket
in the parser to just write, send this pickup
packet now.
And I actually did that first, I added a SERVER
and CLIENT variable, that I set from the proxy
with the socket reference, and then I could
send out that packet from inside the parser,
but that just broke everything.
The socket didn’t like it to be called from
different threads and it always broke.
So what I did instead was I created a QUEUE,
where I can add packets I want to send out
either to the server or game client.
And then in the proxy thread that handles
that specific socket sending direction I check
if there are items in that queue, and if so,
I pop one off and send it out.
It’s not perfect, I used a regular list
and not a thread safe queue, and also didn’t
loop over the queue to send out multiple items
AND it only does it after it received a packet
before.
But whatever, I just wanna get it to work.
So now, theoretically when a drop is detected,
the pickup packet is placed in the queue and
then shortly also sent to the server.
So let’s try that.
We head into the game, and shoot some bears.
And look!
We automatically pickup the drops.
Even from bears super far away.
That’s awesome for farming items.
And HOLY SH--HAND GRENADE!
What is that?
I wanna throw it at some bears.
BOOM!
This is amazing!
Apaprently it was a purple drop, that must
be super rare.
So this is a Holy Hand Grenade, a Legendary
Grenade and does 300 damage.
And it has a 10s cooldown.
Blow thine enemies to tiny bits.
Thy foe, who being naughty in My sight, shall
snuff it!
What an epic end to an episode.
﻿I was walking around the financial district,
when I stumbled upon this strange device.
Does anybody know what it is?
It does not have any recognisable logos or
marks, only the letters "V1" written on one
side and a USB connector on the other.
Here is a photo.
It probably is some kind of memory, but it
has an unusual design.
I will check it when I arrive at home.
I finally arrived at home.
I connected the USB device to my computer,
but it looks that it is permanently locked.
Now I am curious about the device and its
content.
Would I be able to unlock it using Fault Injection?
Hey guys, this was a reenactment of the story
in the description the Fiesta challenge from
the riscure embedded hardware CTF.
I’m really excited about this one.
So check it out.
The device is permanently locked, we can imagine
that the code could look something like this:
A loop with a condition that will always be
true, so an endless loop.
And it just prints “Lock”, which sucks,
because we want to get to the code after the
loop, where it prints the secret.
“Clearly there is no way to reach that code.
Ever.”
- that’s what a software developer would
say.
But bear with me.
We will perform a hardware attack and glitch
our way out of this loop.
I’m so excited about this challenge it was
my favorite thing to experience and the perfect
end to the riscure embedded hardware CTF for
me.
Get ready to get your mind blown.
<intro>
I have some theoretical knowledge about hardware
attacks from university and also watched some
conference talks about it.
Which is just theoretical knowledge, but least
I had somewhat of a plan.
So the challenge is a fault injection challenge,
which means you kinda screw with the hardware
so that it does something wrong.
And there are several ways how you can perform
a fault attack.
For example you know from movies how an EMP
can crash electronics, so trigger a small
electromagnetic pulse to the chip and it might
do something weird.
Or the chip runs from a clock at a certain
speed and weird things happen once you let
it run faster than intended or a lot slower.
But what I will do is a power glitch.
Which means I want to cut the power supply
for a really short amount of time, so that
the device does not reset, but it does something
weird.
And so to do this I need to build something.
I choose to do it with an FPGA developer board
that I have still laying around.
An FPGA is for now just like any other electronics
board, something that you can program to do
whatever you want.
In my case I want to use the switches to control
the length of the power drop and a button
as a trigger.
And I want to use a single wire as an output
of the FPGA to control an electronic switch
that turns on or off the power supply - so
a transistor.
So let’s focus on the first part, programming
the FPGA so that it does what we want.
If you are a software developer then you might
find the code that you write for FPGAs very
weird.
At least for me it took quite a while until
it clicked for me.
Because you are not writing sequential programs,
but you are actually just writing a definition,
a description of a digital circuit.
The same description languages are basically
used in designing real chips like CPUs.
And so what you are looking at here is a very
very simple chip that I have designed.
This is just a first test to get into writing
verilog code again but let me try to explain.
Like I said I’m describing the behaviour
of the chip here.
And at the beginning I’m saying, this chip
has a few inputs for example a switch a button
and the clock.
So the FPGA board also has a clock signal.
Which is just 0,1,0,1,0,1,0,1…
And I define some outputs: two LEDs and a
regular output pin on the board.
Then I define some internal registers, so
a small memory cell that remembers some values.
I already defined a 32bit counter register,
but ignore that for now.
And a glitch_register, which will be the output
for the glitch so 1 power is on, or 0, power
is off.
Now I connect these internal registers with
an actual output of the chip.
Imagine really wires going from the glitch
register to the output.
So the LED as well as the pin output are directly
connected to the register value.
And I also connect the button input to the
other led output, so obviously when the button
is pressed, the LED will turn on.
You see, really just describing how the chip
is wired up.
Then I set some initial values, these values
are set when the device powers on.
So the counter for now is set to start at
0, but the glitch power output is 1, so turned
on at the start.
And then comes a block that just describes
what happens in each clock-cycle.
Everytime when the clock signal has a positive
edge, so a rising edge, it will do the following.
It will take the value in the glitch register
and invert it.
And you know the glitch register is directly
connected to this output pin, so that pin
will just wiggle 1,0,1,0,1,0 with each clock
cycle.
THen you just compile the hardware definition
and program the FPGA.
And by programming the FPGA I don’t mean
it writes some kind of sequential assembler
code to some memory.
This is not a processor.
You can build a processor with it, so it’s
kind of a layer deeper.
But it basically contains a lot of digital
building blocks which will be connected together
in a way, that it does what you described.
So yeah it’s a lot of magic.
But it’s quite fascinating how it works,
so you should look that up.
And then we can look at the oscilloscope and
see that it works.
You see that the output pin here constantly
goes 0,1,0,1,0,1.
Cool huh?
Now I just have to write a bit more verilog
code to get the behaviour that I want.
So for example I want to use the switches
of the board to set how long the power should
be turned off, so I have to include them in
another definition file.
Developing this hardware stuff is really frustrating
at the beginning, but I learned it on my own
a few years ago, because I heard that FPGAs
are awesome, I think it was just the time
when bitcoin people started to implement mining
on FPGAs.
The verilog code is still very short, because
it’s not a really complicated circuit.
But let’s see.
So first of all, everything here happens when
the FPGA sees a rising edge of the clock.
And then the stuff in here doesn’t happen
sequentially it just defines what happens
when the rising edge is seen.
It’s all simultaneously, it’s connected
wires in a digit circuit not a program.
So if the current state was idle, which it
is when the device it turns on, it checks
if the button is pressed.
If the button is pressed the state will be
set to glitch.
So with the next clock cycle now the FPGA
is in the glitch state where it will output
a 0, to indicate the power will be turned
off and start incrementing the counter.
So with every clock cycle it will now keep
incrementing this counter.
At some clock cycle in the future the counter
will have the exact binary value of the switches.
So with the switches you can obviously set
a binary value with 0s and 1s.
So if that is reached the state will be changed
to holdoff.
By that I mean I don’t want to accidentally
glitch multiple times after eachother, because
a glitch is super short, and when I don’t
release the trigger button fast enough, it
could glitch again.
So holdoff will output a 1 again, so that
the power is turned back on, but also use
a counter to wait for a while.
And when enough clock cycles happened it will
go back into the idle state where we wait
for the button press again to perform another
glitch.
So now we can have a look at that with the
oscilloscope, you can see that the power is
high, and when we press the trigger button,
the power will drop to 0 for a very short
amount of time.
You can see here the scale of the oscilloscope
in the nano seconds.
And with the switches we can set a counter
value to indicate how long a glitch should
be.
Oh this looks really good.
I think we are ready to go.
So now we just have to wire up our target
so we control the power.
This is actually a bit tricky, because the
board gets the power through the USB cable,
which also carries the serial communication
so we can interact with the board.
But let’s go step by step, first of all
let’s take care of the power.
The FPGA board does not run with 5V, so we
have to use a small circuit to convert the
3.3V to 5V, which we already did for the power
side channel analysis a few videos ago.
So I just reuse the unidirectional level converter.
Looks complicated but does nothing else than
being able to switch 5V with a 3V signal.
And we can hook now that 5V up to the VCC,
the power in of the board.
You see you don’t have to go through the
USB cable, you can just directly connect to
the power supply.
Now we just need to somehow be able to interact
with the board via serial.
As you know those arduino boards have an extra
chip on there, a USB to UART so serial converter.
Which is great, because we already have the
USB drivers for that installed on my laptop.
Now I just take an arduino UNO that I have
and remove the atmega microchip.
So basically now only the USB to UART chip
is left and I can directly connect the RX
and TX to the target board.
When I now establish a serial connection with
this arduino UNO board, what I actually do
is, I talk directly to the serial of the challenge
board.
And here is the complete setup.
We have the FPGA which performs a power glitch
which can configured with the switches.
And pressing the button will actually do it.
The 3V glitch output of the FPGA is converted
to 5V via the unidirectional level converter
and then is connected to the VCC, the power
in of the target board.
So when the glitch output of the FPGA drops,
the power supply to the challenge board is
cut for a short moment.
And to interact with the board via serial,
we have hooked up the USB to serial converter
chip from another Arduino.
Awesome.
Now all we got to do is to connect to the
serial so we can observe the “LOCKED”
message, and then play around with the length
of the glitch.
You can also see that the power doesn’t
completely drop like it did before without
a target.
I think maybe it has something to do with
the capacitors on the target board that reslease
charge when the power drops.
But it actually is not too bad, so the power
doesn’t completly cut out, but just drops
a little bit under the recommended voltage
threshold.
I think that’s better for a glitch.
So when you play with it sometimes you glitch
the board so hard, that it resets.
Which is not what we want.
And sometimes it even loses the program you
flashed on it.
You can see here that after the glitch it
started blinking red, which means the program
was lost and the bootloader waits for it to
be flashed.
No idea why it happens but you can see, that
glitches are somewhat dangerous and you could
theoretially brick the board if you glitch
a critical code path in the bootloader.
But when you get the timing right, so the
right moment where you want to glitch and
the voltage drop has the right length, then
magically the loop is broken and the flag
pops out.
How crazy is that!
Solved!
Let’s quickly recap.
The board had an endless loop that will never
stop, and the flag is printed after the loop.
So theoretically you could never reach that
part.
It’s dead code.
But we know, that microchips can behave weird
and miscalculate stuff, for example when the
power is below the minimum voltage for a short
amount of time.
Usually the chip is not operational with those
voltage levels, but because we just do it
for a very very short amount of time, it won’t
just stop working, but it just might miscalculate
some loop condition, or maybe skip instructions
entirely.
We don’t really know.
I also assume that riscure made it very easy,
so that you don’t have to actually glitch
one exact compare instruction, but they maybe
made a lot of calculations and if only ONE
fails it will break out, so that we have a
lot of chances to actually glitch something
important.
But nevertheless I think this is just amazing.
I always felt like these kind of fault injections
are very theoretical and unrealistic, but
having done a simple one myself and not even
a professional, that was amazing.
I hope you can appreciate how crazy that is
too.
I just wish the side channel power analysis
challenge would have been on the same level.
﻿Mindreader had more solves than any other
challenge and was considered easy.
And still, I failed to solve it.
In the end I had solved two medium and one
hard challenge, so what was my issue with
mindreader?
Well.
Let me tell you about how I approached this
challenge and what went wrong.
Mindreader.
Can you read my mind?
I was wondering what that could mean.
Reading your mind.
I thought maybe it could be related to reading
a processes memory.
Well.
Challenge is running at mindreader.web.ctfcompetition.com
When we visit this site we find a very easy
form with a text input.
If you write something it passes a GET variable
f with your input but returns a Not Found
error.
Well that already smells bad.
So a natural first thing to do is to try local
file inclusion.
And sure, /etc/passwd works.
So what do we do now, where can we find the
flag.
Usually when I work with a web challenge I
use a web proxy like Burp.
My firefox has already the proxy server configured
so I just have to start burp and then can
visit the site.
Disable the request interception, visit the
page and look for the request in the HTTP
history.
And there it is.
When you highlight it you see the request
and response details of the HTTP request down
here.
Then I hand over this request to the repeater,
which is a neat feature of burp where you
can repeat those requests.
So it becomes really easy to change the f
GET parameter and see the result on the right.
So now I wonder what I could be looking for.
I remember a few interesting files on linux,
but obviously I don’t know everything.
And one of the first things I noticed was
the Server nginx in the response.
Which made me start to google for the default
config and log locations because I was hoping
to learn something about the web app running
there.
So for example /var/log/nginx/error.log.
Or /etc/nginx/nginx.conf.
But nothing worked… mhmh
At some point I opened up a terminal and connected
to a linux VM I had running somewhere to find
interesting files.
Especially because I wanted to check the /proc
filesystem.
There is a lot of information about your own
process there.
So I tried to access a few things like /proc/self/environ
which should print the environment variables
of your current process.
But it didn’t work.
Here is the first mistake I made.
I wonder if you notice it.
I will come back to it in a second.
I then went on and looked for other interesting
files, maybe there is something in /dev/.
I started to continue trying out different
interesting /dev/ files and there was this
fd folder.
Fildescriptors.
And it’s actually a symlink to /proc/self/fd,
so pointing at your own fildescriptors.
You can see that fd 0 returns OK, and fd 1
and fd 2 just keep hanging, but no error.
And there seem to be even more open filedescriptors;
not only the standard stdin, stdout and stderr.
That’s interesting but didn’t give me
anything.
Anyway.
This was my second mistake.
Do you notice my mistake here?
I didn’t so I thought this is going nowhere.
So I started to work on another challenge
and procrastinated checking twitter.
And there was an unread message.
This guy had some problems with Joe and asked
me about it.
Had a short chat about the CTF and because
he saw I didn’t solve mindreader yet, he
told me I could easily do it.
Well… yeah I assume because it’s an easy
challenge that I should be able to do it,
but so far I’m stuck.
And then the worst thing happened.
He sent me a spoiler for the challenge.
Please don’t do this.
If I don’t solve a challenge I don’t mind
and I will seek out writeups after the event.
But in the moment you deprive me of a valuable
learning experience.
Because even when I’m stuck with a challenge
I start researching.
And the bits of information I read and pick
up left and right makes me more knowledgeable
in general.
And next CTF I will be better.
I tried to stay away from mindreader after
that, but it was bugging me and for my own
curiosity and because I was failing with another
challenge I just had to look what the hint
is.
I just can’t ignore this, it’s in my head.
And the code revealed that the flag is in
the environment variables, which I already
had a hunch for as the possible place, but
now I know the goal.
And it also shows why /proc/ didn’t work.
There is a filter.
And it hit me in the face.
I realized the two major mistakes I made and
how I could have solved it on my own.
This right here has turned into a valuable
lesson for me.
Ok let’s have a look at my first mistake.
When I tried to access something in /proc
and get the error, it’s actually a different
error then when I try to access some random
other file.
I did not notice that.
The second mistake I made was when I checked
/dev/fd/.
Because I knew it was a symlink to /proc/self/fd
from my example linux system, and while I
did wonder for a second why that works, I
filed it away as a small oddity.
If I had made notes of the weirdness that
I see with accessing /proc and that apparently
the symlink works I could have combined those
two things and figured it out myself.
But I didn’t.
I was sloppy, I didn’t take proper notes,
and most importantly I didn’t pay attention
to the details.
Oftentimes when it comes to hunting for bugs
it’s the small oddities you must not ignore.
A hacker who can focus on details, will discover
great vulnerabilities.
So when I saw that proc was filtered and returned
another error, and that I had to access the
processes environment variables, I immediately
knew what to do and tried to use the symlink
to /proc/self/environ through /dev/fd/..
One directory up ../environ and get the flag.
Solved.
Well not really.
I got a spoiler.
I’m not sure if I had solved it without.
Maybe, maybe not.
It was certainly not hard, but I made mistakes.
And while it was a good lesson for myself,
I hope it will also show you that, if you
allow me this arrogance, that even I can fail
easy challenges.
Sometimes knowledge and experience is missing,
but oftentimes the issue is just not paying
attention to all the information you have
been given.
﻿Last weeks video was about revisiting format
level 0 from exploit-exercises/protostar on
a modern ubuntu system.
And we played around with it to see if we
can figure out a way to exploit it, but in
the end I wasn’t able to solve it.
But lucky for me a user with the name wcbowling
on reddit thought it was fun too and actually
had a method to exploit it.
So let’s have a look at it.
So here is wcbowlings post:
I love going back to old challenged like this
:) Managed to get a fairly reliable exploit,
normally under 500 iterations.
And there is a highlevel description on how
it works:
Overwrite the GOT entry for __stack_chk_fail
with an address so we jump there instead.
The address can be passed in via argv, we
cant use nulls but we can use blank strings
instead.
As the argv location is semi random, it takes
around 500 iterations which is pretty reasonable
for 64bit
So obviously I didn’t manage to figure that
out, which means I didn’t know something
and here is a learning opportunity for me.
So I’m not going to pretend I knew this.
For whatever reason I never noticed that __stack_chk_fail
is in the global offset table.
And the reason for that might be, that I never
encountered a challenge with these constraints?
We have A) a format string exploit that generally
allows us to write anything anywhere B)
No libc function after the format string vuln
that we could overwrite in the global offset
table
And C) where we also have a buffer overflow
with a stack cookie.
So I really like this challenge now, because
the solution is so clever.
So the function that is being called when
the stack cookie got overwritten through a
buffer overflow is also on the global offset
table.
Which means our goal is to redirect code execution
to our winning message by overwrite the GOT
entry for __stack_chk_fail.
And then do a buffer overflow, to trigger
that function.
To write to that global offset table entry,
we have to get the address somewhere onto
the stack, so that we can use %n with the
format string vulnerability.
And the issue is that it contains nullbytes
which we can’t pass in via the arguments.
I think the arguments are string copied onto
the stack?
So we can’t enter arbitrary nullbytes.
But wcbowling had a cool trick with empty
strings as arguments.
Because a string ends with a nullbyte, so
an empty string is just null.
I think I had a super early video to talk
about the environment and arguments on the
stack, but quick recap, you have the argv[]
char pointer array, so it’s a list with
addresses that point to the strings.
And then you just have memory with all the
strings.
And so this way you can get the address with
null-bytes on to the stack.
Pretty clever, I never thought about this
before.
And now you basically just have to put everything
together.
Wcbowling uses pwnlib to implement the exploit,
it’s a very useful python library, check
it out.
And so here the magic format string is built
with a large offset into the stack that hopefully
hits the addresses passed in via the arguments.
And so there are two single byte writes.
Why are only two bytes written?
well the GOT already contains an address that
is almost the target address, except the last
two bytes.
So you can just reuse most of it.
Then this is being executed in a loop until
the winning message is shown.
The stack has some randomized offsets, thus
you have to try it a few times.
Here is the asciicinema recording by wcbowling.
By the way, if you have a problem with a challenge
and you write me an email, you could use that
to record a screencast so I can actually see
how you debug it and what the problem is.
So while I understand now the basic idea,
I still wanted to implement it myself.
There are a few challenges that you have to
solve like, what is good offset into the stack
to hit the arguments, and the alignment of
the address through the arguments.
And while I was doing that and struggling
with exactly those details, I had an epiphany.
And I’m sooo grateful that wcbowling shared
this exploit, because it pushed me into discovering
this.
So I actually found a 100% reliable exploit
for this challenge, and you can’t believe
how excited that makes me.
Though I have to admit, that it might only
work on my compiled binary, and for somebody
else it might not work, you will see in a
second why.
So here it is.
That’s all.
And when we execute it, you can see it gets
into an execution loop of the winning message.
And while it looks like a simple format string
vulnerability with the padding to increase
the amount of printed characters, an address
and a %n or %hn to write to an address, there
are quite a few beautiful puzzle pieces here.
So the basic idea came, when I was playing
around with overwriting the GOT entry for
__stack_check_fail.
wcbowling had two writes and placed the address
in the arguments, which made it so unreliable.
I thought, maybe we get lucky if we place
the address into our string, like I did in
the last video.
But there is one problem.
The string that is printed is coming from
the arguments, which has an unpredictable
position.
But the string is formatted with sprintf into
a buffer, which will have a fixed relative
position on our stack.
So basically the format string will be evaluated,
so first it handles the %d with the 1640 character
padding and places it into the buffer.
Then comes the raw bytes of the address, and
places it.
And then comes the format modifier to write
to an address on the stack.
So now the position of this address that was
just written onto the buffer is at a fixed
offset location and we always get it with
214.
Though the problem is, we can’t have an
arbitrary amount of bytes padding.
Because the address has to be 8byte alligned.
So we can only increase or decrease the padding
in 8 byte steps.
Which affects the amounts of bytes we can
write.
With %n.
It’s always in these 8 steps.
So we don’t have an write anything condition,
but we can write something close to the wiining
address.
Now there are two challenges.
First, the stack is fairly small, and the
format result is written into buffer on the
stack, so if we use too much padding, to write
a large number with %n, we run out of stack
memory and get a segfault.
But wcbowling’s trick has made me realize,
that we can in fact increase the size of the
stack by just using more arguments.
It will add entries to the argv array and
increase it.
The second problem is, that the address is
only written with 3 bytes, so if the location
on the stack had other values in it, it won’t
work.
We need to write our address onto the stack
where there was a zero, or generally a small
number before.
And here is also where the arguments help
us again, because we can groom the stack,
by adding or remove entries in the argv array,
so that the stack is large enough, and we
have a zero at the correct spot.
<grunt> I love it!
So now we know how to groom the stack to write
to the GOT entry, but we still have the issue
that we are not sure what to write because
of our multiples of 8 restrictions.
I wrote a simple python function that generates
me valid exploit arguments with different
paddings and adjusts the amount of arguments
and the write offset accordingly.
And I started by looking around the printing
of the winning message.
So ideally we would like to write 0x670, that’s
1648, but becuase of our alignment restrictions
that doesn’t work.
Anyway, I was then just trying them, to see
if anything interesting would come from it.
And luckily this one worked.
Let me debug this with gdb, I set a breakpoint
after the sprintf, before we check the stack
cookie.
Let’s look at the stack.
So this is the %d padding with spaces, to
print the amount of characters we want to
write to.
And then here at the end is the target address
we want to write to.
The GOT address.
We can also look now what value has been written
there.
So we will jump to 0x40066b.
Let’s look at the disassembly and see where
that would be.
66b.
Mhmmh… wait!
That is not a valid address, this is not right?
It’s in between the compare and the jump-not-equal.
Let’s use x to print 3 instructions, instead
of the disassemble command.
Do you see that.
WTF there are now moves, and not a cmp?
What the heck?
Welcome to intel assembler and more advanced
ROP.
This kind of property was called the geometry
of intel assembler, in the famous ROP paper,
but never heard anybody using that term.
Anyway, we jump in between the bytes of the
intended instruction, and the CPU is dumb,
it will just read those bytes and interpret
them as assembler.
And so in this case, the cmp and jne turned
into two simple moves.
Which means, now there is no check for deadbeef
and we run into the printf to print the winning
message.
When we single step forward now, we get into
the procedure linkage table for stack_check_fail,
we jump to the GOT entry, which is our weird
address into vuln, we execute the mov, and
then we call puts to print the message.
﻿In this episode we will have a look at the
first level of protostar from exploit-exercises.com.
If you have questions about the setup, you
can watch the previous video.
Generally I advise you to stop the video right
here, and work on it by yourself first. Maybe
give it a day and see how much you can figure
out. And after that, watch my explanation.
But if you feel completely lost, then just
follow me. This here should give you enough
information to solve the next level on your
own.
So let’s first have a look at the challenge
description.
This level introduces the concept that memory
can be accessed outside of its allocated region,
how the stack variables are laid out, and
that modifying outside of the allocated memory
can modify program execution.
And this level is located at /opt/protostar/bin/stack0
Ok. Next we will have a look at the source
code which is provided below. Let’s start
with a first quick overview.
This is clearly a program written in C. It
reads some input with gets(), then checks
the modified variable and prints either a
success or fail message. So obviously the
goal of this level is to make the program
print the success string. Note, this level
is not about executing arbitrary code to gain
root privileges. First we have to understand
a couple of basics. A real full root exploit
will come in later levels. So for now, let’s
focus on this smaller goal.
We can also execute the stack0 program. And
we can see that it seems to wait for some
input, and then prints “Try again?”.
Ok so let’s have a more detailed look at
the code. There are two local variables. An
integer number modified, and a char array
buffer with space for 64 characters. An array
of chars in C is basically just a string.
Then modified will be set to 0. And apparently
never changed changed.
Next is the gets function with our 64 character
long char buffer. Let’s have a look at the
gets man page. So gets is used to read a string
from the input. When we scroll down we can
also find a Bugs section, which is telling
us, to never use gets()! This cannot be more
clear that this is the vulnerability in this
program. As an explanation it says, that it’s
impossible to tell how many characters gets
will read. It has been used to break computer
security.
And after the gets call, modified is compared
to 0. If it is not 0, we have won. But how
can modified ever become non zero? It’s
set to 0 and never changed.
btw. the volatile is a way to tell the compiler,
that it should not optimize the usage of this
variable. Because at first glance it looks
like modified will always be 0 and thus it
might simply remove the unnecessary if-case.
But with volatile we can force the compiler
to keep it as it is.
I think we have a good understanding of this
program now in C. Let’s open it with gdb
and start debugging.
First let’s set a breakpoint in main with
break *main. Then type run or short r to start
the program from the beginning. Now it stopped
at the start of main. With disassemble you
can disassemble the current function. But
also set the disassembly-flavor to intel,
because I like it more.
Let’s try to understand fully what is happening
here. I ignored those parts in my reverse-engineering
introduction, but here we need to fully understand
how the stack works. So let’s start with
the first instruction ‘push ebp’.
A quick flashback to my CPU introduction video.
I mentioned that the stack is just a memory
area at the bottom. When we look at the mapped
memory with ‘info proc mappings’, we can
see that the stack goes from bffeb000 to c0000.
And because the stack grows from the bottom,
it starts at the highest address. c0000 doesnt
belong to it anymore, so basically the stack
starts at c0000-8. which is bfffff8.
So push EBP. EBP is a register which is used
as the base pointer. And it contains an address
pointing somwhere into the stack. esp right
now is actually bffff7bc. And at that position
is this b7something value.
Ok so whatever the meaning of this address
is, it seems to be important, because it get’s
pushed on the stack. Which is like saving
the value. And at the end of the main function
you find a leave. And the intel instruction
reference tells us that leave is just basically
a mov esp, ebp and pop ebp.
As you can see the start and end of a function
is symmetrical. At the start we push ebp and
mov esp into ebp. And when the function is
done, we do the reverse.
Don’t worry, I will illustrate this nicely
in a moment. Just one more little thing.
After those two instructions we mask esp,
which basically just sets the last 4 bits
to 0, to keep it nicely aligned. Not that
important. And then we subtract hex 60 from
it. So ESP, the stack pointer now points to
a bit lower address than ebp. And the next
instruction moves a 0 at the memory location
at offset hex 5c from the stack pointer. And
that seems to perfectly match our modified
variable that gets set to 0. At first it’s
a lot to take in. But let’s do it again
but this time with an animation.
So here on the left you can see the assembler
code. And on the right I will illustrate the
stack. with the 3 important registers, the
instruction pointer EIP, the stack pointer
ESP and the base pointer EBP. So first it
starts somewhere else with a ‘call main’.
Call will push the theoretically next instruction
pointer onto the stack. And then jump to our
main function. As you can see, when the address
of the next instruction was pushed, the stack
pointer got incremented and the address placed
there.
So now comes our push EBP. I will illustrate
with some arrows that this value is a stack
address, which points to another location
on the stack. Now we overwrite EBP with the
value from ESP. mov ebp, esp.
Then we subtract hex 0x60 from esp. Look at
the stack now. This area between esp and ebp
is called a stack frame. This is now a small
area of memory, that we can use for local
variables and calculations inside the main
function. And do you notice where EBP is pointing
to? It’s pointing to the OLD ebp. So this
area here is basically the stack frame of
the previous function, which called main.
And we know that we move 0 into esp+0x5c.
Which we think is the modified variable. And
that’s true. The local variables all have
their space in this stack frame. And it’s
so big, because it had to make space for at
least 64 characters and the modified integer.
At the end of this function we will now perform
a leave. Which moves EBP into ESP. Effectively
destroying the previous stack frame. Then
we pop EBP, which restores the previous stack
frame. Isn’t that amazing? But WAIT! it
gets cooler. How do we now know where to return
to from main? Well if you remember, call pushed
the address of the instruction after the call.
So the next value on the stack is where we
want to return to. And the ret instruction
is basically just popping this address into
the instruction pointer. And thus jumping
back where we came from.
Computers. ha! aren’t they mindblowing.
So much smart stuff in there.
Now let’s continue with the assembler code.
After a value on the stack got set to 0, we
prepare the eax register with an address from
the stack at offset 0x1c. LEA (load effective
address) is similar to a move, but instead
of moving the content of an register offset
into a register, it moves the address of an
register offset into a register.
And this address then get’s placed at the
top of the stack. This is called calling convention.
The programs and functions have to agree how
to pass function parameters in assembler.
In this case the parameters are placed on
the stack. And the gets function takes one
parameter, which points to a character buffer.
and the character buffer is on the stack,
thus we have to pass it the address where
the character buffer starts.
Afterwards we read the value we previously
set to 0, and with test we can check if it
is 0 or not. And branch off to print one of
the messages.
So let’s remove the breakpoint form main
with ‘del’ delete and set a breakpoint
before and after the gets. Before we restart,
I want to show you a cool trick. We will define
a hook, that will execute some gdb commands
when we stop at a breakpoint. To do this type
define hook-stop
then info registers to show the registers
and x/24wx $esp.
and x/2i $eip
and finish with end.
This will now print the registers, the stack
and the next two instructions every time when
we hit a breakpoint.
Now restart the program. Boom. first breakpoint.
Now continue and enter a couple of capital
A’s.
Do you see those hex 41s. those are all the
As you have entered. Now let’s see the content
of the address we check if it’s 0. Simply
examine $esp + hex 5c. Still 0. But it shows
us where it is located on the stack. and when
we look at our stack, we see that our As are
still a little bit too far away.
So let’s count how much we need. 4 characters
here. Then 4 times 4 that’s 16 for a row.
And we have 3 full rows. And with the next
full row we can apparently write into those
zeroes.
So run again. Enter that many characters.
I like to use recognizable patterns. So I
can clearly see which letter which row is.
looks promising. So a single step forward,
and it will load the modified variable from
the stack into eax. And indeed. Those are
the characters that we entered.
Let’s try this without gdb.
We can use echo and our previous string and
pipe it into the stack0 program. Cool! it
worked.
Before we end, let me show you how we can
make the input a bit more convenient thanks
to python.
With python -c we can specify a command that
should be executed. Then we can use print
and pythons cool string syntax which allows
us to repeat this character multiple times.
With this knowledge you should be able to
solve stack1 and stack2. It’s pretty much
the same task, just with some different ways
of input and a different vulnerable function.
But if you invest some time, you can absolutely
solve it. And I will not make a video about
those.
Next video will be about stack3. This is when
things start to get juicy.
See you next time!
﻿Today we will reach a milestone in this series.
We will figure out how to send a malicious
update, that is not signed by ledger, to the
device.
And it will persist and run.
As you probably remember, early in the boot
sequence of the ledger, the ledger checks
this address 0x8003000 for the magic value
0xf00dbabe.
Only then it will continue execution.
otherwise it will just return and continue
into the bootloader.
So we know this value has to be set, if we
want to run our own code.
So let’s investigate further.
Let’s do again some more roleplaying.
We know what the goal and issue here is and
we already know some details from the advisory,
but let’s pretend we are doing this research
for the first time, and only know what we
have figured out so far.
Then there are two things we would work with
now.
First we have this sequence of APDU commands
that we recorded during a valid update.
So we can extract some of the unique commands
as a sample sequence how an update would work.
The second information we have is the source
code of a pretty old version.
Together with reverse engineering and comparing
this code, we know about the 0xf00dbabe check
during boot, but we don’t know yet how that
affects the update.
We don’t actually know that there is some
kind of checks and verification happening.
We might even assume there is none.
I decided as a first step lets get an overview
over the APDU commands.
And I don’t need to spend too much time
on this, it’s super straight forward.
You remember we had this loop with the switch
case statements and these defines that tell
us what byte means what and so we can quickly
extract their meaning.
This is the instruction “VALIDATE_TARGET_ID”.
And I guess this is the particular matching
ID.
Then came a secure instruction “SELECT_SEGMENT”,
and we can already see here the famous 0x8003000
address.
So we select a memory segment now.
And this is then followed up with multiple
secure instruction “LOAD”s.
Where we, according to the source code, have
an offset that is simply added to the segment
set previously, we have a length of data here.
Here that byte is stored into the variable
rx, and later we see how that length value
is checked and even used.
And then followed by data, which doesn’t
necessarily interest us, however at the start
of 0x8003000, we of course find also the magic
value 0xf00dbabe.
Then we find a secure instruction “FLUSH”,
followed up by a secure instruction “BOOT”.
So let’s approach this naively.
Let’s use our test APDU script and build
up a test update.
We basically just copy the apdu commands we
had above and just slightly adjust them.
At this point for example I ignored the first
command VALIDATE_TARGET_ID, because I thought
it’s not important.
Then I did the select segment and then I had
to come up with a load.
Of course we need the 0xf00dbabe value so
I leave that, but I also adjust the size,
because I don’t need to write that much.
Just to kinda better see what happens I make
the bytes I write longer and just add some
recognizable bytes.
0x41 0x41
Besides that we also need some code.
And from reverse engineering we know that
the regular firmware code typically starts
at 0x80030c0.
Which means I added another select segment
and then a LOAD to write some assembler code.
But what code do we write there?
The easiest thing, which also Thomas originally
did, was testing an endless loop.
That would be easy for us to see if it works.
And so I’m using radare2, or more specifically
the rasm2 utility, to get the bytes for an
endless loop.
Now I have actually never used rasm before,
and never assembled ARM, so let me just quickly
show you how I figrued out how to use the
tool.
First I check the help page, I figure out
that -a can be used to Set architecture to
assemble or disassemble.
And which ones are available can be checked
with -L. So did that.
And now in here I found the arm.as.
So I tried rasm2, -a arm.as followed by the
assembly I want to assemble.
And an endless loop would just be a branch
0.
Branch is the arm equivalent of a JUMP in
x86.
And even though we often see absolute address
in disassemblers we use, actually these branch
and jump instructions are typically encoded
as offsets.
So because this code is theoretically at address
0, and we jump to address 0, it’s also just
a relative branch to the offset 0.
And thus it’s an endless loop.
However trying to assemble that will result
in an error, because it can’t find the arm
-as, assembler, binary.
But I remembered that it said it uses the
ARM_AS environment variable, so just as a
quick check to see how that affects things
I set it to asdasd, and then suddenly the
error said it can’t find the asdasd program.
Which means this environment variable has
to be set to the path of the arm assembler,
and that one comes with the arm cross compiler
utilities we downloaded some time ago.
So setting the path to this binary, now it
works.
Or almost, this is now clearly 4 bytes, so
32bit.
But we have thumb code which is 16bit, and
from the help we can find out how to set the
bit length as well.
So adding a -b16.
And voila.
So 0xfee7 appears to be the machine code for
a branch to itself, so an endless loop.
And now let’s copy that to our test script.
And of course we then complete the script
with the remaining APDU commands that are
used for whatever.
And then let’s try it !
But it doesn’t work.
However it looks like it already failed in
with the first command.
The ledger answers with this error code.
So let’s look in the code what could cause
this, and it appears that it checks this state
value.
Looking around where this state is changed
reveals, that we actually do have to send
the instruction VALIDATE_TARGET_ID.
So let’s include that as well and try again.
And of course this doesn’t work.
If you restart the device and attach GDB to
it, you will see it didn’t go into our endless
loop.
And when we examine now the ledger’s memory,
we see that the f00dbabe value is missing.
The As are there, but the magic value that
is necessary to boot, is not there.
So this is an indication that there is some
check happening.
There are multiple ways how you could figure
out what happens, I used a very pragmatic
approach.
I basically set a breakpoint at 0x080007f2,
to break on each new APDU command.
And I was not interested in the first ones,
but I was interested in the one that would
apparently write 0xf00dbabe.
And I just decided to slowly step through
the program to see what happens.
How does the f00dbabe dissappear?
We also know where our APDU buffer is and
we can see, that foodbabe definetly arrived
as a command.
So what happens?
Again I don’t want to bore you with unimportant
details, you can imagine yourself it just
takes time to step through the code and see
what happens.
There is no magic to it, it’s just tedious.
But at some point you reach here a code path
where it actually checks the current address
you try to write to.
So the selected segment and your offset.
In our case that would be 0x8003000.
And here in particular it actually does a
BRANCH NOT EQUAL, so a direct comparison between
R7 and R4.
With debugging you see that in our case both
are 0x8003000.
And if you check the code and just traced
what happend you see that R7 is just a constant
that came here from R3 and is the constant
0x8003000.
And R4 is the address we have selected with
APDU.
So here is just straight up a direct check
of this address.
And ONLY when it matches it will go into the
block here.
In any other cases it would skip it.
ANd in here we find two functions.
Let’s look at the first one.
By now you all should be experts in reverse
engineering and pretty quickly figure out
what it does.
At this point here I could also recommend
the Pwn Adventure playlist where we reverse
engineer code, there you get a bit more of
this kind of reversing.
Here you see a simple loop, and the major
code in that loop seems to load a value from
R1 into R4.
And then stores R4 into R0.
But in both cases with an offset R3 that is
incremented.
And one other hint is that this function has
TONS of cross references.
So this must be a super normal common function,
it’s nothing special.
And of course this is just a basic memcpy.
Copy from source to destination.
We can also with gdb see the address where
it does that.
And it copies data from one RAM address to
another.
Basically from our APDU incoming buffer into
another buffer.
And the function right after the memcpy is
similar but different.
Has the same kind of traits, it’s a loop
and called from many places.
But it only has a simple store in a loop.
And it writes always R1 at an address.
And R1 is set outside of this function to
0.
So this is a MEMSET with 0.
It is clearing, overwriting memory with 0.
And in fact it overwites 4 bytes with 0.
And checking with gdb what it actually overwrites,
we can see it destroys and overwrites the
0xfoodbabe value.
So here is the magical check.
If we try to write any value to address 0x8003000,
we will get into this block which will overwrite
it with 0.
We have no chance to write 0xf00dbabe there.
Now from the checks before you would also
see there are no other real special address
checks.
These just make sure you don’t write to
the bootloader area from 0x8000000 to 0x8003000.
But this also means you cant start writing
a lot of data before 8003000 and include f00dbabe
later.
So this is the only overwrite protection and
seems strong enough.
If we try to write to the f00dbabe address
it will get overwritten.
And we need it to run our own code.
One attack idea would be to analyse how a
VALID firmware would somehow get the 0xf00dbabe
value there.
I didn’t do this and you also know it’s
not necessary, But one of these other APDU
commands would probably trigger a cryptographic
check on the loaded new firmware, and if everything
is correct, it would set the f00dbabe value.
However this is where hardware knowledge and
experience with chips and embedded debices
comes into play.
And now I’m referring back to the original
f00dbabe disclosure where we looked into the
chip’s documentation.
There we learned about the memory map, and
that the ROM from 0x8000000 is also mapped
to 0x0000000.
And if you know that, and your brain has a
spark of creativity, you might come up with
the following attack idea.
What if we instead of writing f00dbabe to
that address we are not allowed to, but instead
write to 0x00003000.
Let’s do that change and try it again.
we can also set a breakpoint at the comparison
where it would ensure that we don’t overwrite
foodbabe and then look at it.
And so here we hit it and we see in the register
output, that now the segent we want to write
to is obviously NOT EQUAL, thus we skip this
block and go directly here.
The f00babe value is not overwritten.
Awesome.
So let’s restart the ledger and see if we
run into our endless loop!
We run it…
CTRL+C let’s see where we ended up in!?
Oh… uh… this is clearly an invalid address.
Fffff.
Something went really wrong… let’s do
it again and set a breakpoint where it would
decide to jump to the firmware code.
So all looks good.
The f00dbabe check is passed and…
OHHHH!
We try to jump to 0x4141414…
I completly forgot that this code here would
take the value right after f00dbabe as the
entry address for the firmware.
So let’s change that address to where we
have our code.
0x80030c1.
Rmember the 1 is to make sure it’s thumb
code.
Let’s try it again…
WAIT AGAIN!?
Invalid?
Urgh….
I see… endianess.
The bytes are all reversed.
So let’s fix thaat… do it again.
Aaaannnd not it seems to work.
Look we are here in our firmware code at 0x80030c0.
And we are trapped in this endless loop!
AWESOME!
We have successfully updated the Ledger without
an officially signed firmware.
Now we are basically done.
I’d like to remind you that this doesn’t
fully compromise the ledger and you can’t
extract the secret keys because they are stored
on the secure element.
In my opinion it is a vulnerability, because
we do bypass some security assumptions here.
But to be completly honest with you, The impact
of this is, as of creating this video, is
fairly small and attacks building on this
are pretty theoretical at this point.
So this definitely shouldn’t be seen as
ledger bashing.
And for me this was an awesome project.
I learned so much new things about embedded
hardware and how to reverse engineer firmware.
And I hope you did too.
﻿Hello everybody, let’s talk in this loopback
video about the recent events.
First we will talk about the new logo and
intro, then about reaching 10.000 subscribers,
that’s why we are doing a small Q&A. And
a little bit of an outlook into what’s coming
next.
<intro>
So that was the new intro. Some videos I have
edited before I created this, so don’t get
confused when you see the old one again.
But what do you think about the new intro
and logo? I know it’s not the green hacky
rabbit and console anymore, which I used to
appeal to these people who are drawn to these
misrepresentations of hackers and show them
the “correct” way, and also because I’m
a sucker for these hacker stereotypes. Hack
the planet!
But I think these new style of videos, with
the hand-drawn overlays, match this new intro
better. I think it’s more professional and
future proof.
Let me know what you think about it. Especially
constructive criticism.
The channel hit 10.000 subscribers recently,
which is amazing, because it’s such a niche
topic. But that shows to me, that there is
real demand for this kind of content. And
people appreciate it as valuable information.
Which makes me really proud.
So, now I’m going to answer questions I
got. I have to say, not many people sent me
questions which is a bit of a bummer, but
actually, I think this just shows that you
are more interested in technical content,
rather than the social youtuber interaction
personality thing, which is also why I don’t
show a face. I want this place to be about
learning new things about computers. Not me.
And now let me do a 180 on this opinion, and
answer some personal questions :D
Do you practice these things alot?
Most of what I do is practicing or learning
in a way. Especially playing CTFs you have
easy stuff you have done before and you get
faster, or new things to practice new tools
or techniques. One benefit of this channel
is, it forces me to not brush over topics
but make sure I understand them properly.
So creating these videos is very convenient
practice.
Do you make money with those skills?
I work as a freelance penetration tester,
or maybe betetr described as application security
analyst. I look at code and software, mostly
web, from customers and try to find vulnerabilities.
It’s a lot of fun, I’m very lucky I can
do this kind of work, and it allows me to
be very flexible. Especially because I still
have to finish my masters degree at university.
Do you have an or many Idol(s) (someone you
look up to for one or more reason(s))?
Everybody who is better than me in something.
So that’s a loooot of people :D
There are just so many who I admire for their
contribution to this field that I couldn’t
even start a list. There is no single idol
I follow, but more of an Ideal that I thrive
towards.
Would you consider yourself skillful, cognitively
gifted, or both?
I would say I’m not stupid. School was pretty
easy with a few exceptions like languages.
But I have seen a lot of peers understanding
certain things a lot faster a lot deeper than
me. And I benchmark myself against these people.
And you have to understand that I have spend
most of my life in front of these computers,
and I have days where I don’t leave the
apartment. And my friends are also not really
the types that constantly do stuff. So all
the skill I have, I have because I spend an
inconceivable amount of time doing this. And
I’m still no expert. I still fail the hard
complex challenges and I still haven’t created
an iOS or Browser exploit. I’m trying to
catch up but it’s hard. And so, knowing
how much time I have spent, and I have not
been able to compete with people at Pwn2own
or CTFs, shows me that I’m in no way gifted.
And there are many people who are much faster
than me.
What are some things you're currently trying
to "hack"?
Ehm, there are always work related projects
I can’t talk about. Or things that will
make it into a video, like the embedded hardware
CTF that is currently running.
When you get exhausted during a challenge,
what symptoms do you have and how do you mitigate
them?
I turn in a circle. I try the same things
over and over hoping it would magically work,
or that I have overseen something. That is
a time killer. I also start watching youtube
videos instead of working. The best thing
is to take a break, like a shower, or a quick
shopping trip.
do you (or did you at some point) play video
games?
Yeah I do play occasionally. Not much. For
a long time it used to be Guild Wars 2, did
some cool hacks with that, maybe it’s something
I can show off some time, but because it’s
still a very active game I feel a bit uncomfortable
disclosing it.
And currently I like to play Overwatch, because
I can play quick rounds when my brain needs
a break.
Have you found any zero day bugs yet? And
if so, how did you find it/them :D
I did find bugs you can consider 0day, but
they were nothing great. Nothing world breaking.
Not in any way comparable to cool remote memory
corruption bug in a popular sofawre. So I’m
still hunting for a cool one.
The ones I found were mostly web related and
found during work. So also something I can’t
talk about at this point. But believe me,
nothing exciting.
What are you using as your productive system?
I use a MacBook for most of my work. With
VMs as I need them. And also have a Windows
Desktop PC for editing or overwatch. As well
as multiple Laptops with Linux or whatever
on it. But mostly I work on mac.
So, now, what will come next. We are almost
done with exploit-exercises.com protostar.
That will be a great milestone for me. This
basically means I have now a whole series
that covers the basics of exploitation, and
which I believe is one of the better tutorials
on the topic on the internet.
I will push through this, with two videos
a week on friday and tuesday, which I have
done for a while now, but I can’t keep up
this pace for much longer. I spend too much
time on this, and while it’s fun, I can’t
neglect my real responsibilities too much.
So with christmas coming up, and finishing
protostar, I will start moving to a once a
week schedule. And hopefully the one or other
video in between.
But ignoring this huge disappointment, we
will slowly move into the modern age of exploitation
with ASLR, DEP and so forth.Also in february
the embedded hardware CTF will be over, so
you will get a bunch of low-level related
videos then.
Otherwise, I currently plan to make LiveOverflow
stickers, which if they turn out to be ok,
will bring
them to the 33c3 congress in december and
will distribute them on the well known tables
around the conference for people to grab.
Thank you all for your ongoing support, It
means a lot to me that people ask how to donate,
but the best thing you can give me, is to
comment and share the videos with more people
who might be interested in them.
Talk to you soon!
﻿Something funny happened to me.
I wanna tell you a story how I got a free
Burger when I ordered food.
And use it to explain what injection vulnerabilities
are.
So last night I was super lazy, didn’t wanna
cook so I ordered food.
I ordered food there before so certain fields
like the address were already filled out.
But also the comment field was still filled
out.
And on the previous order, in the comment
field I requested a different sauce for one
of the Burgers.
I didn’t realize that and just continued
and paid online.
A little bit later the delivery guy shows
up and told me that he changed the sauce for
the Country Burger as I had requested.
Country burger?
I didn’t order one?
He said: yeah, you did.
Look here on the receipt.
And I look at it and I realized what happened
the comment I wrote was printed just above
the other items that I actually ordered, I
used capital letters to emphasize my request
and I didn’t notice that it just made it
look like it is one of the ordered items.
And so he actually thought I ordered a Country
Burger and the comment after it was just my
modification request.
I mean looking at it now everybody would say
it’s pretty clear that it’s not an Item
I order.
There is no price on it and it’s not bold.
But this is a fast food restaurant and those
guys have a lot to do, it has to go fast and
maybe comments are also not a common thing.
I can totally see how it happened.
I offered to pay for the Burger, but he said
it’s fine.
So that’s how I got a free Burger through
an unintended Burger Injection or unintended
social engineering attack.
So what does this teach us about injection
vulnerabilities in software.
You see, programs are just acting on instructions
that they have been given.
Like a guy in a restaurant has instructions
he gets from the order that gets printed out.
And in this case data, or this comment, was
mixed together with business critical information.
And whoever created and printed out this order
didn’t make it clear to the entity that
processes this data, that this is just a comment,
not an order instruction.
The bill could have been structured differently
so that it is very clear.
And this is always what happens with injection
vulnerabilities.
Let’s take SQL injections.
A programmer writing code that builds an SQL
query and doesn’t make it clear that this
user data is just a string, by wrapping it
in quotes and making sure that no quotes can
appear in the data by escaping them, then
whatever processes the query can be fooled.
Or cross site scripting.
The programmer writes user data into a surrounding
HTML document without explicitly marking this
data to just be plaintext without special
characters.
Thus somebody can inject HTML tags like script
tags and perform a XSS attack.
And obviously there are many many cases in
security where the underlying security issue
is an injection.
Yes SQL injections and XSS have a very different
impact and are very different, but only at
the surface.
The underlying principle is exactly the same.
So whenever you place data into some other
structure that gets then handed to another
entity for further procesing, may this be
a webserver, a database server, a browser
or a fast food employee, you have to make
sure your data is clearly marked as what it
is.
Just data.
Not an instruction meant for that entity.
﻿So the public disclosure of dirtyc0w or CVE-2016-5195
just happened.
This vulnerability is ancient, and allows
a regular user on a system to perform a local
privilege escalation and become root.
I want to show it to you, explore how it works
and generally talk about it.
Let’s cut right to the chase and start by
looking at the provided proof-of-concept exploit.
I have here a vulnerable Ubuntu system where
I can downloa and compile the exploit.
Then I create a file owned by root to that
I as a normal user can’t write to.
I can read it, but not write.
This is true for many files on the file system
like for example the ping binary.
ping belongs to root and has the setuid bit
set.
This means anybody can execute it and it will
run as root, but ping doesn’t do much except
sending out some networking traffic.
So our root file we just created resembles
a file or binary like ping.
It’s owned by root and we can’t write
to it.
Now, when we execute dirtyc0w, and pass it
the root file and specify a string we want
to write, we can observe, that the string
got written to the file.
We, as a regular user of the system, have
written to a root file, that we don’t have
write access to.
This is insane.
Now imagine we would have written a backdoor
into the ping binary, we could become root
anytime.
Without knowing the password of root.
Now let’s try to understand the exploit
code.
Let’s check out main() first where the code
starts.
So first it opens the file we want to write
to as READ_ONLY.
Next comes a call to mmap().
Mmap is used to create a new mapped memory
segment in the current process.
One of these parameters can be a file descriptor
and in this case it’s the READ_ONLY file
owned by root.
This means it maps the file into a new memory
area.
Also the permission flags show, that this
new memory area is READ_ONLY.
So far so good.
The other important flag is the MAP_PRIVATE
flag.
The comment here is copied from the man page
of mmap and it states, that this creates a
private copy-on-write mapping.
Or short C.O.W, cow.
This is where one part of the name for this
vulnerability is from.
With this flag, mmap doesn’t copy the whole
content of the file into memory, mmap maps
the file into your memory.
This is awesome because you don’t need huge
amounts of RAM to load a copy of the file,
you just directly read from the file on disk.
Or relatively directly, we will learn more
about memory in a second
And copy-on-write means, that if you were
to write to this memory segment, you would
then create a copy of it.
So eventhough the file was mapped as READ_ONLY,
because of the private mapping we can write
to a copy of it.
So the important takeaway here is, that mmap
will map the root file directly into your
memory, and you can read the content of the
file, or write to a COPY of it.
The changes to your copy should not be propagated
to the real underlaying file.
It’s just for you
Next we start two threads that will run in
parallel.
Dirtyc0w is a race condition vulnerability,
this means certain events have to occur in
a specific order, that are fairly unlikely
to happen under normal circumstances.
So you try to race against the probability
of it not happenign.
And you simply try it over and over again.
And maybe you get lucky.
So let’s see what the two threads are doing.
The first thread is the madviseThread.
This thread uses the syscall madvise, which
probably doesn’t stand for memory advise,
but mad advise, I think the marketing department
failed here, naming this vulerability not
mad cow, am I right?
Ok. done with the dad jokes.
So this syscall can be used for optimization
reasons.
You can provide the kernel some information
on how you intend to use a memory mapped area,
because there are different techniques how
you handle caching, look ahead and so forth.
And the one advise we give the kernel is,
that the memory area where we mapped the file
to, or at least the first 100 byte, is probably
not needed anytime soon.
We say that with the MADV_DONTNEED flag, which
stands for:
Do not expect access in the near future.
(For the time being, the application is finished
with the given range, so the kernel can free
resources associated with it.)
Subsequent accesses of pages in this range
will succeed, but will result in reloading
of the memory contents from the underlying
mapped file.
The last sentence is key to the exploit.
Otherwise not much else happening here.
The other thread, procselfmemThread, opens
the file /proc/self/mem.
This is a special file and I try to explain
really quick.
So /proc is a so called pseudo filesystem.
In fact most resources on linux are managed
as “files”.
So you should always see “files” in quotation
marks when talking about them.
Imagine a file just to be something, you can
read from, or write to.
So this could be printer, and writing to the
printer “file” could result in an actual
physical printer printing the string on a
piece of paper.
So /proc does not really contain “files”
in the common sense.
They refer to something more general, most
importantly for our case, something you can
read and write to.
So in this case /proc/self refers to special
“files” provided for the current process.
So every process will have it’s own /proc/self.
And in there is a “file” called mem, which
is a representation of the current process’s
memory.
So you could theoretically read your own process’s
memory by reading from this file.
Now in this case, the exploit WRITES to this
file in a loop.
So first it performs a seek, which moves the
current cursors to the start of the file that
we mapped into memory.
And then it writes the string we pass via
the program arguments to it.
So this will trigger a copy of the memory,
so that we can write to it and see these changes.
But remember, we will not write to the real
underlaying file.
So if you would do these things once, or just
isolated from eachother, probably nothing
would happen.
Because that would be the expected result.
But because there is a race condition issue
somewhere, trying this over and over again
will create a weird edgecase, that usually
doesn’t occur, but in this case tricks the
kernel into actually writing to the underlaying
file.
Now let’s have a look at the patch, because
I think this is very interesting and not very
big.
So in the commit message the author states
that
This is an ancient bug that was actually attempted
to be fixed once (badly) by me eleven years
ago in commit 4ceb5db9757a ("Fix get_user_pages()
race for write access") but that was then
undone due to problems on s390 by commit f33ea7f404e5
("fix get_user_pages bug").
So I’m a little bit disappointed here at
my IBM friends, because they almost have a
partial guilt here.
S390 is the architecture used by IBM mainfraimes,
system z.
Anyhow, let’s have a quick look.
The file that is patched belongs to the linux
memory manager, hence the mm directory.
And the file itself is called GUP, which stands
for get_user_pages.
Vm stands for virtual memory and pte for page
table entry.
I think that should help a little bit to understand
the code.
So when you want to write to this mapped memory,
the kernel has to copy it, because you are
not allowed to write to the underlying file.
But a copy takes time.
Now usually you do the copy once and you are
fine, but in this case we call madvise with
DONTNEED over and over again.
Let’s look this up in the code.
So if this flag is used, this function is
executed.
The kernel source code explains that the:
Application no longer needs these pages.
If the pages are dirty, it's OK to just throw
them away.
The app will be more careful about data it
wants to keep.
Be sure to free swap resources too.
I guess I quickly explain dirty.
This is also where the other part of the name
is from.
When you read and write to disk you never
do this directly, that would be wayyy to slow.
So you cache, or buffer them.
This means you hold this data somewhere and
at some point in time you write it to the
disk.
Ok.
So if you read data from disk into memory
you can just leave it there in the cache for
further reads.
BUT, if you want to write to the disk, you
write it into this cache/buffer, but now you
have to tell the system, that this buffer
got touched and is dirty now.
It’s not clean fresh memory anymore.
In this case the system has to make sure that
the change is properly propagated to the underlaying
physical memory.
Let it be a file on disk or flash memory.
So in this case, if you wrote to the copied
mmaped memory, the memory page got flagged
dirty.
And because you tell the kernel now, that
the page is not needed anymore, this means
you don’t care that the dirty page has not
been written yet.
You just toss it.
So this madvise call causes the throwing away
of this memory.
This means it’s not in any of the memory
caches anymore.
This is important for this exploit, because
this means, everytime when we try to write
to it again, the copy of the memory might
have been tossed.
So we have to re load a new copy from memory
so we can write to it.
And creating this copy takes time.
And this is the race condition, if the copy-on-write
cycle is not complete yet.
The patch added this function that checks
if the copy-on-write is complete yet, and
only then allows writing to it.
To be honest, I don’t understand this code
really to tell you why this snippet makes
sure that the copy on write is complete.
But it added some additional checks, so I
assume now it’s fine.
So here is the mental picture of our race
condition.
We constantly use madvise to drop any cached
copy of the mapped file.
And at the same time we try to write to it,
which causes a copy of that memory.
Now in some rare condition, that can be hit
very reliably by just trying over and over
again, we perform the write to the memory,
before the page table is updated to point
us to our copied version.
And we write to the real file instead of the
copied memory.
So the crazy thing about this vulnerability
is, that it has been in the kernel for a very
long time.
And it was even a known issue, according to
the patch author, that had been attempted
to be patched before.
So over time this apparently theoretical race
condition got viable because our systems got
faster and faster.
And Petr Matousek also states, that this was
an 0day exploit used in the wild.
So there was a real threat.
Now a bit of controversy.
And this goes into the unresolved debate that
has been going on for decates how to do vulnerability
disclosure.
If you were the person who found this exploit
in the wild, what would you do?
The obvious arguments are:
Full disclosure, because it was actively exploited,
fully disclosing it right away would have
not given advanced attackers anything new.
But the knowledge would have allowed system
administrators to immediately patch their
systems.
But on the other hand it is such an easy and
widespread vulnerability, that a full disclosure
would have allowed armies of less skilled
hackers to take advantage of it, until less
professional sysadmins or private people could
patch it.
On the otherside we have the responsible disclosure
where you first contact the developers, create
a fix, try to roll it out and then tell people
afterwards.
The obvious arguments here are, you stopped
professional sysadmins for hotpatching their
system quickly and leave them exposed for
the ongoing attacks.
Now I don’t know what is the best way.
Both ways have advantages and disadvantages.
And it entirely depends on your threat model.
In general I lean slightly more towards full
disclosure, because I like information to
be free, though I myself do responsible disclosure
because I’m a hypocrite.
I hope you liked this kind of exploit walkthrough
video and that I could show you something
new and interesting.
If I said something wrong or you have additional
info on why this exploit has to be triggered
through a write to /proc/ mem and not directly
writing to the address, please correct me
or post additional info in the comments below,
so that other attentive viewers can benefit
from it.
Thanks.
﻿Hey,
You are probably watching this video because
you know that I create educational videos
about IT security, and you are thinking about
supporting this project.
For that already I want to say thank you.
But let me explain everything.
So the first problem is to decide between,
monthly, or a per video/per creation, support.
That’s why I decided to go with both.
On youtube you can find the Join button which
allows you to support me with a fixed monthly
amount - it’s roughly 5$.
On Patreon on the other hand you can pledge
money per video, but you also have the option
to set an upper LIMIT per month.
Both options have advantages and disadvantages
which I want to quickly explain.
With a monthly pledge you provide some income
stability.
Much more like a regular job.
With this I also hope I could receive ongoing
support if for example I get sick or just
need a break, or want to take more time for
a really good video.
On the other hand we have patreon with a per
video support.
Certain dollar amounts per video sound high
but you can intelligently use the monthly
limit to clearly communicate what you want.
For example.
You could pledge like 2$ per video, but set
a 10$ monthly limit, which means you like
to just see more videos, up to five a month.
That means less effort, but more output.
For example basic tutorial series.
But if you would pledge 10$ with a 10$ limit,
then you clearly tell me: “take your time,
I rather would have one single high quality
in-depth video per month”.
So this allows me to clearly justify how many
days of work should go into a particular video.
Up until now I think I have never skipped
a week for a video.
Not during any holidays, crazy work weeks,
vacations or when I got sick.
AND there were weeks with bonus videos.
So it’s understandable that you as a monthly
supporter might expect I deliver every week.
But.
I have dealt with this stress for a long time
now, and I actually would like to not feel
this stress anymore.
So keep in mind that a video every week is
not a guarantee.
However with a per video pledge I would only
receive money if I make videos, so then it’s
no problem.
And this leads me to expectations in general.
when somebody pledges 5$ per video, and then
I publish a video about a boring topic, or
I cut a CTF video write-up into multiple parts,
they might feel cheated out of 5$.
So… this is very important.
before you support me in any way, be it monthly,
or be it per video, I want to make it clear,
please don’t have any expectations.
I’m already extremely stressed out by trying
to balance what are essentially two full-time
jobs.
I really cannot add more stress in my life
by having possibly hundreds of people with
even more expectations.
So please only click on the Join button if
you think the LiveOverflow channel has retroactively
qualified for your support, by having released
hundreds of videos in the past.
And please go check them out, I think there
are a many great ones that so few people have
seen because they are older.
So… whatever you will decide, thanks for
even considering supporting LiveOverflow.
Oh and also, if you are a student or you don’t
have the means to spend a few dollars, that
is totally fine and that’s why I try to
keep videos free in the first place.
However if you are an overpaid security professional,
sysadmin or developer and my videos have helped
you in your job or career, you know… it
would be nice.
To summarize, sorry for the underwhelming
rewards structure.
What an amazing sales pitch, right!
Bit I just don’t want to promise anything
and then disappoint.
So let’s see how this goes, this is an experiment
for me and I’m sure things will evolve and
change over time.
﻿Anybody remember the riscure embedded hardware
CTF a long time ago? Rhme2? I have a whole
playlist covering various different challenges.
Two of them cover reverse engineering a binary
that would be running on the arduino board.
Which means their architecture is AVR. And
if you are not very familiar with reversing
embedded devices or AVR I would recommend
watching these videos before continuing here.
This video will be about another reversing
challenge, but explained by Zeta Two. I didn’t
solve that challenge, but he was really excited
of sharing this write-up with us. This video
was planned for a long time and because I
still don’t have a good process for working
with other people I screwed up the first time
we recorded this. So thank you for sitting
down with me a second time.
So I’m carl, or on the internet known as
zeta two and I play a lot of CTFs.
But before we fully head into the technical
parts I want to highlight something. I know
from the time when all of this stuff was new
to me, that reverse engineering and reading
all of this assembler code and figuring out
what it does, seemed so impossible. How can
anybody ever know and learn all of that. The
truth is, we don’t know all of it. It’s
a mix of knowledge, experience, gut feeling,
research and guessing and assumptions. The
over time all of these things get better,
more refined and you are able to understand
more and more complex systems. And so when
you listened to carl I want you to pay attention
to his language. Even when he is fairly certain
with something, he uses language like “it
looks like”, “it could be”, “maybe”,
“if we assume”. And that makes sense because
we are exploring an unknown target we have
to start somewhere and piece together the
puzzle. Early on you can make guesses like
“this is blue, could be the sky in the top
of the picture”, but maybe later you realize
it was actually part of a blue car. And so
I think a key takeaway here is how important
it is to always make assumptions, try to picture
the whole thing, but try to verify it somehow
and be always ready to accept that an assumption
was wrong. And that is probably the key to
success.
Anyway. Let’s head in.
FridgeJit, reverse engineering 400 points.
A senior technical manager of a fridge manufaturer
demanded the ability t update the firmware.
It turned out that the CPU that comes with
the fridges does not allow self-upgrading
the firmware, so the developers built a VM
for the fridge software.
A crafty customer has been able to reverse
engineer the software and programmed the fridge
with different software. His goal was to build
a digital safe.
Are you able to crack the password? We have
been able to extract the full firmware image
of a slightly different fridge and a memory
dump of their fridge. We hope this is enough.
And we get the challenge binary, which you
could flash onto the board, which is basically
the same as the firmware.bin and the memory.dmp.
As you can see rhme2 had this neat map for
the challenges. And here is FridgeJit.
This was one in a series of challenges about
reversing a virtual machine on the AVR.
You can see that the path connects to more
challenges. But let’s look at the first
one.
So carl will now retell how he reverse engineered
and solved this challenge. And obviously it
all starts with IDA.
The first start is to load this into IDA.
So I’m using my old IDA db, so I have already
named stuff but we’ll go through how you
can come up with these names and realize what
is what - like the reversing process.
So IDA is a reverse engineering tool that
helps you puzzle together the pieces. It helps
you by visualizing code flow and some other
stuff and you are able to add names for functions
and add comments. So These function names
were not there at the start. Carl gave that
name to those functions based on what they
do. And so he will now walk us through some
important functions and how you can figure
that out. But some other names referenced,
for example this memory location here called
io_UCSR0A is how IDA can help you.
One thing that's very convenient . That probably
is the absolute first thing you should do
when reversing some kind of embedded thing.
And I did this at some point but took me a
while, is to get the memory mapping of the
device. So that you can name memory areas
properly. So if you look at some datasheet
of the processor there will be a list of what
memory regions are mapped to what function,
different registers have special meanings.
What he describes here you can see in my AVR
reversing video in a bit more detail. But
essentially small CPUs like this atmega have
to interact with other hardware. For example
maybe it supports serial. And you know serial
is this high/low/high/low protocol at a certain
speed and you don’t have to program that
yourself in assembler. The chip has this as
a feature and al you have to do is to write
in assembler which symbol you want to transmit.
And a certain memory address is mapped to
this hardware feature. So when you write a
value to that address in assembler code, some
part of the chip, in the hardware, will receive
that value and then perform the proper low/high
serial communication. That’s what mapped
memory means. Very simple concept but very
powerful. And additionally the memory in general,
like the ROM or RAM are also mapped to certain
memory ranges. And you want to know where
is what in order to understand what is referenced
by addresses in the assembler code. And you
can find all of this information in the manual,
the documentation of the chip used.
And in IDA there is support for having configuration
files where you can define the processor and
you can tell it all the memory areas and what
their names are. For the atmega328, which
is the one used in the CTF, there isn’t
one in IDA, but I actually found a forum post
where somebody had created one like this and
I just copied it into my IDA AVR config file.
So this is a definition file for the atmega328
where you have names for all the different
registers.
And the point of this is, when you load the
binary into IDA you will have things named
from the start. If we go here you will have
some memory areas named in IDA, and this is
very nice, because then you can look for interesting
registers and look where they are used in
the code and you can start working your way
backwards from there.
For example one very basic thing that we want
to find out, is like how and where in the
code does it communicate. Like send and receive
data on the serial port.
So If you look in the manual you will see
that it uses this register to communicate
on the serial port, you can see where this
is used you will find a function. And this
means that this is a function responsible
for sending data on the serial port.
Wait, how do you know that it’s sending
data here exactly?
It basically tells, “I’m going to send
stuff” and then it loads data in this register
and then it gets send away on the serial.
So basically we are looking for a place where
something is writing to this register. And
also, conversely it receives data by reading
this register. So if we look where this register
is used we find exactly two places. So one
place it writes data into the register, and
one place it reads data from this register.
So basically we look at this function. It
first checks the status of this register.
And basically what it’s doing here it’s
checking that it’s clear to send data. That
it’s not busy. It just loops here until
it’s ready to send. And then it sends one
byte.
And the other way around, if we get the other
function, we have here. It loop until it’s
ready to receive and then it receives one
byte. And returns that. So it felt very natural
to name it io_receive and io_send.
And we can then see where this is used. And
it’s used in a number of places. For example
this function. Which I have named print_text.
So it is basically calling the io_send function
in a loop.
So what this function does is basically it
takes a pointer to some data and then it loops
over this data and sends one byte at a time.
And in the same fashion we have the receiving
end. There are functions using this to receive
data. So that’s nice and we will check deeper
on that track later I think. But for now we
can just go back to like where the program
starts. This is also a thing that you get
from loading the config. You get the interrupt
table, or what do you call it, so and the
reset one is basically the entry point for
the processor. So this is where everything
starts running. Where the program starts.
And this is basically like a standard thing
where it copies some static data in some location
and clears a memory region.
So up until here, carl sounds like he knows
exactly what he is doing. Like if he reads
this stuff every day. And yes, this is clearly
coming from experience how programs and chips
work and being able to read the documentation,
the manual of the chip and making sense of
it. But of course he doesn’t know everything.
It’s a puzzle, other parts of the picture
take more effort and time until he realises
it.
In the beginning I thought this is important,
but then I realized this is just a standard
set up thing. It’s like the start function
before the main function in a regular x86
program.
So he had an assumption at the beginning which
much later turned out to be wrong.
I mean I think I moved on but then I’ve
revisited it later. And I realized that what
it’s doing, It’s copying static data from
the ROM into the RAM. So I think here maybe.
Yeah. Basically the RAM is empty when you
start and then the program loads basically
global variables and constants and things
like that. So it’s a loop copying data from
the ROM into the RAM at a certain location.
And then there is this part which is just
zeroes out basically the rest of the RAM.
So this is just setting up the whole ram region.
And then you call a function. Which eventually
ends up. So this is more like the main function
where interesting things start to happen.
So now that we know where the main function
starts, Carl goes into the section here which
uses the very obvious print_text function.
It’s not far fetched to understand that
the loading instructions before the call,
load the data for the printing.
I mean if you look down here a little bit
and look at these addresses. So in the ROM
we have some string constants embedded. Basically
there are these strings related to laoding
a program into the machine. And there is something
here that looks like a debug menu. And something
here that looks like a table of registers.
So and here is FridgeJit Console. And so it
looks like all of this is related to like
debugging this thing.
Remember that the challenge description said
that the developers built a VM.
So this is some kind of Virtual Machine built
on top of AVR so we could then guess that
there is some debugging feature in the virtual
machine. Here you also have this interesting
thing with AVR. that it’s basically an 8bit
processor, but it has 16bit addressing, so
you load some addresses you load them one
byte at a time. So those are the two halves
of an address. Which is pointing to this string.
Before these were named, this region already
looks interesting. Because it has this repeating
pattern. Like load two bytes, call a function,
load two bytes, call a function. You can guess
that this is actually doing something that
is interesting, it’s also the same function.
Maybe it’s like setting up some data. Or
encryption or decryption. I mean I didn’t
know before. So first of all it loads into
r24 and r25 registers. And you have this other
peculiar thing with the AVR that you have
these regular numbered registers and you have
these meta registers X Y Z, which are 16bit
registers that consists of a pair of registers.
So basically if you look at this code you
can see that it takes this address stored
in the r24, r25 register, it loops over it
and calls the io_send function. So you can
name this function print_text. And then it’s
very natural to see what this partis doing.
It’s printing out a menu.
So it says that we should provide a boot rom
and then it prints out this prompt thing.
So a natural guess is that the next thing
that it’s going to do is, take input from
the user. right?
I think this is a good point to cut this episode.
We have used the atmega manual and an IDA
config to load the binary, identify important
registers that are used for communication
and traced the usage backwards, to functions
that clearly read or print data with it. And
then we also went the other way around and
started at the real START of the processor
and found the main function that is using
the print_text function from earlier.
So, see you next time.
﻿I thought it would be cool to tell you about
a typical day as a pen-tester.
Especially if you consider it as a career
I think you might appreciate the insight of
how this kind of job really looks like.
So welcome to my desk, I work from home.
And this is also where I edit my videos.
Usually I start by opening my laptop, login,
get pen and paper to take notes and then start.
Sometimes I really have to focus and think
of my next steps.
But then I usually get into the flow.
﻿in the previous videos of this series we have
setup everything.
We flashed the challenge “Secure Filesystem”
on to the board and figured out how to interact
with it over a serial connection.
We also learned about using pyserial to speak
with the embedded device via a python script.
This means we are ready to solve some challenges
So when you connect the board with this challenge
loaded on it, you can see the following output
on the serial console.
It shows a list of files.
And our goal is probably to read the passwd
file.
But let’s first read the challenge description.
Secure File System - We don't remember why,
but we wanted a file system on an AVR328p
(that’s the microcontroller on the arduino
board).
After the system was completed we discovered
that it lacked basic security.
A couple of beers later we came up with what
we think is a revolutionary way to do file
system permissions.
It is now your task to fill in our shoes and
test its security.
The filesystem allows you to request the contents
of one or more available files by using the
following
Format:
A token, followed by a hash and then at least
one filename, followed by multiple optional
filenames colon separated.
And there are multiple example requests to
read different files.
For example this one here would return the
content of cat.txt and finances.csv.
We already successfully did that in the previous
video.
So, while I’m pretty certain what the solution
will be, let’s have a look at the other
examples and approach it with an open mind.
Because maybe it’s not what I think it is.
The first thing we should notice is, that
the tokens look pretty random.
Especially when you compare different tokens
that all request cat.txt, but in combination
with another file, it will completly change.
This means it’s unlikely that data is encoded
in there.
Or that it follows a predictable pattern that
we could analyze statistically.
It’s very likely that it is a hash.
Like a password hash.
Easy to compute and verify, but really hard
to reverse.
From the length i suspect it to be a sha1
hash.
I didn’t record this, but at this moment
we could check if the filename, or the combination
of multiple filenames are simply hashed and
that becomes the token, but it turns out it’s
not.
And at this point I wanted to try out what
I suspected to be the solution.
Because if you see a token, that presumably
protects or authenticates some data, it might
be some kind of MAC, Message authentication
code.
A mac, or how it’s here called, a token,
can be used to prevent somebody else from
changing data.
And we don’t know how to generate a valid
token to request the passwd file.
But, a message authentication code can be
implemented in a weak way, and then you can
mess with it.
And I actually introduced this weakness in
a previous CTF video.
So let me play 
that clip.
<1.5 min clip>
In that video it was about an md5 hash, but
sha1 has the same issue.
If we assume that the embedded device has
a secret key, which is prepended to the requested
filenames, and then a hash calculated around
it, we should be able to attack this with
a length extension attack.
So let’s start to write our attack script
and use hashpump, the tool that I introduced
in the other video already to do that.
We import pyserial, setup the serial connection
with the USB to serial device.
Then we can attempt to read from it, write
one of the example tokens which should allow
us to read cat.txt.
And then read again to get that content.
But when we run it, it doesn’t work.
We read nothing.
I assume that we read data too fast and the
board is just too slow with sending.
So I write a little helper function called
read_until, which always reads data from the
serial connection, until the read data contains
the string we expect.
So now we can read until the prompt appears.
When we now test it, it will take a second
until the board sends us something, but we
are eventually able to read the content.
Then I install hashpump and the python module,
hashpumpy.
THis allows easy access to the hashpump utility
from a python script.
One problem with this is, that a hash length
extension attack has to know how long the
secret key is.
And we don’t know that.
But we can simply write a for loop, that just
tries out all different lengths.
And then we simply call the hashpump function.
We give it the hash we have, the data we know,
the data we want to append, in this case we
want to append the passwd file with colons.
Also we don’t know what is in pepper, so
we get that file as well.
At at last we need the key length.
Hashpump will return the updated hash and
the new message which contains the padding
and so forth.
We can also print the tested key lentgh with
that data so we can later see how long the
secret key was.
Then we send the new calculated updated token,
with the hash symbol, and the colon seperated
file request via serial to the board.
Then we should read until the next prompt
after each attempt, so we know the board is
ready to get our next request.
Now we let it run and watch.
And UH!
There it looked like we got something.
Let’s scroll back up.
Yeah and there it is.
The flag.
Let’s submit the flag and collect our first
100 points.
Awesome.
﻿Welcome to the second video in the AngularJS
sandbox bypass series.
In the previous video I have provioded a quick
overview of AngularJS.
Now we will dive right into AngularJS internals
by debugging why alert in an AngularJS expression
doesn’t work.
The research I’m showing off here was not
done by me.
I build upon the research done by other people.
Most notably mario and gareth.
I have not found an angularjs sandbox bypasses
myself, but I understand them now, so I want
to pass on this knowledge.
Now let’s execute the expression with the
alert by submitting this form.
The site loads, executes angularjs, the expression
gets evaluated and we hit our first breakpoint.
The first breakpoint is hit in a function
called getterfn.
That means Getter function.
You can see that in the call stack to the
right.
I have also added some comments here.
Getter fn is a function that creates a string
with some javascript code.
The variable with that code is called code.
And because we hit a breakpoint we are currently
in that context.
So we can access this variable code in the
console and look at what it contains.
You can also see that it somehow includes
the alert that we used in the expression.
It looks like this code checks if alert is
a property of s or k.
And tries get that property from s or k.
And right below the breakpoint you see a call
to the Function constructor.
The constructor is called with s and k, meaning
those are variables that should be known inside
of the function.
And third parameter is finally the javascript
code.
So this function constructor is fancy javascript
stuff.
That creates now a function with two parameters
s and k.
With the code that was created as a string.
And that function could then be actually called.
So that function contains some dynamically
generated javascript code trying to get the
property alert of s or k.
Let’s quickly make an example what getting
the property means in javascripot.
So here is a simple object a, with two properties
b and c.
You can now check that a has the property
b, but not the property f.
And you can access the propertie’s value
with .b or in brackets.
That’s the same.
Also the object a automatically has the function
to String.
So functions are also just properties on an
object.
Instead of getting a value like 1, you get
a function back.
And you can call it by adding the parantheses
for the function call.
Ok…
So this geterfn function in angulars creates
a new function which tries to get the property
alert from an object passed as parameters
s or k if executed.
Let’s see what happens when we continue
in the code.
The next breakpoint is hit and we are now
in a function with the name underscore functionCall.
This function prepares arguments for a function
to call.
Our expression attempts to calls the function
alert, so that makes sense.
Our first argument of our alert is the number
1..
So this function parses the parentheses with
the arguments and creates an array args with
all the parameters.
And args is now an array with only one element.
The number 1.
Below our breakpoint you can see a call to
a function called fn, with the scope as the
first parameter.
Thats the angular app scope we have talked
about earlier.
If that returns nothing, noop will be used
instead.
So what is fn.
Fn is a short function calling another function
getter.
When we click on getter we can see what getter
is.
Getter is set here as the result of getterFn.
And we know what getterFN does.
GetterFn creates a function that tries to
get the property alert of an object.
So getter is now that function.
And getter is basically fn.
And fn is called with the scope.
So all this fn calls tries to do is, to get
the property alert from the scope.
If that was sucessful, fnPtr, function pointer,
would contain a reference to the alert function
from the scoe.
But the alert function doesn’t exist in
the scope object, thus fnptr will be noop.
And noop is just an empty function doing nothing.
And this is why the alert(1) fails.
Because the scope has no function alert defined.
Okay now we understand angularjs expressions
better.
AngularJS evaluates those expressions.
It parses them and does some fancy javascript
foo.
So when you write an identifier like username
or in this case alert into an expression,
angularjs tries, in a fancy way, to get the
property alert from the scope object.
And then call this as a function.
So we know now, basically whatever we type
in an expression, it has to exist in the scope.
This is basically a javscript sandbox.
AngularJS expressions are kinda javascript
syntax, but are parsed and evaluated by angular
and you are only allowed to access variables
on functions from that scope object.
You are not allowed to access global functions
like alert.
Or the cookies.
Now we want to break out of this scope object
and try to access those dangerous global functions.
So here it comes.
How we can break out of the scope.
The scope object is like any other Javscript
object, it automatically has the property
constructor.
The constructor of the scope object gives
us the object constructor.
And the constructor of the object constructor
gives us the function constructor.
That’s like the highest constructor in Javascript.
The constructor of a Function constructor
is again the function constructor.
And we have just learned what the function
constructor can do, from getterFn.
We can create an arbitrary javascript function.
So for example we can create a function containing
the code alert(1).
The constructor created now a new javascript
function.
And then we can call this function by adding
parentheses and get an alert!
So because we can get the function constructor
from the scope by using constructor two times,
we should be able to create a function with
alert and execute it.
At least that seems works in the console.
Does that also work in an angularjs expression?
To put it into an angular expression we simply
have to remove the scope in the beginning,
because each expression gets already evaluated
against the scope.
So lets put it in there and try it.
So the first breakpoint is again in the getterFn
function.
And when we look at the dynamic code that
got generated this time we see it attempts
to get the constructor of s.
So that seems to work!
This means it will then later try to get the
property constructor of the scope, which obviously
does exist.
That looks good!
And if we just let the code run, we get the
alert!
Awesome!
In the next part of this series we will have
a look at a more advanced and more recent
bypass for angularjs version 1.4.7.
﻿“What is a security vulnerability?”.
I don’t think that there is an easy answer
to this question.
And so in this video I want to go over a examples,
and share my thoughts.
I’m really curious how you think about it,
because my actual job is to find and report
vulnerabilities, but I don’t really have
a clear definition.
For me it’s actually often just a “feeling”
or an intuition that I have when I determine
if something is a vulnerability or not.
And I hope you find these examples thought
provoking as well.
Let’s start with a CVE.
The Common Vulnerabilities and Exposures (CVE)
system provides a reference-method for publicly
known information-security vulnerabilities
and exposures.
So if something got a CVE assigned, it could
mean that we all agree that it’s a vulnerability.
But have a look at CVE-2018-17793.
This is labeled as a “virtualenv 16.0.0
- Sandbox Escape”, and doesnt make any sense.
virtualenv is a tool to create isolated Python
environments.
The basic problem being addressed is one of
dependencies and versions.
Imagine you have an application that needs
version 1 of LibFoo, but another application
requires version 2.
How can you use both these applications, If
you install everything into /usr/lib/python2.7/site-packages?
Also, what if you can’t install packages
into the global site-packages directory?
For instance, on a shared host.
In all these cases, virtualenv can help you.
It creates an environment that has its own
installation directories, that doesn’t share
libraries with other virtualenv environments.
So this just helps you developing python programs
and I use it ALL the time for the reasons
that were just mentioned.
However I can see that maybe somebody misunderstands
the purpose.
The name VIRTUAL environment, and it creates
an ISOLATED python environment could be misunderstood.
Also we use language like we “enter” the
virtual environment and we sometimes use shells
that indicate when a virtual environment is
active.
So It does sound like a typical virtualisation
technology, which we do use for security reasons.
For example using virtual machines to isolate
malware.
And a virtualbox escape is indeed a vulnerability.
You escalate priviledges from the virtual
machine to the host.
However here you should immediately understand
that this is not the same thing.
This “virtual python environment” in quotation
marks is just a way to structure python projects,
and maybe the language is slightly misleading
to an outsider but of course any code ran
here can do anything.
That’s why also the maintainers were so
frustrated with the report and why so many
people, including me, joked about it.
Just because it’s called virtual environment,
it doesn’t mean there is a virtual machine
with the goal of privilege separation.
So here we don’t have a vulnerability.
Let’s look at a second example.
I do quite a bit of ethereum smart contract
audits.
And in those audits, we of course, look for
typical security issues like reentrancy attacks,
logic bugs, and what ever.
So from the ICOs point of view, they want
to issue a token, sell the token for an initial
amount of money, ICO (initial coin offering)
to raise capital and use it to build something
with that raised money.
And the people buying those tokens hope that
whatever this company builds, will cause the
token later to rise in value.
So from the ICOs point of view they mostly
care about bugs that would allow others to
steal tokens or even to just manipulate their
token balance.
That of course would mean huge financial losses.
However just because this is the ICOs point
of view, and the ICO pays for the audit, this
is not my point of view.
Smart contracts are meant to be decentralized
contracts between different parties.
So to me the point of view of somebody investing
into that token is equally important.
So let’s do an example of a vulnerable that
I find thought provoking.
sometimes an ICO will advertise that a token
has a limited available amount.
A fixed total supply.
But then they might implement a function on
the contract that allows the owner of the
contract, so the ICO, to mint new tokens.
This means they can, at will, just raise the
number of available tokens.
But this contradicts what they promised.
They promised limited availability but actually
implement unlimited availability.
From the point of view of the ICO this is
not really a security vulnerability.
They are the owner, they are in control, why
would they care.
But from the point of view of an investor
who would like to buy these tokens, I think
this is a big issue.
This contract is now very unfair, but the
main issue is the contract contradicts promises
that were made.
So the issue could be titled “contract allows
to mint tokens despite claim of fixed supply”,
and that for me is a vulnerability.
Okay… third example.
A while ago a person wrote me that they found
a session account hijack or something.
I can’t find the original messages so I’m
just telling based on how I remember it going.
the person also included reproduction steps
in the message.
They were going like this:
First, Login to this site.
Then copy the cookie.
Now imagine you go to a different computer,
we use a different browser now.
So we login here with a different account.
You can see it here.
Now we intercept this request again but replace
the cookie from the first account.
BOOM we got access to the other account.
When people send me reports like this I don’t
even know what to say.
Like it’s like DoS attack on my brain because
I try so hard to understand if there is a
vulnerability.
Of course there is none, this just how cookies
work.
And just because you describe reproduction
steps that resulted into access to the other
account doesn’t mean this is a security
issue.
You just literally explained how session cookies
work.
Btw this is the kind of weird crap bugbounty
triage people have to read.
Because people who don’t really understand
it report stuff like that.
And now try to explain to them that this not
an issue.
Which of course I did.
Btw it was a regular PHP session id.
And the person still didn’t quite get it.
And they insisted this is a security issue,
a session or account hijacking.
They were arguing that this is just hex data.
So just 0-9 and a-f.
This is a lot less characters than a full
alphabet from a-z.
They were saying it could be bruteforced.
Of course it cannot be realistically bruteforced
it’s way too long, and thus this isn’t
a security issue but this opens up an interesting
discussions.
Because let’s say the session id is one
character shorter.
Do we now have a Secrutiy issue?
Let’s make it again shorter.
Now?
Now?
Now?
Well it think we can all agree that if the
session id only had two characters, which
means there would only be 256 possible values
for a session id, that this definetly would
be a security issue.
This could be easily bruteforced in a matter
of seconds and you could access the account.
So we have this spectrum here and somewhere
this example moves from being a vulnerability
to it not being a vulnerability.
And I’m sure we all would draw the line
somewhere else, especially in those grey areas
where you can argue with bruteforce speed
limitations and so forth.
Let’s look at a fourth example.
XSS.
So in cross site scripting issues you can
somehow place javascript into a website.
And that javascript can then just do anything
in that site.
So if your victim opens a site with your XSS
payload, the XSS can do anything like stealing
their session cookie.
So one kind of XSS is what we call reflective
XSS.
This happens when part of the URL is directly
echoed back into the content of the page.
Now some browser vendors came up with the
idea to implement a so called XSS auditor.
This is a best effort defense where the browser
tries to look at the URL and check if it contains
something that looks like a javascript XSS
injection and then see if it appears in the
document itself.
And then there are different strategies, the
browser could for example block the whole
page, or just try to block that specific script.
But this creates two challenges.
Because people quickly figured out you can
abuse that.
You could for example take a valid javascript
snippet from the document, place it into the
URL and the browser will think you injected
it.
But of course you didn’t but the browser
doesn’t know that.
So this is a false positive.
So over the years those XSS auditors got refined
but they just can’t be perfect.
Because the browser can only guess and bypasses
are found all the time.
Though in several cases it actually does stop
XSS attacks, which is arguably great for the
user.
However this caused a different problem.
Edge actually stopped and removed the XSS
auditor and just recently we saw another proposal
to also remove the Chrome XSS auditor.
And maybe you wonder why, but let’s read
what it says here.
XSSAuditor Retirement Plan Proposal
We haven't found any evidence the XSSAuditor
stops any XSS, and instead we have been experiencing
difficulty explaining to developers at scale,
why they should fix the bugs even when the
browser says the attack was stopped.
In the past 3 months we surveyed all (google)
internal XSS bugs that triggered the XSSAuditor
and were able to find bypasses to all of them.
[...] Furthermore, we've surveyed security
pentesters and found out some do not report
vulnerabilities unless they can find a bypass
of the XSSAuditor.
And when I retweetetd this one person even
commented.
I used to work for a security vendor.
We used to report XSS even if it got stopped
by the auditor.
A lot of clients got unreasonably angry about
us doing that, so we stopped.
The XSS auditor seems to be a nice first defense,
but it was never meant as a protection or
mitigation against XSS.
XSS is not an issue in the browser, the issue
is the webapp that doesn’t properly encode
output.
Triggering the XSS auditor means your site
is vulnerable to XSS.
Maybe the XSS auditor stops one attack, but
this doesn’t mean it can’t be bypassed
or your users use an old or different browser
without the XSS auditor.
And now it lead to a culture where clients
or the defensive-side in general, say, that
a XSS example that triggers the XSS auditor
is not a vulnerability because it got stopped.
So when people try to report vulnerabilities,
instead of spending there time on finding
more issues, they now have to spend time over
and over again trying to argue why it is still
a vulnerability, or waste time on trying to
bypass the auditor.
Even though the underlaying issue is the webapp
failing to properly encode output.
I always report XSS issues even when they
trigger the XSS auditor.
I don’t think it’s in the client’s best
interest, for me to waste time on trying to
bypass the browser.
My job is it to find vulnerabilities or vulnerability
patterns in the software of a client, so the
client can fix the actual issues.
That’s what they pay for.
I have actually a small related series to
a similar topic.
Checkout my AngularJS playlist where I analyse
a few angularjS sandbox bypasses.
Several people constantly had to find bypasses
to proof to clients that by simply updating
angularjs it doesn’t fix the underlying
issue.
And this was successful, in the end the sandbox
was removed, which allowed easier XSS without
a bypass, because the nice-to-have sandbox
was misused as a security mitigation.
The client should just fix the underlying
issue.
So this XSS example shows that even if it
might not be directly exploitable because
something stopped you, it doesn’t mean it’s
not a vulnerability.
And I have actually even one more example
that goes a step further.
So here is example five.
So there was once a mobile app which communicated
over SSL with the server, and SSL was properly
implemented in this case.
As you know, SSL protects against man in the
middle attacks.
So even if you somehow man in the middle the
network connection you cannot see, nor you
modify the messages exchanged between the
mobile app and the server.
We can call this an ecnrypted TLS tunnel.
Now the messages exchanged were actually encrypted
with AES in CBC mode with PKCS5 Padding.
And it turned out that the server was vulnerable
to a padding oracle attack, because there
were kinda verbose errors when you sent a
corrupted message to the server.
I don’t wanna explain how that attack works
here, but it can be used to recover the encrypted
data.
So if you could somehow get your hands on
an encrypted message sent from the app to
the server, then you could abuse the error
messages to perform a padding oracle attack
and extract the clear-text data.
Is that a vulnerability, that you can decrypt
encrytped data?
Well we had huge discussions about this because
all of that happened inside of a TLS tunnel.
so even if you were able to get a network
man-in-the-middle.
there was no way to actually get to the encrypted
message.
SSL or TLS prevents that.
Now think about that.
If there were no encrypted messages, just
SSL.
I would never report that “it uses SSL,
that protects against MITM, this is safe”).
Though I argue that because the client implemented
this second layer of encryption, they wanted
that additional layer of protection, and breaking
that layer through a padding oracle, is a
vulnerability.
So I report that
So… now we had five different examples that
all have something weird about them.
I hope they really help you to think about
what a vulnerability is and how hard it is
to define what that means.
I don’t think I have a clear definition
and if I would try to come up with one, I
would find exceptions and contradictions easily.
For me it’s actually mostly intuitive and
a “feeling”.
I think I know when something is a vulnerability
and I know when it’s not.
I would tell you that you should just read
vulnerability reports to also learn that,
but actually it’s not easy to build an intuition,
because you would need the intuition in the
first place to filter out the stupid reports.
And I think this is what we see happening.
Due to more and more unexperienced bug bounty
reports we get flooded with vulnerability
reports that are not vulnerabilities.
And sometimes they might even get a bounty,
because the receiving client might not be
able to realize that the report doesn’t
make sense.
And suddenly you normalise a certain type
of finding as it being a valid vulnerability
for a bug bounty.
And this creates this whole weird economic
around it.
When at some point a site or triage team rejects
those reports because they realise it’s
not actually an issue, then you have people
complain and point at previous payouts.
It’s really messy.
All advice I can give is to stay sceptical
about reports and when in doubt ask a few
trustworthy professionals about their opinion.
And hopefully over time you get the experience
you need.
Oh… and we haven’t even talked about severity
ratings yet.
But I don’t really care about that.
I have a hard time to determine if a vulnerability
is low, medium, high or critical in a certain
context, so I don’t think that calculating
a precise score like CVSS makes sense.
I understand why for business tracking reasons
the Common Vulnerability Scoring System exists,
but I don’t know.
I never used it and I feel like something
is forced to be ranked, that cannot realistically
be ranked.
Well… let me know how you feel about this.
And by the way, this is my view in late 2018,
and my opinions on something like this can
change, so keep that in mind before you angrily
explode.
And now let the hunger games begin.
﻿This post caught my attention.
A reddit user posted pictures of a mysterious
raspberry pi zero.
He wrote that his roommate found a bunch of
these hidden behind desks, vending machines
and trashcans in the college library.
Some people were speculating: a wifi dongle
attached and used to intercept internet traffic...
Looks like a pi he was using it as a rogue
access point to do a man-in-the-middle attack.
YEP. definitely
So I reached out to them and offered my help
to figure out what it does.
And to my surprise, they were interested and
we hopped onto a Skype call.
So in this video I want to tell you the process
of us analysing this raspberry pi zero and
how we figured out what it does.
Before I joined this fun, they already took
the SD card out of the raspberry pi and plugged
it into a PC.
This caused an F: drive to show up.
It’s called boot and contains some weird
files that can be really confusing.
they first thought it’s encrypted stuff,
But they quickly realized that maybe windows
is not the best operating system to look at
this.
Actually when you open the Windows Disk management
utility, you can see that the F drive is only
one partition on this whole removable disk.
And there are 3.6GB in another partition.
But Windows didn’t mount this.
Windows only automatically mounted, and made
the filesystem accessible for the first partition
called boot.
That filesystem was FAT32.
The File Allocation Table (FAT) is a computer
file system.
The FAT file system is a [...] , legacy file
system and proves to be simple and robust.
If you're a windows user you definitely have
seen FAT before.
It’s very simple and very old, so a lot
of systems support that.
And so it’s used for the boot partition
of the raspberry pi.
Also google is your best friend, if you are
confused by those files here, you can simply
pick one and google it.
You will immediately find this repository
with that file, and it looks exactly like
that partition.
And as you can see this is part of the official
raspberrypi firmware repository.
This repository contains pre-compiled binaries
of the current Raspberry Pi kernel and modules,
userspace libraries, and bootloader/GPU firmware.
Because we are looking here for whatever this
raspberry pi does, these files are mostly
uninteresting.
They are just part of the raspberry pi system
and we can ignore them.
However when you are very careful you might
notice that there is one weird file.
Waitz.txt.
And it contains the wifi and bluetooth mac
address.
We didn’t know what to make from it, just
keep that name in the back of your mind, it
will come up again.
So our goal was it to look at the second partition.
And the issue why Windows can’t mount it
is, because it’s very likely a typical linux
filesystem like ext4.
The ext4 or fourth extended filesystem is
a journaling file system for Linux, developed
as the successor to ext3.
And Windows just doesn’t have filesystem
drivers to understand that filesystem.
Those bits and bytes on there just don’t
make sense for Windows.
Because I was in a skype call with this guy,
we first tried to make this work on his windows
machine.
And we found and downloaded a program called
ext2fsd, hoping it would allow windows to
mount it, but it later said that it can’t
process ext4.
So that didn’t work.
Of course we were also thinking about different
options.
Either we try to create an image of the sd
card, and upload it so I can have a look at
it on a linux machine, or he could install
a linux virtual machine.
Before we install a full VM, we tried the
windows linux subsystem, where you get kinda
like a ubunut VM inside of windows and I thought
that could then just mount it.
Then we thought about using dd in linux to
create an image.
But nope.
The drives are not exposed and accessible
from in there…
This was all so frustrating… okay… so
I guess we have to download a tool for windows
to create an image of the sd card.
I did a quick google search for windows dd
alternatives and I found this image burner
tool.
Hoping it could just create a damn image from
the card.
And now something very embarrassing happened.
So… when downloading that tool we made sure
to use the site’s own mirror, so we don’t
get malware bundled software from these shady
mirrors, and when he installs it, this happened…
next next next.
Installed.
Then we execute it…
Search Manager added… uhmmmm…… ooooops...
this doesn’t look good….
Virus threat protection.
Doing a quick scan… and…
1 Threats found.
Cleaning that up… hopefully…
We are so dumb…
I’m such an idiot… later during editing
I actually noticed that we just cliked next
next next when the installer asked if we want
to install that crapware.
I feel so embarrassed.
I’m supposed to be a security professional
here, and I just made some computer science
student install some malware…
And even I fall for these shitty tools once
in a while out of frustration…
I’m so sorry that I did that to your laptop…
And it turns out this tool is crap and can’t
create an image from the disk… goddamit…
Then I had some other idea… maybe the git
bash comes with dd???
I remember that git for windows comes with
a nice bash terminal where you get a lot of
linux tools… so I made him install that
and to my surprise, it does list the drives
in /dev as sda, sdb and so forth…
And it also has dd… awesome!!
dd is a command-line utility for Unix and
Unix-like operating systems whose primary
purpose is to convert and copy files.
But here comes the cool things.
On Unix, device drivers for hardware (such
as hard disk drives) [...] appear in the file
system just like normal files; thus dd can
also read and/or write from/to these files.
As a result, dd can be used for tasks such
as backing up the boot sector of a hard drive.
I link an older video from me where I talk
a bit more about linux files as well.
But what this means is we can now use dd,
and then specify the correct device drive,
in our case sdc as in file… so sdc is the
whole drive, and sdc1 and sdc2 are the two
single partitions.
But let’s take an image of the whole card.
the input file, IF, is the sdc drive.
And as out file, OF, we can write a sd.img
file somewhere.
And then he uplaoded it for me and then I
downlaoded it.
All of that took a while because it’s a
full like 7GB image of the whole disk.
Anyway… so here I have it now on my linux.
The first thing I did was using fdisk.
For computer file systems, fdisk is a command-line
utility that provides disk partitioning functions.
As we know the SD card contains two partitions,
so fdisk can help us understand the raw bits
and bytes of that sd.image file to understand
the partitions.
And it finds two.
It also specifies at what exact sectors inside
of the sd.img this particular partition starts
and ends… a sector is simply a unit of 512
bytes. and now you can also understand why
you can’t easily move or insert partitions
in front of another, because they are at fixed
places in there on that disk.
At exactly this offset.
So now we are going to mount that second filesystem.
To do this we have to find the byte offset,
so we can take the sector offset from fdisk
times the sector size in bytes and this is
it.
Then we use the mount command to create a
loop device from this particular sd.image’s
byte offset…
A loop device is like a virtual or pseudo
device that doesn’t physically exist.
We could also write that partition onto a
real disk, like a usb stick and then plug
it in and mount it, or we use that loop feature.
And we tell the mount command to mount it
into the folder partition2.
So now it will take the sd.img file and understands
it as if it was a disk that was just plugged
in.
And ubuntu automatically noticed that a new
file system got mounted and opens the file
explorer of that device… see here, the device
now shows up as rootfs… the name of that
partition was root filesystem.
When we look at these folder, we can already
tell that this is a typical linux filesystem.
Here are well known folders like bin, dev,
etc, home, lib, media, mnt, opt and so forth…
We also can immediately see a tshark.txt file…
TShark is a network protocol analyzer like
wireshark, just as commandline tool… sooo…
were the people right?
Does this try to sniff and man-in-the-middle
WIFI connections?
Is this a malicious device?
So now we need to find out how it works.
This is actually just a bit of boring detective
work.
We have here a linux system and we have to
look for programs that could run here…
But like with the boot partition, here experience
really helps.
If you know how a typical linux filesystem
looks like, you can just ignore that stuff
and directly look for non-typical files.
And looking at locations where a developer
might have placed the programs that are executed
on here.
You could also directly look for scripts and
config files that determine what will be automatically
executed on start.
All this is just experience you acquire over
time if you work on linux.
So I start with the home folder.
When you login as a user, this is your default
folder, so maybe important or interesting
files are located there.
And we can then immediatly find a clean.sh
script.
That is definetly not a standard linux file.
And here we can see a systemctl call to stop
the waitz service.
You remember that name, right?
So there is a systemd service called waitz
running.
There are also other intersting paths here
which are definetly worth investigating too.
But before we moved on, we thought that waitz
is maybe the person’s nickname.
So we did a quick google search for things
like a potential github profile, but no luck.
Now that we know there is a service called
waitz, and waitz appears to be an important
string, we can search for files and folders
with that name…
And this reveals that there is a folder in
home/pi/hubCode/bin/com/waitz… and there
are java classes in here… so com.waitz.hub.scanning
blah are typical java paths.
This is a java program.
And look at those class names…
CommandListener, NetworkThread, Channel Hopper,
WifiData, WifiPacket, BluetoothPacket, BluetoothReader,
SHELL COMMAND THREAD?
Whow… okay…
At this point I was wondering if hubCode is
maybe a known tool that people use.
So we can google for names and snippets like
that, and search on github directly, but nothing
shows up.
So then the detective work continues.
Let’s look at some of these files here…
the state.txt turned out to be itnersting.
There is a wifiCmd specified with a tcpdump,
so a packet reading dump of the wlan1 interface…
there is also a flood 1 config and maybe some
bt, bluetooth settings… mhmhhm… really
suspicious.
here we also found the systemd waitz service
configuration file.
systemd will use this config file to automatically
start the service described in here… the
name is Waitz MQTT Service…
huh??
I know MQTT, it’s a machine-to-machine connectivity
protocol.
It was designed as an extremely lightweight
publish/subscribe messaging transport.
It is useful for connections with remote locations.
For example, it has been used in sensors communicating
[...] and in a range of home automation and
small device scenarios..
It kinda would make sense because the person
said that there were multiple raspberry pies
scattered around the library, hidden in various
places.
And so maybe MQTT is used to create a distributed
network of wifi and bluetooth things… for
whatever purpose?!
Well..
We can also learn from the systemd service
config here, that the following script is
executed on start.
Service.sh…
And in there are a few interesting comments…
get device information, download bundle.
Unzipping bundle… blah… looks like an
update mechanism…
And then when that is done it will call the
hubCode scripts, start.sh.
And look at that one… this prints “starting
waitz service script”.
It will make sure the system has tshark installed.
Then it will call tshark on the wlan1 interface.
And it also seems to get some broker credentials…
broker is a term from MQTT, so this again
reinforces that MQTT is infact used here.
And then later the java application is executed…
the waitz.hub.production program and it even
sets include path for a mqtt library… so
yep okay, there is some mqtt communication
going on.
We can also have a look at the getcreds python
script, because credentials are always cool.
And it will use this amazon API to get them.
But to do so you need to know those parameters
sent along that request.
And in the gen_token module we should be able
to find those parameters.
And that module will actually execute a shell
script called fingerprint.sh and take the
output as a secret, and then calculate like
a secret token… crc32 of the secret + the
current time…
Okay… my code audit inner-self is screaming
loud right now.
Because I see what they try to do here.
But they use crc32 with a secret concatenated
to the time t.
My chest hurts…
They actually want to use HMAC instead…
but in the end it doesn’t matter too much,
because while the fingerprint is like a unique
hardware ID based on the bluetooth mac, the
wifi mac and the pi serial number, this is
not perfect.
Anybody with access to such a raspberry pi
can easily extract or possibly even guess
those values, because none of these are really
random.
So becasue anybody with physical access can
always extract those tokens, I suggest to
just use preshared secret unique to each device,
like an API token.
It can be compromised but you can then also
revoke access for that particular api token.
This little bit of obfuscation here is useless
for anybody who actually wants to do harm
and figure out the secret… it just takes
like 1minute longer to get it, but adds unecessary
development complexity…
You actually can’t do this better with a
raspberry pi.
It’s not a secure hardware device.
Anyway… we were going basically slowly through
all scripts and codes… at some point even
used JD-gui to look at the java classes to
understand what they are doing.
I mean at this point it’s just like reading
code of any programming project.
It’s just like a code audit or getting familiar
with a new project.
You just have to know how to read code and
how software projects might be structured
and deployed.
Our main goal was to determine if this is
a malicious actor who wanted to attack or
sniff wifi of students in the library, or
if this is a harmless school project…
So we spent maybe 1 or 2 hours on looking
around, reading those files and slowly assemble
the mysterious puzzles of “what this is”.
So fast forward a bit.
We slowly realized that it doesn’t do much.
It does not collect any packet data or trying
to sniff passwords or whatever.
Actually it just logs MAC addresses that it
finds from bluetooth and wifi devices in the
area…
This is to 99% just to track people…
This is a very typical application.
Probably every public place you go has stuff
like that.
Probably most shopping malls or airports do
that… it helps to autoamtically record how
busy areas are and how people are moving through
a building.
This is very valuable data for businesses…
they don’t care about the individual person,
it’s just to understand the flow of people.
So this is probably doing a similar thing...
One other thing we did was, We knew the raspberry
pi zero has bluetooth and the wifi dongle
is actually dual band and offers two wifi
interfaces.
So if it is monitoring bluetooth and wifi
in the area, it probably would use the second
wifi to connect to the school’s wifi to
use MQTT and send away the data.
So we thought it would be interesting to find
the username and password they are using to
connect to the wifi.
So I can easily search for that in files on
the raspberry pi. he told me the name of the
school and the name of the school’s wifi.
He is from UCSD… and like I often do, I
google stuff… and for whatever reason I
decided to google “waitz ucsd”,l to see
if there is any connection… and this reddit
thread pops up…
UCSD - the name of the school - Waitz.
Did they stop supporting the app?
Now listen to this beautiful reaction.
Oh wowowowo… what?!
And we find this website…
Is this it?!
What does Waitz do??
Waitz reports the real-time "busyness" for
locations around campus.
How does waitz work?
Waitz gathers our data through small hardware
devices.
These devices pick up smartphone signals in
the area around them.
We then normalize these signals to reach a
"busyness" measurement.
Don't waste time
Know before you go
So this was just part of a network to give
students indication how busy certain areas
at the school are… actually that’s a really
cool and useful project… but Oh man…
Oh my god!
Hahahahah… you found it…
I guess I contact them and and say I found
one of their cthings…
And you know what makes the whole story even
more beautiful?
There was actually a comment 9h before we
figured it out, on the original thread on
reddit.
Please return this to the Library, this is
the property of Waitz, it isn’t nefarious,
it is extremely basic and giving you an idea
of how many people are in the library.
Waitz was started by a recent graduate who
did this as a project while enrolled at the
university.
This was so much fun...
﻿This post caught my attention.
A reddit user posted pictures of a mysterious
raspberry pi zero.
He wrote that his roommate found a bunch of
these hidden behind desks, vending machines
and trashcans in the college library.
Some people were speculating: a wifi dongle
attached and used to intercept internet traffic...
Looks like a pi he was using it as a rogue
access point to do a man-in-the-middle attack.
YEP. definitely
So I reached out to them and offered my help
to figure out what it does.
And to my surprise, they were interested and
we hopped onto a Skype call.
So in this video I want to tell you the process
of us analysing this raspberry pi zero and
how we figured out what it does.
Before I joined this fun, they already took
the SD card out of the raspberry pi and plugged
it into a PC.
This caused an F: drive to show up.
It’s called boot and contains some weird
files that can be really confusing.
they first thought it’s encrypted stuff,
But they quickly realized that maybe windows
is not the best operating system to look at
this.
Actually when you open the Windows Disk management
utility, you can see that the F drive is only
one partition on this whole removable disk.
And there are 3.6GB in another partition.
But Windows didn’t mount this.
Windows only automatically mounted, and made
the filesystem accessible for the first partition
called boot.
That filesystem was FAT32.
The File Allocation Table (FAT) is a computer
file system.
The FAT file system is a [...] , legacy file
system and proves to be simple and robust.
If you're a windows user you definitely have
seen FAT before.
It’s very simple and very old, so a lot
of systems support that.
And so it’s used for the boot partition
of the raspberry pi.
Also google is your best friend, if you are
confused by those files here, you can simply
pick one and google it.
You will immediately find this repository
with that file, and it looks exactly like
that partition.
And as you can see this is part of the official
raspberrypi firmware repository.
This repository contains pre-compiled binaries
of the current Raspberry Pi kernel and modules,
userspace libraries, and bootloader/GPU firmware.
Because we are looking here for whatever this
raspberry pi does, these files are mostly
uninteresting.
They are just part of the raspberry pi system
and we can ignore them.
However when you are very careful you might
notice that there is one weird file.
Waitz.txt.
And it contains the wifi and bluetooth mac
address.
We didn’t know what to make from it, just
keep that name in the back of your mind, it
will come up again.
So our goal was it to look at the second partition.
And the issue why Windows can’t mount it
is, because it’s very likely a typical linux
filesystem like ext4.
The ext4 or fourth extended filesystem is
a journaling file system for Linux, developed
as the successor to ext3.
And Windows just doesn’t have filesystem
drivers to understand that filesystem.
Those bits and bytes on there just don’t
make sense for Windows.
Because I was in a skype call with this guy,
we first tried to make this work on his windows
machine.
And we found and downloaded a program called
ext2fsd, hoping it would allow windows to
mount it, but it later said that it can’t
process ext4.
So that didn’t work.
Of course we were also thinking about different
options.
Either we try to create an image of the sd
card, and upload it so I can have a look at
it on a linux machine, or he could install
a linux virtual machine.
Before we install a full VM, we tried the
windows linux subsystem, where you get kinda
like a ubunut VM inside of windows and I thought
that could then just mount it.
Then we thought about using dd in linux to
create an image.
But nope.
The drives are not exposed and accessible
from in there…
This was all so frustrating… okay… so
I guess we have to download a tool for windows
to create an image of the sd card.
I did a quick google search for windows dd
alternatives and I found this image burner
tool.
Hoping it could just create a damn image from
the card.
And now something very embarrassing happened.
So… when downloading that tool we made sure
to use the site’s own mirror, so we don’t
get malware bundled software from these shady
mirrors, and when he installs it, this happened…
next next next.
Installed.
Then we execute it…
Search Manager added… uhmmmm…… ooooops...
this doesn’t look good….
Virus threat protection.
Doing a quick scan… and…
1 Threats found.
Cleaning that up… hopefully…
We are so dumb…
I’m such an idiot… later during editing
I actually noticed that we just cliked next
next next when the installer asked if we want
to install that crapware.
I feel so embarrassed.
I’m supposed to be a security professional
here, and I just made some computer science
student install some malware…
And even I fall for these shitty tools once
in a while out of frustration…
I’m so sorry that I did that to your laptop…
And it turns out this tool is crap and can’t
create an image from the disk… goddamit…
Then I had some other idea… maybe the git
bash comes with dd???
I remember that git for windows comes with
a nice bash terminal where you get a lot of
linux tools… so I made him install that
and to my surprise, it does list the drives
in /dev as sda, sdb and so forth…
And it also has dd… awesome!!
dd is a command-line utility for Unix and
Unix-like operating systems whose primary
purpose is to convert and copy files.
But here comes the cool things.
On Unix, device drivers for hardware (such
as hard disk drives) [...] appear in the file
system just like normal files; thus dd can
also read and/or write from/to these files.
As a result, dd can be used for tasks such
as backing up the boot sector of a hard drive.
I link an older video from me where I talk
a bit more about linux files as well.
But what this means is we can now use dd,
and then specify the correct device drive,
in our case sdc as in file… so sdc is the
whole drive, and sdc1 and sdc2 are the two
single partitions.
But let’s take an image of the whole card.
the input file, IF, is the sdc drive.
And as out file, OF, we can write a sd.img
file somewhere.
And then he uplaoded it for me and then I
downlaoded it.
All of that took a while because it’s a
full like 7GB image of the whole disk.
Anyway… so here I have it now on my linux.
The first thing I did was using fdisk.
For computer file systems, fdisk is a command-line
utility that provides disk partitioning functions.
As we know the SD card contains two partitions,
so fdisk can help us understand the raw bits
and bytes of that sd.image file to understand
the partitions.
And it finds two.
It also specifies at what exact sectors inside
of the sd.img this particular partition starts
and ends… a sector is simply a unit of 512
bytes. and now you can also understand why
you can’t easily move or insert partitions
in front of another, because they are at fixed
places in there on that disk.
At exactly this offset.
So now we are going to mount that second filesystem.
To do this we have to find the byte offset,
so we can take the sector offset from fdisk
times the sector size in bytes and this is
it.
Then we use the mount command to create a
loop device from this particular sd.image’s
byte offset…
A loop device is like a virtual or pseudo
device that doesn’t physically exist.
We could also write that partition onto a
real disk, like a usb stick and then plug
it in and mount it, or we use that loop feature.
And we tell the mount command to mount it
into the folder partition2.
So now it will take the sd.img file and understands
it as if it was a disk that was just plugged
in.
And ubuntu automatically noticed that a new
file system got mounted and opens the file
explorer of that device… see here, the device
now shows up as rootfs… the name of that
partition was root filesystem.
When we look at these folder, we can already
tell that this is a typical linux filesystem.
Here are well known folders like bin, dev,
etc, home, lib, media, mnt, opt and so forth…
We also can immediately see a tshark.txt file…
TShark is a network protocol analyzer like
wireshark, just as commandline tool… sooo…
were the people right?
Does this try to sniff and man-in-the-middle
WIFI connections?
Is this a malicious device?
So now we need to find out how it works.
This is actually just a bit of boring detective
work.
We have here a linux system and we have to
look for programs that could run here…
But like with the boot partition, here experience
really helps.
If you know how a typical linux filesystem
looks like, you can just ignore that stuff
and directly look for non-typical files.
And looking at locations where a developer
might have placed the programs that are executed
on here.
You could also directly look for scripts and
config files that determine what will be automatically
executed on start.
All this is just experience you acquire over
time if you work on linux.
So I start with the home folder.
When you login as a user, this is your default
folder, so maybe important or interesting
files are located there.
And we can then immediatly find a clean.sh
script.
That is definetly not a standard linux file.
And here we can see a systemctl call to stop
the waitz service.
You remember that name, right?
So there is a systemd service called waitz
running.
There are also other intersting paths here
which are definetly worth investigating too.
But before we moved on, we thought that waitz
is maybe the person’s nickname.
So we did a quick google search for things
like a potential github profile, but no luck.
Now that we know there is a service called
waitz, and waitz appears to be an important
string, we can search for files and folders
with that name…
And this reveals that there is a folder in
home/pi/hubCode/bin/com/waitz… and there
are java classes in here… so com.waitz.hub.scanning
blah are typical java paths.
This is a java program.
And look at those class names…
CommandListener, NetworkThread, Channel Hopper,
WifiData, WifiPacket, BluetoothPacket, BluetoothReader,
SHELL COMMAND THREAD?
Whow… okay…
At this point I was wondering if hubCode is
maybe a known tool that people use.
So we can google for names and snippets like
that, and search on github directly, but nothing
shows up.
So then the detective work continues.
Let’s look at some of these files here…
the state.txt turned out to be itnersting.
There is a wifiCmd specified with a tcpdump,
so a packet reading dump of the wlan1 interface…
there is also a flood 1 config and maybe some
bt, bluetooth settings… mhmhhm… really
suspicious.
here we also found the systemd waitz service
configuration file.
systemd will use this config file to automatically
start the service described in here… the
name is Waitz MQTT Service…
huh??
I know MQTT, it’s a machine-to-machine connectivity
protocol.
It was designed as an extremely lightweight
publish/subscribe messaging transport.
It is useful for connections with remote locations.
For example, it has been used in sensors communicating
[...] and in a range of home automation and
small device scenarios..
It kinda would make sense because the person
said that there were multiple raspberry pies
scattered around the library, hidden in various
places.
And so maybe MQTT is used to create a distributed
network of wifi and bluetooth things… for
whatever purpose?!
Well..
We can also learn from the systemd service
config here, that the following script is
executed on start.
Service.sh…
And in there are a few interesting comments…
get device information, download bundle.
Unzipping bundle… blah… looks like an
update mechanism…
And then when that is done it will call the
hubCode scripts, start.sh.
And look at that one… this prints “starting
waitz service script”.
It will make sure the system has tshark installed.
Then it will call tshark on the wlan1 interface.
And it also seems to get some broker credentials…
broker is a term from MQTT, so this again
reinforces that MQTT is infact used here.
And then later the java application is executed…
the waitz.hub.production program and it even
sets include path for a mqtt library… so
yep okay, there is some mqtt communication
going on.
We can also have a look at the getcreds python
script, because credentials are always cool.
And it will use this amazon API to get them.
But to do so you need to know those parameters
sent along that request.
And in the gen_token module we should be able
to find those parameters.
And that module will actually execute a shell
script called fingerprint.sh and take the
output as a secret, and then calculate like
a secret token… crc32 of the secret + the
current time…
Okay… my code audit inner-self is screaming
loud right now.
Because I see what they try to do here.
But they use crc32 with a secret concatenated
to the time t.
My chest hurts…
They actually want to use HMAC instead…
but in the end it doesn’t matter too much,
because while the fingerprint is like a unique
hardware ID based on the bluetooth mac, the
wifi mac and the pi serial number, this is
not perfect.
Anybody with access to such a raspberry pi
can easily extract or possibly even guess
those values, because none of these are really
random.
So becasue anybody with physical access can
always extract those tokens, I suggest to
just use preshared secret unique to each device,
like an API token.
It can be compromised but you can then also
revoke access for that particular api token.
This little bit of obfuscation here is useless
for anybody who actually wants to do harm
and figure out the secret… it just takes
like 1minute longer to get it, but adds unecessary
development complexity…
You actually can’t do this better with a
raspberry pi.
It’s not a secure hardware device.
Anyway… we were going basically slowly through
all scripts and codes… at some point even
used JD-gui to look at the java classes to
understand what they are doing.
I mean at this point it’s just like reading
code of any programming project.
It’s just like a code audit or getting familiar
with a new project.
You just have to know how to read code and
how software projects might be structured
and deployed.
Our main goal was to determine if this is
a malicious actor who wanted to attack or
sniff wifi of students in the library, or
if this is a harmless school project…
So we spent maybe 1 or 2 hours on looking
around, reading those files and slowly assemble
the mysterious puzzles of “what this is”.
So fast forward a bit.
We slowly realized that it doesn’t do much.
It does not collect any packet data or trying
to sniff passwords or whatever.
Actually it just logs MAC addresses that it
finds from bluetooth and wifi devices in the
area…
This is to 99% just to track people…
This is a very typical application.
Probably every public place you go has stuff
like that.
Probably most shopping malls or airports do
that… it helps to autoamtically record how
busy areas are and how people are moving through
a building.
This is very valuable data for businesses…
they don’t care about the individual person,
it’s just to understand the flow of people.
So this is probably doing a similar thing...
One other thing we did was, We knew the raspberry
pi zero has bluetooth and the wifi dongle
is actually dual band and offers two wifi
interfaces.
So if it is monitoring bluetooth and wifi
in the area, it probably would use the second
wifi to connect to the school’s wifi to
use MQTT and send away the data.
So we thought it would be interesting to find
the username and password they are using to
connect to the wifi.
So I can easily search for that in files on
the raspberry pi. he told me the name of the
school and the name of the school’s wifi.
He is from UCSD… and like I often do, I
google stuff… and for whatever reason I
decided to google “waitz ucsd”,l to see
if there is any connection… and this reddit
thread pops up…
UCSD - the name of the school - Waitz.
Did they stop supporting the app?
Now listen to this beautiful reaction.
Oh wowowowo… what?!
And we find this website…
Is this it?!
What does Waitz do??
Waitz reports the real-time "busyness" for
locations around campus.
How does waitz work?
Waitz gathers our data through small hardware
devices.
These devices pick up smartphone signals in
the area around them.
We then normalize these signals to reach a
"busyness" measurement.
Don't waste time
Know before you go
So this was just part of a network to give
students indication how busy certain areas
at the school are… actually that’s a really
cool and useful project… but Oh man…
Oh my god!
Hahahahah… you found it…
I guess I contact them and and say I found
one of their cthings…
And you know what makes the whole story even
more beautiful?
There was actually a comment 9h before we
figured it out, on the original thread on
reddit.
Please return this to the Library, this is
the property of Waitz, it isn’t nefarious,
it is extremely basic and giving you an idea
of how many people are in the library.
Waitz was started by a recent graduate who
did this as a project while enrolled at the
university.
This was so much fun...
﻿This post caught my attention.
A reddit user posted pictures of a mysterious
raspberry pi zero.
He wrote that his roommate found a bunch of
these hidden behind desks, vending machines
and trashcans in the college library.
Some people were speculating: a wifi dongle
attached and used to intercept internet traffic...
Looks like a pi he was using it as a rogue
access point to do a man-in-the-middle attack.
YEP. definitely
So I reached out to them and offered my help
to figure out what it does.
And to my surprise, they were interested and
we hopped onto a Skype call.
So in this video I want to tell you the process
of us analysing this raspberry pi zero and
how we figured out what it does.
Before I joined this fun, they already took
the SD card out of the raspberry pi and plugged
it into a PC.
This caused an F: drive to show up.
It’s called boot and contains some weird
files that can be really confusing.
they first thought it’s encrypted stuff,
But they quickly realized that maybe windows
is not the best operating system to look at
this.
Actually when you open the Windows Disk management
utility, you can see that the F drive is only
one partition on this whole removable disk.
And there are 3.6GB in another partition.
But Windows didn’t mount this.
Windows only automatically mounted, and made
the filesystem accessible for the first partition
called boot.
That filesystem was FAT32.
The File Allocation Table (FAT) is a computer
file system.
The FAT file system is a [...] , legacy file
system and proves to be simple and robust.
If you're a windows user you definitely have
seen FAT before.
It’s very simple and very old, so a lot
of systems support that.
And so it’s used for the boot partition
of the raspberry pi.
Also google is your best friend, if you are
confused by those files here, you can simply
pick one and google it.
You will immediately find this repository
with that file, and it looks exactly like
that partition.
And as you can see this is part of the official
raspberrypi firmware repository.
This repository contains pre-compiled binaries
of the current Raspberry Pi kernel and modules,
userspace libraries, and bootloader/GPU firmware.
Because we are looking here for whatever this
raspberry pi does, these files are mostly
uninteresting.
They are just part of the raspberry pi system
and we can ignore them.
However when you are very careful you might
notice that there is one weird file.
Waitz.txt.
And it contains the wifi and bluetooth mac
address.
We didn’t know what to make from it, just
keep that name in the back of your mind, it
will come up again.
So our goal was it to look at the second partition.
And the issue why Windows can’t mount it
is, because it’s very likely a typical linux
filesystem like ext4.
The ext4 or fourth extended filesystem is
a journaling file system for Linux, developed
as the successor to ext3.
And Windows just doesn’t have filesystem
drivers to understand that filesystem.
Those bits and bytes on there just don’t
make sense for Windows.
Because I was in a skype call with this guy,
we first tried to make this work on his windows
machine.
And we found and downloaded a program called
ext2fsd, hoping it would allow windows to
mount it, but it later said that it can’t
process ext4.
So that didn’t work.
Of course we were also thinking about different
options.
Either we try to create an image of the sd
card, and upload it so I can have a look at
it on a linux machine, or he could install
a linux virtual machine.
Before we install a full VM, we tried the
windows linux subsystem, where you get kinda
like a ubunut VM inside of windows and I thought
that could then just mount it.
Then we thought about using dd in linux to
create an image.
But nope.
The drives are not exposed and accessible
from in there…
This was all so frustrating… okay… so
I guess we have to download a tool for windows
to create an image of the sd card.
I did a quick google search for windows dd
alternatives and I found this image burner
tool.
Hoping it could just create a damn image from
the card.
And now something very embarrassing happened.
So… when downloading that tool we made sure
to use the site’s own mirror, so we don’t
get malware bundled software from these shady
mirrors, and when he installs it, this happened…
next next next.
Installed.
Then we execute it…
Search Manager added… uhmmmm…… ooooops...
this doesn’t look good….
Virus threat protection.
Doing a quick scan… and…
1 Threats found.
Cleaning that up… hopefully…
We are so dumb…
I’m such an idiot… later during editing
I actually noticed that we just cliked next
next next when the installer asked if we want
to install that crapware.
I feel so embarrassed.
I’m supposed to be a security professional
here, and I just made some computer science
student install some malware…
And even I fall for these shitty tools once
in a while out of frustration…
I’m so sorry that I did that to your laptop…
And it turns out this tool is crap and can’t
create an image from the disk… goddamit…
Then I had some other idea… maybe the git
bash comes with dd???
I remember that git for windows comes with
a nice bash terminal where you get a lot of
linux tools… so I made him install that
and to my surprise, it does list the drives
in /dev as sda, sdb and so forth…
And it also has dd… awesome!!
dd is a command-line utility for Unix and
Unix-like operating systems whose primary
purpose is to convert and copy files.
But here comes the cool things.
On Unix, device drivers for hardware (such
as hard disk drives) [...] appear in the file
system just like normal files; thus dd can
also read and/or write from/to these files.
As a result, dd can be used for tasks such
as backing up the boot sector of a hard drive.
I link an older video from me where I talk
a bit more about linux files as well.
But what this means is we can now use dd,
and then specify the correct device drive,
in our case sdc as in file… so sdc is the
whole drive, and sdc1 and sdc2 are the two
single partitions.
But let’s take an image of the whole card.
the input file, IF, is the sdc drive.
And as out file, OF, we can write a sd.img
file somewhere.
And then he uplaoded it for me and then I
downlaoded it.
All of that took a while because it’s a
full like 7GB image of the whole disk.
Anyway… so here I have it now on my linux.
The first thing I did was using fdisk.
For computer file systems, fdisk is a command-line
utility that provides disk partitioning functions.
As we know the SD card contains two partitions,
so fdisk can help us understand the raw bits
and bytes of that sd.image file to understand
the partitions.
And it finds two.
It also specifies at what exact sectors inside
of the sd.img this particular partition starts
and ends… a sector is simply a unit of 512
bytes. and now you can also understand why
you can’t easily move or insert partitions
in front of another, because they are at fixed
places in there on that disk.
At exactly this offset.
So now we are going to mount that second filesystem.
To do this we have to find the byte offset,
so we can take the sector offset from fdisk
times the sector size in bytes and this is
it.
Then we use the mount command to create a
loop device from this particular sd.image’s
byte offset…
A loop device is like a virtual or pseudo
device that doesn’t physically exist.
We could also write that partition onto a
real disk, like a usb stick and then plug
it in and mount it, or we use that loop feature.
And we tell the mount command to mount it
into the folder partition2.
So now it will take the sd.img file and understands
it as if it was a disk that was just plugged
in.
And ubuntu automatically noticed that a new
file system got mounted and opens the file
explorer of that device… see here, the device
now shows up as rootfs… the name of that
partition was root filesystem.
When we look at these folder, we can already
tell that this is a typical linux filesystem.
Here are well known folders like bin, dev,
etc, home, lib, media, mnt, opt and so forth…
We also can immediately see a tshark.txt file…
TShark is a network protocol analyzer like
wireshark, just as commandline tool… sooo…
were the people right?
Does this try to sniff and man-in-the-middle
WIFI connections?
Is this a malicious device?
So now we need to find out how it works.
This is actually just a bit of boring detective
work.
We have here a linux system and we have to
look for programs that could run here…
But like with the boot partition, here experience
really helps.
If you know how a typical linux filesystem
looks like, you can just ignore that stuff
and directly look for non-typical files.
And looking at locations where a developer
might have placed the programs that are executed
on here.
You could also directly look for scripts and
config files that determine what will be automatically
executed on start.
All this is just experience you acquire over
time if you work on linux.
So I start with the home folder.
When you login as a user, this is your default
folder, so maybe important or interesting
files are located there.
And we can then immediatly find a clean.sh
script.
That is definetly not a standard linux file.
And here we can see a systemctl call to stop
the waitz service.
You remember that name, right?
So there is a systemd service called waitz
running.
There are also other intersting paths here
which are definetly worth investigating too.
But before we moved on, we thought that waitz
is maybe the person’s nickname.
So we did a quick google search for things
like a potential github profile, but no luck.
Now that we know there is a service called
waitz, and waitz appears to be an important
string, we can search for files and folders
with that name…
And this reveals that there is a folder in
home/pi/hubCode/bin/com/waitz… and there
are java classes in here… so com.waitz.hub.scanning
blah are typical java paths.
This is a java program.
And look at those class names…
CommandListener, NetworkThread, Channel Hopper,
WifiData, WifiPacket, BluetoothPacket, BluetoothReader,
SHELL COMMAND THREAD?
Whow… okay…
At this point I was wondering if hubCode is
maybe a known tool that people use.
So we can google for names and snippets like
that, and search on github directly, but nothing
shows up.
So then the detective work continues.
Let’s look at some of these files here…
the state.txt turned out to be itnersting.
There is a wifiCmd specified with a tcpdump,
so a packet reading dump of the wlan1 interface…
there is also a flood 1 config and maybe some
bt, bluetooth settings… mhmhhm… really
suspicious.
here we also found the systemd waitz service
configuration file.
systemd will use this config file to automatically
start the service described in here… the
name is Waitz MQTT Service…
huh??
I know MQTT, it’s a machine-to-machine connectivity
protocol.
It was designed as an extremely lightweight
publish/subscribe messaging transport.
It is useful for connections with remote locations.
For example, it has been used in sensors communicating
[...] and in a range of home automation and
small device scenarios..
It kinda would make sense because the person
said that there were multiple raspberry pies
scattered around the library, hidden in various
places.
And so maybe MQTT is used to create a distributed
network of wifi and bluetooth things… for
whatever purpose?!
Well..
We can also learn from the systemd service
config here, that the following script is
executed on start.
Service.sh…
And in there are a few interesting comments…
get device information, download bundle.
Unzipping bundle… blah… looks like an
update mechanism…
And then when that is done it will call the
hubCode scripts, start.sh.
And look at that one… this prints “starting
waitz service script”.
It will make sure the system has tshark installed.
Then it will call tshark on the wlan1 interface.
And it also seems to get some broker credentials…
broker is a term from MQTT, so this again
reinforces that MQTT is infact used here.
And then later the java application is executed…
the waitz.hub.production program and it even
sets include path for a mqtt library… so
yep okay, there is some mqtt communication
going on.
We can also have a look at the getcreds python
script, because credentials are always cool.
And it will use this amazon API to get them.
But to do so you need to know those parameters
sent along that request.
And in the gen_token module we should be able
to find those parameters.
And that module will actually execute a shell
script called fingerprint.sh and take the
output as a secret, and then calculate like
a secret token… crc32 of the secret + the
current time…
Okay… my code audit inner-self is screaming
loud right now.
Because I see what they try to do here.
But they use crc32 with a secret concatenated
to the time t.
My chest hurts…
They actually want to use HMAC instead…
but in the end it doesn’t matter too much,
because while the fingerprint is like a unique
hardware ID based on the bluetooth mac, the
wifi mac and the pi serial number, this is
not perfect.
Anybody with access to such a raspberry pi
can easily extract or possibly even guess
those values, because none of these are really
random.
So becasue anybody with physical access can
always extract those tokens, I suggest to
just use preshared secret unique to each device,
like an API token.
It can be compromised but you can then also
revoke access for that particular api token.
This little bit of obfuscation here is useless
for anybody who actually wants to do harm
and figure out the secret… it just takes
like 1minute longer to get it, but adds unecessary
development complexity…
You actually can’t do this better with a
raspberry pi.
It’s not a secure hardware device.
Anyway… we were going basically slowly through
all scripts and codes… at some point even
used JD-gui to look at the java classes to
understand what they are doing.
I mean at this point it’s just like reading
code of any programming project.
It’s just like a code audit or getting familiar
with a new project.
You just have to know how to read code and
how software projects might be structured
and deployed.
Our main goal was to determine if this is
a malicious actor who wanted to attack or
sniff wifi of students in the library, or
if this is a harmless school project…
So we spent maybe 1 or 2 hours on looking
around, reading those files and slowly assemble
the mysterious puzzles of “what this is”.
So fast forward a bit.
We slowly realized that it doesn’t do much.
It does not collect any packet data or trying
to sniff passwords or whatever.
Actually it just logs MAC addresses that it
finds from bluetooth and wifi devices in the
area…
This is to 99% just to track people…
This is a very typical application.
Probably every public place you go has stuff
like that.
Probably most shopping malls or airports do
that… it helps to autoamtically record how
busy areas are and how people are moving through
a building.
This is very valuable data for businesses…
they don’t care about the individual person,
it’s just to understand the flow of people.
So this is probably doing a similar thing...
One other thing we did was, We knew the raspberry
pi zero has bluetooth and the wifi dongle
is actually dual band and offers two wifi
interfaces.
So if it is monitoring bluetooth and wifi
in the area, it probably would use the second
wifi to connect to the school’s wifi to
use MQTT and send away the data.
So we thought it would be interesting to find
the username and password they are using to
connect to the wifi.
So I can easily search for that in files on
the raspberry pi. he told me the name of the
school and the name of the school’s wifi.
He is from UCSD… and like I often do, I
google stuff… and for whatever reason I
decided to google “waitz ucsd”,l to see
if there is any connection… and this reddit
thread pops up…
UCSD - the name of the school - Waitz.
Did they stop supporting the app?
Now listen to this beautiful reaction.
Oh wowowowo… what?!
And we find this website…
Is this it?!
What does Waitz do??
Waitz reports the real-time "busyness" for
locations around campus.
How does waitz work?
Waitz gathers our data through small hardware
devices.
These devices pick up smartphone signals in
the area around them.
We then normalize these signals to reach a
"busyness" measurement.
Don't waste time
Know before you go
So this was just part of a network to give
students indication how busy certain areas
at the school are… actually that’s a really
cool and useful project… but Oh man…
Oh my god!
Hahahahah… you found it…
I guess I contact them and and say I found
one of their cthings…
And you know what makes the whole story even
more beautiful?
There was actually a comment 9h before we
figured it out, on the original thread on
reddit.
Please return this to the Library, this is
the property of Waitz, it isn’t nefarious,
it is extremely basic and giving you an idea
of how many people are in the library.
Waitz was started by a recent graduate who
did this as a project while enrolled at the
university.
This was so much fun...
﻿This post caught my attention.
A reddit user posted pictures of a mysterious
raspberry pi zero.
He wrote that his roommate found a bunch of
these hidden behind desks, vending machines
and trashcans in the college library.
Some people were speculating: a wifi dongle
attached and used to intercept internet traffic...
Looks like a pi he was using it as a rogue
access point to do a man-in-the-middle attack.
YEP. definitely
So I reached out to them and offered my help
to figure out what it does.
And to my surprise, they were interested and
we hopped onto a Skype call.
So in this video I want to tell you the process
of us analysing this raspberry pi zero and
how we figured out what it does.
Before I joined this fun, they already took
the SD card out of the raspberry pi and plugged
it into a PC.
This caused an F: drive to show up.
It’s called boot and contains some weird
files that can be really confusing.
they first thought it’s encrypted stuff,
But they quickly realized that maybe windows
is not the best operating system to look at
this.
Actually when you open the Windows Disk management
utility, you can see that the F drive is only
one partition on this whole removable disk.
And there are 3.6GB in another partition.
But Windows didn’t mount this.
Windows only automatically mounted, and made
the filesystem accessible for the first partition
called boot.
That filesystem was FAT32.
The File Allocation Table (FAT) is a computer
file system.
The FAT file system is a [...] , legacy file
system and proves to be simple and robust.
If you're a windows user you definitely have
seen FAT before.
It’s very simple and very old, so a lot
of systems support that.
And so it’s used for the boot partition
of the raspberry pi.
Also google is your best friend, if you are
confused by those files here, you can simply
pick one and google it.
You will immediately find this repository
with that file, and it looks exactly like
that partition.
And as you can see this is part of the official
raspberrypi firmware repository.
This repository contains pre-compiled binaries
of the current Raspberry Pi kernel and modules,
userspace libraries, and bootloader/GPU firmware.
Because we are looking here for whatever this
raspberry pi does, these files are mostly
uninteresting.
They are just part of the raspberry pi system
and we can ignore them.
However when you are very careful you might
notice that there is one weird file.
Waitz.txt.
And it contains the wifi and bluetooth mac
address.
We didn’t know what to make from it, just
keep that name in the back of your mind, it
will come up again.
So our goal was it to look at the second partition.
And the issue why Windows can’t mount it
is, because it’s very likely a typical linux
filesystem like ext4.
The ext4 or fourth extended filesystem is
a journaling file system for Linux, developed
as the successor to ext3.
And Windows just doesn’t have filesystem
drivers to understand that filesystem.
Those bits and bytes on there just don’t
make sense for Windows.
Because I was in a skype call with this guy,
we first tried to make this work on his windows
machine.
And we found and downloaded a program called
ext2fsd, hoping it would allow windows to
mount it, but it later said that it can’t
process ext4.
So that didn’t work.
Of course we were also thinking about different
options.
Either we try to create an image of the sd
card, and upload it so I can have a look at
it on a linux machine, or he could install
a linux virtual machine.
Before we install a full VM, we tried the
windows linux subsystem, where you get kinda
like a ubunut VM inside of windows and I thought
that could then just mount it.
Then we thought about using dd in linux to
create an image.
But nope.
The drives are not exposed and accessible
from in there…
This was all so frustrating… okay… so
I guess we have to download a tool for windows
to create an image of the sd card.
I did a quick google search for windows dd
alternatives and I found this image burner
tool.
Hoping it could just create a damn image from
the card.
And now something very embarrassing happened.
So… when downloading that tool we made sure
to use the site’s own mirror, so we don’t
get malware bundled software from these shady
mirrors, and when he installs it, this happened…
next next next.
Installed.
Then we execute it…
Search Manager added… uhmmmm…… ooooops...
this doesn’t look good….
Virus threat protection.
Doing a quick scan… and…
1 Threats found.
Cleaning that up… hopefully…
We are so dumb…
I’m such an idiot… later during editing
I actually noticed that we just cliked next
next next when the installer asked if we want
to install that crapware.
I feel so embarrassed.
I’m supposed to be a security professional
here, and I just made some computer science
student install some malware…
And even I fall for these shitty tools once
in a while out of frustration…
I’m so sorry that I did that to your laptop…
And it turns out this tool is crap and can’t
create an image from the disk… goddamit…
Then I had some other idea… maybe the git
bash comes with dd???
I remember that git for windows comes with
a nice bash terminal where you get a lot of
linux tools… so I made him install that
and to my surprise, it does list the drives
in /dev as sda, sdb and so forth…
And it also has dd… awesome!!
dd is a command-line utility for Unix and
Unix-like operating systems whose primary
purpose is to convert and copy files.
But here comes the cool things.
On Unix, device drivers for hardware (such
as hard disk drives) [...] appear in the file
system just like normal files; thus dd can
also read and/or write from/to these files.
As a result, dd can be used for tasks such
as backing up the boot sector of a hard drive.
I link an older video from me where I talk
a bit more about linux files as well.
But what this means is we can now use dd,
and then specify the correct device drive,
in our case sdc as in file… so sdc is the
whole drive, and sdc1 and sdc2 are the two
single partitions.
But let’s take an image of the whole card.
the input file, IF, is the sdc drive.
And as out file, OF, we can write a sd.img
file somewhere.
And then he uplaoded it for me and then I
downlaoded it.
All of that took a while because it’s a
full like 7GB image of the whole disk.
Anyway… so here I have it now on my linux.
The first thing I did was using fdisk.
For computer file systems, fdisk is a command-line
utility that provides disk partitioning functions.
As we know the SD card contains two partitions,
so fdisk can help us understand the raw bits
and bytes of that sd.image file to understand
the partitions.
And it finds two.
It also specifies at what exact sectors inside
of the sd.img this particular partition starts
and ends… a sector is simply a unit of 512
bytes. and now you can also understand why
you can’t easily move or insert partitions
in front of another, because they are at fixed
places in there on that disk.
At exactly this offset.
So now we are going to mount that second filesystem.
To do this we have to find the byte offset,
so we can take the sector offset from fdisk
times the sector size in bytes and this is
it.
Then we use the mount command to create a
loop device from this particular sd.image’s
byte offset…
A loop device is like a virtual or pseudo
device that doesn’t physically exist.
We could also write that partition onto a
real disk, like a usb stick and then plug
it in and mount it, or we use that loop feature.
And we tell the mount command to mount it
into the folder partition2.
So now it will take the sd.img file and understands
it as if it was a disk that was just plugged
in.
And ubuntu automatically noticed that a new
file system got mounted and opens the file
explorer of that device… see here, the device
now shows up as rootfs… the name of that
partition was root filesystem.
When we look at these folder, we can already
tell that this is a typical linux filesystem.
Here are well known folders like bin, dev,
etc, home, lib, media, mnt, opt and so forth…
We also can immediately see a tshark.txt file…
TShark is a network protocol analyzer like
wireshark, just as commandline tool… sooo…
were the people right?
Does this try to sniff and man-in-the-middle
WIFI connections?
Is this a malicious device?
So now we need to find out how it works.
This is actually just a bit of boring detective
work.
We have here a linux system and we have to
look for programs that could run here…
But like with the boot partition, here experience
really helps.
If you know how a typical linux filesystem
looks like, you can just ignore that stuff
and directly look for non-typical files.
And looking at locations where a developer
might have placed the programs that are executed
on here.
You could also directly look for scripts and
config files that determine what will be automatically
executed on start.
All this is just experience you acquire over
time if you work on linux.
So I start with the home folder.
When you login as a user, this is your default
folder, so maybe important or interesting
files are located there.
And we can then immediatly find a clean.sh
script.
That is definetly not a standard linux file.
And here we can see a systemctl call to stop
the waitz service.
You remember that name, right?
So there is a systemd service called waitz
running.
There are also other intersting paths here
which are definetly worth investigating too.
But before we moved on, we thought that waitz
is maybe the person’s nickname.
So we did a quick google search for things
like a potential github profile, but no luck.
Now that we know there is a service called
waitz, and waitz appears to be an important
string, we can search for files and folders
with that name…
And this reveals that there is a folder in
home/pi/hubCode/bin/com/waitz… and there
are java classes in here… so com.waitz.hub.scanning
blah are typical java paths.
This is a java program.
And look at those class names…
CommandListener, NetworkThread, Channel Hopper,
WifiData, WifiPacket, BluetoothPacket, BluetoothReader,
SHELL COMMAND THREAD?
Whow… okay…
At this point I was wondering if hubCode is
maybe a known tool that people use.
So we can google for names and snippets like
that, and search on github directly, but nothing
shows up.
So then the detective work continues.
Let’s look at some of these files here…
the state.txt turned out to be itnersting.
There is a wifiCmd specified with a tcpdump,
so a packet reading dump of the wlan1 interface…
there is also a flood 1 config and maybe some
bt, bluetooth settings… mhmhhm… really
suspicious.
here we also found the systemd waitz service
configuration file.
systemd will use this config file to automatically
start the service described in here… the
name is Waitz MQTT Service…
huh??
I know MQTT, it’s a machine-to-machine connectivity
protocol.
It was designed as an extremely lightweight
publish/subscribe messaging transport.
It is useful for connections with remote locations.
For example, it has been used in sensors communicating
[...] and in a range of home automation and
small device scenarios..
It kinda would make sense because the person
said that there were multiple raspberry pies
scattered around the library, hidden in various
places.
And so maybe MQTT is used to create a distributed
network of wifi and bluetooth things… for
whatever purpose?!
Well..
We can also learn from the systemd service
config here, that the following script is
executed on start.
Service.sh…
And in there are a few interesting comments…
get device information, download bundle.
Unzipping bundle… blah… looks like an
update mechanism…
And then when that is done it will call the
hubCode scripts, start.sh.
And look at that one… this prints “starting
waitz service script”.
It will make sure the system has tshark installed.
Then it will call tshark on the wlan1 interface.
And it also seems to get some broker credentials…
broker is a term from MQTT, so this again
reinforces that MQTT is infact used here.
And then later the java application is executed…
the waitz.hub.production program and it even
sets include path for a mqtt library… so
yep okay, there is some mqtt communication
going on.
We can also have a look at the getcreds python
script, because credentials are always cool.
And it will use this amazon API to get them.
But to do so you need to know those parameters
sent along that request.
And in the gen_token module we should be able
to find those parameters.
And that module will actually execute a shell
script called fingerprint.sh and take the
output as a secret, and then calculate like
a secret token… crc32 of the secret + the
current time…
Okay… my code audit inner-self is screaming
loud right now.
Because I see what they try to do here.
But they use crc32 with a secret concatenated
to the time t.
My chest hurts…
They actually want to use HMAC instead…
but in the end it doesn’t matter too much,
because while the fingerprint is like a unique
hardware ID based on the bluetooth mac, the
wifi mac and the pi serial number, this is
not perfect.
Anybody with access to such a raspberry pi
can easily extract or possibly even guess
those values, because none of these are really
random.
So becasue anybody with physical access can
always extract those tokens, I suggest to
just use preshared secret unique to each device,
like an API token.
It can be compromised but you can then also
revoke access for that particular api token.
This little bit of obfuscation here is useless
for anybody who actually wants to do harm
and figure out the secret… it just takes
like 1minute longer to get it, but adds unecessary
development complexity…
You actually can’t do this better with a
raspberry pi.
It’s not a secure hardware device.
Anyway… we were going basically slowly through
all scripts and codes… at some point even
used JD-gui to look at the java classes to
understand what they are doing.
I mean at this point it’s just like reading
code of any programming project.
It’s just like a code audit or getting familiar
with a new project.
You just have to know how to read code and
how software projects might be structured
and deployed.
Our main goal was to determine if this is
a malicious actor who wanted to attack or
sniff wifi of students in the library, or
if this is a harmless school project…
So we spent maybe 1 or 2 hours on looking
around, reading those files and slowly assemble
the mysterious puzzles of “what this is”.
So fast forward a bit.
We slowly realized that it doesn’t do much.
It does not collect any packet data or trying
to sniff passwords or whatever.
Actually it just logs MAC addresses that it
finds from bluetooth and wifi devices in the
area…
This is to 99% just to track people…
This is a very typical application.
Probably every public place you go has stuff
like that.
Probably most shopping malls or airports do
that… it helps to autoamtically record how
busy areas are and how people are moving through
a building.
This is very valuable data for businesses…
they don’t care about the individual person,
it’s just to understand the flow of people.
So this is probably doing a similar thing...
One other thing we did was, We knew the raspberry
pi zero has bluetooth and the wifi dongle
is actually dual band and offers two wifi
interfaces.
So if it is monitoring bluetooth and wifi
in the area, it probably would use the second
wifi to connect to the school’s wifi to
use MQTT and send away the data.
So we thought it would be interesting to find
the username and password they are using to
connect to the wifi.
So I can easily search for that in files on
the raspberry pi. he told me the name of the
school and the name of the school’s wifi.
He is from UCSD… and like I often do, I
google stuff… and for whatever reason I
decided to google “waitz ucsd”,l to see
if there is any connection… and this reddit
thread pops up…
UCSD - the name of the school - Waitz.
Did they stop supporting the app?
Now listen to this beautiful reaction.
Oh wowowowo… what?!
And we find this website…
Is this it?!
What does Waitz do??
Waitz reports the real-time "busyness" for
locations around campus.
How does waitz work?
Waitz gathers our data through small hardware
devices.
These devices pick up smartphone signals in
the area around them.
We then normalize these signals to reach a
"busyness" measurement.
Don't waste time
Know before you go
So this was just part of a network to give
students indication how busy certain areas
at the school are… actually that’s a really
cool and useful project… but Oh man…
Oh my god!
Hahahahah… you found it…
I guess I contact them and and say I found
one of their cthings…
And you know what makes the whole story even
more beautiful?
There was actually a comment 9h before we
figured it out, on the original thread on
reddit.
Please return this to the Library, this is
the property of Waitz, it isn’t nefarious,
it is extremely basic and giving you an idea
of how many people are in the library.
Waitz was started by a recent graduate who
did this as a project while enrolled at the
university.
This was so much fun...
﻿This post caught my attention.
A reddit user posted pictures of a mysterious
raspberry pi zero.
He wrote that his roommate found a bunch of
these hidden behind desks, vending machines
and trashcans in the college library.
Some people were speculating: a wifi dongle
attached and used to intercept internet traffic...
Looks like a pi he was using it as a rogue
access point to do a man-in-the-middle attack.
YEP. definitely
So I reached out to them and offered my help
to figure out what it does.
And to my surprise, they were interested and
we hopped onto a Skype call.
So in this video I want to tell you the process
of us analysing this raspberry pi zero and
how we figured out what it does.
Before I joined this fun, they already took
the SD card out of the raspberry pi and plugged
it into a PC.
This caused an F: drive to show up.
It’s called boot and contains some weird
files that can be really confusing.
they first thought it’s encrypted stuff,
But they quickly realized that maybe windows
is not the best operating system to look at
this.
Actually when you open the Windows Disk management
utility, you can see that the F drive is only
one partition on this whole removable disk.
And there are 3.6GB in another partition.
But Windows didn’t mount this.
Windows only automatically mounted, and made
the filesystem accessible for the first partition
called boot.
That filesystem was FAT32.
The File Allocation Table (FAT) is a computer
file system.
The FAT file system is a [...] , legacy file
system and proves to be simple and robust.
If you're a windows user you definitely have
seen FAT before.
It’s very simple and very old, so a lot
of systems support that.
And so it’s used for the boot partition
of the raspberry pi.
Also google is your best friend, if you are
confused by those files here, you can simply
pick one and google it.
You will immediately find this repository
with that file, and it looks exactly like
that partition.
And as you can see this is part of the official
raspberrypi firmware repository.
This repository contains pre-compiled binaries
of the current Raspberry Pi kernel and modules,
userspace libraries, and bootloader/GPU firmware.
Because we are looking here for whatever this
raspberry pi does, these files are mostly
uninteresting.
They are just part of the raspberry pi system
and we can ignore them.
However when you are very careful you might
notice that there is one weird file.
Waitz.txt.
And it contains the wifi and bluetooth mac
address.
We didn’t know what to make from it, just
keep that name in the back of your mind, it
will come up again.
So our goal was it to look at the second partition.
And the issue why Windows can’t mount it
is, because it’s very likely a typical linux
filesystem like ext4.
The ext4 or fourth extended filesystem is
a journaling file system for Linux, developed
as the successor to ext3.
And Windows just doesn’t have filesystem
drivers to understand that filesystem.
Those bits and bytes on there just don’t
make sense for Windows.
Because I was in a skype call with this guy,
we first tried to make this work on his windows
machine.
And we found and downloaded a program called
ext2fsd, hoping it would allow windows to
mount it, but it later said that it can’t
process ext4.
So that didn’t work.
Of course we were also thinking about different
options.
Either we try to create an image of the sd
card, and upload it so I can have a look at
it on a linux machine, or he could install
a linux virtual machine.
Before we install a full VM, we tried the
windows linux subsystem, where you get kinda
like a ubunut VM inside of windows and I thought
that could then just mount it.
Then we thought about using dd in linux to
create an image.
But nope.
The drives are not exposed and accessible
from in there…
This was all so frustrating… okay… so
I guess we have to download a tool for windows
to create an image of the sd card.
I did a quick google search for windows dd
alternatives and I found this image burner
tool.
Hoping it could just create a damn image from
the card.
And now something very embarrassing happened.
So… when downloading that tool we made sure
to use the site’s own mirror, so we don’t
get malware bundled software from these shady
mirrors, and when he installs it, this happened…
next next next.
Installed.
Then we execute it…
Search Manager added… uhmmmm…… ooooops...
this doesn’t look good….
Virus threat protection.
Doing a quick scan… and…
1 Threats found.
Cleaning that up… hopefully…
We are so dumb…
I’m such an idiot… later during editing
I actually noticed that we just cliked next
next next when the installer asked if we want
to install that crapware.
I feel so embarrassed.
I’m supposed to be a security professional
here, and I just made some computer science
student install some malware…
And even I fall for these shitty tools once
in a while out of frustration…
I’m so sorry that I did that to your laptop…
And it turns out this tool is crap and can’t
create an image from the disk… goddamit…
Then I had some other idea… maybe the git
bash comes with dd???
I remember that git for windows comes with
a nice bash terminal where you get a lot of
linux tools… so I made him install that
and to my surprise, it does list the drives
in /dev as sda, sdb and so forth…
And it also has dd… awesome!!
dd is a command-line utility for Unix and
Unix-like operating systems whose primary
purpose is to convert and copy files.
But here comes the cool things.
On Unix, device drivers for hardware (such
as hard disk drives) [...] appear in the file
system just like normal files; thus dd can
also read and/or write from/to these files.
As a result, dd can be used for tasks such
as backing up the boot sector of a hard drive.
I link an older video from me where I talk
a bit more about linux files as well.
But what this means is we can now use dd,
and then specify the correct device drive,
in our case sdc as in file… so sdc is the
whole drive, and sdc1 and sdc2 are the two
single partitions.
But let’s take an image of the whole card.
the input file, IF, is the sdc drive.
And as out file, OF, we can write a sd.img
file somewhere.
And then he uplaoded it for me and then I
downlaoded it.
All of that took a while because it’s a
full like 7GB image of the whole disk.
Anyway… so here I have it now on my linux.
The first thing I did was using fdisk.
For computer file systems, fdisk is a command-line
utility that provides disk partitioning functions.
As we know the SD card contains two partitions,
so fdisk can help us understand the raw bits
and bytes of that sd.image file to understand
the partitions.
And it finds two.
It also specifies at what exact sectors inside
of the sd.img this particular partition starts
and ends… a sector is simply a unit of 512
bytes. and now you can also understand why
you can’t easily move or insert partitions
in front of another, because they are at fixed
places in there on that disk.
At exactly this offset.
So now we are going to mount that second filesystem.
To do this we have to find the byte offset,
so we can take the sector offset from fdisk
times the sector size in bytes and this is
it.
Then we use the mount command to create a
loop device from this particular sd.image’s
byte offset…
A loop device is like a virtual or pseudo
device that doesn’t physically exist.
We could also write that partition onto a
real disk, like a usb stick and then plug
it in and mount it, or we use that loop feature.
And we tell the mount command to mount it
into the folder partition2.
So now it will take the sd.img file and understands
it as if it was a disk that was just plugged
in.
And ubuntu automatically noticed that a new
file system got mounted and opens the file
explorer of that device… see here, the device
now shows up as rootfs… the name of that
partition was root filesystem.
When we look at these folder, we can already
tell that this is a typical linux filesystem.
Here are well known folders like bin, dev,
etc, home, lib, media, mnt, opt and so forth…
We also can immediately see a tshark.txt file…
TShark is a network protocol analyzer like
wireshark, just as commandline tool… sooo…
were the people right?
Does this try to sniff and man-in-the-middle
WIFI connections?
Is this a malicious device?
So now we need to find out how it works.
This is actually just a bit of boring detective
work.
We have here a linux system and we have to
look for programs that could run here…
But like with the boot partition, here experience
really helps.
If you know how a typical linux filesystem
looks like, you can just ignore that stuff
and directly look for non-typical files.
And looking at locations where a developer
might have placed the programs that are executed
on here.
You could also directly look for scripts and
config files that determine what will be automatically
executed on start.
All this is just experience you acquire over
time if you work on linux.
So I start with the home folder.
When you login as a user, this is your default
folder, so maybe important or interesting
files are located there.
And we can then immediatly find a clean.sh
script.
That is definetly not a standard linux file.
And here we can see a systemctl call to stop
the waitz service.
You remember that name, right?
So there is a systemd service called waitz
running.
There are also other intersting paths here
which are definetly worth investigating too.
But before we moved on, we thought that waitz
is maybe the person’s nickname.
So we did a quick google search for things
like a potential github profile, but no luck.
Now that we know there is a service called
waitz, and waitz appears to be an important
string, we can search for files and folders
with that name…
And this reveals that there is a folder in
home/pi/hubCode/bin/com/waitz… and there
are java classes in here… so com.waitz.hub.scanning
blah are typical java paths.
This is a java program.
And look at those class names…
CommandListener, NetworkThread, Channel Hopper,
WifiData, WifiPacket, BluetoothPacket, BluetoothReader,
SHELL COMMAND THREAD?
Whow… okay…
At this point I was wondering if hubCode is
maybe a known tool that people use.
So we can google for names and snippets like
that, and search on github directly, but nothing
shows up.
So then the detective work continues.
Let’s look at some of these files here…
the state.txt turned out to be itnersting.
There is a wifiCmd specified with a tcpdump,
so a packet reading dump of the wlan1 interface…
there is also a flood 1 config and maybe some
bt, bluetooth settings… mhmhhm… really
suspicious.
here we also found the systemd waitz service
configuration file.
systemd will use this config file to automatically
start the service described in here… the
name is Waitz MQTT Service…
huh??
I know MQTT, it’s a machine-to-machine connectivity
protocol.
It was designed as an extremely lightweight
publish/subscribe messaging transport.
It is useful for connections with remote locations.
For example, it has been used in sensors communicating
[...] and in a range of home automation and
small device scenarios..
It kinda would make sense because the person
said that there were multiple raspberry pies
scattered around the library, hidden in various
places.
And so maybe MQTT is used to create a distributed
network of wifi and bluetooth things… for
whatever purpose?!
Well..
We can also learn from the systemd service
config here, that the following script is
executed on start.
Service.sh…
And in there are a few interesting comments…
get device information, download bundle.
Unzipping bundle… blah… looks like an
update mechanism…
And then when that is done it will call the
hubCode scripts, start.sh.
And look at that one… this prints “starting
waitz service script”.
It will make sure the system has tshark installed.
Then it will call tshark on the wlan1 interface.
And it also seems to get some broker credentials…
broker is a term from MQTT, so this again
reinforces that MQTT is infact used here.
And then later the java application is executed…
the waitz.hub.production program and it even
sets include path for a mqtt library… so
yep okay, there is some mqtt communication
going on.
We can also have a look at the getcreds python
script, because credentials are always cool.
And it will use this amazon API to get them.
But to do so you need to know those parameters
sent along that request.
And in the gen_token module we should be able
to find those parameters.
And that module will actually execute a shell
script called fingerprint.sh and take the
output as a secret, and then calculate like
a secret token… crc32 of the secret + the
current time…
Okay… my code audit inner-self is screaming
loud right now.
Because I see what they try to do here.
But they use crc32 with a secret concatenated
to the time t.
My chest hurts…
They actually want to use HMAC instead…
but in the end it doesn’t matter too much,
because while the fingerprint is like a unique
hardware ID based on the bluetooth mac, the
wifi mac and the pi serial number, this is
not perfect.
Anybody with access to such a raspberry pi
can easily extract or possibly even guess
those values, because none of these are really
random.
So becasue anybody with physical access can
always extract those tokens, I suggest to
just use preshared secret unique to each device,
like an API token.
It can be compromised but you can then also
revoke access for that particular api token.
This little bit of obfuscation here is useless
for anybody who actually wants to do harm
and figure out the secret… it just takes
like 1minute longer to get it, but adds unecessary
development complexity…
You actually can’t do this better with a
raspberry pi.
It’s not a secure hardware device.
Anyway… we were going basically slowly through
all scripts and codes… at some point even
used JD-gui to look at the java classes to
understand what they are doing.
I mean at this point it’s just like reading
code of any programming project.
It’s just like a code audit or getting familiar
with a new project.
You just have to know how to read code and
how software projects might be structured
and deployed.
Our main goal was to determine if this is
a malicious actor who wanted to attack or
sniff wifi of students in the library, or
if this is a harmless school project…
So we spent maybe 1 or 2 hours on looking
around, reading those files and slowly assemble
the mysterious puzzles of “what this is”.
So fast forward a bit.
We slowly realized that it doesn’t do much.
It does not collect any packet data or trying
to sniff passwords or whatever.
Actually it just logs MAC addresses that it
finds from bluetooth and wifi devices in the
area…
This is to 99% just to track people…
This is a very typical application.
Probably every public place you go has stuff
like that.
Probably most shopping malls or airports do
that… it helps to autoamtically record how
busy areas are and how people are moving through
a building.
This is very valuable data for businesses…
they don’t care about the individual person,
it’s just to understand the flow of people.
So this is probably doing a similar thing...
One other thing we did was, We knew the raspberry
pi zero has bluetooth and the wifi dongle
is actually dual band and offers two wifi
interfaces.
So if it is monitoring bluetooth and wifi
in the area, it probably would use the second
wifi to connect to the school’s wifi to
use MQTT and send away the data.
So we thought it would be interesting to find
the username and password they are using to
connect to the wifi.
So I can easily search for that in files on
the raspberry pi. he told me the name of the
school and the name of the school’s wifi.
He is from UCSD… and like I often do, I
google stuff… and for whatever reason I
decided to google “waitz ucsd”,l to see
if there is any connection… and this reddit
thread pops up…
UCSD - the name of the school - Waitz.
Did they stop supporting the app?
Now listen to this beautiful reaction.
Oh wowowowo… what?!
And we find this website…
Is this it?!
What does Waitz do??
Waitz reports the real-time "busyness" for
locations around campus.
How does waitz work?
Waitz gathers our data through small hardware
devices.
These devices pick up smartphone signals in
the area around them.
We then normalize these signals to reach a
"busyness" measurement.
Don't waste time
Know before you go
So this was just part of a network to give
students indication how busy certain areas
at the school are… actually that’s a really
cool and useful project… but Oh man…
Oh my god!
Hahahahah… you found it…
I guess I contact them and and say I found
one of their cthings…
And you know what makes the whole story even
more beautiful?
There was actually a comment 9h before we
figured it out, on the original thread on
reddit.
Please return this to the Library, this is
the property of Waitz, it isn’t nefarious,
it is extremely basic and giving you an idea
of how many people are in the library.
Waitz was started by a recent graduate who
did this as a project while enrolled at the
university.
This was so much fun...
﻿It is time to get serious.
Reverse Engineering isn’t about toys and
games.
Sometimes it’s about malicious software.
I recommend you run this next challenge in
a VM or someone else’s computer you have
gained access to, especially if they are a
Firefox user.
Okay, this time I needed to get a VM.
And I saw that they also offer this Flare
VM which is like the Kali Linux of Windows
Malware Analysis.
And because I have no clue, I go with that.
For this I used a free Windows Test VM and
then executed the Flare installer to install
all tools.
The challenge description is hinting at malicious
software and itt may target Firefox?
So I also install firefox.
And then we can get started
Before we head into it, I have to say again.
I have very little experience with windows.
I would say about myself, that “I have no
clue what I am doing”.
Of course that is not completly true.
You can’t go a few years in this field without
picking up some knowledge over time.
Actually my very first introduction into reverse
engineering and exploitation WAS with windows,
namely a friend who introduced me to game
cracking with olly debugger and then the corelan
and lena tutorials.
And generally by having a more abstract computer
science knowledge and a basic understanding
of how computers work, I don’t feel completely
lost.
I have a rough idea what I want to do, and
I can somehow figure it out.
I just very much lack detailed technical knowledge
and experience.
for example I have very limited knowledge
about the windows APIs.
And I only know a FEW popular TOOLS.
And so I will be a lot more inefficient and
my approach is a lot less structured than
usual.
But let’s learn together and share your
tips in the comments.
So here we have the binary.
If you forgot to turn off windows defender,
then windows will actually detect it as malware
and then remove it.
So make sure to deal with that.
Because I’m unsure how to approach this
I decided to throw it into virus total.
Of course somebody else did that before.
But I’m not really interested in what tool
flagged this as malware, I was actually interested
in the file details tab.
That one provides a good first quick overview
over the binary, without executing it yourself.
So binstall is a browser assitant installer,
which would match with the firefox hint in
the description.
And it appears to be .net, so maybe another
c# program?
We can also go on the comments tab where other
plattform analysis tools posted their results.
For example we can checkout the joe sandbox
result.
That service appears to run the binary and
record what it does.
It also labeled it malicious.
And here are some great first hints.
It creates an undocumented autostart registry
key.
And it drops a PE file.
PE file is a regular windows binary file.
And you can see it drops a browserassist.dll.
But into the Internet Explorer folder?
Not firefox?
Mhmh..
There is a lot more nice information there,
but let’s move into our own VM.
So Flare installed a lot of tools in various
folders.
Disassemblers, debuggers, decompilers and
other utility tools.
One of the first tools that were ever showed
to me wa PEID, so I use that again.
It’s a tool to detect what kind of binary
it is.
And for binstall it detects that it’s a
C# .net binary.
Extra information will also show some guesses,
that the binary might be packed, so parts
of it might be encrypted.
Because it’s C# we can also trhow it into
IlSpy again, but you can quickly see it got
obfuscated.
So while all the names are gone, you can still
click on them and follow their references,
but also the functions them selve appear to
implement decryption or deobfuscation routines.
So not something we want to really analyse
if we don’t have to.
And we know it drops a .dll anyway, so it’s
probably also not important.
Nontheless I was playing around a bit with
it a bit.
And so I used Process Monitor to monitor all
events on the system as well as checking out
API monitor to monitor all calls.
So when running binstall we can then use the
filters or the search in Process monitor to
hopefully find interesting things it did.
Like accessing the registry or creating a
file.
And so after a bit of digging we can also
discover here the dropped dll location.
I also tried API monitor and selected a few
possibly itnersting APIs such as file system
or networking stuff.
And then I wanted to launch and attach to
the binstall .exe.
But it didn’t really work and crashed.
But trying out different attach methods I
found one that works.
And so API monitor recorded all the Windows
APIs that binstall was using and we selected
to trace.
And also here with a bit of digging we can
find the file it creates.
The browserassist.dll.
With peid we can also investigate the dropped
dll.
And this one looks like a regular binary.
So not C#.
And the extra information checks also think
that it doesn’t look encrypted.
Great.
We can also throw it into the ida free version
here and check a bit the strings.
Here are references to typical HTTP header
values.
Content-type, encoding, POST, GET and so forth.
So again it makes sense that it does something
with the browser.
Now I was confused why the dll was dropped
into the internet explorer folder, so I actually
thought maybe it does infect IE.
And when I opened the internet explorer, I
noticed this weird smiley face.
Send a smile, send a frown?
Did the malware inject that?
That’s funny.
Mhmh.. it appears to fake a Internet Explored
feedback form.
That’s quite interesting.
Let’s have a quick look at the privacy statement.
Mhmh… that looks like the normal microsoft
privacy statement?
Ehhmmm….
Oh… whaaat?
This is not the challenge?
This is actually in the Internet Explorer?
Let’s pretend this didn’t happen.
We move on.
Now in the meantime it was kinda hard to avoid
spoilers on reddit and twitter becasue people
talked about the challenges publicly.
SHAME YOU!
Just kidding, I think it’s great that you
help eachother.
And somewhere I read that you should use an
older firefox version, something like firefox
version 40, so that’s why I also downloaded
that one.
In that moment I was kinda annoyed that it
would only work with older firefox versions
and was wondering how you could even figure
that out.
Anyway… so I opened the old firefox version
and now I was wondering what to do.
There didn’t appear to be anything obviously
different, but it’s a malware right?
So it would do something a bit more sneaky.
Next I thought I could try to trace calls
to the browserassist.dll in case firefox does
anything with it.
You can add external dlls to the API monitor,
but it says that it doesn’t export any functions.
So the .dll appears to not work like a typical
.dll with exported functions… mhmh… next
I decided to attach the x32 debugger to firefox.
And I wasn’t really sure how to approach
it, but I thought a good start would be to
see if the dll is loaded somewhere in memory,
so I checked the Memory Map tab and also found
it in there.
Over her eyou also se a description of the
different segments, but for the debugger the
text segment, the code is obviously the most
interesting.
This lead me to this area here.
So that’s kinda like the entry point of
the dll, I guess.
And because I didn’t know what it does I
simply set a breakpiint at the start and end
of it.
But it didn’t trigger right away when using
the browser, only when I restarted it.
And while pressing the button to continue
execution after that breakpoint, I noticed
that this code was executed quite a lot on
load.
And I happen to notice some ascii strings
being referenced at some point earlier on
the stack.
This is the stack view here.
That’s just memory that’s still around.
For example I saw an injects and content string.
So while I kept doing this continue break
continue break thing, and looking at the stack,
eventually I noticed this json data…
Code, addCmd.
After.
askPassword.
Ont he path js/view.js?
On the host *flare-on.com?
What?
That looks like a filter.
It applies to all flare-on.com domains, includign
subdomains.
And js/views.js is obviously a javascript
file.
So I went into the browser, went to flare-on.com
where we had this simple command line interface,
opened js/views.js and noticed some very suspicious
javascript.
I mean that looks very obfuscated.
So I opened up the same javascript file on
my regular host chrome browser and compared
it.
And holy cat.
Look at the difference.
The malware in firefox appears to have injected
javascript into this script.
In theory this could be now injecting ads
or a script to steal your credit car dinfo
or so.
But this challenge apparently added an askPassword
function.
So clearly this comamndline interface was
extended with some functionality, but what
exactly?
I just randomly tried some stuff but it didn’t
work.
But askPassword is a javascript function,
so we can open the developer tools and just
directly call it.
Now the function itself was defined inside
of com.fireye.flareon.view.
So here is the function.
When we call it, we see that we are now asked
to enter a password.
And when we enter something, we get a su,
authentication failure… ahhh..
So su is the secret command.
Switch user.
So now we need to find the password.
By looking around the other javascript files
I noticed a controller.js which also had additional
code injected.
A cp function which seems to be called when
the password is Entered.
We can also set a breakpoint in cp, then trgger
su and enter a password.
And here we go.
So we see that p in this case is the password
we entered.
The first check is if the length is 10.
So we know the password must be 10 characters
long.
And then we check the first character.
The first character xored with 16 must result
in 123.
Because it’s xor, we can simply xor 123
with 16, and the result will be the first
valid character of our password.
And peaking ahead we can see that there are
similar rules like that for all other characters
of the password.
So I copied the javascript code into a new
html file, to more easily work on it and cleaned
up the if-case a bit.
But then we quickly reach some of these functions.
So the 5th character is equal to an integer
which is returned by this function.
If you carefully check how far this function
spans, you can just copy the whole thing,
let it evaluate, and this is the result.
The whole thing is just obfuscation for the
number 66.
And there are a few more like that, but same
principle.
Here are all the rules cleaned up.
Oh f.
That’s the problem with using this test
vm.
I think it expired and after a little bit
of time it will, you know, shut down.
This is annoying….
Ok… we are back… here are all the rules
cleaned up.
And then I started to write the reverse of
each of these conditions to create the whole
password.
We can simply use the String function fromCharCode,
which takes ascii integer numbers as parameters
and turns them into a regular ascii string.
So the first character is 16 XOR 123.
The second character is shifted to the left
by two and must be equal to 228.
This means if we shift 228 right by 2, we
get the next valid character.
Character three has a little twist, I will
take about it in second.
Next character was this obfuscatied function
and so it’s just 66.
Fifth character subtracted by 109 will result
in -22.
Which means if you subtract 22 from 109 you
will get the correct password character.
And it’s all kinda simple, but then in the
end we reach two more rules that are a bit
more complex.
Feel free to practice your school level math
to rearrange the equation so that our password
character is alone on one side.
But I’m not in school anymore.
And I’m really lazy.
So I just decided to bruteforce those two
values.
I mean each of them only has less than 128
options.
we are talking ascii characters here.
Oh and the 3ird character was a bit special
because the check is doing here a shift right.
Which means the lower bits of that number
will be lost.
So 14 is the result of a shift right, which
means if we shift the 14 back, we don’t
know what the lower bits were.
And up here we do the reverse.
We shift the bits up, but then remove them
with %255, so now only the lower bits remain.
So based on these two values you can easily
assemble all bits of the whole ascii number.
But again, I’m lazy.
I just brute force it too.
I clean up a bit more and here is the final
script.
If we find the correct password I alert it,
and otherwise just return false.
And then I have three nested for loops, each
one is responsible for one of the three unknown
characters.
And then I just open that file in the browser,
and basically instantly it finds the correct
password.
Awesome.
We can copy it now, execute su, enter it and
BOOM!.
We are root.
Awesome……….
Right?...
ehm… how do we get the flag now?
I was hoping this was it?
Goddamit.
After a short moment of rage I tried to approach
it again with logic and saw that when we enter
the password correct, it sets the root variable
to 1.
So I searched the sources for location where
this variable is used.
And I find one location here.
And scrolling up we can see it’s in the
function changeDirectory.
So that’s interesting.
The other aprt in the if case where it checks
for root is again obfuscated.
When we carefully copy that out again and
evaluate it, it evaluates to “key”...
sooooo… let’s try that.
Let’s try to cd to key.
Oh wow that works.
We are now in key.
And as we learned in the first video, we can
enter “ls”.
Urgh… what is that… so first time I saw
that I was a bit shocked, but I think I screwed
up some internal state.
Because I had the clever idea to refresh the
browser and do it again, on a clean session
where I didn’t debug, and now it works.
We get the flag.
Command Injection.
Let’s submit the flag and we are done…
awesome.
Oh and btw.
At the end I checked also the latest version
of firefox, and the malicious javascript was
also injected there.
So the spoiler or tip to use an old firefox
version wasn’t actually necessary.
Eeehhh…
LiveOverflow from the future again.
I was just editing this part, happy that I’m
almost done and then I realized.
Wait a moment.
Could it be that the js file was just locally
cached and the new firefox used the old firefox’s
cache?
So here is the old firefox, showing the injected
js.
Then I open the new firefox, open that js
file and we also see the injected JS.
But now I force a refresh with CTRL+SHIFT
R and boom.
File is actually loaded and the injection
is gone.
I first thought not to include that part in
the video, but I thought it’s quite interesting
that the new browser version 60 was able to
still use the cache written by the older version.
AND this also means another question stands.
How could you have figured out that you needed
an older version.
Were there any references in the dll to that?
Please let me know in the comments.
﻿It is time to get serious.
Reverse Engineering isn’t about toys and
games.
Sometimes it’s about malicious software.
I recommend you run this next challenge in
a VM or someone else’s computer you have
gained access to, especially if they are a
Firefox user.
Okay, this time I needed to get a VM.
And I saw that they also offer this Flare
VM which is like the Kali Linux of Windows
Malware Analysis.
And because I have no clue, I go with that.
For this I used a free Windows Test VM and
then executed the Flare installer to install
all tools.
The challenge description is hinting at malicious
software and itt may target Firefox?
So I also install firefox.
And then we can get started
Before we head into it, I have to say again.
I have very little experience with windows.
I would say about myself, that “I have no
clue what I am doing”.
Of course that is not completly true.
You can’t go a few years in this field without
picking up some knowledge over time.
Actually my very first introduction into reverse
engineering and exploitation WAS with windows,
namely a friend who introduced me to game
cracking with olly debugger and then the corelan
and lena tutorials.
And generally by having a more abstract computer
science knowledge and a basic understanding
of how computers work, I don’t feel completely
lost.
I have a rough idea what I want to do, and
I can somehow figure it out.
I just very much lack detailed technical knowledge
and experience.
for example I have very limited knowledge
about the windows APIs.
And I only know a FEW popular TOOLS.
And so I will be a lot more inefficient and
my approach is a lot less structured than
usual.
But let’s learn together and share your
tips in the comments.
So here we have the binary.
If you forgot to turn off windows defender,
then windows will actually detect it as malware
and then remove it.
So make sure to deal with that.
Because I’m unsure how to approach this
I decided to throw it into virus total.
Of course somebody else did that before.
But I’m not really interested in what tool
flagged this as malware, I was actually interested
in the file details tab.
That one provides a good first quick overview
over the binary, without executing it yourself.
So binstall is a browser assitant installer,
which would match with the firefox hint in
the description.
And it appears to be .net, so maybe another
c# program?
We can also go on the comments tab where other
plattform analysis tools posted their results.
For example we can checkout the joe sandbox
result.
That service appears to run the binary and
record what it does.
It also labeled it malicious.
And here are some great first hints.
It creates an undocumented autostart registry
key.
And it drops a PE file.
PE file is a regular windows binary file.
And you can see it drops a browserassist.dll.
But into the Internet Explorer folder?
Not firefox?
Mhmh..
There is a lot more nice information there,
but let’s move into our own VM.
So Flare installed a lot of tools in various
folders.
Disassemblers, debuggers, decompilers and
other utility tools.
One of the first tools that were ever showed
to me wa PEID, so I use that again.
It’s a tool to detect what kind of binary
it is.
And for binstall it detects that it’s a
C# .net binary.
Extra information will also show some guesses,
that the binary might be packed, so parts
of it might be encrypted.
Because it’s C# we can also trhow it into
IlSpy again, but you can quickly see it got
obfuscated.
So while all the names are gone, you can still
click on them and follow their references,
but also the functions them selve appear to
implement decryption or deobfuscation routines.
So not something we want to really analyse
if we don’t have to.
And we know it drops a .dll anyway, so it’s
probably also not important.
Nontheless I was playing around a bit with
it a bit.
And so I used Process Monitor to monitor all
events on the system as well as checking out
API monitor to monitor all calls.
So when running binstall we can then use the
filters or the search in Process monitor to
hopefully find interesting things it did.
Like accessing the registry or creating a
file.
And so after a bit of digging we can also
discover here the dropped dll location.
I also tried API monitor and selected a few
possibly itnersting APIs such as file system
or networking stuff.
And then I wanted to launch and attach to
the binstall .exe.
But it didn’t really work and crashed.
But trying out different attach methods I
found one that works.
And so API monitor recorded all the Windows
APIs that binstall was using and we selected
to trace.
And also here with a bit of digging we can
find the file it creates.
The browserassist.dll.
With peid we can also investigate the dropped
dll.
And this one looks like a regular binary.
So not C#.
And the extra information checks also think
that it doesn’t look encrypted.
Great.
We can also throw it into the ida free version
here and check a bit the strings.
Here are references to typical HTTP header
values.
Content-type, encoding, POST, GET and so forth.
So again it makes sense that it does something
with the browser.
Now I was confused why the dll was dropped
into the internet explorer folder, so I actually
thought maybe it does infect IE.
And when I opened the internet explorer, I
noticed this weird smiley face.
Send a smile, send a frown?
Did the malware inject that?
That’s funny.
Mhmh.. it appears to fake a Internet Explored
feedback form.
That’s quite interesting.
Let’s have a quick look at the privacy statement.
Mhmh… that looks like the normal microsoft
privacy statement?
Ehhmmm….
Oh… whaaat?
This is not the challenge?
This is actually in the Internet Explorer?
Let’s pretend this didn’t happen.
We move on.
Now in the meantime it was kinda hard to avoid
spoilers on reddit and twitter becasue people
talked about the challenges publicly.
SHAME YOU!
Just kidding, I think it’s great that you
help eachother.
And somewhere I read that you should use an
older firefox version, something like firefox
version 40, so that’s why I also downloaded
that one.
In that moment I was kinda annoyed that it
would only work with older firefox versions
and was wondering how you could even figure
that out.
Anyway… so I opened the old firefox version
and now I was wondering what to do.
There didn’t appear to be anything obviously
different, but it’s a malware right?
So it would do something a bit more sneaky.
Next I thought I could try to trace calls
to the browserassist.dll in case firefox does
anything with it.
You can add external dlls to the API monitor,
but it says that it doesn’t export any functions.
So the .dll appears to not work like a typical
.dll with exported functions… mhmh… next
I decided to attach the x32 debugger to firefox.
And I wasn’t really sure how to approach
it, but I thought a good start would be to
see if the dll is loaded somewhere in memory,
so I checked the Memory Map tab and also found
it in there.
Over her eyou also se a description of the
different segments, but for the debugger the
text segment, the code is obviously the most
interesting.
This lead me to this area here.
So that’s kinda like the entry point of
the dll, I guess.
And because I didn’t know what it does I
simply set a breakpiint at the start and end
of it.
But it didn’t trigger right away when using
the browser, only when I restarted it.
And while pressing the button to continue
execution after that breakpoint, I noticed
that this code was executed quite a lot on
load.
And I happen to notice some ascii strings
being referenced at some point earlier on
the stack.
This is the stack view here.
That’s just memory that’s still around.
For example I saw an injects and content string.
So while I kept doing this continue break
continue break thing, and looking at the stack,
eventually I noticed this json data…
Code, addCmd.
After.
askPassword.
Ont he path js/view.js?
On the host *flare-on.com?
What?
That looks like a filter.
It applies to all flare-on.com domains, includign
subdomains.
And js/views.js is obviously a javascript
file.
So I went into the browser, went to flare-on.com
where we had this simple command line interface,
opened js/views.js and noticed some very suspicious
javascript.
I mean that looks very obfuscated.
So I opened up the same javascript file on
my regular host chrome browser and compared
it.
And holy cat.
Look at the difference.
The malware in firefox appears to have injected
javascript into this script.
In theory this could be now injecting ads
or a script to steal your credit car dinfo
or so.
But this challenge apparently added an askPassword
function.
So clearly this comamndline interface was
extended with some functionality, but what
exactly?
I just randomly tried some stuff but it didn’t
work.
But askPassword is a javascript function,
so we can open the developer tools and just
directly call it.
Now the function itself was defined inside
of com.fireye.flareon.view.
So here is the function.
When we call it, we see that we are now asked
to enter a password.
And when we enter something, we get a su,
authentication failure… ahhh..
So su is the secret command.
Switch user.
So now we need to find the password.
By looking around the other javascript files
I noticed a controller.js which also had additional
code injected.
A cp function which seems to be called when
the password is Entered.
We can also set a breakpoint in cp, then trgger
su and enter a password.
And here we go.
So we see that p in this case is the password
we entered.
The first check is if the length is 10.
So we know the password must be 10 characters
long.
And then we check the first character.
The first character xored with 16 must result
in 123.
Because it’s xor, we can simply xor 123
with 16, and the result will be the first
valid character of our password.
And peaking ahead we can see that there are
similar rules like that for all other characters
of the password.
So I copied the javascript code into a new
html file, to more easily work on it and cleaned
up the if-case a bit.
But then we quickly reach some of these functions.
So the 5th character is equal to an integer
which is returned by this function.
If you carefully check how far this function
spans, you can just copy the whole thing,
let it evaluate, and this is the result.
The whole thing is just obfuscation for the
number 66.
And there are a few more like that, but same
principle.
Here are all the rules cleaned up.
Oh f.
That’s the problem with using this test
vm.
I think it expired and after a little bit
of time it will, you know, shut down.
This is annoying….
Ok… we are back… here are all the rules
cleaned up.
And then I started to write the reverse of
each of these conditions to create the whole
password.
We can simply use the String function fromCharCode,
which takes ascii integer numbers as parameters
and turns them into a regular ascii string.
So the first character is 16 XOR 123.
The second character is shifted to the left
by two and must be equal to 228.
This means if we shift 228 right by 2, we
get the next valid character.
Character three has a little twist, I will
take about it in second.
Next character was this obfuscatied function
and so it’s just 66.
Fifth character subtracted by 109 will result
in -22.
Which means if you subtract 22 from 109 you
will get the correct password character.
And it’s all kinda simple, but then in the
end we reach two more rules that are a bit
more complex.
Feel free to practice your school level math
to rearrange the equation so that our password
character is alone on one side.
But I’m not in school anymore.
And I’m really lazy.
So I just decided to bruteforce those two
values.
I mean each of them only has less than 128
options.
we are talking ascii characters here.
Oh and the 3ird character was a bit special
because the check is doing here a shift right.
Which means the lower bits of that number
will be lost.
So 14 is the result of a shift right, which
means if we shift the 14 back, we don’t
know what the lower bits were.
And up here we do the reverse.
We shift the bits up, but then remove them
with %255, so now only the lower bits remain.
So based on these two values you can easily
assemble all bits of the whole ascii number.
But again, I’m lazy.
I just brute force it too.
I clean up a bit more and here is the final
script.
If we find the correct password I alert it,
and otherwise just return false.
And then I have three nested for loops, each
one is responsible for one of the three unknown
characters.
And then I just open that file in the browser,
and basically instantly it finds the correct
password.
Awesome.
We can copy it now, execute su, enter it and
BOOM!.
We are root.
Awesome……….
Right?...
ehm… how do we get the flag now?
I was hoping this was it?
Goddamit.
After a short moment of rage I tried to approach
it again with logic and saw that when we enter
the password correct, it sets the root variable
to 1.
So I searched the sources for location where
this variable is used.
And I find one location here.
And scrolling up we can see it’s in the
function changeDirectory.
So that’s interesting.
The other aprt in the if case where it checks
for root is again obfuscated.
When we carefully copy that out again and
evaluate it, it evaluates to “key”...
sooooo… let’s try that.
Let’s try to cd to key.
Oh wow that works.
We are now in key.
And as we learned in the first video, we can
enter “ls”.
Urgh… what is that… so first time I saw
that I was a bit shocked, but I think I screwed
up some internal state.
Because I had the clever idea to refresh the
browser and do it again, on a clean session
where I didn’t debug, and now it works.
We get the flag.
Command Injection.
Let’s submit the flag and we are done…
awesome.
Oh and btw.
At the end I checked also the latest version
of firefox, and the malicious javascript was
also injected there.
So the spoiler or tip to use an old firefox
version wasn’t actually necessary.
Eeehhh…
LiveOverflow from the future again.
I was just editing this part, happy that I’m
almost done and then I realized.
Wait a moment.
Could it be that the js file was just locally
cached and the new firefox used the old firefox’s
cache?
So here is the old firefox, showing the injected
js.
Then I open the new firefox, open that js
file and we also see the injected JS.
But now I force a refresh with CTRL+SHIFT
R and boom.
File is actually loaded and the injection
is gone.
I first thought not to include that part in
the video, but I thought it’s quite interesting
that the new browser version 60 was able to
still use the cache written by the older version.
AND this also means another question stands.
How could you have figured out that you needed
an older version.
Were there any references in the dll to that?
Please let me know in the comments.
﻿It is time to get serious.
Reverse Engineering isn’t about toys and
games.
Sometimes it’s about malicious software.
I recommend you run this next challenge in
a VM or someone else’s computer you have
gained access to, especially if they are a
Firefox user.
Okay, this time I needed to get a VM.
And I saw that they also offer this Flare
VM which is like the Kali Linux of Windows
Malware Analysis.
And because I have no clue, I go with that.
For this I used a free Windows Test VM and
then executed the Flare installer to install
all tools.
The challenge description is hinting at malicious
software and itt may target Firefox?
So I also install firefox.
And then we can get started
Before we head into it, I have to say again.
I have very little experience with windows.
I would say about myself, that “I have no
clue what I am doing”.
Of course that is not completly true.
You can’t go a few years in this field without
picking up some knowledge over time.
Actually my very first introduction into reverse
engineering and exploitation WAS with windows,
namely a friend who introduced me to game
cracking with olly debugger and then the corelan
and lena tutorials.
And generally by having a more abstract computer
science knowledge and a basic understanding
of how computers work, I don’t feel completely
lost.
I have a rough idea what I want to do, and
I can somehow figure it out.
I just very much lack detailed technical knowledge
and experience.
for example I have very limited knowledge
about the windows APIs.
And I only know a FEW popular TOOLS.
And so I will be a lot more inefficient and
my approach is a lot less structured than
usual.
But let’s learn together and share your
tips in the comments.
So here we have the binary.
If you forgot to turn off windows defender,
then windows will actually detect it as malware
and then remove it.
So make sure to deal with that.
Because I’m unsure how to approach this
I decided to throw it into virus total.
Of course somebody else did that before.
But I’m not really interested in what tool
flagged this as malware, I was actually interested
in the file details tab.
That one provides a good first quick overview
over the binary, without executing it yourself.
So binstall is a browser assitant installer,
which would match with the firefox hint in
the description.
And it appears to be .net, so maybe another
c# program?
We can also go on the comments tab where other
plattform analysis tools posted their results.
For example we can checkout the joe sandbox
result.
That service appears to run the binary and
record what it does.
It also labeled it malicious.
And here are some great first hints.
It creates an undocumented autostart registry
key.
And it drops a PE file.
PE file is a regular windows binary file.
And you can see it drops a browserassist.dll.
But into the Internet Explorer folder?
Not firefox?
Mhmh..
There is a lot more nice information there,
but let’s move into our own VM.
So Flare installed a lot of tools in various
folders.
Disassemblers, debuggers, decompilers and
other utility tools.
One of the first tools that were ever showed
to me wa PEID, so I use that again.
It’s a tool to detect what kind of binary
it is.
And for binstall it detects that it’s a
C# .net binary.
Extra information will also show some guesses,
that the binary might be packed, so parts
of it might be encrypted.
Because it’s C# we can also trhow it into
IlSpy again, but you can quickly see it got
obfuscated.
So while all the names are gone, you can still
click on them and follow their references,
but also the functions them selve appear to
implement decryption or deobfuscation routines.
So not something we want to really analyse
if we don’t have to.
And we know it drops a .dll anyway, so it’s
probably also not important.
Nontheless I was playing around a bit with
it a bit.
And so I used Process Monitor to monitor all
events on the system as well as checking out
API monitor to monitor all calls.
So when running binstall we can then use the
filters or the search in Process monitor to
hopefully find interesting things it did.
Like accessing the registry or creating a
file.
And so after a bit of digging we can also
discover here the dropped dll location.
I also tried API monitor and selected a few
possibly itnersting APIs such as file system
or networking stuff.
And then I wanted to launch and attach to
the binstall .exe.
But it didn’t really work and crashed.
But trying out different attach methods I
found one that works.
And so API monitor recorded all the Windows
APIs that binstall was using and we selected
to trace.
And also here with a bit of digging we can
find the file it creates.
The browserassist.dll.
With peid we can also investigate the dropped
dll.
And this one looks like a regular binary.
So not C#.
And the extra information checks also think
that it doesn’t look encrypted.
Great.
We can also throw it into the ida free version
here and check a bit the strings.
Here are references to typical HTTP header
values.
Content-type, encoding, POST, GET and so forth.
So again it makes sense that it does something
with the browser.
Now I was confused why the dll was dropped
into the internet explorer folder, so I actually
thought maybe it does infect IE.
And when I opened the internet explorer, I
noticed this weird smiley face.
Send a smile, send a frown?
Did the malware inject that?
That’s funny.
Mhmh.. it appears to fake a Internet Explored
feedback form.
That’s quite interesting.
Let’s have a quick look at the privacy statement.
Mhmh… that looks like the normal microsoft
privacy statement?
Ehhmmm….
Oh… whaaat?
This is not the challenge?
This is actually in the Internet Explorer?
Let’s pretend this didn’t happen.
We move on.
Now in the meantime it was kinda hard to avoid
spoilers on reddit and twitter becasue people
talked about the challenges publicly.
SHAME YOU!
Just kidding, I think it’s great that you
help eachother.
And somewhere I read that you should use an
older firefox version, something like firefox
version 40, so that’s why I also downloaded
that one.
In that moment I was kinda annoyed that it
would only work with older firefox versions
and was wondering how you could even figure
that out.
Anyway… so I opened the old firefox version
and now I was wondering what to do.
There didn’t appear to be anything obviously
different, but it’s a malware right?
So it would do something a bit more sneaky.
Next I thought I could try to trace calls
to the browserassist.dll in case firefox does
anything with it.
You can add external dlls to the API monitor,
but it says that it doesn’t export any functions.
So the .dll appears to not work like a typical
.dll with exported functions… mhmh… next
I decided to attach the x32 debugger to firefox.
And I wasn’t really sure how to approach
it, but I thought a good start would be to
see if the dll is loaded somewhere in memory,
so I checked the Memory Map tab and also found
it in there.
Over her eyou also se a description of the
different segments, but for the debugger the
text segment, the code is obviously the most
interesting.
This lead me to this area here.
So that’s kinda like the entry point of
the dll, I guess.
And because I didn’t know what it does I
simply set a breakpiint at the start and end
of it.
But it didn’t trigger right away when using
the browser, only when I restarted it.
And while pressing the button to continue
execution after that breakpoint, I noticed
that this code was executed quite a lot on
load.
And I happen to notice some ascii strings
being referenced at some point earlier on
the stack.
This is the stack view here.
That’s just memory that’s still around.
For example I saw an injects and content string.
So while I kept doing this continue break
continue break thing, and looking at the stack,
eventually I noticed this json data…
Code, addCmd.
After.
askPassword.
Ont he path js/view.js?
On the host *flare-on.com?
What?
That looks like a filter.
It applies to all flare-on.com domains, includign
subdomains.
And js/views.js is obviously a javascript
file.
So I went into the browser, went to flare-on.com
where we had this simple command line interface,
opened js/views.js and noticed some very suspicious
javascript.
I mean that looks very obfuscated.
So I opened up the same javascript file on
my regular host chrome browser and compared
it.
And holy cat.
Look at the difference.
The malware in firefox appears to have injected
javascript into this script.
In theory this could be now injecting ads
or a script to steal your credit car dinfo
or so.
But this challenge apparently added an askPassword
function.
So clearly this comamndline interface was
extended with some functionality, but what
exactly?
I just randomly tried some stuff but it didn’t
work.
But askPassword is a javascript function,
so we can open the developer tools and just
directly call it.
Now the function itself was defined inside
of com.fireye.flareon.view.
So here is the function.
When we call it, we see that we are now asked
to enter a password.
And when we enter something, we get a su,
authentication failure… ahhh..
So su is the secret command.
Switch user.
So now we need to find the password.
By looking around the other javascript files
I noticed a controller.js which also had additional
code injected.
A cp function which seems to be called when
the password is Entered.
We can also set a breakpoint in cp, then trgger
su and enter a password.
And here we go.
So we see that p in this case is the password
we entered.
The first check is if the length is 10.
So we know the password must be 10 characters
long.
And then we check the first character.
The first character xored with 16 must result
in 123.
Because it’s xor, we can simply xor 123
with 16, and the result will be the first
valid character of our password.
And peaking ahead we can see that there are
similar rules like that for all other characters
of the password.
So I copied the javascript code into a new
html file, to more easily work on it and cleaned
up the if-case a bit.
But then we quickly reach some of these functions.
So the 5th character is equal to an integer
which is returned by this function.
If you carefully check how far this function
spans, you can just copy the whole thing,
let it evaluate, and this is the result.
The whole thing is just obfuscation for the
number 66.
And there are a few more like that, but same
principle.
Here are all the rules cleaned up.
Oh f.
That’s the problem with using this test
vm.
I think it expired and after a little bit
of time it will, you know, shut down.
This is annoying….
Ok… we are back… here are all the rules
cleaned up.
And then I started to write the reverse of
each of these conditions to create the whole
password.
We can simply use the String function fromCharCode,
which takes ascii integer numbers as parameters
and turns them into a regular ascii string.
So the first character is 16 XOR 123.
The second character is shifted to the left
by two and must be equal to 228.
This means if we shift 228 right by 2, we
get the next valid character.
Character three has a little twist, I will
take about it in second.
Next character was this obfuscatied function
and so it’s just 66.
Fifth character subtracted by 109 will result
in -22.
Which means if you subtract 22 from 109 you
will get the correct password character.
And it’s all kinda simple, but then in the
end we reach two more rules that are a bit
more complex.
Feel free to practice your school level math
to rearrange the equation so that our password
character is alone on one side.
But I’m not in school anymore.
And I’m really lazy.
So I just decided to bruteforce those two
values.
I mean each of them only has less than 128
options.
we are talking ascii characters here.
Oh and the 3ird character was a bit special
because the check is doing here a shift right.
Which means the lower bits of that number
will be lost.
So 14 is the result of a shift right, which
means if we shift the 14 back, we don’t
know what the lower bits were.
And up here we do the reverse.
We shift the bits up, but then remove them
with %255, so now only the lower bits remain.
So based on these two values you can easily
assemble all bits of the whole ascii number.
But again, I’m lazy.
I just brute force it too.
I clean up a bit more and here is the final
script.
If we find the correct password I alert it,
and otherwise just return false.
And then I have three nested for loops, each
one is responsible for one of the three unknown
characters.
And then I just open that file in the browser,
and basically instantly it finds the correct
password.
Awesome.
We can copy it now, execute su, enter it and
BOOM!.
We are root.
Awesome……….
Right?...
ehm… how do we get the flag now?
I was hoping this was it?
Goddamit.
After a short moment of rage I tried to approach
it again with logic and saw that when we enter
the password correct, it sets the root variable
to 1.
So I searched the sources for location where
this variable is used.
And I find one location here.
And scrolling up we can see it’s in the
function changeDirectory.
So that’s interesting.
The other aprt in the if case where it checks
for root is again obfuscated.
When we carefully copy that out again and
evaluate it, it evaluates to “key”...
sooooo… let’s try that.
Let’s try to cd to key.
Oh wow that works.
We are now in key.
And as we learned in the first video, we can
enter “ls”.
Urgh… what is that… so first time I saw
that I was a bit shocked, but I think I screwed
up some internal state.
Because I had the clever idea to refresh the
browser and do it again, on a clean session
where I didn’t debug, and now it works.
We get the flag.
Command Injection.
Let’s submit the flag and we are done…
awesome.
Oh and btw.
At the end I checked also the latest version
of firefox, and the malicious javascript was
also injected there.
So the spoiler or tip to use an old firefox
version wasn’t actually necessary.
Eeehhh…
LiveOverflow from the future again.
I was just editing this part, happy that I’m
almost done and then I realized.
Wait a moment.
Could it be that the js file was just locally
cached and the new firefox used the old firefox’s
cache?
So here is the old firefox, showing the injected
js.
Then I open the new firefox, open that js
file and we also see the injected JS.
But now I force a refresh with CTRL+SHIFT
R and boom.
File is actually loaded and the injection
is gone.
I first thought not to include that part in
the video, but I thought it’s quite interesting
that the new browser version 60 was able to
still use the cache written by the older version.
AND this also means another question stands.
How could you have figured out that you needed
an older version.
Were there any references in the dll to that?
Please let me know in the comments.
﻿It is time to get serious.
Reverse Engineering isn’t about toys and
games.
Sometimes it’s about malicious software.
I recommend you run this next challenge in
a VM or someone else’s computer you have
gained access to, especially if they are a
Firefox user.
Okay, this time I needed to get a VM.
And I saw that they also offer this Flare
VM which is like the Kali Linux of Windows
Malware Analysis.
And because I have no clue, I go with that.
For this I used a free Windows Test VM and
then executed the Flare installer to install
all tools.
The challenge description is hinting at malicious
software and itt may target Firefox?
So I also install firefox.
And then we can get started
Before we head into it, I have to say again.
I have very little experience with windows.
I would say about myself, that “I have no
clue what I am doing”.
Of course that is not completly true.
You can’t go a few years in this field without
picking up some knowledge over time.
Actually my very first introduction into reverse
engineering and exploitation WAS with windows,
namely a friend who introduced me to game
cracking with olly debugger and then the corelan
and lena tutorials.
And generally by having a more abstract computer
science knowledge and a basic understanding
of how computers work, I don’t feel completely
lost.
I have a rough idea what I want to do, and
I can somehow figure it out.
I just very much lack detailed technical knowledge
and experience.
for example I have very limited knowledge
about the windows APIs.
And I only know a FEW popular TOOLS.
And so I will be a lot more inefficient and
my approach is a lot less structured than
usual.
But let’s learn together and share your
tips in the comments.
So here we have the binary.
If you forgot to turn off windows defender,
then windows will actually detect it as malware
and then remove it.
So make sure to deal with that.
Because I’m unsure how to approach this
I decided to throw it into virus total.
Of course somebody else did that before.
But I’m not really interested in what tool
flagged this as malware, I was actually interested
in the file details tab.
That one provides a good first quick overview
over the binary, without executing it yourself.
So binstall is a browser assitant installer,
which would match with the firefox hint in
the description.
And it appears to be .net, so maybe another
c# program?
We can also go on the comments tab where other
plattform analysis tools posted their results.
For example we can checkout the joe sandbox
result.
That service appears to run the binary and
record what it does.
It also labeled it malicious.
And here are some great first hints.
It creates an undocumented autostart registry
key.
And it drops a PE file.
PE file is a regular windows binary file.
And you can see it drops a browserassist.dll.
But into the Internet Explorer folder?
Not firefox?
Mhmh..
There is a lot more nice information there,
but let’s move into our own VM.
So Flare installed a lot of tools in various
folders.
Disassemblers, debuggers, decompilers and
other utility tools.
One of the first tools that were ever showed
to me wa PEID, so I use that again.
It’s a tool to detect what kind of binary
it is.
And for binstall it detects that it’s a
C# .net binary.
Extra information will also show some guesses,
that the binary might be packed, so parts
of it might be encrypted.
Because it’s C# we can also trhow it into
IlSpy again, but you can quickly see it got
obfuscated.
So while all the names are gone, you can still
click on them and follow their references,
but also the functions them selve appear to
implement decryption or deobfuscation routines.
So not something we want to really analyse
if we don’t have to.
And we know it drops a .dll anyway, so it’s
probably also not important.
Nontheless I was playing around a bit with
it a bit.
And so I used Process Monitor to monitor all
events on the system as well as checking out
API monitor to monitor all calls.
So when running binstall we can then use the
filters or the search in Process monitor to
hopefully find interesting things it did.
Like accessing the registry or creating a
file.
And so after a bit of digging we can also
discover here the dropped dll location.
I also tried API monitor and selected a few
possibly itnersting APIs such as file system
or networking stuff.
And then I wanted to launch and attach to
the binstall .exe.
But it didn’t really work and crashed.
But trying out different attach methods I
found one that works.
And so API monitor recorded all the Windows
APIs that binstall was using and we selected
to trace.
And also here with a bit of digging we can
find the file it creates.
The browserassist.dll.
With peid we can also investigate the dropped
dll.
And this one looks like a regular binary.
So not C#.
And the extra information checks also think
that it doesn’t look encrypted.
Great.
We can also throw it into the ida free version
here and check a bit the strings.
Here are references to typical HTTP header
values.
Content-type, encoding, POST, GET and so forth.
So again it makes sense that it does something
with the browser.
Now I was confused why the dll was dropped
into the internet explorer folder, so I actually
thought maybe it does infect IE.
And when I opened the internet explorer, I
noticed this weird smiley face.
Send a smile, send a frown?
Did the malware inject that?
That’s funny.
Mhmh.. it appears to fake a Internet Explored
feedback form.
That’s quite interesting.
Let’s have a quick look at the privacy statement.
Mhmh… that looks like the normal microsoft
privacy statement?
Ehhmmm….
Oh… whaaat?
This is not the challenge?
This is actually in the Internet Explorer?
Let’s pretend this didn’t happen.
We move on.
Now in the meantime it was kinda hard to avoid
spoilers on reddit and twitter becasue people
talked about the challenges publicly.
SHAME YOU!
Just kidding, I think it’s great that you
help eachother.
And somewhere I read that you should use an
older firefox version, something like firefox
version 40, so that’s why I also downloaded
that one.
In that moment I was kinda annoyed that it
would only work with older firefox versions
and was wondering how you could even figure
that out.
Anyway… so I opened the old firefox version
and now I was wondering what to do.
There didn’t appear to be anything obviously
different, but it’s a malware right?
So it would do something a bit more sneaky.
Next I thought I could try to trace calls
to the browserassist.dll in case firefox does
anything with it.
You can add external dlls to the API monitor,
but it says that it doesn’t export any functions.
So the .dll appears to not work like a typical
.dll with exported functions… mhmh… next
I decided to attach the x32 debugger to firefox.
And I wasn’t really sure how to approach
it, but I thought a good start would be to
see if the dll is loaded somewhere in memory,
so I checked the Memory Map tab and also found
it in there.
Over her eyou also se a description of the
different segments, but for the debugger the
text segment, the code is obviously the most
interesting.
This lead me to this area here.
So that’s kinda like the entry point of
the dll, I guess.
And because I didn’t know what it does I
simply set a breakpiint at the start and end
of it.
But it didn’t trigger right away when using
the browser, only when I restarted it.
And while pressing the button to continue
execution after that breakpoint, I noticed
that this code was executed quite a lot on
load.
And I happen to notice some ascii strings
being referenced at some point earlier on
the stack.
This is the stack view here.
That’s just memory that’s still around.
For example I saw an injects and content string.
So while I kept doing this continue break
continue break thing, and looking at the stack,
eventually I noticed this json data…
Code, addCmd.
After.
askPassword.
Ont he path js/view.js?
On the host *flare-on.com?
What?
That looks like a filter.
It applies to all flare-on.com domains, includign
subdomains.
And js/views.js is obviously a javascript
file.
So I went into the browser, went to flare-on.com
where we had this simple command line interface,
opened js/views.js and noticed some very suspicious
javascript.
I mean that looks very obfuscated.
So I opened up the same javascript file on
my regular host chrome browser and compared
it.
And holy cat.
Look at the difference.
The malware in firefox appears to have injected
javascript into this script.
In theory this could be now injecting ads
or a script to steal your credit car dinfo
or so.
But this challenge apparently added an askPassword
function.
So clearly this comamndline interface was
extended with some functionality, but what
exactly?
I just randomly tried some stuff but it didn’t
work.
But askPassword is a javascript function,
so we can open the developer tools and just
directly call it.
Now the function itself was defined inside
of com.fireye.flareon.view.
So here is the function.
When we call it, we see that we are now asked
to enter a password.
And when we enter something, we get a su,
authentication failure… ahhh..
So su is the secret command.
Switch user.
So now we need to find the password.
By looking around the other javascript files
I noticed a controller.js which also had additional
code injected.
A cp function which seems to be called when
the password is Entered.
We can also set a breakpoint in cp, then trgger
su and enter a password.
And here we go.
So we see that p in this case is the password
we entered.
The first check is if the length is 10.
So we know the password must be 10 characters
long.
And then we check the first character.
The first character xored with 16 must result
in 123.
Because it’s xor, we can simply xor 123
with 16, and the result will be the first
valid character of our password.
And peaking ahead we can see that there are
similar rules like that for all other characters
of the password.
So I copied the javascript code into a new
html file, to more easily work on it and cleaned
up the if-case a bit.
But then we quickly reach some of these functions.
So the 5th character is equal to an integer
which is returned by this function.
If you carefully check how far this function
spans, you can just copy the whole thing,
let it evaluate, and this is the result.
The whole thing is just obfuscation for the
number 66.
And there are a few more like that, but same
principle.
Here are all the rules cleaned up.
Oh f.
That’s the problem with using this test
vm.
I think it expired and after a little bit
of time it will, you know, shut down.
This is annoying….
Ok… we are back… here are all the rules
cleaned up.
And then I started to write the reverse of
each of these conditions to create the whole
password.
We can simply use the String function fromCharCode,
which takes ascii integer numbers as parameters
and turns them into a regular ascii string.
So the first character is 16 XOR 123.
The second character is shifted to the left
by two and must be equal to 228.
This means if we shift 228 right by 2, we
get the next valid character.
Character three has a little twist, I will
take about it in second.
Next character was this obfuscatied function
and so it’s just 66.
Fifth character subtracted by 109 will result
in -22.
Which means if you subtract 22 from 109 you
will get the correct password character.
And it’s all kinda simple, but then in the
end we reach two more rules that are a bit
more complex.
Feel free to practice your school level math
to rearrange the equation so that our password
character is alone on one side.
But I’m not in school anymore.
And I’m really lazy.
So I just decided to bruteforce those two
values.
I mean each of them only has less than 128
options.
we are talking ascii characters here.
Oh and the 3ird character was a bit special
because the check is doing here a shift right.
Which means the lower bits of that number
will be lost.
So 14 is the result of a shift right, which
means if we shift the 14 back, we don’t
know what the lower bits were.
And up here we do the reverse.
We shift the bits up, but then remove them
with %255, so now only the lower bits remain.
So based on these two values you can easily
assemble all bits of the whole ascii number.
But again, I’m lazy.
I just brute force it too.
I clean up a bit more and here is the final
script.
If we find the correct password I alert it,
and otherwise just return false.
And then I have three nested for loops, each
one is responsible for one of the three unknown
characters.
And then I just open that file in the browser,
and basically instantly it finds the correct
password.
Awesome.
We can copy it now, execute su, enter it and
BOOM!.
We are root.
Awesome……….
Right?...
ehm… how do we get the flag now?
I was hoping this was it?
Goddamit.
After a short moment of rage I tried to approach
it again with logic and saw that when we enter
the password correct, it sets the root variable
to 1.
So I searched the sources for location where
this variable is used.
And I find one location here.
And scrolling up we can see it’s in the
function changeDirectory.
So that’s interesting.
The other aprt in the if case where it checks
for root is again obfuscated.
When we carefully copy that out again and
evaluate it, it evaluates to “key”...
sooooo… let’s try that.
Let’s try to cd to key.
Oh wow that works.
We are now in key.
And as we learned in the first video, we can
enter “ls”.
Urgh… what is that… so first time I saw
that I was a bit shocked, but I think I screwed
up some internal state.
Because I had the clever idea to refresh the
browser and do it again, on a clean session
where I didn’t debug, and now it works.
We get the flag.
Command Injection.
Let’s submit the flag and we are done…
awesome.
Oh and btw.
At the end I checked also the latest version
of firefox, and the malicious javascript was
also injected there.
So the spoiler or tip to use an old firefox
version wasn’t actually necessary.
Eeehhh…
LiveOverflow from the future again.
I was just editing this part, happy that I’m
almost done and then I realized.
Wait a moment.
Could it be that the js file was just locally
cached and the new firefox used the old firefox’s
cache?
So here is the old firefox, showing the injected
js.
Then I open the new firefox, open that js
file and we also see the injected JS.
But now I force a refresh with CTRL+SHIFT
R and boom.
File is actually loaded and the injection
is gone.
I first thought not to include that part in
the video, but I thought it’s quite interesting
that the new browser version 60 was able to
still use the cache written by the older version.
AND this also means another question stands.
How could you have figured out that you needed
an older version.
Were there any references in the dll to that?
Please let me know in the comments.
﻿In this video we will cover heap level 0 from
exploit-exercises.com/protostar.
It’s the heap exploitation introductory
challenge and is very easy.
We again compile this on a Ubuntu 16.04 LTS
version, so basically a modern system, to
see if or how it’s still exploitable.
And spoiler alert, nothing changed for this
challenge, it’s super straight forward.
But I have a special idea for this video and
even if it’s a bit easy for you, you might
want to checkout what else we learn at the
end.
In the previous videos of this series I usually
create the exploit and then think of a way
how to explain and show it to you.
But this is so simple, that I thought it would
be cool if I would instead record myself solving
it, kind of like a blind solve or a speedrun.
But I didn’t try to be super fast but it
was quite straight forward and I include all
the mistakes and pauses I made.
And now we will step through the video and
I explain to you what I have been thinking
in different moments and point out some other
things.
In the top right corner you can also see a
timer that will keep track of how long it
took me in real time.
But before we start doing the exploit let’s
have a look at the code again.
There are two functions winner() and nowinner().
And obviously we have to somehow call winner().
We can also see there are two structs that
get space allocated for them on the heap.
And this fp construct here looks complex,
but you can ignore that weirdness because
when you look in the code it’s clear what
it does.
We set fp to nowinner.
Notice how nowinner has no parantheses, this
means it’s not being called.
This is literally the function pointer and
adding paraentheses would cause a call.
And then later we have those paraentheses
for fp.
And fp has been set to point to nowinner,
so nowinner is executed().
And our goal is it to somehow use the strcpy,
which will overflow the name buffer which
is only 64byte large and overwrite the function
pointer.
So sounds easy.
I start by opening up the binary in gdb.
And do a first test execution, but I run into
a segfault which startled me for a few seconds,
but then I realized I forgot the argument
parameter again.
The strcpy uses the first argument to copy
into name.
Ok now we had a clean execution.
Now I want to set a good breakpoint so I disassemble
main.
I’m quickly scanning the assembler code
here, mainly looking at the different function
calls to figure out what corresponds to what
in the C code.
And at first I was thinking about setting
a breakpoint before or after the strcpy, to
catch the before and after of the overflow,
but in the last moment then figured that I
probably don’t need to look at it this closely,
and I can simply go to the magic position
right away.
The call rdx.
This is calling the function pointer that
contains nowinner().
Ok, so I execute it again and we hit the breakpoint.
Now this challenge is about a heap overflow,
so I first check the virtual memory map of
the process with vmmap.
Here you can see in which memory regions we
have the binary itself with the code and data
segments, we can also see where the stack
is and where shared libraries like libc are
loaded too, and we also have the heap here.
So obviously I want to check out how the heap
looks like.
Examine 32 64bit hex values from the start
of the heap.
I immediately look for the name we entered
as an argument, which was “AAAA”, so here
they are.
And I also immediately look for the function
pointer.
This looks like an address.
Quick sanity check with the disassemble command.
Here is a puts call using this address as
a paremter, and so that is our nowinner string.
So yep, that’s nowinner.
So now we want to overwrite that with winner,
so we need that address.
Here it is.
Next I need to figure out how much we have
to overflow, to do that I simply look at the
addresses to the left.
Address of the start of the name ends in 0x10,
and the function pointer is ath 0x60.
So we have an offset of 0x50.
So now I’m feeling confident and actually
drop out of gdb and hope to have a working
exploit right away.
So I start by writing a short python inline
script to print the exploit string.
Essentially we need a couple of characters
as padding to reach the function pointer and
so I print a few As.
Quick check again how many that was, 0x60-0x10
so we need 0x50.
After that we need the address of winner.
So 0x40, OOPS!
Almost made a mistake - this stil happens
to me sometime, we obviously have to start
with 0xf6, 0x05 and then 0x40.
Because of the endianess.
Now for a sanity and debugging step I pipe
that output into hexdump to see if it is what
I expect.
But then I notice a 0x0a at the end, and that’s
a newline.
Python print will add a newline at the end
which we don’t want.
So now I change the script to use the sys
module instead in order to directly write
a string to stdout, so we don’t have a newline.
And I verify that again with hexdump.
And then I’m basically done and try it on
the target binary.
So the input is passed as argument, so I use
backticks to execute the inner python command,
and the output is then basically replaced
by it and placed here as the arguments.
Level passed!
Awesome!
I executed the winner function().
You see this was super simple.
So when I was writing this script with the
commentary of my recording, I noticed a small
detail that I didn’t think about.
And I actually never thought about before.
So here is the heap output again.
Do you see this data down here?
That is clearly ascii.
And that’s weird, in our program we did
not allocate any string like this on the heap.
So how did this happen?
When you look at this ascii text, then you
will realize it’s in fact the printf output.
But why is that on the heap?
Let’s investigate.
First I thought we could checkout valgrind.
Valgrind is an instrumentation framework for
building dynamic analysis tools.
There are Valgrind tools that can automatically
detect many memory management and threading
bugs, and profile your programs in detail.
I really should use valgrind more often, I
use it wayy to little.
But here is for example the valgrind output
with tracing mallocs enabled.
And then we run our heap0 level.
And we can indeed see here our two mallocs
of the structs we do, but also a malloc we
didn’t do of 1024.
That’s also the only memory that is freed
again.
The mallocs we do have no free.
So why is that happening?
Another interesting output is strace.
Strace traces syscalls.
And while we don’t see mallocs here, because
malloc is just some algorithm and memory managment
implemented in libc, we can see the brk syscall,
which gets the memory from the operating system
in the first place.
So this is where we get memory that will then
be used by libc for the heap.
So if malloc is a libc function, we can also
checkout ltrace, which traces linked dynamic
library function calls.
But oddly enough we only see two mallocs for
the two structs.
Nothing about the mysterious third malloc.
It might not be immediately obvious, but that
is actually already a really good hint that
the mysterious malloc did not happen from
a dynamically linked library call.
Which means, this malloc must have been executed
for example by libc itself.
And valgrind is a bit smarter and also traces
these internal mallocs.
For the third test I create a simple program
that calls puts, so it prints a string.
Because we know the heap did contain the printf
output so it must have to do something with
that.
And then we can debug that program and set
a breakpoint on brk.
Remember brk is the syscall that is called
when a program requests additional virtual
memory, and so this is called when the heap
is set up.
And the heap is not always setup, only if
it is required.
So if we assume printf or puts calls malloc,
it would have to setup the heap first.
Now that’s also why I created this small
test program, because the original heap0 has
obviously regular mallocs before the printf,
which makes it a bit annoying, so this is
a clean example.
On a second note, when you set a breakpoint
with a symbol name like brk, there has to
be a symbol name for it.
And a syscall doesn’t have a symbol name.
A syscall is an asembler interrup instruction
with a number as paramter to indicate which
syscall you want.
But there is a brk symbol, but it’s not
initially found.
You first have to execute the program in order
to load the dynamic library libc, which does
contain a brk symbol.
And infact that is a regular function as a
wrapper around the brk syscall.
So anything inside of libc would not directly
do the syscall interrupt, it would call the
internal brk function.
So that;s why we can easily set a breakpoint
like this.
Long story short we can now continue and hit
that breakpoint and then examine the function
backtrace which tells us which functions have
been called that lead to this brk call.
I clean that up a bit.
So here we go.
And as you can see it starts with IO_puts.
You can also look at the libc code for that
stuff, I just pulled up some mirror of libc
on github, and you can read the code there.
The reason why the function is not called
puts, but IO_puts, eventhough we only use
puts when we call it, has to do with a lot
of C macros in libc.
I find it really difficult to read that code.
For example we know that the next function
has the symbol name _IO_new_file_xsputn, but
that doesn’t show up in the C code.
But there is this similarely called IO_sputn,
which when you look that up leads to a macro
that says that it’s actually IO_Xsputn.
Which itself is another macro that is JUMP2
with __xsputn as the first argument , and
JUMP2 is obviously another macro.
And it just keeps going like that.
Feel free to do that on your own.
But if we trust our trace we can see that
at some point it calls doallocbuffer.
And there is also a comment saying: “Allocate
a buffer if needed”.
So this 1024 byte malloc has to do with the
standard output buffer.
A printf doesn’t immediatly result in a
syscall write, but libc implements a lot of
stuff like this in order to achieve higher
performances by buffering output instead of
waiting for files, or writing a few bigger
chunks instead of a lot of small pieces.
Yeah.
I would consider this a solved mystery.
Just a little excursion into the inner workings
of programs.
I hope you liked that.
See you next week.
﻿With the all the information that you are
being bombarded with when auditing, testing,
reverse engineer and so forth, it’s important
AND natural to look out for patterns.
For example a lot of web applications encode
data in base64.
Sometimes in cookies, sometimes in APIs.
And one thing I immediately notice in base64
strings is “ey!”
Look at this string.
Does it tell you anything?
Well maybe you already can recognise that
it is base64 without having to attempt to
decode it, but anything besides that?
Anything about the data it encodes?
Without having to do a base64 decoding I KNOW
this is going to be JSON data.
You see, JSON starts with a curly brace and
a quote, and that results in e, y
And being able to see that saves time, and
allows you to quickly find interesting data.
Same with debugging binary exploitation challenges.
When you look at a hex memory dump, it is
very overwhelming when you start out.
So many different values.
But eventually you start to learn to see here
patterns.
That is a stack address, I know that because
it’s very similar to the stack pointer and
something you see a lot when doing this stuff.
But also here this fairly random looking data,
I don’t even have to decode values from
it, to see what it is, it is clearly ASCII.
These bytes are in the ascii range.
You can generally see that based of the first
nibble.
Ascii really only goes from around 2-something
to 7-something.
20 is a space.
You might also see soem null bytes and obviously
A or D also for new lines but most characters
are in this area.
So over time your brain develops this intuition
to quickly judge if most of these values look
like ascii.
And so looking for and learning patterns like
this will help you to be much more efficient
when researching something.
﻿With the all the information that you are
being bombarded with when auditing, testing,
reverse engineer and so forth, it’s important
AND natural to look out for patterns.
For example a lot of web applications encode
data in base64.
Sometimes in cookies, sometimes in APIs.
And one thing I immediately notice in base64
strings is “ey!”
Look at this string.
Does it tell you anything?
Well maybe you already can recognise that
it is base64 without having to attempt to
decode it, but anything besides that?
Anything about the data it encodes?
Without having to do a base64 decoding I KNOW
this is going to be JSON data.
You see, JSON starts with a curly brace and
a quote, and that results in e, y
And being able to see that saves time, and
allows you to quickly find interesting data.
Same with debugging binary exploitation challenges.
When you look at a hex memory dump, it is
very overwhelming when you start out.
So many different values.
But eventually you start to learn to see here
patterns.
That is a stack address, I know that because
it’s very similar to the stack pointer and
something you see a lot when doing this stuff.
But also here this fairly random looking data,
I don’t even have to decode values from
it, to see what it is, it is clearly ASCII.
These bytes are in the ascii range.
You can generally see that based of the first
nibble.
Ascii really only goes from around 2-something
to 7-something.
20 is a space.
You might also see soem null bytes and obviously
A or D also for new lines but most characters
are in this area.
So over time your brain develops this intuition
to quickly judge if most of these values look
like ascii.
And so looking for and learning patterns like
this will help you to be much more efficient
when researching something.
﻿A lot of hacking videos on youtube are about
Wifi hacking.
They show how you can use various tools, on
Kali linux, like aircrack or some deauther
to DoS clients.
But I never wanted to do that, I find it quite
boring.
That doesn’t mean that I’m entirely not
interested in wifi hacking, it’s just that
if I would make a video about it, it would
be about one specific attack in detail, how
it works, rather than just how to use a tool.
And so with the recent disclosure for KRACK
- Key Reinstallation Attacks on WPA2, I figured,
that’s the perfect moment to do exactly
that.
“Key Reinstallation Attacks: Forcing Nonce
Reuse in WPA2” by Mathy Vanhoef released
around October 2017, is a paper detailing
a specific protocol flaw.
And I encourage you to read this paper, because
the news around this attack is obviously going
completely insane with sooo much misinformation
going around.
And so if you are actually interested in what
this attack means, how it works, and what
are the actual threats read it from the source.
I know papers can look intimidating, but it’s
often enough to read the “Abstract” and
the “Conclusion” to get a good intuition
for what this is about.
And then you have all the content in between
to go more indepth.
So let’s start with that.
“All protected Wi-Fi networks use the 4-way
handshake to generate a fresh session key.
[...] However, we show that the 4-way handshake
is vulnerable to a key reinstallation
attack.
Here, the adversary tricks a victim into reinstalling
an already-in-use key.
This is achieved by manipulating and replaying
handshake messages.
When reinstalling the key, associated parameters
such as the incremental transmit packet number
(nonce) and
receive packet number (replay counter) are
reset to their initial value.
Our key reinstallation attack also breaks
the PeerKey, group key, and Fast BSS Transition
handshake.
The impact depends on the handshake being
attacked, and the data-confidentiality protocol
in use.
Notably, our attack is exceptionally devastating
against Android 6.0: it forces the client
into using a predictable all-zero encryption
key”
So, there is a lot of information here and
so let’s try to dissect the meaning of this.
“All protected Wi-Fi networks use the 4-way
handshake to generate a fresh session key”.
Figure 2 shows the messages exchanged when
a client connects to an access point.
And of course those initial messages are not
encrypted.
You see that after the 4-way handshake “encrypted
data frames can now be exchanged”.
The fresh session key they were talking about
is the the PTK (the Pairwise Transient Key),
which is derived here.
The PTK is “generated by concatenating the
Pairwise master key, which itself is derived
from basically the password you enter for
the Wifi, the Access Point nonce (ANonce),
you see it here being sent from the access
point to the client and the client nonce (SNonce),
which is generated by the client and sent
to the access point, but that’s not all,
also the access point MAC address, and the
station MAC address is used in the generation
of PTK.
So using this pre-shared secret (the wifi
password) both the client and the server now
know the same Pairwise Transient Key.
And you can already see here what that means
generally for the security.
If anybody else also knows the wifi password,
and observes these nonces being exchanged
they can derive your Pairwise Transient Key
and can decrypt your traffic.
So when you connect to a “secure” wifi
in a hotel, you might not be as secure as
you thought you would be.
But that’s a different issues.
And then there are different protocols to
actually implement the encryption.
For example if TKIP is used then the encryption
algorithm is RC4 and that is basically the
same as WEP, and therefore vulnerable to a
number of similar attacks.
But another option is “the CCMP protocol,
which is AES in
CCM mode (counter mode with CBC-MAC).
[... it is] secure as long as no Initialization
Vector (IV) is repeated under a particular
key.
And the IV here is the nonce.
And the nonce is again constantly incremented
to make sure it will never repeat.
And basically the same is true for the GCMP
protocol, it uses AES-GCM, and is secure as
long as no IV is repeated under a particular
key.
If that sounds weird to you, you could watch
my video “Breaking ECDSA (Elliptic Curve
Cryptography)”.
Of course ECDSA is very strong but there can
be a flaw if it’s not properly implemented,
namely if a fixed value is used for a parameter
instead of a random one.
So very similar in the sense that the security
of a crypto algorithm can be very fragile.
And so for these algorithms, if the IV, the
nonce, is reused for the same key it can probably
be broken.
So you can kinda see where this is going.
Let’s continue reading,
“[...], we show that the 4-way handshake
is vulnerable to a key reinstallation attack.
Here, the adversary tricks a victim into reinstalling
an already-in-use key.
This is achieved by manipulating and replaying
handshake messages.”
Just in case it confuses you what “reinstalling”
or “installing” the key, it basically
just means that the protocol decided “this
is the key we use”.
If we make an analogy how that is implemented
in code, it’s basically just assigning the
key now to the variable “the_key_we_use”.
Ok.
So radio networks, or any other communication
has to handle the case when messages get lost.
And they have to agree how to handle that.
For example retransmitting them.
And so, “[...], because messages may be
lost or dropped, the Access Point will retransmit
message 3 if it did not receive an appropriate
response as acknowledgment.
As a result, the client may receive message
3 multiple times.
Each time it receives this message, it will
reinstall the same session key, and thereby
reset the incremental transmit packet number
(nonce) [...].
We show that an attacker can force these nonce
resets by collecting and replaying retransmissions
of message 3”
“When reinstalling the key, associated parameters
such as the incremental transmit packet number
(nonce) and receive packet number (replay
counter) are reset to their initial value.”
“Depending on which protocol is used, this
allows an adversary to replay, decrypt, and/or
forge packets.”
And so it’s now pretty easy to imagine that
if you can keep resetting the key parameters
some crypto stuff will be f’ed up.
And this is a protocol flaw because the official
specification tells you that message 3 could
be resent and you have to reset the parameters.
Thus resetting the crypto algorithm parameters.
And thus opening the door for certain crypto
attackes depending on which crypto algorithm
is used.
Some are more susceptible than others.
The author also checked the behaviour of different
implementations and it turns out iOS and Windows
both don’t follow the spec and don’t accept
the retransmission of message 3.
And the worst implementation is by some linux
based systems because there is an additional
implementation bug that resets the key to
all zeroes.
So you don’t even have to perform this crypto
attack, limiting you to maybe “only” decryption,
I don’t know.
Because with this flaw you actually now know
the key because all the values are set to
0.
Okay.
There are a lot of technical details and challenges
and nuances that you can read about in the
paper.
I presented it more simplified but hopefully
it’s more accurate than some other news
headlines.
So summarise.
WAP2 uses a 4way handshake where nonces are
exchanged and used together with the wifi
password to generate a key.
This key is then used for encrypting packets.
How it is used depends on the actual crypto
algorithm being used.
A lot of crypto algorithms are very fragile
when certain values are reused.
And the attack presented in this paper is
about forcing a reset of these values - specifically
the nonce which would be constantly incremented
and thus would always be different.
And thus opening the door to perform certain
crypto attacks.
And this is a protocol design flaw.
But additionally, during this research, a
very serious software bug was discovered where
on certain implementations the key was not
just reset to initial parameters, but was
actually set to 0.
So you actually know the key and you don’t
have to perform a crypto attack.
But you know what.
Why don’t read the paper.
You don’t learn hacking when reading security
news headlines or use the tool Mathy Vanhoef
wrote.
Go read the actual research, or at least parts
of it.
﻿In this miniseries I want to explore a hardware
reversing project.
I have this air-conditioner which uses a remote,
and we want to understand how it works.
So in this miniseries I want to reverse engineer
the communication between the remote and the
A/C unit.
It’s not advanced or new in any way, it
was done countless of times already, but if
you have never done any electronics stuff,
I think this is an awesome example to get
started.
I have not done this before either, I just
know theoretically how it should work, so
I want to take you along how I approach this
project.
First we try to understand the behaviour of
the remote and A/C Unit, because from that
we can already infer a lot of information.
And after that we will use some electronics
and build a poor man’s logic analyzer with
an arduino.
I have here this remote with a display, showing
the set temperature and other settings such
as cooling or fan modus and some other stuff.
The first question is how does the click information
on the remote travel to the A/C, and is there
any communication back from the A/C because
we can see the set temperature on the remote
screen.
This is easy to test.
We can simply walk into another room, far
away from the A/C, change a few settings and
then walk back to the main unit and look on
that display.
And we can see that the settings on the main
unit hasn’t changed, but the remote says
something else.
And when we click now another button on the
remote, the A/C unit immediately jumps to
that value.
This already tells as soo much on how the
protocol works.
Not every single click is transmitted alone.
So when I press temperature UP, it doesn’t
send an “UP command”.
It actually transmits the whole state of the
settings.
This means there is some kind of packet, that
is transmitted, that contains all values.
To verify this assumption we can also change
the settings on the unit and see if the remote
changes.
Which it doesn’t.
And as soon as we press something on the remote,
it jumps back to that value.
So this reveals so much about the protocol
already.
It’s one way from the remote to the A/C
unit.
And it seems to be a bigger packet containing
all the settings information.
So how does the remote transmit this information.
Well when we look at the remote we can see
at the front - what looks like any normal
LED.
And you probably_ know that that is an infrared
LED.
Just a quick refresher about the electromagnetic
spectrum.
Not that I claim to know physics in any meaningful
way, but we should have some idea about it..
So visible light is a tiny area of the electromagnetic
radiation.
Our cells just happen to respond to those
wavelengths and our eyes are dark for all
the others.
That’s bad for a few things, so for example
we cannot see dangerous gamma or X rays.
But also good because we can use the non-visible
em spectrum to transmit data.
So your WIFI, bluetooth, mobile, radio is
all just different kinds of electromagnetic
radioation, it just happens to be a different
wavelength our eyes can’t pick up.
And Infrared is also defined as a certain
wavelength, which is just barely out of our
capabilities to see.
Though there are some animals that can see
infrared light.
Also most of our photo sensors in our cameras
react to the wavelength of infrared light,
thus we can use strong Infrared lights to
see in the darkness with cameras.
And we can also point the remote at our phone
camera to see that light.
Uh. mmh…
I can barely see it.
Well, a lot of times cameras use an IR filter,
because humans can’t see Infrared, thus
capturing infrared could falsify the colours
and stuff.
I’m using an iPhone here, and I know that
front facing camera doesn’t have an IR filter,
so we can see it better with that one, and
also if we go into a darker room we can really
see it easily.
So to properly analyse it, because it just
quickly flashes, we need something to capture
this.
The 24 or maybe 60 frames a second of a camera
are way to slow to capture the fast flickering.
So we will build a small circuit to analyse
this.
We need a sensor that reacts to infrared light,
but not to other light.
There are light sensors, so called photo-resistors,
which increases or decreases resistance depending
on the amount of light.
Though this one is calibrated for regular
visible light so it’s no good use to us.
But I have here this IR receiver, which works
more like a transistor.
It has three pins, two pins are basically
the power supply, +5v and ground.
And the third pin is either high or low depending
on if it captures a significant amount of
IR light or not.
I put this here on a so called breadboard.
That is a convinient rapid prototyping plattform.
So for example the long red and blue lines
on the side are all connected in a row.
Which I use for the power supply.
So I connected the IR receiver’s power supply
with those lines.
And the holes in the middle are also connected
in columns but divided in the middle.
So I can plug in the IR here and it will get
the power.
There is this great hobby eletronics platform,
which you probably know called arduino, which
makes it super easy to use by everybody.
I use an arudino compatible board from SainSmart,
because it came in this cheap electronics
tutorial learning box.
But you should definetly check out all those
arduino learning packs and resources.
They are awesome.
Those 50-60$ are worth more than buying a
game.
You learn so much.
Anyhow, this board has some pins and they
are are labelled.
And we can see here a 5V and GND, which stands
for ground pin.
So we can use that to supply the breadboard
with power.
And we can use one of the digital input and
output pins to connect to the third leg of
the IR receiver.
If you have never done this yourself it might
look already a bit complicated, but it’s
really really easy.
You just ahve to do it once yourself.
Here is also the schematic how this setup
looks like.
We have the IR receiver.
It’s connected to ground here and to VCC,
which refers to the power-supply, here.
And the third pin is connected to the digital
pin of this arduino, or sainsmart leonardo
board.
Arduinos have this super easy programming
IDE, where you can program in C and simply
upload the compiled program to the board.
And it just works.
So we want to write some code that reads the
output of the IR receiver so we can analyse
it.
We can take an arduino example, that would
read the state of a button and just modify
it to read the state of the IR receiver.
So there are 2 main functions.
The setup function which initialises the serial
communication, that’s a protocol so the
computer can communicate with the board and
send text.
Out of scope right now, but we will look at
serial some other time.
And we initiate the pin number 8 as an input
pin.
Then the loop function here is like an endless
while loop.
This is what will be executed constantly in
a loop.
And here we want to read the state of the
input pin 8.
And send this input via serial to our computer.
Then we can compile it, we have to make sure
the board is properly recognized with the
software, and then we can push it onto the
board.
Now it’s running there, we can open the
serial console and see the output.
So currently it’s sending only 1s, so the
IR receiver outputs always high, 5V, which
is a digital one, when it’s idle.
And now we point the remote at it and when
we press it, we can see some 0s rushing by.
That’s cool but a bit hard to analyse.
So let’s modify the code to use a so called
trigger.
We can start with a state 0, where we constantly
read the input, and once it drops to a 0 for
the first time, we switch the state to 1,
where we now send the input, including the
microseconds, so we have some time information
as well, to the computer.
Now we push it to the board, wait until it’s
booted, and now we see now input being sent
to the computer.
But if we point now the remote at the IR receiver,
and we press a button, we get the first 0
and now the data is rushing in.
That’s better.
Now we can simply copy this output into a
text file, to analyse.
We can collect now multiple samples, for example
the packet to select farenheit or celsius,
or turning it on and off.
I use jupyter notebooks to work with stuff
like this.
It’s basically python, just with an awesome
interface to do explorative scripts.
I first start by including some important
modules, so we can plot data.
And then we read one of the logged data files
with numpy and specify that the data is comma
seperated.
This will give us a big numpy array.
Now we can extract the microseconds and the
single bits.
Next we can use pyplot to plot this data in
steps.
Looks a bit awkward so let’s play around
a little bit with the limits of the y and
x axis, as well as the figure size of the
plot.
And maybe also cut the data points at some
length, because we only are interested in
the data at the front.
We can now also wrap this into a function
so we can simply call load, with a filename
and get this nice digital logic plot.
Awesome.
Look at this.
This is a great poor mans logic analyzers.
Though we might want to add some points, so
we can see exactly where our datapoints are.
And then we can compare for example celsius
to farenheit packet and the on and off packet.
But how do we read this.
They clearly look similar, so this is not
random wiggling.
This is some kind of real pattern.
This is the infrared LED flickering on and
off in a specific way.
But how the LED flickers is defined in the
protocol.
And somehow we have to understand now how
the protocol works.
So one attack you can do, without knowing
the protocol, is compare multiple packets
of the same command, like multiple turning
ON packets, and then you would see that it
is always the same.
So there is no crypto, or timestamp, or whatever
involved.
So a replay attack is easily possible.
Without knowing what the bits mean we can
just resend this pattern to perform this action.
Another thing to work out the protocol is
to compare similar packets.
Like celsius and farenheit.
And we notice that some spikes are very close
together and some spikes are far appart.
And we can try to see if this pattern is different
for both of them.
Because farenheit or ceslisu can be represented
by one bit, it’s either 0 or 1, we can infer
from that what a bit 0 or 1 might look like
in this pattern.
Maybe you can pause this video here and try
to extract the single bits from those packets.
But there is a big problem here.
Each single dot is a point where we read the
state of the receiver.
And they are so little compared to the amount
of spikes.
Thus maybe we missed some spikes.
Or some spiked appear wider or thinner even
though they were the same.
So 
this arduino and laptop setup is a great start,
but it’s not very precise.
It is enough to work out the protocol, but
next video I want to show you how you can
do this a little bit more advanced.
And we will start reversing the packets.
﻿The last few videos were already getting really
difficult to follow and required a lot of
concentration and patience to understand them.
So I’m happy that we can now move on to
the networking challenges from exploit-exercises
protostar, which will be a lot easier because
we have to establish some basics first.
Let’s have quick look at networking level
0.
The description says you have to convert strings
to little endian integers.
And this level is very easy, but to fully
understand what’s going on, the code is
not quite enough.
I show you why.
So main calls a function background_process
and passes it a name and the user and group
ID it will run with.
But this function is not a common libc function.
You can also check /etc/passwd for the user
id 999 and you will notice there is no such
user.
This might seem weird but just don’t think
so abstractly about computers.
What does it mean to have a user on a linux
system?
In the end, a user is just an ID, a number
in memory, and for example an owner of a file
just means that this file has this number
as owner set.
Now if the user is listed here in the /etc/passwd
file, linux will be so nice and display the
name instead of the number, but under the
hood it is still just an integer.
So even though there is no name assigned to
that ID, you are still free to use it.
Anyway, back to the code.
The other functions such as serve_forever
and set_io are also not known functions.
And when you look at the includes, you will
notice that it references a common.c file.
So the author of this challenge implemented
a lot of the code in a different file and
we don’t know what it does.
But one function is here, and that is the
run() function.
You can see that it is called at the end of
main().
Run generated a random number, tells us that
you should send that number as little endian.
Then performs a read from a filedescriptor,
in this case from standard input, interprets
this input as a number and compares if it’s
the same as the random number before.
So just a simple test.
As I said earlier, we could solve the challenge
without knowing these unknown functionsbelow
, because just reading the comments and function
names tells us everything we need to know,
but as you know, we are not satisfied on this
channel when we ignore underlying concepts.
We want to understand computers better.
And these functions implement two interesting
concepts that are mentioned here, one is running
the process as a daemon, and the other one
is about networking and sockets.
So how can we figure out what it does?
Well we know already everything we need, to
be able to reverse engineer this.
So let’s start by exploring the behaviour
of the program before digging deeper.
When you try to run the program, nothing happens.
But when you look at the running processes
you can see that net0 is already running.
So let’s quickly switch to the root user
so we cann kill that process and start it
ourselves.
The default root password for this VM is “godmode”.
Now we can kill net0 and we can verify that
it is not running anymore.
So, let’s execute it again.
Nothing happens?
But if we check the processes we can see that
it’s running again.
So what happened?
Let’s kill it again and start it with strace.
So it finishes with an exit but what happens
before?
It seems to open a net0.pid file with write
permissions.
Then it changes the user and group id to 999
with set effective uid and gid.
So this means the process drops it’s root
permissions, which is uid 1 down to user with
id 999.
After that it calls clone().
The manpages says that clone creates a new
process similar to fork.
So this will spawn a new process as a clone,
a copy, of itself.
And the return value is the process ID of
this new process, which is equal to the value
written into the .pid file.
So that file just helps you keeping track
of the new process you created.
And after that the parent process exits and
leaves the child process orphaned.
This is literally referred to as an orphaned
process and because we did this intentionally
we also refer to this now as a daemon.
It’s now a background process.
So what we can do is, we can run strace with
the -f flag, to follow child processes created
instead of staying in the parent process.
When we do that, we see that after the clone
we attached to the new process and in the
background the old process exits.
Then we change directory and open up /dev/null,
which is another special pseudo file that
acts like a blackhole.
And then we dup the stdinput, stdoutput and
stderror of this process, which basically
means we bend all these standard streams to
point into the blackhole.
Basically we just throw away anything.
And then we write the child’s process id
to the .pid file from earlier which had filedescriptor
number 3.
Now the fun part starts, a new socket is created.
A socket is used for network communications
and you can choose what kind of socket you
want with those flags and settings.
But most importantly is then the call to bind,
which attempts to bind this process here to
the port 2999.
Which means that if the operating system receives
a packet that want’s to establish a connection
with this process, it will do so and then
forward the packet with data inside to the
process.
But!, this function call fails because the
address and port is already in use by another
process.
Which makes sense because we called net0 already
way earlier.
So let’s kill the process again and retry
this.
OKAY!
This looks great.
Now we listen on the port we opened and are
waiting for a packet to arrive with the accept
syscall.
So let’s open a second terminal and use
netstat to find this listening process.
And here it is.
On port 2999 the process net0 is listening.
Cool.
Now let’s use netcat to establish a TCP
connection with this port.
This will cause the accept call to return,
because a new connection got established.
And immediatly after accept you see another
call to clone, which creates another process
to now handle this server-client connection.
This way another user can also establish a
connection and doesn’t have to wait until
you are done, because you have now your own
dedicated process.
Also accept returned a new filedescriptor
that references this socket.
So like with regular files you can now perform
read and write with this filedescriptor, like
you would with any other file.
The kernel underneath makes sure to send the
data you write as a TCP packet to the client.
And when it receives data it will make sure
that you can read it from this socket.
So now it will change the std input, output
and error streams from /dev/null to this new
filedescriptor.
And the program can then just read from stdinput
and will read the data you sent it.
And that is what the run function does.
If you compare run with the last two syscalls
we first have a write to stdout which came
from this printf here, and then an fread from
stdin and this is where we are right now.
When we now type a line into netcat, netcat
will send a packet with this text through
the network to the program, the server.
And on the server side you can see that it
read the string you sent to it, and then it
performed the write telling you that it is
the wrong number.
That’s the failed printf in run().
So let’s summarize what the hidden code
is doing.
It first deamonizes by cloning itself and
killing the parent, to become an orphan.
Then it starts listening on port 2999 for
TCP connections.
Once a connection is established, and we will
have a detailed look at the TCP protocol some
other time, it will create another clone of
the process to handle this established connection.
While the parent is ready again to accept
another connection in parallel.
The child process that handles the connection
is now basically just calling run().
So in simple terms you can say, the program
runs as a background process that executes
run() for every client that connects to it.
Awesome!
We understood that.
Now let’s solve the challenge.
First of all we need to get the string representation
of that number.
We can use python for that, specifically the
struct package - which we already used before.
So with struct.pack we can convert a number
to the byte string representation.
But as you can see, the resulting string doesn’t
use characters we can type with the keyboard.
We can print these byte values with echo and
-e, but simply piping this into nc doesn’t
work, because the number is randomized.
But we can use a simple trick.
We can use echo -e, but inside of the quotes
we use backticks to execute cat with a minus,
which simply redirects anything we type to
the output again, and the output is then placed
in the quotes of echo.
So when we now pipe that into netcat, we see
the number and cat is waiting for input, we
use python to convert the number and then
we simply paste the escape string back into
the other terminal, hit enter and then use
CTRL+D, to indicate we are done with input,
which closes cat and echo will send the string
to netcat.
And that works, we get the sucess “thank
you sir/madam message”.
﻿popunders are like popups, just a lot more
annoying.
Their goal is to open a popup in the background
- pop under the current window - so that you
won’t see it until you want to close your
browser and you don’t know which site created
it.
Creating a popunder used to be fairly easy
because there are actually functions called
blur() and focus() which exist solely to focus
an element with focus() or prevent focus,
with blur().
So you would blur() the popup window you open
and focus() the current main window.
And that technique still works in for example
Edge, but Chrome will always try to focus
the new window - thus preventing popunders.
But I did some more research into this and
found a Demo site that actually is able to
create a popunder, which obviously caught
my attention.
This guy even sells a license for a javascript
library that can create popunders in any browser
and ad networks pay good money for it.
So I wanted to know how this script manages
to do a popunder on Chrome 59, as other libraries
can’t do that.
So I started to analyse it.
Let’s check out the demo for the popunder.
I click the link.
And yes indeed, here is a pop-under.
Let’s try to figure out how it’s done.
Obviously one of the first ideas is to look
into the sources, the solution should be right
there.
But shortly after you open the developer tools
a debugger statement triggers a breakpoint.
And you can’t just continue, as this is
constantly called on a timer.
It’s an anti-debugging attempt.
You can disable breakpoints entirely, but
then that also prevents you from setting breakpoints
in the sources themselve and you maybe would
want that for debugging.
So that’s annoying.
But first, let’s look generally at the scripts.
The main page loads a loader.js file, which
loads three other scripts.
Script.js, license.demo.js and demo.js.
Let’s have a quick look at each of those.
Demo.js seems to be the script a potential
client would use.
It configures the BetterJsPop module and allows
developers to react on before and after popup
creation.
Otherwise not much else is there, the real
functionality is probably in BetterJsPop itself.
License.demo could be interesting in how licensing
works, but when you look at the code it’s
heavily obfuscated.
Even if you pretty print it, it’s completely
rubbish code.
And script.js, which is presumably the main
script, looks similar.
There are some easy functions and nonsensical
function which you could clean up, like these
here just return the argument or perform a
simple operation, but even if you clean that
up, it still looks terrible.
And it’s long.
So… how do we figure out what it does.
I will go now over the path I took, but it
would be awesome to hear from you how you
would have approached this, as I’m sure
there are many different techniques to go
about this and I don’t know if I know them
all.
So the first thing I did was mirror the whole
site locally.
I didn’t really test it, but I assumed if
they put so much effort into licensing for
domains and have a demo here, that these scripts
will check the domain they are loaded from
and won’t function properly if loaded from
somewhere else.
So you can’t simply use the demo on your
site.
That’s why I not only downloaded each file
and placed it in the same path, but also modified
/etc/hosts to point the domain to localhost.
This way when I visit the site again, it attempts
to load it from 127.0.0.1.
Which means we can start a simple php or python
server on port 80 and load the site in the
browser.
I make a small modification to the local file,
And remove the embedded video and image and
cleaned up the site.
now you can easily see that it loads this
version instead of the live web version.
And we can verify that the popunder still
works.
So the reason why I want a local mirror is,
so that I have all the freedom of modifying
and playing around with it.
But where do I really start now.
In theory in the end the javascript code will
have to call the main API functions.
functions like window.open and window.setTimeout
or like createElement or appendChild.
But we can’t easily search for this in the
script as these calls are heavily obfuscated,
but we can try to hook or proxy or intercept
those calls.
This way we can learn more about what’s
happening,
I’m using a Proxy object for this.
It’s like a web proxy that sits between
you and your destination, a proxy object in
javascript sits between the caller and the
actual target.
The Proxy object is used to define custom
behavior for fundamental operations (e.g.
property lookup, assignment, enumeration,
function invocation, etc).
So now I’m defining a handler function that
can be used to intercept and log all the function
calls.
And then I can overwrite functions I want,
with a proxied version.
And because we want to learn more about popups,
I wanted to intercept window.open, which is
the function to open a popup.
Oh and I write this code before the loader
loads the other scripts, so I can overwrite
any functions it would use.
I disable the breakpoints and reload the page.
But when I click the link, I don’t see any
call to open, which is super weird.
But In the console I notice two deprecation
warnings.
And one of them is interesting.
[Deprecation] Using the Notification API from
an iframe is deprecated and will be removed
in Chrome version 61, around September 2017.
You should consider requesting permission
from the top-level frame or opening a new
window instead.
Waiiit.
That’s so weird.
First, why the heck does it call the Notification
API, what does it have to do with a popup,
and what’s up with the iframe.
I feel like this must be a key component,
some kind of trick, to achieve a pop under.
Mmhh…
As there are no iframes in the .html code,
let’s see if we can hook the dynamic creation
of those iframes.
It probably uses the createElement, appendChild
and removeChild functions to achieve that.
So let’s proxy these.
As appendChild could be called on any HTML
element I can use the protytpe of the general
Element object to overwrite the function for
all Elements.
If we reload the page now we can already see
that it works with some div.
But let’s see what happens when we click
the link.
Uhhh look at that.
It creates an iframe.
Unfortunately we can’t inspect what the
iframe is for, because later the iframe is
removed with removeChild.
Around this time I started to get really curious
about the stuff that pops up briefly.
So weird.
So I decided to record it in order to slow
down and see what happens.
And when you go step by step you first notice
a popup window being opened in the bottom
right corner, so the user might not really
notice it, then the notification permission
requests pops up and around the same time
an alert box is shown with Chrome PDF viewer.
WTF?
And then they disappear again.
What the heck is going on?
At this point I realized what seems to be
the basic idea behind all of this.
To create a popunder you somehow want to get
the main window back in focus.
And it looks like with this weird combination
of notification requests and alert box you
can get back the focus to the main window.
Knowing this, let’s move on with some debugging.
The remove Child prevents us from inspecting
the iframe, as it is gone by that point.
So Instead of calling removeChild, let’s
overwrite it with a custom function.
We could use the Proxy object and not call
the original function, but I just wanted to
show another method how you can change the
behaviour of something.
A proxy Object is cleaner, but this works
also well.
So now instead of removing an element, we
log the element it tried to remove.
And then let’s try it again.
And it looks like that removeChild was necessary
to remove the notification permission requestv
and the alert box.
Because they stay now here.
But we can also look now into the iframe.
Mh.
It basically just defines a function mkp which
calls window.open.
That’s the trick used why we couldn’t
proxy window.open, because here they will
dynamically create an iframe and use it’s
clean new default window.open function instead.
This is not meant to throw off analysis, it’s
actually a simple popup blocker bypass.
Some basic blockers simply overwrite window.open,
like I attempted to do, and with this trick
you can get back the original window.open
function.
So it’s just a bypass for simple popup blockers.
And you can also check that window.mkp, which
I guess stands for make popup, exists here
in our global scope pointing at window.open.
So clever.
But let’s move on, because a few steps later
there is a second iframe created and if we
look into that one, we see that it executes
a script that requests Notification permissions.
So that’s why we get the deprication warning
here.
Not sure yet why Notification permissions
are requested, but now we know when and where
they do it.
At this point I felt I understand what was
going on more and more and I started playing
around with this knowledge myself, doing simple
tests.
I first opened a new window and then caused
a notification permission request.
And as it turns out, with the notification
request Chrome focuses the main window again.
But once the user clicks this box away, the
focus goes back to the other window.
Two things to observe here.
First, we get focus of the main window, which
is exactly what we want, question is just
how to keep it.
Second problem, how do you remove the Notification
request again automatically.
Both shouldn’t be really possible, but we
know that removeChild with an iframe could
be the solution so we can try that.
First we create the iframe and append it to
the DOM, then we execute the javascript in
the iframe and after that use a timeout to
wait 3 seconds and remove it again.
And testing that shows that it works!
But what’s up with the PDF message we see.
When you think about it, it kinda looks like
an alert box.
So let’s play a bit more with our test and
remove the iframe with the Notification for
now and instead call alert().
And we get the same behaviour.
The main window gains focus because of the
alert, but as soon as the user clicks it away
focus is restored to the popup.
Unfortunately a simple iframe won’t help
here to remove the alert box, because alert
blocks and pauses everything.
But… anyway... we can try to combine those
two now like we saw in the slowed down video.
So we trigger the notification permission
request.
Then we wait a bit with settimeout and trigger
an alert, and then we wait a bit longer and
remove the notification again.
Let’s run it.
Aaand when we now close the alert by handt,
and the netoficiation request is automatically
removed, surprisingly the popup window stays
in the backrgound, the main window kept the
focus!
So the last remaining question is, how do
they now remove the alert box automatically.
It looks like the alert is triggered from
the PDF viewer.
It said “please wait” so I assumed maybe
it happens if you load a huuuge PDF or so,
I did some tests but it didn’t work out.
I also couldn’t find useful info about this
waiting dialog online.
So I decided to take a step back and analyse
the demo further.
And besides the iframes there is another element
created.
An embedded object that defines a data URI
of the media type pdf and base64 encoded.
So we can decode that and find the raw .pdf
file.
Which contains a JavaScript app.alert(“please
wait…”).
Ahhhh, so it also calls alert, just from a
PDF file.
And that’s the trick, because that alert
box can be closed again by removing the embedded
pdf from the DOM.
To not steal anybody elses code, we can also
create our own minimal PDF that calls alert
and convert it to base64.
Now everything falls into place.
We first open a new window, then dynamically
embed a PDF with an app.alert() and create
an iframe that requests Notification permissions.
And after a short moment we then remove the
iframe and the embedded PDF again.
And that’s it.
If it doesn’t work, then maybe you have
the timing wrong.
It’s not a 100% reliable.
So wow.
We created a pop under.
wasn’t this interesting!
Hopefully Chrome will fix this, so I don’t
have to experience these annoying 
popunders anymore.
﻿Now that we played the game to learn more
about the game mechanics in the first episode,
and that we have set up our own server in
the second episode, we can finally start gathering
technical information about the game and start
reverse engineering the client.
The very first lead that we get is provided
on the official website “Our hackable components
all live in their own sandbox, (the net code
and game logic are completely custom), so
you won't have to hack the engine (Unreal
4) itself!”.
That is already very good information and
we will keep that in mind.
So my plan right now is, not immediately to
try to hack anything.
That’s stupid.
I have no clue what to do.
So first I want to get a good overview of
the whole thing.
And then that will lead to information I can
probably use to dig even deeper.
I’m essentially doing information gathering
or reconnaissance.
And sure I will poke certain parts that I
find intriguing and have a quick deeper look.
But it makes no sense wanting to jump into
a hole right away, if you don’t even know
where the holes are.
We also have 3 different clients, a windows,
linux and mac client.
And obviously the code had to be compiled
for each one of them differently.
But also probably not every file is different.
So I thought it might be interesting to look
at the differences and similarities.
To do that I wrote a simple python script
that simply walks the directory tree to get
all files, and then creates hashes of all
of them in order to figure out which files
are identical and which files are unique.
So let’s try this out on the clean client
files downloaded from pwnadventure.com.
And we can see quite a lot of files are identical.
Some .dlls, some config files.
Nothing sounds too interesting.
Maybe you wonder why there are .dlls in the
linux and mac clients, because dlls are for
windows, that’s because this game is based
on mono.
And mono is a Cross platform, open source
.NET framework.
So this allows you basically to write windows
.net applications and compile them to run
on mac and linux.
The unique files are also not that interesting,
you can see different binaries for the different
systems.
So dylib is a dynamic library for mac, while
on linux it’s an .so file a shared object.
But the clients we just compared are essentially
just the launcher.
The actual game is downloaded during the update
process.
So here I have gathered all three updated
game directories, and so let’s run the script
on it as well.
Each fully updated client is around 2gb of
files each, so this will take a little bit
to run.
Hashing those big files takes a few seconds.
Ok so now we have a lot more files to compare.
But they are all pretty boring.
A lot of .ini files, so these are mostly config
files and then also a lot of .pak files, these
are, based on the name, I assume, the actual
3D files and stuff like that.
Though it’s a bit weird to me that other
resource files, such as MapTerrain.pak are
different on each system.
I would have assumed all of them are the same.
But whatever.
Nothing really looks that interesting here.
Though this way you might discover a file
that is called “GameLogic”.
A GameLogic.ddl for windows, a GameLogic.dylib
for mac and a shared object libGameLogic for
linux.
Mhmhm…
But let’s have a bit more dynamic approach.
Like I said in the first video, I will mostly
do this on Linux, so let’s start with that
and execute the Launcher.
But the Launcher is not the real game, so
let’s just hit play and wait for the actual
game to have started.
Once it’s on the main menu, we look at the
process tree with pstree and some flags to
get more details.
Here it is.
PwnAdventure3 has this process ID.
The children of this process here are threads,
ondicated by the curly braces.
And each thread was also given a meaningful
name, whichs quite awesome.
So we have an async I/O thread, some message
passing stuff, the main thread I guess, RT,
remote,(?) or real time(?) heart beat, a render
thread, SDL Timer, and SDL is a framework
often used for games, so no suprise here,
a TaskGraph and I don’t know.
Okay.
Let’s take the process ID and look for it
in the regular process list.
So this binary that was executed lies in the
launcher directory, but then PwnAdventure3_Data,
PwnAdventure3, PwnAdventure3, Binaries, Linux,
and then the file is called PwnAdventure3-Linux_shipping.
Let’s exit the game and see what happens
when we call it directly.
We see some kind of debug or log output, and
the game is actually starting!
So we have just bypassed, so to say, the launcher
or updater and figured out how to directly
start the game.
Next let’s look at the /proc file system.
That’s magical linux stuff, it looks like
folders and files, it feels like folders and
files, but is actually a bit more magic than
that.
However we can explore it like files.
So we go to /proc and the process ID of our
currently executed game.
And with ls we can see the available folders
and files.
For example here you can check all the environment
variables, the commandlines on how the program
was executed, but also the memory map of the
virtual memory of this process.
The output is huge for this game, so let’s
pipe it into `less` so we can scroll more
nicely.
So up here we have our game binary mapped
into memory.
Then some memory areas that are used for something
else, probably a lot of different heaps and
mapped memory of the game files and stuff
like that.
Oh damn there are a LOT.
Let’s just skipt o the end with SHIFT+G.
Ok so here are the addresses of our stack,
the linux dynamic loader and linker and if
we scroll up a bit we find some other dynamic
libraries used by the game.
Lib thread, libdl, and the libGameLogic again.
Interesting! lib rt, libm, and libstdc++.
Oh so we might actually have a game written
in C++ here.
Libcrypto, mhmh.
We can also search for “mono” in here
with / mono Enter.
And then with n and SHIFT+n we can search
for it.
Though it doesn’t appear in this process.
So it looks like only the launcher is written
in .net using the mono framework, the game
itself is not.
Let’s have a quick look at the binaries
themselves.
Let’s start with the “file” command.
So the main game binary here is a 64bit executable,
it’s dynamically linked and stripped.
So no debugging information available.
With ldd we can see which dynamic libraries
it requires.
And here we can also find the libGameLogic.so
again.
Most of the other libraries are system libraries,
so these just offer basic functionality like
threading and crypto functions, but the gameLibrary
most certainly is something that has to do
with the game itself.
Obviously.
If we check the file output for that binary,
we see that it’s a shared object, so not
a standalone executable, it’s also dynamically
linked and is NOT STRIPPED.
Damn.
So that means we get a lot of debug information.
Before we leave the proc filesystem, let’s
quickly check the fd folder.
That folder contains a list of all the currently
opened file descriptors and to which file
they point.
Which means this is a list of all the files
currently accessed by the game.
0,1 and 2 are obviously stdin, stdout and
stderr, so pretty standard, but all the other
ones are other files.
As you can see most of them are the .pak resource
files.
Let’s try to head into the game.
Connection Error.
Failed to load master server certificate.
Oh oh.
I guess it wasn’t that easy to bypass the
updater and make it work?
Let’s see if we can fix that.
We execute the launcher again, head into the
game.
And then verify that now we can connect and
find that server certificate.
Yup. ok… so let’s find the process id
of this process now, by listing all processes
and grepping for pwn, and then we go to cd
/proc/ the process id.
Now let’s see if the process was executed
with any special command line arguments.
We can do that by reading the cmdline file.
But nope, it’s just the binary path, which
is always the first command line argument.
No additional ones used.
Then let’s check the environment variables.
You can also cat that file, but the file is
not pretty, the variables are null byte seperated.
But we can pipe the file into sed and use
a simple replace rule to match all null-bytes
and replace them with newlines.
Now we get a nice formatted output.
But I didn’t see any special environment
variables either.
Also the current working directory is the
same as from where we launched it previously.
So I just played around with it a bit and
simply went into the folder of the binary
and executed it from there.
And then it worked.
Oh well.
There is me trying to be smart.
Anyway.
Let’s do one last thing, and that is investigating
the networking side.
To do that I drop into the game and start
by checking netstat.
With netstat and -a for Showing both listening
and non-listening sockets, as well as -c to
continiously print connections, then grepping
the output for pwn, we see that the game periodically
connects to master.pwn3 on port 3333 and 3002.
Port 3333 is the master server, as specified
in the server.ini file, but port 3002 is actually
the game server, but master and game server
are on the same IP, so instead of showing
game.pwn3 it shows master.pwn3.
Cool.
Next let’s exit the game again and open
wireshark.
Then monitor any interface and filter for
all tcp packets to port 3333 and filter for
only packets that contain a payload.
So where the tcp length is larger than 0.
Then launch the game again.
And I also log in with an account.
If we peak into the content of the packets,
it looks like binary and we can’t immediatly
see what it stands for.
It’s certainly not like HTTP human readable
json data or sth like that.
Howeve ther are a few ascii strings in there,
which is an indication that it might not be
encrypted?
“Ghost in the shellcode”.
That was the name of the CTF this was part
of.
However these packets going from the client
to the server, with all the same size, change
a lot.
So that looks more like encrypted content,
or maybe just compressed.
But we did see some libcrypto earlier, so
yeah, we don’t know yet.
Now let’s switch to port 3002, which we
saw in netstat to be assigned as our game
server.
There is a lot more action here.
The game constantly sends updates to the server
and receives updates.
Of course it’s an MMO so we expect a flood
of packets.
Let’s go back to the start.
Wireshark tells us that these are some weird
packets.
However that doesn’t look right to me at
all.
Wireshark tries to guess and decode certain
protocols, but it looks like it might be something
custom.
Of course layers below, the ethernet, TCP
and IP layer are ok, just the payload of TCP
is probably something custom.
So in order to not get wrong decrypted protcols
I go into the settings and disable all enabled
protocols, and just enable ethernet, ipv4,
and TCP.
Ok that looks less awful now.
So these packets are much smaller, which also
makes sense.
With every little change you want to inform
the server and vice-versa.
All these packets with size 70, are actually
just 2 bytes of data of actual TCP payload.
The values changing here belong to the ethernet,
IP and TCP protocol layer.
For example that part here is a timestamp.
So that probably doesn’t interest us.
We probably want to focus on the data.
And the server just sent us a lot of zeroes.
OK here we have the first time I think, the
client sending something to the server.
Actual ascii data, so that doesn’t look
encrypted either.
But I don’t know what it stands for yet.
\After that it sends a huge bunch of packets
with the same data.
Mhmmh..
Maybe we see nothing happen because nothing
happens in the game?
Let’s go down where there is more action.
Let’s try to do some stuff.
Then we observe the traffic while playing
the game.
Walking around doesn’t immediately show
a change, however jumping triggers a slightly
larger packet.
And actually it seems to trigger two.
One for initiating the jump, and one for getting
back onto the ground.
Because of walking and looking around, we
can also see some slight changes in the previous
packets.
So this is an indication that it’s not encrypted
and it might be simply our position in the
game world.
And jumping added something to it, but a lot
of it stays the same, so it might be something
like “I jumped at this position”.
And “I landed on this position”.
I think we already learned a lot about the
game today.
No worries, I won’t show every little detail
I play around with, but it was important to
me to show you that it’s important to investigate,
and that you can slowly and incrementally
learning more about the game, how it works
and that can be fun too.
Also btw.
Make notes of these things.
While doing this I was writing down what i
did and what I found, because this way I don’t
forget a week later what I already discovered.
Next week, we will open the disassembler.
﻿Now that we played the game to learn more
about the game mechanics in the first episode,
and that we have set up our own server in
the second episode, we can finally start gathering
technical information about the game and start
reverse engineering the client.
The very first lead that we get is provided
on the official website “Our hackable components
all live in their own sandbox, (the net code
and game logic are completely custom), so
you won't have to hack the engine (Unreal
4) itself!”.
That is already very good information and
we will keep that in mind.
So my plan right now is, not immediately to
try to hack anything.
That’s stupid.
I have no clue what to do.
So first I want to get a good overview of
the whole thing.
And then that will lead to information I can
probably use to dig even deeper.
I’m essentially doing information gathering
or reconnaissance.
And sure I will poke certain parts that I
find intriguing and have a quick deeper look.
But it makes no sense wanting to jump into
a hole right away, if you don’t even know
where the holes are.
We also have 3 different clients, a windows,
linux and mac client.
And obviously the code had to be compiled
for each one of them differently.
But also probably not every file is different.
So I thought it might be interesting to look
at the differences and similarities.
To do that I wrote a simple python script
that simply walks the directory tree to get
all files, and then creates hashes of all
of them in order to figure out which files
are identical and which files are unique.
So let’s try this out on the clean client
files downloaded from pwnadventure.com.
And we can see quite a lot of files are identical.
Some .dlls, some config files.
Nothing sounds too interesting.
Maybe you wonder why there are .dlls in the
linux and mac clients, because dlls are for
windows, that’s because this game is based
on mono.
And mono is a Cross platform, open source
.NET framework.
So this allows you basically to write windows
.net applications and compile them to run
on mac and linux.
The unique files are also not that interesting,
you can see different binaries for the different
systems.
So dylib is a dynamic library for mac, while
on linux it’s an .so file a shared object.
But the clients we just compared are essentially
just the launcher.
The actual game is downloaded during the update
process.
So here I have gathered all three updated
game directories, and so let’s run the script
on it as well.
Each fully updated client is around 2gb of
files each, so this will take a little bit
to run.
Hashing those big files takes a few seconds.
Ok so now we have a lot more files to compare.
But they are all pretty boring.
A lot of .ini files, so these are mostly config
files and then also a lot of .pak files, these
are, based on the name, I assume, the actual
3D files and stuff like that.
Though it’s a bit weird to me that other
resource files, such as MapTerrain.pak are
different on each system.
I would have assumed all of them are the same.
But whatever.
Nothing really looks that interesting here.
Though this way you might discover a file
that is called “GameLogic”.
A GameLogic.ddl for windows, a GameLogic.dylib
for mac and a shared object libGameLogic for
linux.
Mhmhm…
But let’s have a bit more dynamic approach.
Like I said in the first video, I will mostly
do this on Linux, so let’s start with that
and execute the Launcher.
But the Launcher is not the real game, so
let’s just hit play and wait for the actual
game to have started.
Once it’s on the main menu, we look at the
process tree with pstree and some flags to
get more details.
Here it is.
PwnAdventure3 has this process ID.
The children of this process here are threads,
ondicated by the curly braces.
And each thread was also given a meaningful
name, whichs quite awesome.
So we have an async I/O thread, some message
passing stuff, the main thread I guess, RT,
remote,(?) or real time(?) heart beat, a render
thread, SDL Timer, and SDL is a framework
often used for games, so no suprise here,
a TaskGraph and I don’t know.
Okay.
Let’s take the process ID and look for it
in the regular process list.
So this binary that was executed lies in the
launcher directory, but then PwnAdventure3_Data,
PwnAdventure3, PwnAdventure3, Binaries, Linux,
and then the file is called PwnAdventure3-Linux_shipping.
Let’s exit the game and see what happens
when we call it directly.
We see some kind of debug or log output, and
the game is actually starting!
So we have just bypassed, so to say, the launcher
or updater and figured out how to directly
start the game.
Next let’s look at the /proc file system.
That’s magical linux stuff, it looks like
folders and files, it feels like folders and
files, but is actually a bit more magic than
that.
However we can explore it like files.
So we go to /proc and the process ID of our
currently executed game.
And with ls we can see the available folders
and files.
For example here you can check all the environment
variables, the commandlines on how the program
was executed, but also the memory map of the
virtual memory of this process.
The output is huge for this game, so let’s
pipe it into `less` so we can scroll more
nicely.
So up here we have our game binary mapped
into memory.
Then some memory areas that are used for something
else, probably a lot of different heaps and
mapped memory of the game files and stuff
like that.
Oh damn there are a LOT.
Let’s just skipt o the end with SHIFT+G.
Ok so here are the addresses of our stack,
the linux dynamic loader and linker and if
we scroll up a bit we find some other dynamic
libraries used by the game.
Lib thread, libdl, and the libGameLogic again.
Interesting! lib rt, libm, and libstdc++.
Oh so we might actually have a game written
in C++ here.
Libcrypto, mhmh.
We can also search for “mono” in here
with / mono Enter.
And then with n and SHIFT+n we can search
for it.
Though it doesn’t appear in this process.
So it looks like only the launcher is written
in .net using the mono framework, the game
itself is not.
Let’s have a quick look at the binaries
themselves.
Let’s start with the “file” command.
So the main game binary here is a 64bit executable,
it’s dynamically linked and stripped.
So no debugging information available.
With ldd we can see which dynamic libraries
it requires.
And here we can also find the libGameLogic.so
again.
Most of the other libraries are system libraries,
so these just offer basic functionality like
threading and crypto functions, but the gameLibrary
most certainly is something that has to do
with the game itself.
Obviously.
If we check the file output for that binary,
we see that it’s a shared object, so not
a standalone executable, it’s also dynamically
linked and is NOT STRIPPED.
Damn.
So that means we get a lot of debug information.
Before we leave the proc filesystem, let’s
quickly check the fd folder.
That folder contains a list of all the currently
opened file descriptors and to which file
they point.
Which means this is a list of all the files
currently accessed by the game.
0,1 and 2 are obviously stdin, stdout and
stderr, so pretty standard, but all the other
ones are other files.
As you can see most of them are the .pak resource
files.
Let’s try to head into the game.
Connection Error.
Failed to load master server certificate.
Oh oh.
I guess it wasn’t that easy to bypass the
updater and make it work?
Let’s see if we can fix that.
We execute the launcher again, head into the
game.
And then verify that now we can connect and
find that server certificate.
Yup. ok… so let’s find the process id
of this process now, by listing all processes
and grepping for pwn, and then we go to cd
/proc/ the process id.
Now let’s see if the process was executed
with any special command line arguments.
We can do that by reading the cmdline file.
But nope, it’s just the binary path, which
is always the first command line argument.
No additional ones used.
Then let’s check the environment variables.
You can also cat that file, but the file is
not pretty, the variables are null byte seperated.
But we can pipe the file into sed and use
a simple replace rule to match all null-bytes
and replace them with newlines.
Now we get a nice formatted output.
But I didn’t see any special environment
variables either.
Also the current working directory is the
same as from where we launched it previously.
So I just played around with it a bit and
simply went into the folder of the binary
and executed it from there.
And then it worked.
Oh well.
There is me trying to be smart.
Anyway.
Let’s do one last thing, and that is investigating
the networking side.
To do that I drop into the game and start
by checking netstat.
With netstat and -a for Showing both listening
and non-listening sockets, as well as -c to
continiously print connections, then grepping
the output for pwn, we see that the game periodically
connects to master.pwn3 on port 3333 and 3002.
Port 3333 is the master server, as specified
in the server.ini file, but port 3002 is actually
the game server, but master and game server
are on the same IP, so instead of showing
game.pwn3 it shows master.pwn3.
Cool.
Next let’s exit the game again and open
wireshark.
Then monitor any interface and filter for
all tcp packets to port 3333 and filter for
only packets that contain a payload.
So where the tcp length is larger than 0.
Then launch the game again.
And I also log in with an account.
If we peak into the content of the packets,
it looks like binary and we can’t immediatly
see what it stands for.
It’s certainly not like HTTP human readable
json data or sth like that.
Howeve ther are a few ascii strings in there,
which is an indication that it might not be
encrypted?
“Ghost in the shellcode”.
That was the name of the CTF this was part
of.
However these packets going from the client
to the server, with all the same size, change
a lot.
So that looks more like encrypted content,
or maybe just compressed.
But we did see some libcrypto earlier, so
yeah, we don’t know yet.
Now let’s switch to port 3002, which we
saw in netstat to be assigned as our game
server.
There is a lot more action here.
The game constantly sends updates to the server
and receives updates.
Of course it’s an MMO so we expect a flood
of packets.
Let’s go back to the start.
Wireshark tells us that these are some weird
packets.
However that doesn’t look right to me at
all.
Wireshark tries to guess and decode certain
protocols, but it looks like it might be something
custom.
Of course layers below, the ethernet, TCP
and IP layer are ok, just the payload of TCP
is probably something custom.
So in order to not get wrong decrypted protcols
I go into the settings and disable all enabled
protocols, and just enable ethernet, ipv4,
and TCP.
Ok that looks less awful now.
So these packets are much smaller, which also
makes sense.
With every little change you want to inform
the server and vice-versa.
All these packets with size 70, are actually
just 2 bytes of data of actual TCP payload.
The values changing here belong to the ethernet,
IP and TCP protocol layer.
For example that part here is a timestamp.
So that probably doesn’t interest us.
We probably want to focus on the data.
And the server just sent us a lot of zeroes.
OK here we have the first time I think, the
client sending something to the server.
Actual ascii data, so that doesn’t look
encrypted either.
But I don’t know what it stands for yet.
\After that it sends a huge bunch of packets
with the same data.
Mhmmh..
Maybe we see nothing happen because nothing
happens in the game?
Let’s go down where there is more action.
Let’s try to do some stuff.
Then we observe the traffic while playing
the game.
Walking around doesn’t immediately show
a change, however jumping triggers a slightly
larger packet.
And actually it seems to trigger two.
One for initiating the jump, and one for getting
back onto the ground.
Because of walking and looking around, we
can also see some slight changes in the previous
packets.
So this is an indication that it’s not encrypted
and it might be simply our position in the
game world.
And jumping added something to it, but a lot
of it stays the same, so it might be something
like “I jumped at this position”.
And “I landed on this position”.
I think we already learned a lot about the
game today.
No worries, I won’t show every little detail
I play around with, but it was important to
me to show you that it’s important to investigate,
and that you can slowly and incrementally
learning more about the game, how it works
and that can be fun too.
Also btw.
Make notes of these things.
While doing this I was writing down what i
did and what I found, because this way I don’t
forget a week later what I already discovered.
Next week, we will open the disassembler.
﻿Now that we played the game to learn more
about the game mechanics in the first episode,
and that we have set up our own server in
the second episode, we can finally start gathering
technical information about the game and start
reverse engineering the client.
The very first lead that we get is provided
on the official website “Our hackable components
all live in their own sandbox, (the net code
and game logic are completely custom), so
you won't have to hack the engine (Unreal
4) itself!”.
That is already very good information and
we will keep that in mind.
So my plan right now is, not immediately to
try to hack anything.
That’s stupid.
I have no clue what to do.
So first I want to get a good overview of
the whole thing.
And then that will lead to information I can
probably use to dig even deeper.
I’m essentially doing information gathering
or reconnaissance.
And sure I will poke certain parts that I
find intriguing and have a quick deeper look.
But it makes no sense wanting to jump into
a hole right away, if you don’t even know
where the holes are.
We also have 3 different clients, a windows,
linux and mac client.
And obviously the code had to be compiled
for each one of them differently.
But also probably not every file is different.
So I thought it might be interesting to look
at the differences and similarities.
To do that I wrote a simple python script
that simply walks the directory tree to get
all files, and then creates hashes of all
of them in order to figure out which files
are identical and which files are unique.
So let’s try this out on the clean client
files downloaded from pwnadventure.com.
And we can see quite a lot of files are identical.
Some .dlls, some config files.
Nothing sounds too interesting.
Maybe you wonder why there are .dlls in the
linux and mac clients, because dlls are for
windows, that’s because this game is based
on mono.
And mono is a Cross platform, open source
.NET framework.
So this allows you basically to write windows
.net applications and compile them to run
on mac and linux.
The unique files are also not that interesting,
you can see different binaries for the different
systems.
So dylib is a dynamic library for mac, while
on linux it’s an .so file a shared object.
But the clients we just compared are essentially
just the launcher.
The actual game is downloaded during the update
process.
So here I have gathered all three updated
game directories, and so let’s run the script
on it as well.
Each fully updated client is around 2gb of
files each, so this will take a little bit
to run.
Hashing those big files takes a few seconds.
Ok so now we have a lot more files to compare.
But they are all pretty boring.
A lot of .ini files, so these are mostly config
files and then also a lot of .pak files, these
are, based on the name, I assume, the actual
3D files and stuff like that.
Though it’s a bit weird to me that other
resource files, such as MapTerrain.pak are
different on each system.
I would have assumed all of them are the same.
But whatever.
Nothing really looks that interesting here.
Though this way you might discover a file
that is called “GameLogic”.
A GameLogic.ddl for windows, a GameLogic.dylib
for mac and a shared object libGameLogic for
linux.
Mhmhm…
But let’s have a bit more dynamic approach.
Like I said in the first video, I will mostly
do this on Linux, so let’s start with that
and execute the Launcher.
But the Launcher is not the real game, so
let’s just hit play and wait for the actual
game to have started.
Once it’s on the main menu, we look at the
process tree with pstree and some flags to
get more details.
Here it is.
PwnAdventure3 has this process ID.
The children of this process here are threads,
ondicated by the curly braces.
And each thread was also given a meaningful
name, whichs quite awesome.
So we have an async I/O thread, some message
passing stuff, the main thread I guess, RT,
remote,(?) or real time(?) heart beat, a render
thread, SDL Timer, and SDL is a framework
often used for games, so no suprise here,
a TaskGraph and I don’t know.
Okay.
Let’s take the process ID and look for it
in the regular process list.
So this binary that was executed lies in the
launcher directory, but then PwnAdventure3_Data,
PwnAdventure3, PwnAdventure3, Binaries, Linux,
and then the file is called PwnAdventure3-Linux_shipping.
Let’s exit the game and see what happens
when we call it directly.
We see some kind of debug or log output, and
the game is actually starting!
So we have just bypassed, so to say, the launcher
or updater and figured out how to directly
start the game.
Next let’s look at the /proc file system.
That’s magical linux stuff, it looks like
folders and files, it feels like folders and
files, but is actually a bit more magic than
that.
However we can explore it like files.
So we go to /proc and the process ID of our
currently executed game.
And with ls we can see the available folders
and files.
For example here you can check all the environment
variables, the commandlines on how the program
was executed, but also the memory map of the
virtual memory of this process.
The output is huge for this game, so let’s
pipe it into `less` so we can scroll more
nicely.
So up here we have our game binary mapped
into memory.
Then some memory areas that are used for something
else, probably a lot of different heaps and
mapped memory of the game files and stuff
like that.
Oh damn there are a LOT.
Let’s just skipt o the end with SHIFT+G.
Ok so here are the addresses of our stack,
the linux dynamic loader and linker and if
we scroll up a bit we find some other dynamic
libraries used by the game.
Lib thread, libdl, and the libGameLogic again.
Interesting! lib rt, libm, and libstdc++.
Oh so we might actually have a game written
in C++ here.
Libcrypto, mhmh.
We can also search for “mono” in here
with / mono Enter.
And then with n and SHIFT+n we can search
for it.
Though it doesn’t appear in this process.
So it looks like only the launcher is written
in .net using the mono framework, the game
itself is not.
Let’s have a quick look at the binaries
themselves.
Let’s start with the “file” command.
So the main game binary here is a 64bit executable,
it’s dynamically linked and stripped.
So no debugging information available.
With ldd we can see which dynamic libraries
it requires.
And here we can also find the libGameLogic.so
again.
Most of the other libraries are system libraries,
so these just offer basic functionality like
threading and crypto functions, but the gameLibrary
most certainly is something that has to do
with the game itself.
Obviously.
If we check the file output for that binary,
we see that it’s a shared object, so not
a standalone executable, it’s also dynamically
linked and is NOT STRIPPED.
Damn.
So that means we get a lot of debug information.
Before we leave the proc filesystem, let’s
quickly check the fd folder.
That folder contains a list of all the currently
opened file descriptors and to which file
they point.
Which means this is a list of all the files
currently accessed by the game.
0,1 and 2 are obviously stdin, stdout and
stderr, so pretty standard, but all the other
ones are other files.
As you can see most of them are the .pak resource
files.
Let’s try to head into the game.
Connection Error.
Failed to load master server certificate.
Oh oh.
I guess it wasn’t that easy to bypass the
updater and make it work?
Let’s see if we can fix that.
We execute the launcher again, head into the
game.
And then verify that now we can connect and
find that server certificate.
Yup. ok… so let’s find the process id
of this process now, by listing all processes
and grepping for pwn, and then we go to cd
/proc/ the process id.
Now let’s see if the process was executed
with any special command line arguments.
We can do that by reading the cmdline file.
But nope, it’s just the binary path, which
is always the first command line argument.
No additional ones used.
Then let’s check the environment variables.
You can also cat that file, but the file is
not pretty, the variables are null byte seperated.
But we can pipe the file into sed and use
a simple replace rule to match all null-bytes
and replace them with newlines.
Now we get a nice formatted output.
But I didn’t see any special environment
variables either.
Also the current working directory is the
same as from where we launched it previously.
So I just played around with it a bit and
simply went into the folder of the binary
and executed it from there.
And then it worked.
Oh well.
There is me trying to be smart.
Anyway.
Let’s do one last thing, and that is investigating
the networking side.
To do that I drop into the game and start
by checking netstat.
With netstat and -a for Showing both listening
and non-listening sockets, as well as -c to
continiously print connections, then grepping
the output for pwn, we see that the game periodically
connects to master.pwn3 on port 3333 and 3002.
Port 3333 is the master server, as specified
in the server.ini file, but port 3002 is actually
the game server, but master and game server
are on the same IP, so instead of showing
game.pwn3 it shows master.pwn3.
Cool.
Next let’s exit the game again and open
wireshark.
Then monitor any interface and filter for
all tcp packets to port 3333 and filter for
only packets that contain a payload.
So where the tcp length is larger than 0.
Then launch the game again.
And I also log in with an account.
If we peak into the content of the packets,
it looks like binary and we can’t immediatly
see what it stands for.
It’s certainly not like HTTP human readable
json data or sth like that.
Howeve ther are a few ascii strings in there,
which is an indication that it might not be
encrypted?
“Ghost in the shellcode”.
That was the name of the CTF this was part
of.
However these packets going from the client
to the server, with all the same size, change
a lot.
So that looks more like encrypted content,
or maybe just compressed.
But we did see some libcrypto earlier, so
yeah, we don’t know yet.
Now let’s switch to port 3002, which we
saw in netstat to be assigned as our game
server.
There is a lot more action here.
The game constantly sends updates to the server
and receives updates.
Of course it’s an MMO so we expect a flood
of packets.
Let’s go back to the start.
Wireshark tells us that these are some weird
packets.
However that doesn’t look right to me at
all.
Wireshark tries to guess and decode certain
protocols, but it looks like it might be something
custom.
Of course layers below, the ethernet, TCP
and IP layer are ok, just the payload of TCP
is probably something custom.
So in order to not get wrong decrypted protcols
I go into the settings and disable all enabled
protocols, and just enable ethernet, ipv4,
and TCP.
Ok that looks less awful now.
So these packets are much smaller, which also
makes sense.
With every little change you want to inform
the server and vice-versa.
All these packets with size 70, are actually
just 2 bytes of data of actual TCP payload.
The values changing here belong to the ethernet,
IP and TCP protocol layer.
For example that part here is a timestamp.
So that probably doesn’t interest us.
We probably want to focus on the data.
And the server just sent us a lot of zeroes.
OK here we have the first time I think, the
client sending something to the server.
Actual ascii data, so that doesn’t look
encrypted either.
But I don’t know what it stands for yet.
\After that it sends a huge bunch of packets
with the same data.
Mhmmh..
Maybe we see nothing happen because nothing
happens in the game?
Let’s go down where there is more action.
Let’s try to do some stuff.
Then we observe the traffic while playing
the game.
Walking around doesn’t immediately show
a change, however jumping triggers a slightly
larger packet.
And actually it seems to trigger two.
One for initiating the jump, and one for getting
back onto the ground.
Because of walking and looking around, we
can also see some slight changes in the previous
packets.
So this is an indication that it’s not encrypted
and it might be simply our position in the
game world.
And jumping added something to it, but a lot
of it stays the same, so it might be something
like “I jumped at this position”.
And “I landed on this position”.
I think we already learned a lot about the
game today.
No worries, I won’t show every little detail
I play around with, but it was important to
me to show you that it’s important to investigate,
and that you can slowly and incrementally
learning more about the game, how it works
and that can be fun too.
Also btw.
Make notes of these things.
While doing this I was writing down what i
did and what I found, because this way I don’t
forget a week later what I already discovered.
Next week, we will open the disassembler.
﻿Now that we played the game to learn more
about the game mechanics in the first episode,
and that we have set up our own server in
the second episode, we can finally start gathering
technical information about the game and start
reverse engineering the client.
The very first lead that we get is provided
on the official website “Our hackable components
all live in their own sandbox, (the net code
and game logic are completely custom), so
you won't have to hack the engine (Unreal
4) itself!”.
That is already very good information and
we will keep that in mind.
So my plan right now is, not immediately to
try to hack anything.
That’s stupid.
I have no clue what to do.
So first I want to get a good overview of
the whole thing.
And then that will lead to information I can
probably use to dig even deeper.
I’m essentially doing information gathering
or reconnaissance.
And sure I will poke certain parts that I
find intriguing and have a quick deeper look.
But it makes no sense wanting to jump into
a hole right away, if you don’t even know
where the holes are.
We also have 3 different clients, a windows,
linux and mac client.
And obviously the code had to be compiled
for each one of them differently.
But also probably not every file is different.
So I thought it might be interesting to look
at the differences and similarities.
To do that I wrote a simple python script
that simply walks the directory tree to get
all files, and then creates hashes of all
of them in order to figure out which files
are identical and which files are unique.
So let’s try this out on the clean client
files downloaded from pwnadventure.com.
And we can see quite a lot of files are identical.
Some .dlls, some config files.
Nothing sounds too interesting.
Maybe you wonder why there are .dlls in the
linux and mac clients, because dlls are for
windows, that’s because this game is based
on mono.
And mono is a Cross platform, open source
.NET framework.
So this allows you basically to write windows
.net applications and compile them to run
on mac and linux.
The unique files are also not that interesting,
you can see different binaries for the different
systems.
So dylib is a dynamic library for mac, while
on linux it’s an .so file a shared object.
But the clients we just compared are essentially
just the launcher.
The actual game is downloaded during the update
process.
So here I have gathered all three updated
game directories, and so let’s run the script
on it as well.
Each fully updated client is around 2gb of
files each, so this will take a little bit
to run.
Hashing those big files takes a few seconds.
Ok so now we have a lot more files to compare.
But they are all pretty boring.
A lot of .ini files, so these are mostly config
files and then also a lot of .pak files, these
are, based on the name, I assume, the actual
3D files and stuff like that.
Though it’s a bit weird to me that other
resource files, such as MapTerrain.pak are
different on each system.
I would have assumed all of them are the same.
But whatever.
Nothing really looks that interesting here.
Though this way you might discover a file
that is called “GameLogic”.
A GameLogic.ddl for windows, a GameLogic.dylib
for mac and a shared object libGameLogic for
linux.
Mhmhm…
But let’s have a bit more dynamic approach.
Like I said in the first video, I will mostly
do this on Linux, so let’s start with that
and execute the Launcher.
But the Launcher is not the real game, so
let’s just hit play and wait for the actual
game to have started.
Once it’s on the main menu, we look at the
process tree with pstree and some flags to
get more details.
Here it is.
PwnAdventure3 has this process ID.
The children of this process here are threads,
ondicated by the curly braces.
And each thread was also given a meaningful
name, whichs quite awesome.
So we have an async I/O thread, some message
passing stuff, the main thread I guess, RT,
remote,(?) or real time(?) heart beat, a render
thread, SDL Timer, and SDL is a framework
often used for games, so no suprise here,
a TaskGraph and I don’t know.
Okay.
Let’s take the process ID and look for it
in the regular process list.
So this binary that was executed lies in the
launcher directory, but then PwnAdventure3_Data,
PwnAdventure3, PwnAdventure3, Binaries, Linux,
and then the file is called PwnAdventure3-Linux_shipping.
Let’s exit the game and see what happens
when we call it directly.
We see some kind of debug or log output, and
the game is actually starting!
So we have just bypassed, so to say, the launcher
or updater and figured out how to directly
start the game.
Next let’s look at the /proc file system.
That’s magical linux stuff, it looks like
folders and files, it feels like folders and
files, but is actually a bit more magic than
that.
However we can explore it like files.
So we go to /proc and the process ID of our
currently executed game.
And with ls we can see the available folders
and files.
For example here you can check all the environment
variables, the commandlines on how the program
was executed, but also the memory map of the
virtual memory of this process.
The output is huge for this game, so let’s
pipe it into `less` so we can scroll more
nicely.
So up here we have our game binary mapped
into memory.
Then some memory areas that are used for something
else, probably a lot of different heaps and
mapped memory of the game files and stuff
like that.
Oh damn there are a LOT.
Let’s just skipt o the end with SHIFT+G.
Ok so here are the addresses of our stack,
the linux dynamic loader and linker and if
we scroll up a bit we find some other dynamic
libraries used by the game.
Lib thread, libdl, and the libGameLogic again.
Interesting! lib rt, libm, and libstdc++.
Oh so we might actually have a game written
in C++ here.
Libcrypto, mhmh.
We can also search for “mono” in here
with / mono Enter.
And then with n and SHIFT+n we can search
for it.
Though it doesn’t appear in this process.
So it looks like only the launcher is written
in .net using the mono framework, the game
itself is not.
Let’s have a quick look at the binaries
themselves.
Let’s start with the “file” command.
So the main game binary here is a 64bit executable,
it’s dynamically linked and stripped.
So no debugging information available.
With ldd we can see which dynamic libraries
it requires.
And here we can also find the libGameLogic.so
again.
Most of the other libraries are system libraries,
so these just offer basic functionality like
threading and crypto functions, but the gameLibrary
most certainly is something that has to do
with the game itself.
Obviously.
If we check the file output for that binary,
we see that it’s a shared object, so not
a standalone executable, it’s also dynamically
linked and is NOT STRIPPED.
Damn.
So that means we get a lot of debug information.
Before we leave the proc filesystem, let’s
quickly check the fd folder.
That folder contains a list of all the currently
opened file descriptors and to which file
they point.
Which means this is a list of all the files
currently accessed by the game.
0,1 and 2 are obviously stdin, stdout and
stderr, so pretty standard, but all the other
ones are other files.
As you can see most of them are the .pak resource
files.
Let’s try to head into the game.
Connection Error.
Failed to load master server certificate.
Oh oh.
I guess it wasn’t that easy to bypass the
updater and make it work?
Let’s see if we can fix that.
We execute the launcher again, head into the
game.
And then verify that now we can connect and
find that server certificate.
Yup. ok… so let’s find the process id
of this process now, by listing all processes
and grepping for pwn, and then we go to cd
/proc/ the process id.
Now let’s see if the process was executed
with any special command line arguments.
We can do that by reading the cmdline file.
But nope, it’s just the binary path, which
is always the first command line argument.
No additional ones used.
Then let’s check the environment variables.
You can also cat that file, but the file is
not pretty, the variables are null byte seperated.
But we can pipe the file into sed and use
a simple replace rule to match all null-bytes
and replace them with newlines.
Now we get a nice formatted output.
But I didn’t see any special environment
variables either.
Also the current working directory is the
same as from where we launched it previously.
So I just played around with it a bit and
simply went into the folder of the binary
and executed it from there.
And then it worked.
Oh well.
There is me trying to be smart.
Anyway.
Let’s do one last thing, and that is investigating
the networking side.
To do that I drop into the game and start
by checking netstat.
With netstat and -a for Showing both listening
and non-listening sockets, as well as -c to
continiously print connections, then grepping
the output for pwn, we see that the game periodically
connects to master.pwn3 on port 3333 and 3002.
Port 3333 is the master server, as specified
in the server.ini file, but port 3002 is actually
the game server, but master and game server
are on the same IP, so instead of showing
game.pwn3 it shows master.pwn3.
Cool.
Next let’s exit the game again and open
wireshark.
Then monitor any interface and filter for
all tcp packets to port 3333 and filter for
only packets that contain a payload.
So where the tcp length is larger than 0.
Then launch the game again.
And I also log in with an account.
If we peak into the content of the packets,
it looks like binary and we can’t immediatly
see what it stands for.
It’s certainly not like HTTP human readable
json data or sth like that.
Howeve ther are a few ascii strings in there,
which is an indication that it might not be
encrypted?
“Ghost in the shellcode”.
That was the name of the CTF this was part
of.
However these packets going from the client
to the server, with all the same size, change
a lot.
So that looks more like encrypted content,
or maybe just compressed.
But we did see some libcrypto earlier, so
yeah, we don’t know yet.
Now let’s switch to port 3002, which we
saw in netstat to be assigned as our game
server.
There is a lot more action here.
The game constantly sends updates to the server
and receives updates.
Of course it’s an MMO so we expect a flood
of packets.
Let’s go back to the start.
Wireshark tells us that these are some weird
packets.
However that doesn’t look right to me at
all.
Wireshark tries to guess and decode certain
protocols, but it looks like it might be something
custom.
Of course layers below, the ethernet, TCP
and IP layer are ok, just the payload of TCP
is probably something custom.
So in order to not get wrong decrypted protcols
I go into the settings and disable all enabled
protocols, and just enable ethernet, ipv4,
and TCP.
Ok that looks less awful now.
So these packets are much smaller, which also
makes sense.
With every little change you want to inform
the server and vice-versa.
All these packets with size 70, are actually
just 2 bytes of data of actual TCP payload.
The values changing here belong to the ethernet,
IP and TCP protocol layer.
For example that part here is a timestamp.
So that probably doesn’t interest us.
We probably want to focus on the data.
And the server just sent us a lot of zeroes.
OK here we have the first time I think, the
client sending something to the server.
Actual ascii data, so that doesn’t look
encrypted either.
But I don’t know what it stands for yet.
\After that it sends a huge bunch of packets
with the same data.
Mhmmh..
Maybe we see nothing happen because nothing
happens in the game?
Let’s go down where there is more action.
Let’s try to do some stuff.
Then we observe the traffic while playing
the game.
Walking around doesn’t immediately show
a change, however jumping triggers a slightly
larger packet.
And actually it seems to trigger two.
One for initiating the jump, and one for getting
back onto the ground.
Because of walking and looking around, we
can also see some slight changes in the previous
packets.
So this is an indication that it’s not encrypted
and it might be simply our position in the
game world.
And jumping added something to it, but a lot
of it stays the same, so it might be something
like “I jumped at this position”.
And “I landed on this position”.
I think we already learned a lot about the
game today.
No worries, I won’t show every little detail
I play around with, but it was important to
me to show you that it’s important to investigate,
and that you can slowly and incrementally
learning more about the game, how it works
and that can be fun too.
Also btw.
Make notes of these things.
While doing this I was writing down what i
did and what I found, because this way I don’t
forget a week later what I already discovered.
Next week, we will open the disassembler.
﻿Now that we played the game to learn more
about the game mechanics in the first episode,
and that we have set up our own server in
the second episode, we can finally start gathering
technical information about the game and start
reverse engineering the client.
The very first lead that we get is provided
on the official website “Our hackable components
all live in their own sandbox, (the net code
and game logic are completely custom), so
you won't have to hack the engine (Unreal
4) itself!”.
That is already very good information and
we will keep that in mind.
So my plan right now is, not immediately to
try to hack anything.
That’s stupid.
I have no clue what to do.
So first I want to get a good overview of
the whole thing.
And then that will lead to information I can
probably use to dig even deeper.
I’m essentially doing information gathering
or reconnaissance.
And sure I will poke certain parts that I
find intriguing and have a quick deeper look.
But it makes no sense wanting to jump into
a hole right away, if you don’t even know
where the holes are.
We also have 3 different clients, a windows,
linux and mac client.
And obviously the code had to be compiled
for each one of them differently.
But also probably not every file is different.
So I thought it might be interesting to look
at the differences and similarities.
To do that I wrote a simple python script
that simply walks the directory tree to get
all files, and then creates hashes of all
of them in order to figure out which files
are identical and which files are unique.
So let’s try this out on the clean client
files downloaded from pwnadventure.com.
And we can see quite a lot of files are identical.
Some .dlls, some config files.
Nothing sounds too interesting.
Maybe you wonder why there are .dlls in the
linux and mac clients, because dlls are for
windows, that’s because this game is based
on mono.
And mono is a Cross platform, open source
.NET framework.
So this allows you basically to write windows
.net applications and compile them to run
on mac and linux.
The unique files are also not that interesting,
you can see different binaries for the different
systems.
So dylib is a dynamic library for mac, while
on linux it’s an .so file a shared object.
But the clients we just compared are essentially
just the launcher.
The actual game is downloaded during the update
process.
So here I have gathered all three updated
game directories, and so let’s run the script
on it as well.
Each fully updated client is around 2gb of
files each, so this will take a little bit
to run.
Hashing those big files takes a few seconds.
Ok so now we have a lot more files to compare.
But they are all pretty boring.
A lot of .ini files, so these are mostly config
files and then also a lot of .pak files, these
are, based on the name, I assume, the actual
3D files and stuff like that.
Though it’s a bit weird to me that other
resource files, such as MapTerrain.pak are
different on each system.
I would have assumed all of them are the same.
But whatever.
Nothing really looks that interesting here.
Though this way you might discover a file
that is called “GameLogic”.
A GameLogic.ddl for windows, a GameLogic.dylib
for mac and a shared object libGameLogic for
linux.
Mhmhm…
But let’s have a bit more dynamic approach.
Like I said in the first video, I will mostly
do this on Linux, so let’s start with that
and execute the Launcher.
But the Launcher is not the real game, so
let’s just hit play and wait for the actual
game to have started.
Once it’s on the main menu, we look at the
process tree with pstree and some flags to
get more details.
Here it is.
PwnAdventure3 has this process ID.
The children of this process here are threads,
ondicated by the curly braces.
And each thread was also given a meaningful
name, whichs quite awesome.
So we have an async I/O thread, some message
passing stuff, the main thread I guess, RT,
remote,(?) or real time(?) heart beat, a render
thread, SDL Timer, and SDL is a framework
often used for games, so no suprise here,
a TaskGraph and I don’t know.
Okay.
Let’s take the process ID and look for it
in the regular process list.
So this binary that was executed lies in the
launcher directory, but then PwnAdventure3_Data,
PwnAdventure3, PwnAdventure3, Binaries, Linux,
and then the file is called PwnAdventure3-Linux_shipping.
Let’s exit the game and see what happens
when we call it directly.
We see some kind of debug or log output, and
the game is actually starting!
So we have just bypassed, so to say, the launcher
or updater and figured out how to directly
start the game.
Next let’s look at the /proc file system.
That’s magical linux stuff, it looks like
folders and files, it feels like folders and
files, but is actually a bit more magic than
that.
However we can explore it like files.
So we go to /proc and the process ID of our
currently executed game.
And with ls we can see the available folders
and files.
For example here you can check all the environment
variables, the commandlines on how the program
was executed, but also the memory map of the
virtual memory of this process.
The output is huge for this game, so let’s
pipe it into `less` so we can scroll more
nicely.
So up here we have our game binary mapped
into memory.
Then some memory areas that are used for something
else, probably a lot of different heaps and
mapped memory of the game files and stuff
like that.
Oh damn there are a LOT.
Let’s just skipt o the end with SHIFT+G.
Ok so here are the addresses of our stack,
the linux dynamic loader and linker and if
we scroll up a bit we find some other dynamic
libraries used by the game.
Lib thread, libdl, and the libGameLogic again.
Interesting! lib rt, libm, and libstdc++.
Oh so we might actually have a game written
in C++ here.
Libcrypto, mhmh.
We can also search for “mono” in here
with / mono Enter.
And then with n and SHIFT+n we can search
for it.
Though it doesn’t appear in this process.
So it looks like only the launcher is written
in .net using the mono framework, the game
itself is not.
Let’s have a quick look at the binaries
themselves.
Let’s start with the “file” command.
So the main game binary here is a 64bit executable,
it’s dynamically linked and stripped.
So no debugging information available.
With ldd we can see which dynamic libraries
it requires.
And here we can also find the libGameLogic.so
again.
Most of the other libraries are system libraries,
so these just offer basic functionality like
threading and crypto functions, but the gameLibrary
most certainly is something that has to do
with the game itself.
Obviously.
If we check the file output for that binary,
we see that it’s a shared object, so not
a standalone executable, it’s also dynamically
linked and is NOT STRIPPED.
Damn.
So that means we get a lot of debug information.
Before we leave the proc filesystem, let’s
quickly check the fd folder.
That folder contains a list of all the currently
opened file descriptors and to which file
they point.
Which means this is a list of all the files
currently accessed by the game.
0,1 and 2 are obviously stdin, stdout and
stderr, so pretty standard, but all the other
ones are other files.
As you can see most of them are the .pak resource
files.
Let’s try to head into the game.
Connection Error.
Failed to load master server certificate.
Oh oh.
I guess it wasn’t that easy to bypass the
updater and make it work?
Let’s see if we can fix that.
We execute the launcher again, head into the
game.
And then verify that now we can connect and
find that server certificate.
Yup. ok… so let’s find the process id
of this process now, by listing all processes
and grepping for pwn, and then we go to cd
/proc/ the process id.
Now let’s see if the process was executed
with any special command line arguments.
We can do that by reading the cmdline file.
But nope, it’s just the binary path, which
is always the first command line argument.
No additional ones used.
Then let’s check the environment variables.
You can also cat that file, but the file is
not pretty, the variables are null byte seperated.
But we can pipe the file into sed and use
a simple replace rule to match all null-bytes
and replace them with newlines.
Now we get a nice formatted output.
But I didn’t see any special environment
variables either.
Also the current working directory is the
same as from where we launched it previously.
So I just played around with it a bit and
simply went into the folder of the binary
and executed it from there.
And then it worked.
Oh well.
There is me trying to be smart.
Anyway.
Let’s do one last thing, and that is investigating
the networking side.
To do that I drop into the game and start
by checking netstat.
With netstat and -a for Showing both listening
and non-listening sockets, as well as -c to
continiously print connections, then grepping
the output for pwn, we see that the game periodically
connects to master.pwn3 on port 3333 and 3002.
Port 3333 is the master server, as specified
in the server.ini file, but port 3002 is actually
the game server, but master and game server
are on the same IP, so instead of showing
game.pwn3 it shows master.pwn3.
Cool.
Next let’s exit the game again and open
wireshark.
Then monitor any interface and filter for
all tcp packets to port 3333 and filter for
only packets that contain a payload.
So where the tcp length is larger than 0.
Then launch the game again.
And I also log in with an account.
If we peak into the content of the packets,
it looks like binary and we can’t immediatly
see what it stands for.
It’s certainly not like HTTP human readable
json data or sth like that.
Howeve ther are a few ascii strings in there,
which is an indication that it might not be
encrypted?
“Ghost in the shellcode”.
That was the name of the CTF this was part
of.
However these packets going from the client
to the server, with all the same size, change
a lot.
So that looks more like encrypted content,
or maybe just compressed.
But we did see some libcrypto earlier, so
yeah, we don’t know yet.
Now let’s switch to port 3002, which we
saw in netstat to be assigned as our game
server.
There is a lot more action here.
The game constantly sends updates to the server
and receives updates.
Of course it’s an MMO so we expect a flood
of packets.
Let’s go back to the start.
Wireshark tells us that these are some weird
packets.
However that doesn’t look right to me at
all.
Wireshark tries to guess and decode certain
protocols, but it looks like it might be something
custom.
Of course layers below, the ethernet, TCP
and IP layer are ok, just the payload of TCP
is probably something custom.
So in order to not get wrong decrypted protcols
I go into the settings and disable all enabled
protocols, and just enable ethernet, ipv4,
and TCP.
Ok that looks less awful now.
So these packets are much smaller, which also
makes sense.
With every little change you want to inform
the server and vice-versa.
All these packets with size 70, are actually
just 2 bytes of data of actual TCP payload.
The values changing here belong to the ethernet,
IP and TCP protocol layer.
For example that part here is a timestamp.
So that probably doesn’t interest us.
We probably want to focus on the data.
And the server just sent us a lot of zeroes.
OK here we have the first time I think, the
client sending something to the server.
Actual ascii data, so that doesn’t look
encrypted either.
But I don’t know what it stands for yet.
\After that it sends a huge bunch of packets
with the same data.
Mhmmh..
Maybe we see nothing happen because nothing
happens in the game?
Let’s go down where there is more action.
Let’s try to do some stuff.
Then we observe the traffic while playing
the game.
Walking around doesn’t immediately show
a change, however jumping triggers a slightly
larger packet.
And actually it seems to trigger two.
One for initiating the jump, and one for getting
back onto the ground.
Because of walking and looking around, we
can also see some slight changes in the previous
packets.
So this is an indication that it’s not encrypted
and it might be simply our position in the
game world.
And jumping added something to it, but a lot
of it stays the same, so it might be something
like “I jumped at this position”.
And “I landed on this position”.
I think we already learned a lot about the
game today.
No worries, I won’t show every little detail
I play around with, but it was important to
me to show you that it’s important to investigate,
and that you can slowly and incrementally
learning more about the game, how it works
and that can be fun too.
Also btw.
Make notes of these things.
While doing this I was writing down what i
did and what I found, because this way I don’t
forget a week later what I already discovered.
Next week, we will open the disassembler.
﻿“What is a security vulnerability?”.
I don’t think that there is an easy answer
to this question.
And so in this video I want to go over a examples,
and share my thoughts.
I’m really curious how you think about it,
because my actual job is to find and report
vulnerabilities, but I don’t really have
a clear definition.
For me it’s actually often just a “feeling”
or an intuition that I have when I determine
if something is a vulnerability or not.
And I hope you find these examples thought
provoking as well.
Let’s start with a CVE.
The Common Vulnerabilities and Exposures (CVE)
system provides a reference-method for publicly
known information-security vulnerabilities
and exposures.
So if something got a CVE assigned, it could
mean that we all agree that it’s a vulnerability.
But have a look at CVE-2018-17793.
This is labeled as a “virtualenv 16.0.0
- Sandbox Escape”, and doesnt make any sense.
virtualenv is a tool to create isolated Python
environments.
The basic problem being addressed is one of
dependencies and versions.
Imagine you have an application that needs
version 1 of LibFoo, but another application
requires version 2.
How can you use both these applications, If
you install everything into /usr/lib/python2.7/site-packages?
Also, what if you can’t install packages
into the global site-packages directory?
For instance, on a shared host.
In all these cases, virtualenv can help you.
It creates an environment that has its own
installation directories, that doesn’t share
libraries with other virtualenv environments.
So this just helps you developing python programs
and I use it ALL the time for the reasons
that were just mentioned.
However I can see that maybe somebody misunderstands
the purpose.
The name VIRTUAL environment, and it creates
an ISOLATED python environment could be misunderstood.
Also we use language like we “enter” the
virtual environment and we sometimes use shells
that indicate when a virtual environment is
active.
So It does sound like a typical virtualisation
technology, which we do use for security reasons.
For example using virtual machines to isolate
malware.
And a virtualbox escape is indeed a vulnerability.
You escalate priviledges from the virtual
machine to the host.
However here you should immediately understand
that this is not the same thing.
This “virtual python environment” in quotation
marks is just a way to structure python projects,
and maybe the language is slightly misleading
to an outsider but of course any code ran
here can do anything.
That’s why also the maintainers were so
frustrated with the report and why so many
people, including me, joked about it.
Just because it’s called virtual environment,
it doesn’t mean there is a virtual machine
with the goal of privilege separation.
So here we don’t have a vulnerability.
Let’s look at a second example.
I do quite a bit of ethereum smart contract
audits.
And in those audits, we of course, look for
typical security issues like reentrancy attacks,
logic bugs, and what ever.
So from the ICOs point of view, they want
to issue a token, sell the token for an initial
amount of money, ICO (initial coin offering)
to raise capital and use it to build something
with that raised money.
And the people buying those tokens hope that
whatever this company builds, will cause the
token later to rise in value.
So from the ICOs point of view they mostly
care about bugs that would allow others to
steal tokens or even to just manipulate their
token balance.
That of course would mean huge financial losses.
However just because this is the ICOs point
of view, and the ICO pays for the audit, this
is not my point of view.
Smart contracts are meant to be decentralized
contracts between different parties.
So to me the point of view of somebody investing
into that token is equally important.
So let’s do an example of a vulnerable that
I find thought provoking.
sometimes an ICO will advertise that a token
has a limited available amount.
A fixed total supply.
But then they might implement a function on
the contract that allows the owner of the
contract, so the ICO, to mint new tokens.
This means they can, at will, just raise the
number of available tokens.
But this contradicts what they promised.
They promised limited availability but actually
implement unlimited availability.
From the point of view of the ICO this is
not really a security vulnerability.
They are the owner, they are in control, why
would they care.
But from the point of view of an investor
who would like to buy these tokens, I think
this is a big issue.
This contract is now very unfair, but the
main issue is the contract contradicts promises
that were made.
So the issue could be titled “contract allows
to mint tokens despite claim of fixed supply”,
and that for me is a vulnerability.
Okay… third example.
A while ago a person wrote me that they found
a session account hijack or something.
I can’t find the original messages so I’m
just telling based on how I remember it going.
the person also included reproduction steps
in the message.
They were going like this:
First, Login to this site.
Then copy the cookie.
Now imagine you go to a different computer,
we use a different browser now.
So we login here with a different account.
You can see it here.
Now we intercept this request again but replace
the cookie from the first account.
BOOM we got access to the other account.
When people send me reports like this I don’t
even know what to say.
Like it’s like DoS attack on my brain because
I try so hard to understand if there is a
vulnerability.
Of course there is none, this just how cookies
work.
And just because you describe reproduction
steps that resulted into access to the other
account doesn’t mean this is a security
issue.
You just literally explained how session cookies
work.
Btw this is the kind of weird crap bugbounty
triage people have to read.
Because people who don’t really understand
it report stuff like that.
And now try to explain to them that this not
an issue.
Which of course I did.
Btw it was a regular PHP session id.
And the person still didn’t quite get it.
And they insisted this is a security issue,
a session or account hijacking.
They were arguing that this is just hex data.
So just 0-9 and a-f.
This is a lot less characters than a full
alphabet from a-z.
They were saying it could be bruteforced.
Of course it cannot be realistically bruteforced
it’s way too long, and thus this isn’t
a security issue but this opens up an interesting
discussions.
Because let’s say the session id is one
character shorter.
Do we now have a Secrutiy issue?
Let’s make it again shorter.
Now?
Now?
Now?
Well it think we can all agree that if the
session id only had two characters, which
means there would only be 256 possible values
for a session id, that this definetly would
be a security issue.
This could be easily bruteforced in a matter
of seconds and you could access the account.
So we have this spectrum here and somewhere
this example moves from being a vulnerability
to it not being a vulnerability.
And I’m sure we all would draw the line
somewhere else, especially in those grey areas
where you can argue with bruteforce speed
limitations and so forth.
Let’s look at a fourth example.
XSS.
So in cross site scripting issues you can
somehow place javascript into a website.
And that javascript can then just do anything
in that site.
So if your victim opens a site with your XSS
payload, the XSS can do anything like stealing
their session cookie.
So one kind of XSS is what we call reflective
XSS.
This happens when part of the URL is directly
echoed back into the content of the page.
Now some browser vendors came up with the
idea to implement a so called XSS auditor.
This is a best effort defense where the browser
tries to look at the URL and check if it contains
something that looks like a javascript XSS
injection and then see if it appears in the
document itself.
And then there are different strategies, the
browser could for example block the whole
page, or just try to block that specific script.
But this creates two challenges.
Because people quickly figured out you can
abuse that.
You could for example take a valid javascript
snippet from the document, place it into the
URL and the browser will think you injected
it.
But of course you didn’t but the browser
doesn’t know that.
So this is a false positive.
So over the years those XSS auditors got refined
but they just can’t be perfect.
Because the browser can only guess and bypasses
are found all the time.
Though in several cases it actually does stop
XSS attacks, which is arguably great for the
user.
However this caused a different problem.
Edge actually stopped and removed the XSS
auditor and just recently we saw another proposal
to also remove the Chrome XSS auditor.
And maybe you wonder why, but let’s read
what it says here.
XSSAuditor Retirement Plan Proposal
We haven't found any evidence the XSSAuditor
stops any XSS, and instead we have been experiencing
difficulty explaining to developers at scale,
why they should fix the bugs even when the
browser says the attack was stopped.
In the past 3 months we surveyed all (google)
internal XSS bugs that triggered the XSSAuditor
and were able to find bypasses to all of them.
[...] Furthermore, we've surveyed security
pentesters and found out some do not report
vulnerabilities unless they can find a bypass
of the XSSAuditor.
And when I retweetetd this one person even
commented.
I used to work for a security vendor.
We used to report XSS even if it got stopped
by the auditor.
A lot of clients got unreasonably angry about
us doing that, so we stopped.
The XSS auditor seems to be a nice first defense,
but it was never meant as a protection or
mitigation against XSS.
XSS is not an issue in the browser, the issue
is the webapp that doesn’t properly encode
output.
Triggering the XSS auditor means your site
is vulnerable to XSS.
Maybe the XSS auditor stops one attack, but
this doesn’t mean it can’t be bypassed
or your users use an old or different browser
without the XSS auditor.
And now it lead to a culture where clients
or the defensive-side in general, say, that
a XSS example that triggers the XSS auditor
is not a vulnerability because it got stopped.
So when people try to report vulnerabilities,
instead of spending there time on finding
more issues, they now have to spend time over
and over again trying to argue why it is still
a vulnerability, or waste time on trying to
bypass the auditor.
Even though the underlaying issue is the webapp
failing to properly encode output.
I always report XSS issues even when they
trigger the XSS auditor.
I don’t think it’s in the client’s best
interest, for me to waste time on trying to
bypass the browser.
My job is it to find vulnerabilities or vulnerability
patterns in the software of a client, so the
client can fix the actual issues.
That’s what they pay for.
I have actually a small related series to
a similar topic.
Checkout my AngularJS playlist where I analyse
a few angularjS sandbox bypasses.
Several people constantly had to find bypasses
to proof to clients that by simply updating
angularjs it doesn’t fix the underlying
issue.
And this was successful, in the end the sandbox
was removed, which allowed easier XSS without
a bypass, because the nice-to-have sandbox
was misused as a security mitigation.
The client should just fix the underlying
issue.
So this XSS example shows that even if it
might not be directly exploitable because
something stopped you, it doesn’t mean it’s
not a vulnerability.
And I have actually even one more example
that goes a step further.
So here is example five.
So there was once a mobile app which communicated
over SSL with the server, and SSL was properly
implemented in this case.
As you know, SSL protects against man in the
middle attacks.
So even if you somehow man in the middle the
network connection you cannot see, nor you
modify the messages exchanged between the
mobile app and the server.
We can call this an ecnrypted TLS tunnel.
Now the messages exchanged were actually encrypted
with AES in CBC mode with PKCS5 Padding.
And it turned out that the server was vulnerable
to a padding oracle attack, because there
were kinda verbose errors when you sent a
corrupted message to the server.
I don’t wanna explain how that attack works
here, but it can be used to recover the encrypted
data.
So if you could somehow get your hands on
an encrypted message sent from the app to
the server, then you could abuse the error
messages to perform a padding oracle attack
and extract the clear-text data.
Is that a vulnerability, that you can decrypt
encrytped data?
Well we had huge discussions about this because
all of that happened inside of a TLS tunnel.
so even if you were able to get a network
man-in-the-middle.
there was no way to actually get to the encrypted
message.
SSL or TLS prevents that.
Now think about that.
If there were no encrypted messages, just
SSL.
I would never report that “it uses SSL,
that protects against MITM, this is safe”).
Though I argue that because the client implemented
this second layer of encryption, they wanted
that additional layer of protection, and breaking
that layer through a padding oracle, is a
vulnerability.
So I report that
So… now we had five different examples that
all have something weird about them.
I hope they really help you to think about
what a vulnerability is and how hard it is
to define what that means.
I don’t think I have a clear definition
and if I would try to come up with one, I
would find exceptions and contradictions easily.
For me it’s actually mostly intuitive and
a “feeling”.
I think I know when something is a vulnerability
and I know when it’s not.
I would tell you that you should just read
vulnerability reports to also learn that,
but actually it’s not easy to build an intuition,
because you would need the intuition in the
first place to filter out the stupid reports.
And I think this is what we see happening.
Due to more and more unexperienced bug bounty
reports we get flooded with vulnerability
reports that are not vulnerabilities.
And sometimes they might even get a bounty,
because the receiving client might not be
able to realize that the report doesn’t
make sense.
And suddenly you normalise a certain type
of finding as it being a valid vulnerability
for a bug bounty.
And this creates this whole weird economic
around it.
When at some point a site or triage team rejects
those reports because they realise it’s
not actually an issue, then you have people
complain and point at previous payouts.
It’s really messy.
All advice I can give is to stay sceptical
about reports and when in doubt ask a few
trustworthy professionals about their opinion.
And hopefully over time you get the experience
you need.
Oh… and we haven’t even talked about severity
ratings yet.
But I don’t really care about that.
I have a hard time to determine if a vulnerability
is low, medium, high or critical in a certain
context, so I don’t think that calculating
a precise score like CVSS makes sense.
I understand why for business tracking reasons
the Common Vulnerability Scoring System exists,
but I don’t know.
I never used it and I feel like something
is forced to be ranked, that cannot realistically
be ranked.
Well… let me know how you feel about this.
And by the way, this is my view in late 2018,
and my opinions on something like this can
change, so keep that in mind before you angrily
explode.
And now let the hunger games begin.
﻿It is time to get serious.
Reverse Engineering isn’t about toys and
games.
Sometimes it’s about malicious software.
I recommend you run this next challenge in
a VM or someone else’s computer you have
gained access to, especially if they are a
Firefox user.
Okay, this time I needed to get a VM.
And I saw that they also offer this Flare
VM which is like the Kali Linux of Windows
Malware Analysis.
And because I have no clue, I go with that.
For this I used a free Windows Test VM and
then executed the Flare installer to install
all tools.
The challenge description is hinting at malicious
software and itt may target Firefox?
So I also install firefox.
And then we can get started
Before we head into it, I have to say again.
I have very little experience with windows.
I would say about myself, that “I have no
clue what I am doing”.
Of course that is not completly true.
You can’t go a few years in this field without
picking up some knowledge over time.
Actually my very first introduction into reverse
engineering and exploitation WAS with windows,
namely a friend who introduced me to game
cracking with olly debugger and then the corelan
and lena tutorials.
And generally by having a more abstract computer
science knowledge and a basic understanding
of how computers work, I don’t feel completely
lost.
I have a rough idea what I want to do, and
I can somehow figure it out.
I just very much lack detailed technical knowledge
and experience.
for example I have very limited knowledge
about the windows APIs.
And I only know a FEW popular TOOLS.
And so I will be a lot more inefficient and
my approach is a lot less structured than
usual.
But let’s learn together and share your
tips in the comments.
So here we have the binary.
If you forgot to turn off windows defender,
then windows will actually detect it as malware
and then remove it.
So make sure to deal with that.
Because I’m unsure how to approach this
I decided to throw it into virus total.
Of course somebody else did that before.
But I’m not really interested in what tool
flagged this as malware, I was actually interested
in the file details tab.
That one provides a good first quick overview
over the binary, without executing it yourself.
So binstall is a browser assitant installer,
which would match with the firefox hint in
the description.
And it appears to be .net, so maybe another
c# program?
We can also go on the comments tab where other
plattform analysis tools posted their results.
For example we can checkout the joe sandbox
result.
That service appears to run the binary and
record what it does.
It also labeled it malicious.
And here are some great first hints.
It creates an undocumented autostart registry
key.
And it drops a PE file.
PE file is a regular windows binary file.
And you can see it drops a browserassist.dll.
But into the Internet Explorer folder?
Not firefox?
Mhmh..
There is a lot more nice information there,
but let’s move into our own VM.
So Flare installed a lot of tools in various
folders.
Disassemblers, debuggers, decompilers and
other utility tools.
One of the first tools that were ever showed
to me wa PEID, so I use that again.
It’s a tool to detect what kind of binary
it is.
And for binstall it detects that it’s a
C# .net binary.
Extra information will also show some guesses,
that the binary might be packed, so parts
of it might be encrypted.
Because it’s C# we can also trhow it into
IlSpy again, but you can quickly see it got
obfuscated.
So while all the names are gone, you can still
click on them and follow their references,
but also the functions them selve appear to
implement decryption or deobfuscation routines.
So not something we want to really analyse
if we don’t have to.
And we know it drops a .dll anyway, so it’s
probably also not important.
Nontheless I was playing around a bit with
it a bit.
And so I used Process Monitor to monitor all
events on the system as well as checking out
API monitor to monitor all calls.
So when running binstall we can then use the
filters or the search in Process monitor to
hopefully find interesting things it did.
Like accessing the registry or creating a
file.
And so after a bit of digging we can also
discover here the dropped dll location.
I also tried API monitor and selected a few
possibly itnersting APIs such as file system
or networking stuff.
And then I wanted to launch and attach to
the binstall .exe.
But it didn’t really work and crashed.
But trying out different attach methods I
found one that works.
And so API monitor recorded all the Windows
APIs that binstall was using and we selected
to trace.
And also here with a bit of digging we can
find the file it creates.
The browserassist.dll.
With peid we can also investigate the dropped
dll.
And this one looks like a regular binary.
So not C#.
And the extra information checks also think
that it doesn’t look encrypted.
Great.
We can also throw it into the ida free version
here and check a bit the strings.
Here are references to typical HTTP header
values.
Content-type, encoding, POST, GET and so forth.
So again it makes sense that it does something
with the browser.
Now I was confused why the dll was dropped
into the internet explorer folder, so I actually
thought maybe it does infect IE.
And when I opened the internet explorer, I
noticed this weird smiley face.
Send a smile, send a frown?
Did the malware inject that?
That’s funny.
Mhmh.. it appears to fake a Internet Explored
feedback form.
That’s quite interesting.
Let’s have a quick look at the privacy statement.
Mhmh… that looks like the normal microsoft
privacy statement?
Ehhmmm….
Oh… whaaat?
This is not the challenge?
This is actually in the Internet Explorer?
Let’s pretend this didn’t happen.
We move on.
Now in the meantime it was kinda hard to avoid
spoilers on reddit and twitter becasue people
talked about the challenges publicly.
SHAME YOU!
Just kidding, I think it’s great that you
help eachother.
And somewhere I read that you should use an
older firefox version, something like firefox
version 40, so that’s why I also downloaded
that one.
In that moment I was kinda annoyed that it
would only work with older firefox versions
and was wondering how you could even figure
that out.
Anyway… so I opened the old firefox version
and now I was wondering what to do.
There didn’t appear to be anything obviously
different, but it’s a malware right?
So it would do something a bit more sneaky.
Next I thought I could try to trace calls
to the browserassist.dll in case firefox does
anything with it.
You can add external dlls to the API monitor,
but it says that it doesn’t export any functions.
So the .dll appears to not work like a typical
.dll with exported functions… mhmh… next
I decided to attach the x32 debugger to firefox.
And I wasn’t really sure how to approach
it, but I thought a good start would be to
see if the dll is loaded somewhere in memory,
so I checked the Memory Map tab and also found
it in there.
Over her eyou also se a description of the
different segments, but for the debugger the
text segment, the code is obviously the most
interesting.
This lead me to this area here.
So that’s kinda like the entry point of
the dll, I guess.
And because I didn’t know what it does I
simply set a breakpiint at the start and end
of it.
But it didn’t trigger right away when using
the browser, only when I restarted it.
And while pressing the button to continue
execution after that breakpoint, I noticed
that this code was executed quite a lot on
load.
And I happen to notice some ascii strings
being referenced at some point earlier on
the stack.
This is the stack view here.
That’s just memory that’s still around.
For example I saw an injects and content string.
So while I kept doing this continue break
continue break thing, and looking at the stack,
eventually I noticed this json data…
Code, addCmd.
After.
askPassword.
Ont he path js/view.js?
On the host *flare-on.com?
What?
That looks like a filter.
It applies to all flare-on.com domains, includign
subdomains.
And js/views.js is obviously a javascript
file.
So I went into the browser, went to flare-on.com
where we had this simple command line interface,
opened js/views.js and noticed some very suspicious
javascript.
I mean that looks very obfuscated.
So I opened up the same javascript file on
my regular host chrome browser and compared
it.
And holy cat.
Look at the difference.
The malware in firefox appears to have injected
javascript into this script.
In theory this could be now injecting ads
or a script to steal your credit car dinfo
or so.
But this challenge apparently added an askPassword
function.
So clearly this comamndline interface was
extended with some functionality, but what
exactly?
I just randomly tried some stuff but it didn’t
work.
But askPassword is a javascript function,
so we can open the developer tools and just
directly call it.
Now the function itself was defined inside
of com.fireye.flareon.view.
So here is the function.
When we call it, we see that we are now asked
to enter a password.
And when we enter something, we get a su,
authentication failure… ahhh..
So su is the secret command.
Switch user.
So now we need to find the password.
By looking around the other javascript files
I noticed a controller.js which also had additional
code injected.
A cp function which seems to be called when
the password is Entered.
We can also set a breakpoint in cp, then trgger
su and enter a password.
And here we go.
So we see that p in this case is the password
we entered.
The first check is if the length is 10.
So we know the password must be 10 characters
long.
And then we check the first character.
The first character xored with 16 must result
in 123.
Because it’s xor, we can simply xor 123
with 16, and the result will be the first
valid character of our password.
And peaking ahead we can see that there are
similar rules like that for all other characters
of the password.
So I copied the javascript code into a new
html file, to more easily work on it and cleaned
up the if-case a bit.
But then we quickly reach some of these functions.
So the 5th character is equal to an integer
which is returned by this function.
If you carefully check how far this function
spans, you can just copy the whole thing,
let it evaluate, and this is the result.
The whole thing is just obfuscation for the
number 66.
And there are a few more like that, but same
principle.
Here are all the rules cleaned up.
Oh f.
That’s the problem with using this test
vm.
I think it expired and after a little bit
of time it will, you know, shut down.
This is annoying….
Ok… we are back… here are all the rules
cleaned up.
And then I started to write the reverse of
each of these conditions to create the whole
password.
We can simply use the String function fromCharCode,
which takes ascii integer numbers as parameters
and turns them into a regular ascii string.
So the first character is 16 XOR 123.
The second character is shifted to the left
by two and must be equal to 228.
This means if we shift 228 right by 2, we
get the next valid character.
Character three has a little twist, I will
take about it in second.
Next character was this obfuscatied function
and so it’s just 66.
Fifth character subtracted by 109 will result
in -22.
Which means if you subtract 22 from 109 you
will get the correct password character.
And it’s all kinda simple, but then in the
end we reach two more rules that are a bit
more complex.
Feel free to practice your school level math
to rearrange the equation so that our password
character is alone on one side.
But I’m not in school anymore.
And I’m really lazy.
So I just decided to bruteforce those two
values.
I mean each of them only has less than 128
options.
we are talking ascii characters here.
Oh and the 3ird character was a bit special
because the check is doing here a shift right.
Which means the lower bits of that number
will be lost.
So 14 is the result of a shift right, which
means if we shift the 14 back, we don’t
know what the lower bits were.
And up here we do the reverse.
We shift the bits up, but then remove them
with %255, so now only the lower bits remain.
So based on these two values you can easily
assemble all bits of the whole ascii number.
But again, I’m lazy.
I just brute force it too.
I clean up a bit more and here is the final
script.
If we find the correct password I alert it,
and otherwise just return false.
And then I have three nested for loops, each
one is responsible for one of the three unknown
characters.
And then I just open that file in the browser,
and basically instantly it finds the correct
password.
Awesome.
We can copy it now, execute su, enter it and
BOOM!.
We are root.
Awesome……….
Right?...
ehm… how do we get the flag now?
I was hoping this was it?
Goddamit.
After a short moment of rage I tried to approach
it again with logic and saw that when we enter
the password correct, it sets the root variable
to 1.
So I searched the sources for location where
this variable is used.
And I find one location here.
And scrolling up we can see it’s in the
function changeDirectory.
So that’s interesting.
The other aprt in the if case where it checks
for root is again obfuscated.
When we carefully copy that out again and
evaluate it, it evaluates to “key”...
sooooo… let’s try that.
Let’s try to cd to key.
Oh wow that works.
We are now in key.
And as we learned in the first video, we can
enter “ls”.
Urgh… what is that… so first time I saw
that I was a bit shocked, but I think I screwed
up some internal state.
Because I had the clever idea to refresh the
browser and do it again, on a clean session
where I didn’t debug, and now it works.
We get the flag.
Command Injection.
Let’s submit the flag and we are done…
awesome.
Oh and btw.
At the end I checked also the latest version
of firefox, and the malicious javascript was
also injected there.
So the spoiler or tip to use an old firefox
version wasn’t actually necessary.
Eeehhh…
LiveOverflow from the future again.
I was just editing this part, happy that I’m
almost done and then I realized.
Wait a moment.
Could it be that the js file was just locally
cached and the new firefox used the old firefox’s
cache?
So here is the old firefox, showing the injected
js.
Then I open the new firefox, open that js
file and we also see the injected JS.
But now I force a refresh with CTRL+SHIFT
R and boom.
File is actually loaded and the injection
is gone.
I first thought not to include that part in
the video, but I thought it’s quite interesting
that the new browser version 60 was able to
still use the cache written by the older version.
AND this also means another question stands.
How could you have figured out that you needed
an older version.
Were there any references in the dll to that?
Please let me know in the comments.
﻿It is time to get serious.
Reverse Engineering isn’t about toys and
games.
Sometimes it’s about malicious software.
I recommend you run this next challenge in
a VM or someone else’s computer you have
gained access to, especially if they are a
Firefox user.
Okay, this time I needed to get a VM.
And I saw that they also offer this Flare
VM which is like the Kali Linux of Windows
Malware Analysis.
And because I have no clue, I go with that.
For this I used a free Windows Test VM and
then executed the Flare installer to install
all tools.
The challenge description is hinting at malicious
software and itt may target Firefox?
So I also install firefox.
And then we can get started
Before we head into it, I have to say again.
I have very little experience with windows.
I would say about myself, that “I have no
clue what I am doing”.
Of course that is not completly true.
You can’t go a few years in this field without
picking up some knowledge over time.
Actually my very first introduction into reverse
engineering and exploitation WAS with windows,
namely a friend who introduced me to game
cracking with olly debugger and then the corelan
and lena tutorials.
And generally by having a more abstract computer
science knowledge and a basic understanding
of how computers work, I don’t feel completely
lost.
I have a rough idea what I want to do, and
I can somehow figure it out.
I just very much lack detailed technical knowledge
and experience.
for example I have very limited knowledge
about the windows APIs.
And I only know a FEW popular TOOLS.
And so I will be a lot more inefficient and
my approach is a lot less structured than
usual.
But let’s learn together and share your
tips in the comments.
So here we have the binary.
If you forgot to turn off windows defender,
then windows will actually detect it as malware
and then remove it.
So make sure to deal with that.
Because I’m unsure how to approach this
I decided to throw it into virus total.
Of course somebody else did that before.
But I’m not really interested in what tool
flagged this as malware, I was actually interested
in the file details tab.
That one provides a good first quick overview
over the binary, without executing it yourself.
So binstall is a browser assitant installer,
which would match with the firefox hint in
the description.
And it appears to be .net, so maybe another
c# program?
We can also go on the comments tab where other
plattform analysis tools posted their results.
For example we can checkout the joe sandbox
result.
That service appears to run the binary and
record what it does.
It also labeled it malicious.
And here are some great first hints.
It creates an undocumented autostart registry
key.
And it drops a PE file.
PE file is a regular windows binary file.
And you can see it drops a browserassist.dll.
But into the Internet Explorer folder?
Not firefox?
Mhmh..
There is a lot more nice information there,
but let’s move into our own VM.
So Flare installed a lot of tools in various
folders.
Disassemblers, debuggers, decompilers and
other utility tools.
One of the first tools that were ever showed
to me wa PEID, so I use that again.
It’s a tool to detect what kind of binary
it is.
And for binstall it detects that it’s a
C# .net binary.
Extra information will also show some guesses,
that the binary might be packed, so parts
of it might be encrypted.
Because it’s C# we can also trhow it into
IlSpy again, but you can quickly see it got
obfuscated.
So while all the names are gone, you can still
click on them and follow their references,
but also the functions them selve appear to
implement decryption or deobfuscation routines.
So not something we want to really analyse
if we don’t have to.
And we know it drops a .dll anyway, so it’s
probably also not important.
Nontheless I was playing around a bit with
it a bit.
And so I used Process Monitor to monitor all
events on the system as well as checking out
API monitor to monitor all calls.
So when running binstall we can then use the
filters or the search in Process monitor to
hopefully find interesting things it did.
Like accessing the registry or creating a
file.
And so after a bit of digging we can also
discover here the dropped dll location.
I also tried API monitor and selected a few
possibly itnersting APIs such as file system
or networking stuff.
And then I wanted to launch and attach to
the binstall .exe.
But it didn’t really work and crashed.
But trying out different attach methods I
found one that works.
And so API monitor recorded all the Windows
APIs that binstall was using and we selected
to trace.
And also here with a bit of digging we can
find the file it creates.
The browserassist.dll.
With peid we can also investigate the dropped
dll.
And this one looks like a regular binary.
So not C#.
And the extra information checks also think
that it doesn’t look encrypted.
Great.
We can also throw it into the ida free version
here and check a bit the strings.
Here are references to typical HTTP header
values.
Content-type, encoding, POST, GET and so forth.
So again it makes sense that it does something
with the browser.
Now I was confused why the dll was dropped
into the internet explorer folder, so I actually
thought maybe it does infect IE.
And when I opened the internet explorer, I
noticed this weird smiley face.
Send a smile, send a frown?
Did the malware inject that?
That’s funny.
Mhmh.. it appears to fake a Internet Explored
feedback form.
That’s quite interesting.
Let’s have a quick look at the privacy statement.
Mhmh… that looks like the normal microsoft
privacy statement?
Ehhmmm….
Oh… whaaat?
This is not the challenge?
This is actually in the Internet Explorer?
Let’s pretend this didn’t happen.
We move on.
Now in the meantime it was kinda hard to avoid
spoilers on reddit and twitter becasue people
talked about the challenges publicly.
SHAME YOU!
Just kidding, I think it’s great that you
help eachother.
And somewhere I read that you should use an
older firefox version, something like firefox
version 40, so that’s why I also downloaded
that one.
In that moment I was kinda annoyed that it
would only work with older firefox versions
and was wondering how you could even figure
that out.
Anyway… so I opened the old firefox version
and now I was wondering what to do.
There didn’t appear to be anything obviously
different, but it’s a malware right?
So it would do something a bit more sneaky.
Next I thought I could try to trace calls
to the browserassist.dll in case firefox does
anything with it.
You can add external dlls to the API monitor,
but it says that it doesn’t export any functions.
So the .dll appears to not work like a typical
.dll with exported functions… mhmh… next
I decided to attach the x32 debugger to firefox.
And I wasn’t really sure how to approach
it, but I thought a good start would be to
see if the dll is loaded somewhere in memory,
so I checked the Memory Map tab and also found
it in there.
Over her eyou also se a description of the
different segments, but for the debugger the
text segment, the code is obviously the most
interesting.
This lead me to this area here.
So that’s kinda like the entry point of
the dll, I guess.
And because I didn’t know what it does I
simply set a breakpiint at the start and end
of it.
But it didn’t trigger right away when using
the browser, only when I restarted it.
And while pressing the button to continue
execution after that breakpoint, I noticed
that this code was executed quite a lot on
load.
And I happen to notice some ascii strings
being referenced at some point earlier on
the stack.
This is the stack view here.
That’s just memory that’s still around.
For example I saw an injects and content string.
So while I kept doing this continue break
continue break thing, and looking at the stack,
eventually I noticed this json data…
Code, addCmd.
After.
askPassword.
Ont he path js/view.js?
On the host *flare-on.com?
What?
That looks like a filter.
It applies to all flare-on.com domains, includign
subdomains.
And js/views.js is obviously a javascript
file.
So I went into the browser, went to flare-on.com
where we had this simple command line interface,
opened js/views.js and noticed some very suspicious
javascript.
I mean that looks very obfuscated.
So I opened up the same javascript file on
my regular host chrome browser and compared
it.
And holy cat.
Look at the difference.
The malware in firefox appears to have injected
javascript into this script.
In theory this could be now injecting ads
or a script to steal your credit car dinfo
or so.
But this challenge apparently added an askPassword
function.
So clearly this comamndline interface was
extended with some functionality, but what
exactly?
I just randomly tried some stuff but it didn’t
work.
But askPassword is a javascript function,
so we can open the developer tools and just
directly call it.
Now the function itself was defined inside
of com.fireye.flareon.view.
So here is the function.
When we call it, we see that we are now asked
to enter a password.
And when we enter something, we get a su,
authentication failure… ahhh..
So su is the secret command.
Switch user.
So now we need to find the password.
By looking around the other javascript files
I noticed a controller.js which also had additional
code injected.
A cp function which seems to be called when
the password is Entered.
We can also set a breakpoint in cp, then trgger
su and enter a password.
And here we go.
So we see that p in this case is the password
we entered.
The first check is if the length is 10.
So we know the password must be 10 characters
long.
And then we check the first character.
The first character xored with 16 must result
in 123.
Because it’s xor, we can simply xor 123
with 16, and the result will be the first
valid character of our password.
And peaking ahead we can see that there are
similar rules like that for all other characters
of the password.
So I copied the javascript code into a new
html file, to more easily work on it and cleaned
up the if-case a bit.
But then we quickly reach some of these functions.
So the 5th character is equal to an integer
which is returned by this function.
If you carefully check how far this function
spans, you can just copy the whole thing,
let it evaluate, and this is the result.
The whole thing is just obfuscation for the
number 66.
And there are a few more like that, but same
principle.
Here are all the rules cleaned up.
Oh f.
That’s the problem with using this test
vm.
I think it expired and after a little bit
of time it will, you know, shut down.
This is annoying….
Ok… we are back… here are all the rules
cleaned up.
And then I started to write the reverse of
each of these conditions to create the whole
password.
We can simply use the String function fromCharCode,
which takes ascii integer numbers as parameters
and turns them into a regular ascii string.
So the first character is 16 XOR 123.
The second character is shifted to the left
by two and must be equal to 228.
This means if we shift 228 right by 2, we
get the next valid character.
Character three has a little twist, I will
take about it in second.
Next character was this obfuscatied function
and so it’s just 66.
Fifth character subtracted by 109 will result
in -22.
Which means if you subtract 22 from 109 you
will get the correct password character.
And it’s all kinda simple, but then in the
end we reach two more rules that are a bit
more complex.
Feel free to practice your school level math
to rearrange the equation so that our password
character is alone on one side.
But I’m not in school anymore.
And I’m really lazy.
So I just decided to bruteforce those two
values.
I mean each of them only has less than 128
options.
we are talking ascii characters here.
Oh and the 3ird character was a bit special
because the check is doing here a shift right.
Which means the lower bits of that number
will be lost.
So 14 is the result of a shift right, which
means if we shift the 14 back, we don’t
know what the lower bits were.
And up here we do the reverse.
We shift the bits up, but then remove them
with %255, so now only the lower bits remain.
So based on these two values you can easily
assemble all bits of the whole ascii number.
But again, I’m lazy.
I just brute force it too.
I clean up a bit more and here is the final
script.
If we find the correct password I alert it,
and otherwise just return false.
And then I have three nested for loops, each
one is responsible for one of the three unknown
characters.
And then I just open that file in the browser,
and basically instantly it finds the correct
password.
Awesome.
We can copy it now, execute su, enter it and
BOOM!.
We are root.
Awesome……….
Right?...
ehm… how do we get the flag now?
I was hoping this was it?
Goddamit.
After a short moment of rage I tried to approach
it again with logic and saw that when we enter
the password correct, it sets the root variable
to 1.
So I searched the sources for location where
this variable is used.
And I find one location here.
And scrolling up we can see it’s in the
function changeDirectory.
So that’s interesting.
The other aprt in the if case where it checks
for root is again obfuscated.
When we carefully copy that out again and
evaluate it, it evaluates to “key”...
sooooo… let’s try that.
Let’s try to cd to key.
Oh wow that works.
We are now in key.
And as we learned in the first video, we can
enter “ls”.
Urgh… what is that… so first time I saw
that I was a bit shocked, but I think I screwed
up some internal state.
Because I had the clever idea to refresh the
browser and do it again, on a clean session
where I didn’t debug, and now it works.
We get the flag.
Command Injection.
Let’s submit the flag and we are done…
awesome.
Oh and btw.
At the end I checked also the latest version
of firefox, and the malicious javascript was
also injected there.
So the spoiler or tip to use an old firefox
version wasn’t actually necessary.
Eeehhh…
LiveOverflow from the future again.
I was just editing this part, happy that I’m
almost done and then I realized.
Wait a moment.
Could it be that the js file was just locally
cached and the new firefox used the old firefox’s
cache?
So here is the old firefox, showing the injected
js.
Then I open the new firefox, open that js
file and we also see the injected JS.
But now I force a refresh with CTRL+SHIFT
R and boom.
File is actually loaded and the injection
is gone.
I first thought not to include that part in
the video, but I thought it’s quite interesting
that the new browser version 60 was able to
still use the cache written by the older version.
AND this also means another question stands.
How could you have figured out that you needed
an older version.
Were there any references in the dll to that?
Please let me know in the comments.
﻿It is time to get serious.
Reverse Engineering isn’t about toys and
games.
Sometimes it’s about malicious software.
I recommend you run this next challenge in
a VM or someone else’s computer you have
gained access to, especially if they are a
Firefox user.
Okay, this time I needed to get a VM.
And I saw that they also offer this Flare
VM which is like the Kali Linux of Windows
Malware Analysis.
And because I have no clue, I go with that.
For this I used a free Windows Test VM and
then executed the Flare installer to install
all tools.
The challenge description is hinting at malicious
software and itt may target Firefox?
So I also install firefox.
And then we can get started
Before we head into it, I have to say again.
I have very little experience with windows.
I would say about myself, that “I have no
clue what I am doing”.
Of course that is not completly true.
You can’t go a few years in this field without
picking up some knowledge over time.
Actually my very first introduction into reverse
engineering and exploitation WAS with windows,
namely a friend who introduced me to game
cracking with olly debugger and then the corelan
and lena tutorials.
And generally by having a more abstract computer
science knowledge and a basic understanding
of how computers work, I don’t feel completely
lost.
I have a rough idea what I want to do, and
I can somehow figure it out.
I just very much lack detailed technical knowledge
and experience.
for example I have very limited knowledge
about the windows APIs.
And I only know a FEW popular TOOLS.
And so I will be a lot more inefficient and
my approach is a lot less structured than
usual.
But let’s learn together and share your
tips in the comments.
So here we have the binary.
If you forgot to turn off windows defender,
then windows will actually detect it as malware
and then remove it.
So make sure to deal with that.
Because I’m unsure how to approach this
I decided to throw it into virus total.
Of course somebody else did that before.
But I’m not really interested in what tool
flagged this as malware, I was actually interested
in the file details tab.
That one provides a good first quick overview
over the binary, without executing it yourself.
So binstall is a browser assitant installer,
which would match with the firefox hint in
the description.
And it appears to be .net, so maybe another
c# program?
We can also go on the comments tab where other
plattform analysis tools posted their results.
For example we can checkout the joe sandbox
result.
That service appears to run the binary and
record what it does.
It also labeled it malicious.
And here are some great first hints.
It creates an undocumented autostart registry
key.
And it drops a PE file.
PE file is a regular windows binary file.
And you can see it drops a browserassist.dll.
But into the Internet Explorer folder?
Not firefox?
Mhmh..
There is a lot more nice information there,
but let’s move into our own VM.
So Flare installed a lot of tools in various
folders.
Disassemblers, debuggers, decompilers and
other utility tools.
One of the first tools that were ever showed
to me wa PEID, so I use that again.
It’s a tool to detect what kind of binary
it is.
And for binstall it detects that it’s a
C# .net binary.
Extra information will also show some guesses,
that the binary might be packed, so parts
of it might be encrypted.
Because it’s C# we can also trhow it into
IlSpy again, but you can quickly see it got
obfuscated.
So while all the names are gone, you can still
click on them and follow their references,
but also the functions them selve appear to
implement decryption or deobfuscation routines.
So not something we want to really analyse
if we don’t have to.
And we know it drops a .dll anyway, so it’s
probably also not important.
Nontheless I was playing around a bit with
it a bit.
And so I used Process Monitor to monitor all
events on the system as well as checking out
API monitor to monitor all calls.
So when running binstall we can then use the
filters or the search in Process monitor to
hopefully find interesting things it did.
Like accessing the registry or creating a
file.
And so after a bit of digging we can also
discover here the dropped dll location.
I also tried API monitor and selected a few
possibly itnersting APIs such as file system
or networking stuff.
And then I wanted to launch and attach to
the binstall .exe.
But it didn’t really work and crashed.
But trying out different attach methods I
found one that works.
And so API monitor recorded all the Windows
APIs that binstall was using and we selected
to trace.
And also here with a bit of digging we can
find the file it creates.
The browserassist.dll.
With peid we can also investigate the dropped
dll.
And this one looks like a regular binary.
So not C#.
And the extra information checks also think
that it doesn’t look encrypted.
Great.
We can also throw it into the ida free version
here and check a bit the strings.
Here are references to typical HTTP header
values.
Content-type, encoding, POST, GET and so forth.
So again it makes sense that it does something
with the browser.
Now I was confused why the dll was dropped
into the internet explorer folder, so I actually
thought maybe it does infect IE.
And when I opened the internet explorer, I
noticed this weird smiley face.
Send a smile, send a frown?
Did the malware inject that?
That’s funny.
Mhmh.. it appears to fake a Internet Explored
feedback form.
That’s quite interesting.
Let’s have a quick look at the privacy statement.
Mhmh… that looks like the normal microsoft
privacy statement?
Ehhmmm….
Oh… whaaat?
This is not the challenge?
This is actually in the Internet Explorer?
Let’s pretend this didn’t happen.
We move on.
Now in the meantime it was kinda hard to avoid
spoilers on reddit and twitter becasue people
talked about the challenges publicly.
SHAME YOU!
Just kidding, I think it’s great that you
help eachother.
And somewhere I read that you should use an
older firefox version, something like firefox
version 40, so that’s why I also downloaded
that one.
In that moment I was kinda annoyed that it
would only work with older firefox versions
and was wondering how you could even figure
that out.
Anyway… so I opened the old firefox version
and now I was wondering what to do.
There didn’t appear to be anything obviously
different, but it’s a malware right?
So it would do something a bit more sneaky.
Next I thought I could try to trace calls
to the browserassist.dll in case firefox does
anything with it.
You can add external dlls to the API monitor,
but it says that it doesn’t export any functions.
So the .dll appears to not work like a typical
.dll with exported functions… mhmh… next
I decided to attach the x32 debugger to firefox.
And I wasn’t really sure how to approach
it, but I thought a good start would be to
see if the dll is loaded somewhere in memory,
so I checked the Memory Map tab and also found
it in there.
Over her eyou also se a description of the
different segments, but for the debugger the
text segment, the code is obviously the most
interesting.
This lead me to this area here.
So that’s kinda like the entry point of
the dll, I guess.
And because I didn’t know what it does I
simply set a breakpiint at the start and end
of it.
But it didn’t trigger right away when using
the browser, only when I restarted it.
And while pressing the button to continue
execution after that breakpoint, I noticed
that this code was executed quite a lot on
load.
And I happen to notice some ascii strings
being referenced at some point earlier on
the stack.
This is the stack view here.
That’s just memory that’s still around.
For example I saw an injects and content string.
So while I kept doing this continue break
continue break thing, and looking at the stack,
eventually I noticed this json data…
Code, addCmd.
After.
askPassword.
Ont he path js/view.js?
On the host *flare-on.com?
What?
That looks like a filter.
It applies to all flare-on.com domains, includign
subdomains.
And js/views.js is obviously a javascript
file.
So I went into the browser, went to flare-on.com
where we had this simple command line interface,
opened js/views.js and noticed some very suspicious
javascript.
I mean that looks very obfuscated.
So I opened up the same javascript file on
my regular host chrome browser and compared
it.
And holy cat.
Look at the difference.
The malware in firefox appears to have injected
javascript into this script.
In theory this could be now injecting ads
or a script to steal your credit car dinfo
or so.
But this challenge apparently added an askPassword
function.
So clearly this comamndline interface was
extended with some functionality, but what
exactly?
I just randomly tried some stuff but it didn’t
work.
But askPassword is a javascript function,
so we can open the developer tools and just
directly call it.
Now the function itself was defined inside
of com.fireye.flareon.view.
So here is the function.
When we call it, we see that we are now asked
to enter a password.
And when we enter something, we get a su,
authentication failure… ahhh..
So su is the secret command.
Switch user.
So now we need to find the password.
By looking around the other javascript files
I noticed a controller.js which also had additional
code injected.
A cp function which seems to be called when
the password is Entered.
We can also set a breakpoint in cp, then trgger
su and enter a password.
And here we go.
So we see that p in this case is the password
we entered.
The first check is if the length is 10.
So we know the password must be 10 characters
long.
And then we check the first character.
The first character xored with 16 must result
in 123.
Because it’s xor, we can simply xor 123
with 16, and the result will be the first
valid character of our password.
And peaking ahead we can see that there are
similar rules like that for all other characters
of the password.
So I copied the javascript code into a new
html file, to more easily work on it and cleaned
up the if-case a bit.
But then we quickly reach some of these functions.
So the 5th character is equal to an integer
which is returned by this function.
If you carefully check how far this function
spans, you can just copy the whole thing,
let it evaluate, and this is the result.
The whole thing is just obfuscation for the
number 66.
And there are a few more like that, but same
principle.
Here are all the rules cleaned up.
Oh f.
That’s the problem with using this test
vm.
I think it expired and after a little bit
of time it will, you know, shut down.
This is annoying….
Ok… we are back… here are all the rules
cleaned up.
And then I started to write the reverse of
each of these conditions to create the whole
password.
We can simply use the String function fromCharCode,
which takes ascii integer numbers as parameters
and turns them into a regular ascii string.
So the first character is 16 XOR 123.
The second character is shifted to the left
by two and must be equal to 228.
This means if we shift 228 right by 2, we
get the next valid character.
Character three has a little twist, I will
take about it in second.
Next character was this obfuscatied function
and so it’s just 66.
Fifth character subtracted by 109 will result
in -22.
Which means if you subtract 22 from 109 you
will get the correct password character.
And it’s all kinda simple, but then in the
end we reach two more rules that are a bit
more complex.
Feel free to practice your school level math
to rearrange the equation so that our password
character is alone on one side.
But I’m not in school anymore.
And I’m really lazy.
So I just decided to bruteforce those two
values.
I mean each of them only has less than 128
options.
we are talking ascii characters here.
Oh and the 3ird character was a bit special
because the check is doing here a shift right.
Which means the lower bits of that number
will be lost.
So 14 is the result of a shift right, which
means if we shift the 14 back, we don’t
know what the lower bits were.
And up here we do the reverse.
We shift the bits up, but then remove them
with %255, so now only the lower bits remain.
So based on these two values you can easily
assemble all bits of the whole ascii number.
But again, I’m lazy.
I just brute force it too.
I clean up a bit more and here is the final
script.
If we find the correct password I alert it,
and otherwise just return false.
And then I have three nested for loops, each
one is responsible for one of the three unknown
characters.
And then I just open that file in the browser,
and basically instantly it finds the correct
password.
Awesome.
We can copy it now, execute su, enter it and
BOOM!.
We are root.
Awesome……….
Right?...
ehm… how do we get the flag now?
I was hoping this was it?
Goddamit.
After a short moment of rage I tried to approach
it again with logic and saw that when we enter
the password correct, it sets the root variable
to 1.
So I searched the sources for location where
this variable is used.
And I find one location here.
And scrolling up we can see it’s in the
function changeDirectory.
So that’s interesting.
The other aprt in the if case where it checks
for root is again obfuscated.
When we carefully copy that out again and
evaluate it, it evaluates to “key”...
sooooo… let’s try that.
Let’s try to cd to key.
Oh wow that works.
We are now in key.
And as we learned in the first video, we can
enter “ls”.
Urgh… what is that… so first time I saw
that I was a bit shocked, but I think I screwed
up some internal state.
Because I had the clever idea to refresh the
browser and do it again, on a clean session
where I didn’t debug, and now it works.
We get the flag.
Command Injection.
Let’s submit the flag and we are done…
awesome.
Oh and btw.
At the end I checked also the latest version
of firefox, and the malicious javascript was
also injected there.
So the spoiler or tip to use an old firefox
version wasn’t actually necessary.
Eeehhh…
LiveOverflow from the future again.
I was just editing this part, happy that I’m
almost done and then I realized.
Wait a moment.
Could it be that the js file was just locally
cached and the new firefox used the old firefox’s
cache?
So here is the old firefox, showing the injected
js.
Then I open the new firefox, open that js
file and we also see the injected JS.
But now I force a refresh with CTRL+SHIFT
R and boom.
File is actually loaded and the injection
is gone.
I first thought not to include that part in
the video, but I thought it’s quite interesting
that the new browser version 60 was able to
still use the cache written by the older version.
AND this also means another question stands.
How could you have figured out that you needed
an older version.
Were there any references in the dll to that?
Please let me know in the comments.
﻿It is time to get serious.
Reverse Engineering isn’t about toys and
games.
Sometimes it’s about malicious software.
I recommend you run this next challenge in
a VM or someone else’s computer you have
gained access to, especially if they are a
Firefox user.
Okay, this time I needed to get a VM.
And I saw that they also offer this Flare
VM which is like the Kali Linux of Windows
Malware Analysis.
And because I have no clue, I go with that.
For this I used a free Windows Test VM and
then executed the Flare installer to install
all tools.
The challenge description is hinting at malicious
software and itt may target Firefox?
So I also install firefox.
And then we can get started
Before we head into it, I have to say again.
I have very little experience with windows.
I would say about myself, that “I have no
clue what I am doing”.
Of course that is not completly true.
You can’t go a few years in this field without
picking up some knowledge over time.
Actually my very first introduction into reverse
engineering and exploitation WAS with windows,
namely a friend who introduced me to game
cracking with olly debugger and then the corelan
and lena tutorials.
And generally by having a more abstract computer
science knowledge and a basic understanding
of how computers work, I don’t feel completely
lost.
I have a rough idea what I want to do, and
I can somehow figure it out.
I just very much lack detailed technical knowledge
and experience.
for example I have very limited knowledge
about the windows APIs.
And I only know a FEW popular TOOLS.
And so I will be a lot more inefficient and
my approach is a lot less structured than
usual.
But let’s learn together and share your
tips in the comments.
So here we have the binary.
If you forgot to turn off windows defender,
then windows will actually detect it as malware
and then remove it.
So make sure to deal with that.
Because I’m unsure how to approach this
I decided to throw it into virus total.
Of course somebody else did that before.
But I’m not really interested in what tool
flagged this as malware, I was actually interested
in the file details tab.
That one provides a good first quick overview
over the binary, without executing it yourself.
So binstall is a browser assitant installer,
which would match with the firefox hint in
the description.
And it appears to be .net, so maybe another
c# program?
We can also go on the comments tab where other
plattform analysis tools posted their results.
For example we can checkout the joe sandbox
result.
That service appears to run the binary and
record what it does.
It also labeled it malicious.
And here are some great first hints.
It creates an undocumented autostart registry
key.
And it drops a PE file.
PE file is a regular windows binary file.
And you can see it drops a browserassist.dll.
But into the Internet Explorer folder?
Not firefox?
Mhmh..
There is a lot more nice information there,
but let’s move into our own VM.
So Flare installed a lot of tools in various
folders.
Disassemblers, debuggers, decompilers and
other utility tools.
One of the first tools that were ever showed
to me wa PEID, so I use that again.
It’s a tool to detect what kind of binary
it is.
And for binstall it detects that it’s a
C# .net binary.
Extra information will also show some guesses,
that the binary might be packed, so parts
of it might be encrypted.
Because it’s C# we can also trhow it into
IlSpy again, but you can quickly see it got
obfuscated.
So while all the names are gone, you can still
click on them and follow their references,
but also the functions them selve appear to
implement decryption or deobfuscation routines.
So not something we want to really analyse
if we don’t have to.
And we know it drops a .dll anyway, so it’s
probably also not important.
Nontheless I was playing around a bit with
it a bit.
And so I used Process Monitor to monitor all
events on the system as well as checking out
API monitor to monitor all calls.
So when running binstall we can then use the
filters or the search in Process monitor to
hopefully find interesting things it did.
Like accessing the registry or creating a
file.
And so after a bit of digging we can also
discover here the dropped dll location.
I also tried API monitor and selected a few
possibly itnersting APIs such as file system
or networking stuff.
And then I wanted to launch and attach to
the binstall .exe.
But it didn’t really work and crashed.
But trying out different attach methods I
found one that works.
And so API monitor recorded all the Windows
APIs that binstall was using and we selected
to trace.
And also here with a bit of digging we can
find the file it creates.
The browserassist.dll.
With peid we can also investigate the dropped
dll.
And this one looks like a regular binary.
So not C#.
And the extra information checks also think
that it doesn’t look encrypted.
Great.
We can also throw it into the ida free version
here and check a bit the strings.
Here are references to typical HTTP header
values.
Content-type, encoding, POST, GET and so forth.
So again it makes sense that it does something
with the browser.
Now I was confused why the dll was dropped
into the internet explorer folder, so I actually
thought maybe it does infect IE.
And when I opened the internet explorer, I
noticed this weird smiley face.
Send a smile, send a frown?
Did the malware inject that?
That’s funny.
Mhmh.. it appears to fake a Internet Explored
feedback form.
That’s quite interesting.
Let’s have a quick look at the privacy statement.
Mhmh… that looks like the normal microsoft
privacy statement?
Ehhmmm….
Oh… whaaat?
This is not the challenge?
This is actually in the Internet Explorer?
Let’s pretend this didn’t happen.
We move on.
Now in the meantime it was kinda hard to avoid
spoilers on reddit and twitter becasue people
talked about the challenges publicly.
SHAME YOU!
Just kidding, I think it’s great that you
help eachother.
And somewhere I read that you should use an
older firefox version, something like firefox
version 40, so that’s why I also downloaded
that one.
In that moment I was kinda annoyed that it
would only work with older firefox versions
and was wondering how you could even figure
that out.
Anyway… so I opened the old firefox version
and now I was wondering what to do.
There didn’t appear to be anything obviously
different, but it’s a malware right?
So it would do something a bit more sneaky.
Next I thought I could try to trace calls
to the browserassist.dll in case firefox does
anything with it.
You can add external dlls to the API monitor,
but it says that it doesn’t export any functions.
So the .dll appears to not work like a typical
.dll with exported functions… mhmh… next
I decided to attach the x32 debugger to firefox.
And I wasn’t really sure how to approach
it, but I thought a good start would be to
see if the dll is loaded somewhere in memory,
so I checked the Memory Map tab and also found
it in there.
Over her eyou also se a description of the
different segments, but for the debugger the
text segment, the code is obviously the most
interesting.
This lead me to this area here.
So that’s kinda like the entry point of
the dll, I guess.
And because I didn’t know what it does I
simply set a breakpiint at the start and end
of it.
But it didn’t trigger right away when using
the browser, only when I restarted it.
And while pressing the button to continue
execution after that breakpoint, I noticed
that this code was executed quite a lot on
load.
And I happen to notice some ascii strings
being referenced at some point earlier on
the stack.
This is the stack view here.
That’s just memory that’s still around.
For example I saw an injects and content string.
So while I kept doing this continue break
continue break thing, and looking at the stack,
eventually I noticed this json data…
Code, addCmd.
After.
askPassword.
Ont he path js/view.js?
On the host *flare-on.com?
What?
That looks like a filter.
It applies to all flare-on.com domains, includign
subdomains.
And js/views.js is obviously a javascript
file.
So I went into the browser, went to flare-on.com
where we had this simple command line interface,
opened js/views.js and noticed some very suspicious
javascript.
I mean that looks very obfuscated.
So I opened up the same javascript file on
my regular host chrome browser and compared
it.
And holy cat.
Look at the difference.
The malware in firefox appears to have injected
javascript into this script.
In theory this could be now injecting ads
or a script to steal your credit car dinfo
or so.
But this challenge apparently added an askPassword
function.
So clearly this comamndline interface was
extended with some functionality, but what
exactly?
I just randomly tried some stuff but it didn’t
work.
But askPassword is a javascript function,
so we can open the developer tools and just
directly call it.
Now the function itself was defined inside
of com.fireye.flareon.view.
So here is the function.
When we call it, we see that we are now asked
to enter a password.
And when we enter something, we get a su,
authentication failure… ahhh..
So su is the secret command.
Switch user.
So now we need to find the password.
By looking around the other javascript files
I noticed a controller.js which also had additional
code injected.
A cp function which seems to be called when
the password is Entered.
We can also set a breakpoint in cp, then trgger
su and enter a password.
And here we go.
So we see that p in this case is the password
we entered.
The first check is if the length is 10.
So we know the password must be 10 characters
long.
And then we check the first character.
The first character xored with 16 must result
in 123.
Because it’s xor, we can simply xor 123
with 16, and the result will be the first
valid character of our password.
And peaking ahead we can see that there are
similar rules like that for all other characters
of the password.
So I copied the javascript code into a new
html file, to more easily work on it and cleaned
up the if-case a bit.
But then we quickly reach some of these functions.
So the 5th character is equal to an integer
which is returned by this function.
If you carefully check how far this function
spans, you can just copy the whole thing,
let it evaluate, and this is the result.
The whole thing is just obfuscation for the
number 66.
And there are a few more like that, but same
principle.
Here are all the rules cleaned up.
Oh f.
That’s the problem with using this test
vm.
I think it expired and after a little bit
of time it will, you know, shut down.
This is annoying….
Ok… we are back… here are all the rules
cleaned up.
And then I started to write the reverse of
each of these conditions to create the whole
password.
We can simply use the String function fromCharCode,
which takes ascii integer numbers as parameters
and turns them into a regular ascii string.
So the first character is 16 XOR 123.
The second character is shifted to the left
by two and must be equal to 228.
This means if we shift 228 right by 2, we
get the next valid character.
Character three has a little twist, I will
take about it in second.
Next character was this obfuscatied function
and so it’s just 66.
Fifth character subtracted by 109 will result
in -22.
Which means if you subtract 22 from 109 you
will get the correct password character.
And it’s all kinda simple, but then in the
end we reach two more rules that are a bit
more complex.
Feel free to practice your school level math
to rearrange the equation so that our password
character is alone on one side.
But I’m not in school anymore.
And I’m really lazy.
So I just decided to bruteforce those two
values.
I mean each of them only has less than 128
options.
we are talking ascii characters here.
Oh and the 3ird character was a bit special
because the check is doing here a shift right.
Which means the lower bits of that number
will be lost.
So 14 is the result of a shift right, which
means if we shift the 14 back, we don’t
know what the lower bits were.
And up here we do the reverse.
We shift the bits up, but then remove them
with %255, so now only the lower bits remain.
So based on these two values you can easily
assemble all bits of the whole ascii number.
But again, I’m lazy.
I just brute force it too.
I clean up a bit more and here is the final
script.
If we find the correct password I alert it,
and otherwise just return false.
And then I have three nested for loops, each
one is responsible for one of the three unknown
characters.
And then I just open that file in the browser,
and basically instantly it finds the correct
password.
Awesome.
We can copy it now, execute su, enter it and
BOOM!.
We are root.
Awesome……….
Right?...
ehm… how do we get the flag now?
I was hoping this was it?
Goddamit.
After a short moment of rage I tried to approach
it again with logic and saw that when we enter
the password correct, it sets the root variable
to 1.
So I searched the sources for location where
this variable is used.
And I find one location here.
And scrolling up we can see it’s in the
function changeDirectory.
So that’s interesting.
The other aprt in the if case where it checks
for root is again obfuscated.
When we carefully copy that out again and
evaluate it, it evaluates to “key”...
sooooo… let’s try that.
Let’s try to cd to key.
Oh wow that works.
We are now in key.
And as we learned in the first video, we can
enter “ls”.
Urgh… what is that… so first time I saw
that I was a bit shocked, but I think I screwed
up some internal state.
Because I had the clever idea to refresh the
browser and do it again, on a clean session
where I didn’t debug, and now it works.
We get the flag.
Command Injection.
Let’s submit the flag and we are done…
awesome.
Oh and btw.
At the end I checked also the latest version
of firefox, and the malicious javascript was
also injected there.
So the spoiler or tip to use an old firefox
version wasn’t actually necessary.
Eeehhh…
LiveOverflow from the future again.
I was just editing this part, happy that I’m
almost done and then I realized.
Wait a moment.
Could it be that the js file was just locally
cached and the new firefox used the old firefox’s
cache?
So here is the old firefox, showing the injected
js.
Then I open the new firefox, open that js
file and we also see the injected JS.
But now I force a refresh with CTRL+SHIFT
R and boom.
File is actually loaded and the injection
is gone.
I first thought not to include that part in
the video, but I thought it’s quite interesting
that the new browser version 60 was able to
still use the cache written by the older version.
AND this also means another question stands.
How could you have figured out that you needed
an older version.
Were there any references in the dll to that?
Please let me know in the comments.
﻿It is time to get serious.
Reverse Engineering isn’t about toys and
games.
Sometimes it’s about malicious software.
I recommend you run this next challenge in
a VM or someone else’s computer you have
gained access to, especially if they are a
Firefox user.
Okay, this time I needed to get a VM.
And I saw that they also offer this Flare
VM which is like the Kali Linux of Windows
Malware Analysis.
And because I have no clue, I go with that.
For this I used a free Windows Test VM and
then executed the Flare installer to install
all tools.
The challenge description is hinting at malicious
software and itt may target Firefox?
So I also install firefox.
And then we can get started
Before we head into it, I have to say again.
I have very little experience with windows.
I would say about myself, that “I have no
clue what I am doing”.
Of course that is not completly true.
You can’t go a few years in this field without
picking up some knowledge over time.
Actually my very first introduction into reverse
engineering and exploitation WAS with windows,
namely a friend who introduced me to game
cracking with olly debugger and then the corelan
and lena tutorials.
And generally by having a more abstract computer
science knowledge and a basic understanding
of how computers work, I don’t feel completely
lost.
I have a rough idea what I want to do, and
I can somehow figure it out.
I just very much lack detailed technical knowledge
and experience.
for example I have very limited knowledge
about the windows APIs.
And I only know a FEW popular TOOLS.
And so I will be a lot more inefficient and
my approach is a lot less structured than
usual.
But let’s learn together and share your
tips in the comments.
So here we have the binary.
If you forgot to turn off windows defender,
then windows will actually detect it as malware
and then remove it.
So make sure to deal with that.
Because I’m unsure how to approach this
I decided to throw it into virus total.
Of course somebody else did that before.
But I’m not really interested in what tool
flagged this as malware, I was actually interested
in the file details tab.
That one provides a good first quick overview
over the binary, without executing it yourself.
So binstall is a browser assitant installer,
which would match with the firefox hint in
the description.
And it appears to be .net, so maybe another
c# program?
We can also go on the comments tab where other
plattform analysis tools posted their results.
For example we can checkout the joe sandbox
result.
That service appears to run the binary and
record what it does.
It also labeled it malicious.
And here are some great first hints.
It creates an undocumented autostart registry
key.
And it drops a PE file.
PE file is a regular windows binary file.
And you can see it drops a browserassist.dll.
But into the Internet Explorer folder?
Not firefox?
Mhmh..
There is a lot more nice information there,
but let’s move into our own VM.
So Flare installed a lot of tools in various
folders.
Disassemblers, debuggers, decompilers and
other utility tools.
One of the first tools that were ever showed
to me wa PEID, so I use that again.
It’s a tool to detect what kind of binary
it is.
And for binstall it detects that it’s a
C# .net binary.
Extra information will also show some guesses,
that the binary might be packed, so parts
of it might be encrypted.
Because it’s C# we can also trhow it into
IlSpy again, but you can quickly see it got
obfuscated.
So while all the names are gone, you can still
click on them and follow their references,
but also the functions them selve appear to
implement decryption or deobfuscation routines.
So not something we want to really analyse
if we don’t have to.
And we know it drops a .dll anyway, so it’s
probably also not important.
Nontheless I was playing around a bit with
it a bit.
And so I used Process Monitor to monitor all
events on the system as well as checking out
API monitor to monitor all calls.
So when running binstall we can then use the
filters or the search in Process monitor to
hopefully find interesting things it did.
Like accessing the registry or creating a
file.
And so after a bit of digging we can also
discover here the dropped dll location.
I also tried API monitor and selected a few
possibly itnersting APIs such as file system
or networking stuff.
And then I wanted to launch and attach to
the binstall .exe.
But it didn’t really work and crashed.
But trying out different attach methods I
found one that works.
And so API monitor recorded all the Windows
APIs that binstall was using and we selected
to trace.
And also here with a bit of digging we can
find the file it creates.
The browserassist.dll.
With peid we can also investigate the dropped
dll.
And this one looks like a regular binary.
So not C#.
And the extra information checks also think
that it doesn’t look encrypted.
Great.
We can also throw it into the ida free version
here and check a bit the strings.
Here are references to typical HTTP header
values.
Content-type, encoding, POST, GET and so forth.
So again it makes sense that it does something
with the browser.
Now I was confused why the dll was dropped
into the internet explorer folder, so I actually
thought maybe it does infect IE.
And when I opened the internet explorer, I
noticed this weird smiley face.
Send a smile, send a frown?
Did the malware inject that?
That’s funny.
Mhmh.. it appears to fake a Internet Explored
feedback form.
That’s quite interesting.
Let’s have a quick look at the privacy statement.
Mhmh… that looks like the normal microsoft
privacy statement?
Ehhmmm….
Oh… whaaat?
This is not the challenge?
This is actually in the Internet Explorer?
Let’s pretend this didn’t happen.
We move on.
Now in the meantime it was kinda hard to avoid
spoilers on reddit and twitter becasue people
talked about the challenges publicly.
SHAME YOU!
Just kidding, I think it’s great that you
help eachother.
And somewhere I read that you should use an
older firefox version, something like firefox
version 40, so that’s why I also downloaded
that one.
In that moment I was kinda annoyed that it
would only work with older firefox versions
and was wondering how you could even figure
that out.
Anyway… so I opened the old firefox version
and now I was wondering what to do.
There didn’t appear to be anything obviously
different, but it’s a malware right?
So it would do something a bit more sneaky.
Next I thought I could try to trace calls
to the browserassist.dll in case firefox does
anything with it.
You can add external dlls to the API monitor,
but it says that it doesn’t export any functions.
So the .dll appears to not work like a typical
.dll with exported functions… mhmh… next
I decided to attach the x32 debugger to firefox.
And I wasn’t really sure how to approach
it, but I thought a good start would be to
see if the dll is loaded somewhere in memory,
so I checked the Memory Map tab and also found
it in there.
Over her eyou also se a description of the
different segments, but for the debugger the
text segment, the code is obviously the most
interesting.
This lead me to this area here.
So that’s kinda like the entry point of
the dll, I guess.
And because I didn’t know what it does I
simply set a breakpiint at the start and end
of it.
But it didn’t trigger right away when using
the browser, only when I restarted it.
And while pressing the button to continue
execution after that breakpoint, I noticed
that this code was executed quite a lot on
load.
And I happen to notice some ascii strings
being referenced at some point earlier on
the stack.
This is the stack view here.
That’s just memory that’s still around.
For example I saw an injects and content string.
So while I kept doing this continue break
continue break thing, and looking at the stack,
eventually I noticed this json data…
Code, addCmd.
After.
askPassword.
Ont he path js/view.js?
On the host *flare-on.com?
What?
That looks like a filter.
It applies to all flare-on.com domains, includign
subdomains.
And js/views.js is obviously a javascript
file.
So I went into the browser, went to flare-on.com
where we had this simple command line interface,
opened js/views.js and noticed some very suspicious
javascript.
I mean that looks very obfuscated.
So I opened up the same javascript file on
my regular host chrome browser and compared
it.
And holy cat.
Look at the difference.
The malware in firefox appears to have injected
javascript into this script.
In theory this could be now injecting ads
or a script to steal your credit car dinfo
or so.
But this challenge apparently added an askPassword
function.
So clearly this comamndline interface was
extended with some functionality, but what
exactly?
I just randomly tried some stuff but it didn’t
work.
But askPassword is a javascript function,
so we can open the developer tools and just
directly call it.
Now the function itself was defined inside
of com.fireye.flareon.view.
So here is the function.
When we call it, we see that we are now asked
to enter a password.
And when we enter something, we get a su,
authentication failure… ahhh..
So su is the secret command.
Switch user.
So now we need to find the password.
By looking around the other javascript files
I noticed a controller.js which also had additional
code injected.
A cp function which seems to be called when
the password is Entered.
We can also set a breakpoint in cp, then trgger
su and enter a password.
And here we go.
So we see that p in this case is the password
we entered.
The first check is if the length is 10.
So we know the password must be 10 characters
long.
And then we check the first character.
The first character xored with 16 must result
in 123.
Because it’s xor, we can simply xor 123
with 16, and the result will be the first
valid character of our password.
And peaking ahead we can see that there are
similar rules like that for all other characters
of the password.
So I copied the javascript code into a new
html file, to more easily work on it and cleaned
up the if-case a bit.
But then we quickly reach some of these functions.
So the 5th character is equal to an integer
which is returned by this function.
If you carefully check how far this function
spans, you can just copy the whole thing,
let it evaluate, and this is the result.
The whole thing is just obfuscation for the
number 66.
And there are a few more like that, but same
principle.
Here are all the rules cleaned up.
Oh f.
That’s the problem with using this test
vm.
I think it expired and after a little bit
of time it will, you know, shut down.
This is annoying….
Ok… we are back… here are all the rules
cleaned up.
And then I started to write the reverse of
each of these conditions to create the whole
password.
We can simply use the String function fromCharCode,
which takes ascii integer numbers as parameters
and turns them into a regular ascii string.
So the first character is 16 XOR 123.
The second character is shifted to the left
by two and must be equal to 228.
This means if we shift 228 right by 2, we
get the next valid character.
Character three has a little twist, I will
take about it in second.
Next character was this obfuscatied function
and so it’s just 66.
Fifth character subtracted by 109 will result
in -22.
Which means if you subtract 22 from 109 you
will get the correct password character.
And it’s all kinda simple, but then in the
end we reach two more rules that are a bit
more complex.
Feel free to practice your school level math
to rearrange the equation so that our password
character is alone on one side.
But I’m not in school anymore.
And I’m really lazy.
So I just decided to bruteforce those two
values.
I mean each of them only has less than 128
options.
we are talking ascii characters here.
Oh and the 3ird character was a bit special
because the check is doing here a shift right.
Which means the lower bits of that number
will be lost.
So 14 is the result of a shift right, which
means if we shift the 14 back, we don’t
know what the lower bits were.
And up here we do the reverse.
We shift the bits up, but then remove them
with %255, so now only the lower bits remain.
So based on these two values you can easily
assemble all bits of the whole ascii number.
But again, I’m lazy.
I just brute force it too.
I clean up a bit more and here is the final
script.
If we find the correct password I alert it,
and otherwise just return false.
And then I have three nested for loops, each
one is responsible for one of the three unknown
characters.
And then I just open that file in the browser,
and basically instantly it finds the correct
password.
Awesome.
We can copy it now, execute su, enter it and
BOOM!.
We are root.
Awesome……….
Right?...
ehm… how do we get the flag now?
I was hoping this was it?
Goddamit.
After a short moment of rage I tried to approach
it again with logic and saw that when we enter
the password correct, it sets the root variable
to 1.
So I searched the sources for location where
this variable is used.
And I find one location here.
And scrolling up we can see it’s in the
function changeDirectory.
So that’s interesting.
The other aprt in the if case where it checks
for root is again obfuscated.
When we carefully copy that out again and
evaluate it, it evaluates to “key”...
sooooo… let’s try that.
Let’s try to cd to key.
Oh wow that works.
We are now in key.
And as we learned in the first video, we can
enter “ls”.
Urgh… what is that… so first time I saw
that I was a bit shocked, but I think I screwed
up some internal state.
Because I had the clever idea to refresh the
browser and do it again, on a clean session
where I didn’t debug, and now it works.
We get the flag.
Command Injection.
Let’s submit the flag and we are done…
awesome.
Oh and btw.
At the end I checked also the latest version
of firefox, and the malicious javascript was
also injected there.
So the spoiler or tip to use an old firefox
version wasn’t actually necessary.
Eeehhh…
LiveOverflow from the future again.
I was just editing this part, happy that I’m
almost done and then I realized.
Wait a moment.
Could it be that the js file was just locally
cached and the new firefox used the old firefox’s
cache?
So here is the old firefox, showing the injected
js.
Then I open the new firefox, open that js
file and we also see the injected JS.
But now I force a refresh with CTRL+SHIFT
R and boom.
File is actually loaded and the injection
is gone.
I first thought not to include that part in
the video, but I thought it’s quite interesting
that the new browser version 60 was able to
still use the cache written by the older version.
AND this also means another question stands.
How could you have figured out that you needed
an older version.
Were there any references in the dll to that?
Please let me know in the comments.
